{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1375af72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_workers': 5, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 15000, 'model': {'conv_filters': [[16, [8, 8], 4], [32, [4, 4], 2], [256, [11, 11], 1]], 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_preprocessor': None, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}}, 'optimizer': {}, 'gamma': 0.999, 'horizon': 3000, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': None, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_config': {}, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_gae': True, 'lambda': 0.97, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.02, 'simple_optimizer': False}\n",
      "2022-10-08 18:19:30,383\tWARNING services.py:597 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2022-10-08 18:19:30,384\tINFO resource_spec.py:216 -- Starting Ray with 3.47 GiB memory available for workers and up to 14.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2022-10-08 18:19:30,774\tINFO ray_trial_executor.py:121 -- Trial PPO_WaveAttenuationPOEnv-v0_a95f16f0: Setting up new remote runner.\n",
      "== Status ==\n",
      "Memory usage on this node: 5.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+-------+\n",
      "| Trial name                           | status   | loc   |\n",
      "|--------------------------------------+----------+-------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  |       |\n",
      "+--------------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:19:32,013\tINFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:19:32,242\tINFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:19:35,210\tWARNING util.py:45 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-20-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -4308.520413878485\n",
      "  episode_reward_mean: -4791.254351807184\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 5\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1629.473\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.3442256450653076\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006892228964716196\n",
      "        policy_loss: -0.003897586837410927\n",
      "        total_loss: 1316.4261474609375\n",
      "        vf_explained_var: -0.0077028037048876286\n",
      "        vf_loss: 1316.4288330078125\n",
      "    load_time_ms: 32.076\n",
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 14976\n",
      "    sample_time_ms: 40648.224\n",
      "    update_time_ms: 383.297\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.814516129032256\n",
      "    ram_util_percent: 23.47258064516129\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 8.475484422189876\n",
      "    mean_inference_ms: 0.42545160664117\n",
      "    mean_processing_ms: 4.003199590360749\n",
      "  time_since_restore: 42.71963930130005\n",
      "  time_this_iter_s: 42.71963930130005\n",
      "  time_total_s: 42.71963930130005\n",
      "  timestamp: 1665271217\n",
      "  timesteps_since_restore: 15000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 1\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      1 |          42.7196 |       15000 | -4791.25 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:20:17,990\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 479.0x the scale of `vf_clip_param`. This means that it will take more than 479.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-20-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -4208.272494727222\n",
      "  episode_reward_mean: -4628.656669907699\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 10\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1559.956\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2421236038208008\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01674901507794857\n",
      "        policy_loss: -0.005388439167290926\n",
      "        total_loss: 1077.4542236328125\n",
      "        vf_explained_var: 0.005058943759649992\n",
      "        vf_loss: 1077.4578857421875\n",
      "    load_time_ms: 17.307\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 29952\n",
      "    sample_time_ms: 33759.095\n",
      "    update_time_ms: 193.568\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.4\n",
      "    ram_util_percent: 23.872500000000002\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 7.451943298391852\n",
      "    mean_inference_ms: 0.41952452857907263\n",
      "    mean_processing_ms: 4.008166476618732\n",
      "  time_since_restore: 71.09197354316711\n",
      "  time_this_iter_s: 28.372334241867065\n",
      "  time_total_s: 71.09197354316711\n",
      "  timestamp: 1665271246\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 2\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      2 |           71.092 |       30000 | -4628.66 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:20:46,376\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 463.0x the scale of `vf_clip_param`. This means that it will take more than 463.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-21-15\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -2595.4884319116973\n",
      "  episode_reward_mean: -4190.385255333463\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 15\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1536.269\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.052616000175476\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023625820875167847\n",
      "        policy_loss: -0.008808670565485954\n",
      "        total_loss: 540.90966796875\n",
      "        vf_explained_var: -0.002125317696481943\n",
      "        vf_loss: 540.9161376953125\n",
      "    load_time_ms: 12.626\n",
      "    num_steps_sampled: 45000\n",
      "    num_steps_trained: 44928\n",
      "    sample_time_ms: 31868.67\n",
      "    update_time_ms: 130.126\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.11666666666667\n",
      "    ram_util_percent: 23.90714285714286\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 6.902586012546457\n",
      "    mean_inference_ms: 0.41658212308824305\n",
      "    mean_processing_ms: 4.031025404747281\n",
      "  time_since_restore: 100.68068790435791\n",
      "  time_this_iter_s: 29.588714361190796\n",
      "  time_total_s: 100.68068790435791\n",
      "  timestamp: 1665271275\n",
      "  timesteps_since_restore: 45000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 45000\n",
      "  training_iteration: 3\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      3 |          100.681 |       45000 | -4190.39 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:21:15,978\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 419.0x the scale of `vf_clip_param`. This means that it will take more than 419.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-21-44\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1895.624576232851\n",
      "  episode_reward_mean: -3816.7076858807945\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 20\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1522.093\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8770983815193176\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030317027121782303\n",
      "        policy_loss: -0.011822238564491272\n",
      "        total_loss: 338.8348388671875\n",
      "        vf_explained_var: -0.0029835139866918325\n",
      "        vf_loss: 338.8436584472656\n",
      "    load_time_ms: 10.134\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 59904\n",
      "    sample_time_ms: 30779.57\n",
      "    update_time_ms: 98.31\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.0047619047619\n",
      "    ram_util_percent: 23.802380952380947\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 6.550412844423571\n",
      "    mean_inference_ms: 0.4147886900298743\n",
      "    mean_processing_ms: 4.038714732234208\n",
      "  time_since_restore: 129.6833565235138\n",
      "  time_this_iter_s: 29.002668619155884\n",
      "  time_total_s: 129.6833565235138\n",
      "  timestamp: 1665271304\n",
      "  timesteps_since_restore: 60000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 4\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      4 |          129.683 |       60000 | -3816.71 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:21:44,992\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 382.0x the scale of `vf_clip_param`. This means that it will take more than 382.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-22-14\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1253.4037722725268\n",
      "  episode_reward_mean: -3419.4400972806243\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 25\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1512.889\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6654890179634094\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029795963317155838\n",
      "        policy_loss: -0.010364901274442673\n",
      "        total_loss: 208.9837188720703\n",
      "        vf_explained_var: -0.0015159437898546457\n",
      "        vf_loss: 208.99111938476562\n",
      "    load_time_ms: 8.645\n",
      "    num_steps_sampled: 75000\n",
      "    num_steps_trained: 74880\n",
      "    sample_time_ms: 30201.061\n",
      "    update_time_ms: 79.208\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.98809523809524\n",
      "    ram_util_percent: 23.778571428571425\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 6.304432452077715\n",
      "    mean_inference_ms: 0.41366008320987213\n",
      "    mean_processing_ms: 4.044481479776111\n",
      "  time_since_restore: 159.0576252937317\n",
      "  time_this_iter_s: 29.374268770217896\n",
      "  time_total_s: 159.0576252937317\n",
      "  timestamp: 1665271334\n",
      "  timesteps_since_restore: 75000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 75000\n",
      "  training_iteration: 5\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      5 |          159.058 |       75000 | -3419.44 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:22:14,381\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 342.0x the scale of `vf_clip_param`. This means that it will take more than 342.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-22-43\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -75.4403302279076\n",
      "  episode_reward_mean: -3102.2214896321993\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 30\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1507.495\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5612450838088989\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025660399347543716\n",
      "        policy_loss: -0.0067628794349730015\n",
      "        total_loss: 187.9198455810547\n",
      "        vf_explained_var: -0.0007813924457877874\n",
      "        vf_loss: 187.9240264892578\n",
      "    load_time_ms: 7.714\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 89856\n",
      "    sample_time_ms: 29775.809\n",
      "    update_time_ms: 66.406\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.08048780487804\n",
      "    ram_util_percent: 23.76829268292683\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 6.119682145826426\n",
      "    mean_inference_ms: 0.41279126095939833\n",
      "    mean_processing_ms: 4.049050981886834\n",
      "  time_since_restore: 188.19899106025696\n",
      "  time_this_iter_s: 29.14136576652527\n",
      "  time_total_s: 188.19899106025696\n",
      "  timestamp: 1665271363\n",
      "  timesteps_since_restore: 90000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 6\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      6 |          188.199 |       90000 | -3102.22 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:22:43,534\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 310.0x the scale of `vf_clip_param`. This means that it will take more than 310.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-23-12\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -75.4403302279076\n",
      "  episode_reward_mean: -2847.6012428021577\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 35\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1501.764\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5034546852111816\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013377774506807327\n",
      "        policy_loss: -0.006963650695979595\n",
      "        total_loss: 222.30563354492188\n",
      "        vf_explained_var: -0.0002723830402828753\n",
      "        vf_loss: 222.31124877929688\n",
      "    load_time_ms: 7.11\n",
      "    num_steps_sampled: 105000\n",
      "    num_steps_trained: 104832\n",
      "    sample_time_ms: 29431.305\n",
      "    update_time_ms: 57.382\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.614634146341466\n",
      "    ram_util_percent: 23.9\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.974767154397457\n",
      "    mean_inference_ms: 0.4123751311212596\n",
      "    mean_processing_ms: 4.051315016808043\n",
      "  time_since_restore: 217.0427794456482\n",
      "  time_this_iter_s: 28.843788385391235\n",
      "  time_total_s: 217.0427794456482\n",
      "  timestamp: 1665271392\n",
      "  timesteps_since_restore: 105000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 105000\n",
      "  training_iteration: 7\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:23:12,391\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 285.0x the scale of `vf_clip_param`. This means that it will take more than 285.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      7 |          217.043 |      105000 |  -2847.6 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-23-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 262.1442709570502\n",
      "  episode_reward_mean: -2620.7263871796736\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 40\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1499.066\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39999547600746155\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011474714614450932\n",
      "        policy_loss: -0.003726875176653266\n",
      "        total_loss: 179.338623046875\n",
      "        vf_explained_var: -0.00018425985763315111\n",
      "        vf_loss: 179.34121704101562\n",
      "    load_time_ms: 6.473\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 119808\n",
      "    sample_time_ms: 29165.867\n",
      "    update_time_ms: 50.603\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.7\n",
      "    ram_util_percent: 23.797560975609755\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.8573476549413765\n",
      "    mean_inference_ms: 0.41226974864685834\n",
      "    mean_processing_ms: 4.0518225722087395\n",
      "  time_since_restore: 245.84161353111267\n",
      "  time_this_iter_s: 28.798834085464478\n",
      "  time_total_s: 245.84161353111267\n",
      "  timestamp: 1665271421\n",
      "  timesteps_since_restore: 120000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 8\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      8 |          245.842 |      120000 | -2620.73 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:23:41,203\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 262.0x the scale of `vf_clip_param`. This means that it will take more than 262.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-24-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1114.7475962357853\n",
      "  episode_reward_mean: -2447.6646587658147\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 45\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1496.221\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3545260727405548\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009492599405348301\n",
      "        policy_loss: -0.0029712854884564877\n",
      "        total_loss: 328.2466735839844\n",
      "        vf_explained_var: -6.93635010975413e-05\n",
      "        vf_loss: 328.2486877441406\n",
      "    load_time_ms: 6.081\n",
      "    num_steps_sampled: 135000\n",
      "    num_steps_trained: 134784\n",
      "    sample_time_ms: 28986.333\n",
      "    update_time_ms: 45.336\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00714285714286\n",
      "    ram_util_percent: 23.871428571428574\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.759576711646084\n",
      "    mean_inference_ms: 0.41211092998903615\n",
      "    mean_processing_ms: 4.052900437825875\n",
      "  time_since_restore: 274.87696743011475\n",
      "  time_this_iter_s: 29.035353899002075\n",
      "  time_total_s: 274.87696743011475\n",
      "  timestamp: 1665271450\n",
      "  timesteps_since_restore: 135000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 135000\n",
      "  training_iteration: 9\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:24:10,253\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 245.0x the scale of `vf_clip_param`. This means that it will take more than 245.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      9 |          274.877 |      135000 | -2447.66 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-24-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1114.7475962357853\n",
      "  episode_reward_mean: -2258.088965377811\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 50\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1495.783\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.15614110231399536\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026136763393878937\n",
      "        policy_loss: -0.005501579027622938\n",
      "        total_loss: 229.5237274169922\n",
      "        vf_explained_var: -5.039903771830723e-05\n",
      "        vf_loss: 229.52793884277344\n",
      "    load_time_ms: 5.726\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 149760\n",
      "    sample_time_ms: 28857.829\n",
      "    update_time_ms: 41.052\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.516666666666666\n",
      "    ram_util_percent: 23.83095238095238\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.678011063961877\n",
      "    mean_inference_ms: 0.41196430333261796\n",
      "    mean_processing_ms: 4.053785216845164\n",
      "  time_since_restore: 304.08096265792847\n",
      "  time_this_iter_s: 29.20399522781372\n",
      "  time_total_s: 304.08096265792847\n",
      "  timestamp: 1665271479\n",
      "  timesteps_since_restore: 150000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 10\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     10 |          304.081 |      150000 | -2258.09 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:24:39,470\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 226.0x the scale of `vf_clip_param`. This means that it will take more than 226.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -2022.7947092007557\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 55\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.117\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.10236494988203049\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01100603211671114\n",
      "        policy_loss: -0.0006883026799187064\n",
      "        total_loss: 266.5414733886719\n",
      "        vf_explained_var: -1.7171232684631832e-05\n",
      "        vf_loss: 266.5416259765625\n",
      "    load_time_ms: 2.753\n",
      "    num_steps_sampled: 165000\n",
      "    num_steps_trained: 164736\n",
      "    sample_time_ms: 27628.649\n",
      "    update_time_ms: 2.945\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.214285714285715\n",
      "    ram_util_percent: 23.8547619047619\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.608717909668454\n",
      "    mean_inference_ms: 0.4118085447684999\n",
      "    mean_processing_ms: 4.055278919438012\n",
      "  time_since_restore: 333.9306254386902\n",
      "  time_this_iter_s: 29.84966278076172\n",
      "  time_total_s: 333.9306254386902\n",
      "  timestamp: 1665271509\n",
      "  timesteps_since_restore: 165000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 165000\n",
      "  training_iteration: 11\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     11 |          333.931 |      165000 | -2022.79 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:25:09,333\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 202.0x the scale of `vf_clip_param`. This means that it will take more than 202.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-25-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -1917.6939519085572\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 60\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.979\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.13771802186965942\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026905473321676254\n",
      "        policy_loss: -0.00506002688780427\n",
      "        total_loss: 228.8725128173828\n",
      "        vf_explained_var: -1.2128781236242503e-05\n",
      "        vf_loss: 228.87625122070312\n",
      "    load_time_ms: 2.825\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 179712\n",
      "    sample_time_ms: 27809.099\n",
      "    update_time_ms: 2.796\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.851162790697686\n",
      "    ram_util_percent: 23.765116279069765\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.548404777544189\n",
      "    mean_inference_ms: 0.41167761918346435\n",
      "    mean_processing_ms: 4.058719231113796\n",
      "  time_since_restore: 364.0953333377838\n",
      "  time_this_iter_s: 30.164707899093628\n",
      "  time_total_s: 364.0953333377838\n",
      "  timestamp: 1665271539\n",
      "  timesteps_since_restore: 180000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 12\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     12 |          364.095 |      180000 | -1917.69 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-26-08\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -1763.016387971157\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 65\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.133\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.12103245407342911\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016364462673664093\n",
      "        policy_loss: -0.001606381731107831\n",
      "        total_loss: 281.37225341796875\n",
      "        vf_explained_var: -4.677690867538331e-06\n",
      "        vf_loss: 281.3730773925781\n",
      "    load_time_ms: 2.737\n",
      "    num_steps_sampled: 195000\n",
      "    num_steps_trained: 194688\n",
      "    sample_time_ms: 27784.435\n",
      "    update_time_ms: 2.711\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.03333333333333\n",
      "    ram_util_percent: 23.866666666666664\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.495605771588499\n",
      "    mean_inference_ms: 0.41154511761819396\n",
      "    mean_processing_ms: 4.061547097785623\n",
      "  time_since_restore: 393.4271273612976\n",
      "  time_this_iter_s: 29.331794023513794\n",
      "  time_total_s: 393.4271273612976\n",
      "  timestamp: 1665271568\n",
      "  timesteps_since_restore: 195000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 195000\n",
      "  training_iteration: 13\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     13 |          393.427 |      195000 | -1763.02 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-26-37\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -1735.7444647588334\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 70\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1478.873\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25704774260520935\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01513621211051941\n",
      "        policy_loss: -0.004745267331600189\n",
      "        total_loss: 243.4720916748047\n",
      "        vf_explained_var: -3.484579337964533e-06\n",
      "        vf_loss: 243.47607421875\n",
      "    load_time_ms: 2.739\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 209664\n",
      "    sample_time_ms: 27782.92\n",
      "    update_time_ms: 2.685\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.87380952380953\n",
      "    ram_util_percent: 23.788095238095234\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.448432195726135\n",
      "    mean_inference_ms: 0.4114858220053565\n",
      "    mean_processing_ms: 4.063891517205699\n",
      "  time_since_restore: 422.41189193725586\n",
      "  time_this_iter_s: 28.984764575958252\n",
      "  time_total_s: 422.41189193725586\n",
      "  timestamp: 1665271597\n",
      "  timesteps_since_restore: 210000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 14\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     14 |          422.412 |      210000 | -1735.74 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-27-07\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -1580.7181060844052\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 75\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.727\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.44527119398117065\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019096767529845238\n",
      "        policy_loss: -0.0028846324421465397\n",
      "        total_loss: 254.23687744140625\n",
      "        vf_explained_var: -1.4936822481104173e-06\n",
      "        vf_loss: 254.23883056640625\n",
      "    load_time_ms: 2.676\n",
      "    num_steps_sampled: 225000\n",
      "    num_steps_trained: 224640\n",
      "    sample_time_ms: 27764.271\n",
      "    update_time_ms: 2.709\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.09512195121951\n",
      "    ram_util_percent: 23.87560975609756\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.40652557686741\n",
      "    mean_inference_ms: 0.41142543237699614\n",
      "    mean_processing_ms: 4.065666934966527\n",
      "  time_since_restore: 451.6066608428955\n",
      "  time_this_iter_s: 29.19476890563965\n",
      "  time_total_s: 451.6066608428955\n",
      "  timestamp: 1665271627\n",
      "  timesteps_since_restore: 225000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 225000\n",
      "  training_iteration: 15\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     15 |          451.607 |      225000 | -1580.72 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-27-36\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2150.9826131076466\n",
      "  episode_reward_mean: -1429.2042073408497\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 80\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.806\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.6660086512565613\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030962293967604637\n",
      "        policy_loss: -0.004540848545730114\n",
      "        total_loss: 253.2337188720703\n",
      "        vf_explained_var: -7.600866069878975e-07\n",
      "        vf_loss: 253.23672485351562\n",
      "    load_time_ms: 2.69\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 239616\n",
      "    sample_time_ms: 27769.877\n",
      "    update_time_ms: 2.8\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.25238095238095\n",
      "    ram_util_percent: 23.87142857142857\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.3690243859228115\n",
      "    mean_inference_ms: 0.4113758185645554\n",
      "    mean_processing_ms: 4.067037053210127\n",
      "  time_since_restore: 480.8058223724365\n",
      "  time_this_iter_s: 29.199161529541016\n",
      "  time_total_s: 480.8058223724365\n",
      "  timestamp: 1665271656\n",
      "  timesteps_since_restore: 240000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 16\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     16 |          480.806 |      240000 |  -1429.2 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-28-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2150.9826131076466\n",
      "  episode_reward_mean: -1255.8452811399284\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 85\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.556\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.9721755385398865\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011220017448067665\n",
      "        policy_loss: -0.001499361009337008\n",
      "        total_loss: 317.94952392578125\n",
      "        vf_explained_var: -3.8819436554149434e-07\n",
      "        vf_loss: 317.95050048828125\n",
      "    load_time_ms: 2.607\n",
      "    num_steps_sampled: 255000\n",
      "    num_steps_trained: 254592\n",
      "    sample_time_ms: 27887.381\n",
      "    update_time_ms: 2.712\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.127906976744185\n",
      "    ram_util_percent: 23.92093023255814\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.335660286937466\n",
      "    mean_inference_ms: 0.4113421434827349\n",
      "    mean_processing_ms: 4.068359651679277\n",
      "  time_since_restore: 510.8505461215973\n",
      "  time_this_iter_s: 30.044723749160767\n",
      "  time_total_s: 510.8505461215973\n",
      "  timestamp: 1665271686\n",
      "  timesteps_since_restore: 255000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 255000\n",
      "  training_iteration: 17\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     17 |          510.851 |      255000 | -1255.85 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-28-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2150.9826131076466\n",
      "  episode_reward_mean: -1114.6940064592045\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 90\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.573\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8819290399551392\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007236755918711424\n",
      "        policy_loss: -0.00027255943859927356\n",
      "        total_loss: 268.6373596191406\n",
      "        vf_explained_var: -2.384185791015625e-07\n",
      "        vf_loss: 268.63726806640625\n",
      "    load_time_ms: 2.748\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 269568\n",
      "    sample_time_ms: 27951.423\n",
      "    update_time_ms: 2.724\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.13333333333334\n",
      "    ram_util_percent: 23.95714285714286\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.305567245917672\n",
      "    mean_inference_ms: 0.4113129106258181\n",
      "    mean_processing_ms: 4.069466303462186\n",
      "  time_since_restore: 540.2915470600128\n",
      "  time_this_iter_s: 29.441000938415527\n",
      "  time_total_s: 540.2915470600128\n",
      "  timestamp: 1665271715\n",
      "  timesteps_since_restore: 270000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 18\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     18 |          540.292 |      270000 | -1114.69 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-29-05\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -990.7253668556045\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 95\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.238\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.9742282032966614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.027607323601841927\n",
      "        policy_loss: -0.001836832845583558\n",
      "        total_loss: 307.25146484375\n",
      "        vf_explained_var: -9.271833789625816e-08\n",
      "        vf_loss: 307.25262451171875\n",
      "    load_time_ms: 2.751\n",
      "    num_steps_sampled: 285000\n",
      "    num_steps_trained: 284544\n",
      "    sample_time_ms: 27970.467\n",
      "    update_time_ms: 2.691\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.42142857142858\n",
      "    ram_util_percent: 23.878571428571426\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.27831947652698\n",
      "    mean_inference_ms: 0.4112848069201737\n",
      "    mean_processing_ms: 4.070266254369737\n",
      "  time_since_restore: 569.5235981941223\n",
      "  time_this_iter_s: 29.232051134109497\n",
      "  time_total_s: 569.5235981941223\n",
      "  timestamp: 1665271745\n",
      "  timesteps_since_restore: 285000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 285000\n",
      "  training_iteration: 19\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     19 |          569.524 |      285000 | -990.725 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-29-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -911.7950380860152\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 100\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.323\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.6666787266731262\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026881108060479164\n",
      "        policy_loss: -0.0039021591655910015\n",
      "        total_loss: 215.7240753173828\n",
      "        vf_explained_var: -8.609559642991371e-08\n",
      "        vf_loss: 215.72727966308594\n",
      "    load_time_ms: 2.83\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 299520\n",
      "    sample_time_ms: 27940.609\n",
      "    update_time_ms: 2.737\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.02439024390243\n",
      "    ram_util_percent: 23.86829268292683\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.253148457608845\n",
      "    mean_inference_ms: 0.4112597154316226\n",
      "    mean_processing_ms: 4.070894931782129\n",
      "  time_since_restore: 598.4107913970947\n",
      "  time_this_iter_s: 28.887193202972412\n",
      "  time_total_s: 598.4107913970947\n",
      "  timestamp: 1665271773\n",
      "  timesteps_since_restore: 300000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 20\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     20 |          598.411 |      300000 | -911.795 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-30-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -604.8625944410849\n",
      "  episode_reward_min: -5133.911588643235\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 105\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.202\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.144898772239685\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.033596329391002655\n",
      "        policy_loss: -0.0046270666643977165\n",
      "        total_loss: 307.9708557128906\n",
      "        vf_explained_var: -4.5340286192185886e-08\n",
      "        vf_loss: 307.9745788574219\n",
      "    load_time_ms: 2.928\n",
      "    num_steps_sampled: 315000\n",
      "    num_steps_trained: 314496\n",
      "    sample_time_ms: 27876.498\n",
      "    update_time_ms: 2.742\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.28780487804878\n",
      "    ram_util_percent: 23.892682926829266\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 5.067777979086083\n",
      "    mean_inference_ms: 0.4105118524346444\n",
      "    mean_processing_ms: 4.0748174886049915\n",
      "  time_since_restore: 627.6291782855988\n",
      "  time_this_iter_s: 29.21838688850403\n",
      "  time_total_s: 627.6291782855988\n",
      "  timestamp: 1665271803\n",
      "  timesteps_since_restore: 315000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 315000\n",
      "  training_iteration: 21\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     21 |          627.629 |      315000 | -604.863 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-30-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -319.59679259949263\n",
      "  episode_reward_min: -4210.348871694206\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 110\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.681\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0963475704193115\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03217914700508118\n",
      "        policy_loss: -0.0034363085869699717\n",
      "        total_loss: 377.84210205078125\n",
      "        vf_explained_var: -1.2736035337468365e-08\n",
      "        vf_loss: 377.8447570800781\n",
      "    load_time_ms: 2.84\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 329472\n",
      "    sample_time_ms: 27872.248\n",
      "    update_time_ms: 2.825\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.47441860465116\n",
      "    ram_util_percent: 23.87441860465116\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.98464230560202\n",
      "    mean_inference_ms: 0.4103541778043633\n",
      "    mean_processing_ms: 4.078504803862877\n",
      "  time_since_restore: 657.7460916042328\n",
      "  time_this_iter_s: 30.116913318634033\n",
      "  time_total_s: 657.7460916042328\n",
      "  timestamp: 1665271833\n",
      "  timesteps_since_restore: 330000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 22\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     22 |          657.746 |      330000 | -319.597 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-31-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -102.54571991842141\n",
      "  episode_reward_min: -3362.1349047244466\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 115\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.317\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0031050443649292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0322035551071167\n",
      "        policy_loss: -0.002848793985322118\n",
      "        total_loss: 496.5315856933594\n",
      "        vf_explained_var: -1.1207711203553572e-08\n",
      "        vf_loss: 496.5336608886719\n",
      "    load_time_ms: 2.873\n",
      "    num_steps_sampled: 345000\n",
      "    num_steps_trained: 344448\n",
      "    sample_time_ms: 27892.953\n",
      "    update_time_ms: 2.871\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.853488372093025\n",
      "    ram_util_percent: 23.93255813953488\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.9324359339414885\n",
      "    mean_inference_ms: 0.4103356927650054\n",
      "    mean_processing_ms: 4.079092924632403\n",
      "  time_since_restore: 687.2925012111664\n",
      "  time_this_iter_s: 29.546409606933594\n",
      "  time_total_s: 687.2925012111664\n",
      "  timestamp: 1665271862\n",
      "  timesteps_since_restore: 345000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 345000\n",
      "  training_iteration: 23\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     23 |          687.293 |      345000 | -102.546 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-31-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 84.66621717797645\n",
      "  episode_reward_min: -2783.560989605884\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 120\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.906\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1678290367126465\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02695666439831257\n",
      "        policy_loss: -0.0006163036450743675\n",
      "        total_loss: 431.3108825683594\n",
      "        vf_explained_var: -1.0698269825581974e-08\n",
      "        vf_loss: 431.31085205078125\n",
      "    load_time_ms: 2.876\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 359424\n",
      "    sample_time_ms: 27905.954\n",
      "    update_time_ms: 2.823\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.84878048780487\n",
      "    ram_util_percent: 23.89268292682927\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.895452560492289\n",
      "    mean_inference_ms: 0.41037144851800045\n",
      "    mean_processing_ms: 4.080372494466766\n",
      "  time_since_restore: 716.41277384758\n",
      "  time_this_iter_s: 29.120272636413574\n",
      "  time_total_s: 716.41277384758\n",
      "  timestamp: 1665271892\n",
      "  timesteps_since_restore: 360000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 24\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     24 |          716.413 |      360000 |  84.6662 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-32-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 146.37486129384519\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 125\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.149\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.19539299607276917\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012731901369988918\n",
      "        policy_loss: 0.0009902429301291704\n",
      "        total_loss: 1214.624755859375\n",
      "        vf_explained_var: -6.113296979748384e-09\n",
      "        vf_loss: 1214.6236572265625\n",
      "    load_time_ms: 2.941\n",
      "    num_steps_sampled: 375000\n",
      "    num_steps_trained: 374400\n",
      "    sample_time_ms: 27907.757\n",
      "    update_time_ms: 2.831\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.390476190476186\n",
      "    ram_util_percent: 23.938095238095237\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.866792455096052\n",
      "    mean_inference_ms: 0.41041082602009543\n",
      "    mean_processing_ms: 4.081312454833599\n",
      "  time_since_restore: 745.6298134326935\n",
      "  time_this_iter_s: 29.217039585113525\n",
      "  time_total_s: 745.6298134326935\n",
      "  timestamp: 1665271921\n",
      "  timesteps_since_restore: 375000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 375000\n",
      "  training_iteration: 25\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     25 |           745.63 |      375000 |  146.375 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-32-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 226.9748364868977\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 130\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7585897445678711\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029231322929263115\n",
      "        policy_loss: -0.0013191142352297902\n",
      "        total_loss: 1218.2537841796875\n",
      "        vf_explained_var: -2.2924863785078742e-08\n",
      "        vf_loss: 1218.254150390625\n",
      "    load_time_ms: 2.842\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 389376\n",
      "    sample_time_ms: 27977.183\n",
      "    update_time_ms: 2.818\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.81860465116279\n",
      "    ram_util_percent: 23.90232558139535\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.844346003529898\n",
      "    mean_inference_ms: 0.4104943113985277\n",
      "    mean_processing_ms: 4.082017719666616\n",
      "  time_since_restore: 775.5276658535004\n",
      "  time_this_iter_s: 29.897852420806885\n",
      "  time_total_s: 775.5276658535004\n",
      "  timestamp: 1665271951\n",
      "  timesteps_since_restore: 390000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 26\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     26 |          775.528 |      390000 |  226.975 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-33-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 346.53740662600933\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 135\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.484\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.2142467498779297\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026433037593960762\n",
      "        policy_loss: -0.0023595283273607492\n",
      "        total_loss: 528.091796875\n",
      "        vf_explained_var: 0.007976763881742954\n",
      "        vf_loss: 528.093505859375\n",
      "    load_time_ms: 2.777\n",
      "    num_steps_sampled: 405000\n",
      "    num_steps_trained: 404352\n",
      "    sample_time_ms: 27967.121\n",
      "    update_time_ms: 2.883\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.66428571428572\n",
      "    ram_util_percent: 23.93809523809524\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.826277563593099\n",
      "    mean_inference_ms: 0.41050419809733335\n",
      "    mean_processing_ms: 4.0832681110311055\n",
      "  time_since_restore: 805.4596519470215\n",
      "  time_this_iter_s: 29.931986093521118\n",
      "  time_total_s: 805.4596519470215\n",
      "  timestamp: 1665271981\n",
      "  timesteps_since_restore: 405000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 405000\n",
      "  training_iteration: 27\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     27 |           805.46 |      405000 |  346.537 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-33-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 381.2403436317934\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 140\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.452\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4376133680343628\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026094552129507065\n",
      "        policy_loss: 0.0009768957970663905\n",
      "        total_loss: 760.359130859375\n",
      "        vf_explained_var: 0.5551092624664307\n",
      "        vf_loss: 760.357421875\n",
      "    load_time_ms: 2.757\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 419328\n",
      "    sample_time_ms: 27936.623\n",
      "    update_time_ms: 2.833\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.057142857142864\n",
      "    ram_util_percent: 23.954761904761902\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.811319949342764\n",
      "    mean_inference_ms: 0.4104235933721295\n",
      "    mean_processing_ms: 4.085098857820824\n",
      "  time_since_restore: 834.5948858261108\n",
      "  time_this_iter_s: 29.135233879089355\n",
      "  time_total_s: 834.5948858261108\n",
      "  timestamp: 1665272010\n",
      "  timesteps_since_restore: 420000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 28\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     28 |          834.595 |      420000 |   381.24 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-33-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 434.2930465944985\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 145\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.104\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.6761203408241272\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021178705617785454\n",
      "        policy_loss: 0.0003945417411159724\n",
      "        total_loss: 741.3009033203125\n",
      "        vf_explained_var: 0.7156456708908081\n",
      "        vf_loss: 741.2998657226562\n",
      "    load_time_ms: 2.729\n",
      "    num_steps_sampled: 435000\n",
      "    num_steps_trained: 434304\n",
      "    sample_time_ms: 27949.502\n",
      "    update_time_ms: 2.794\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.98095238095238\n",
      "    ram_util_percent: 23.93809523809524\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.799016883960666\n",
      "    mean_inference_ms: 0.41037060817395643\n",
      "    mean_processing_ms: 4.086666191679509\n",
      "  time_since_restore: 863.9618046283722\n",
      "  time_this_iter_s: 29.366918802261353\n",
      "  time_total_s: 863.9618046283722\n",
      "  timestamp: 1665272039\n",
      "  timesteps_since_restore: 435000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 435000\n",
      "  training_iteration: 29\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     29 |          863.962 |      435000 |  434.293 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-34-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 442.4934132689977\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 150\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.898\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.40116938948631287\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.10207802802324295\n",
      "        policy_loss: -0.015542691573500633\n",
      "        total_loss: 725.0808715820312\n",
      "        vf_explained_var: 0.8073306679725647\n",
      "        vf_loss: 725.0936889648438\n",
      "    load_time_ms: 2.635\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 449280\n",
      "    sample_time_ms: 27994.89\n",
      "    update_time_ms: 2.713\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.49047619047619\n",
      "    ram_util_percent: 23.914285714285715\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.788177884166082\n",
      "    mean_inference_ms: 0.41033501534282857\n",
      "    mean_processing_ms: 4.088195657846636\n",
      "  time_since_restore: 893.3194561004639\n",
      "  time_this_iter_s: 29.357651472091675\n",
      "  time_total_s: 893.3194561004639\n",
      "  timestamp: 1665272069\n",
      "  timesteps_since_restore: 450000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 30\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     30 |          893.319 |      450000 |  442.493 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-34-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 397.1359986847118\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 155\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.795\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.3714442551136017\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011444581672549248\n",
      "        policy_loss: 0.0007020886987447739\n",
      "        total_loss: 886.865234375\n",
      "        vf_explained_var: 0.8329453468322754\n",
      "        vf_loss: 886.8641357421875\n",
      "    load_time_ms: 2.511\n",
      "    num_steps_sampled: 465000\n",
      "    num_steps_trained: 464256\n",
      "    sample_time_ms: 27971.535\n",
      "    update_time_ms: 2.718\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.58292682926829\n",
      "    ram_util_percent: 23.9390243902439\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.77840273976982\n",
      "    mean_inference_ms: 0.4103177498276605\n",
      "    mean_processing_ms: 4.089274791768024\n",
      "  time_since_restore: 922.2919692993164\n",
      "  time_this_iter_s: 28.97251319885254\n",
      "  time_total_s: 922.2919692993164\n",
      "  timestamp: 1665272098\n",
      "  timesteps_since_restore: 465000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 465000\n",
      "  training_iteration: 31\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     31 |          922.292 |      465000 |  397.136 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-35-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 288.136902244383\n",
      "  episode_reward_min: -7735.964549449847\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 160\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.315\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.6021498441696167\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023407192900776863\n",
      "        policy_loss: -0.0003280425735283643\n",
      "        total_loss: 2164.168212890625\n",
      "        vf_explained_var: 0.8373757600784302\n",
      "        vf_loss: 2164.16796875\n",
      "    load_time_ms: 2.507\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 479232\n",
      "    sample_time_ms: 27906.97\n",
      "    update_time_ms: 2.717\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.607142857142854\n",
      "    ram_util_percent: 23.93809523809524\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.76993166836668\n",
      "    mean_inference_ms: 0.41030298628771356\n",
      "    mean_processing_ms: 4.089096718916428\n",
      "  time_since_restore: 951.7783026695251\n",
      "  time_this_iter_s: 29.48633337020874\n",
      "  time_total_s: 951.7783026695251\n",
      "  timestamp: 1665272127\n",
      "  timesteps_since_restore: 480000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 32\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     32 |          951.778 |      480000 |  288.137 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-35-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 239.6607914164302\n",
      "  episode_reward_min: -7735.964549449847\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 165\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.302\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.12797172367572784\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018186938017606735\n",
      "        policy_loss: -0.0006287434371188283\n",
      "        total_loss: 930.6474609375\n",
      "        vf_explained_var: 0.8931397199630737\n",
      "        vf_loss: 930.6474609375\n",
      "    load_time_ms: 2.546\n",
      "    num_steps_sampled: 495000\n",
      "    num_steps_trained: 494208\n",
      "    sample_time_ms: 27904.643\n",
      "    update_time_ms: 2.714\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.15476190476191\n",
      "    ram_util_percent: 23.96666666666667\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.762318238536111\n",
      "    mean_inference_ms: 0.41030713209785946\n",
      "    mean_processing_ms: 4.0891238118195465\n",
      "  time_since_restore: 981.3012747764587\n",
      "  time_this_iter_s: 29.522972106933594\n",
      "  time_total_s: 981.3012747764587\n",
      "  timestamp: 1665272157\n",
      "  timesteps_since_restore: 495000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 495000\n",
      "  training_iteration: 33\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     33 |          981.301 |      495000 |  239.661 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-36-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 283.48924994885715\n",
      "  episode_reward_min: -7735.964549449847\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 170\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.951\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.3942350447177887\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010172453708946705\n",
      "        policy_loss: 0.001523479470051825\n",
      "        total_loss: 746.2391967773438\n",
      "        vf_explained_var: 0.9138190746307373\n",
      "        vf_loss: 746.2373046875\n",
      "    load_time_ms: 2.544\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 509184\n",
      "    sample_time_ms: 28474.725\n",
      "    update_time_ms: 2.803\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.72\n",
      "    ram_util_percent: 23.925999999999995\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.755892276356957\n",
      "    mean_inference_ms: 0.4102908844556432\n",
      "    mean_processing_ms: 4.0916743037360135\n",
      "  time_since_restore: 1016.1197714805603\n",
      "  time_this_iter_s: 34.81849670410156\n",
      "  time_total_s: 1016.1197714805603\n",
      "  timestamp: 1665272191\n",
      "  timesteps_since_restore: 510000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 34\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     34 |          1016.12 |      510000 |  283.489 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-37-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 184.57267226614783\n",
      "  episode_reward_min: -7735.964549449847\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 175\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3882080614566803\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.5299168825149536\n",
      "        policy_loss: 0.024248411878943443\n",
      "        total_loss: 1102.139892578125\n",
      "        vf_explained_var: 0.9181990623474121\n",
      "        vf_loss: 1102.095703125\n",
      "    load_time_ms: 2.536\n",
      "    num_steps_sampled: 525000\n",
      "    num_steps_trained: 524160\n",
      "    sample_time_ms: 28471.37\n",
      "    update_time_ms: 2.789\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.019047619047626\n",
      "    ram_util_percent: 23.98095238095238\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.749942927717289\n",
      "    mean_inference_ms: 0.41028416634534814\n",
      "    mean_processing_ms: 4.09440706999572\n",
      "  time_since_restore: 1045.2915048599243\n",
      "  time_this_iter_s: 29.171733379364014\n",
      "  time_total_s: 1045.2915048599243\n",
      "  timestamp: 1665272221\n",
      "  timesteps_since_restore: 525000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 525000\n",
      "  training_iteration: 35\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     35 |          1045.29 |      525000 |  184.573 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-37-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -24.9372359540199\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 180\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.249\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05624999850988388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.7038577795028687\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01243900042027235\n",
      "        policy_loss: 0.0003519220044836402\n",
      "        total_loss: 2154.837646484375\n",
      "        vf_explained_var: 0.9186643958091736\n",
      "        vf_loss: 2154.836669921875\n",
      "    load_time_ms: 2.52\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 539136\n",
      "    sample_time_ms: 28399.602\n",
      "    update_time_ms: 2.759\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.21463414634146\n",
      "    ram_util_percent: 23.965853658536584\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.744458660116098\n",
      "    mean_inference_ms: 0.41027434663641793\n",
      "    mean_processing_ms: 4.097169478656246\n",
      "  time_since_restore: 1074.4754660129547\n",
      "  time_this_iter_s: 29.183961153030396\n",
      "  time_total_s: 1074.4754660129547\n",
      "  timestamp: 1665272250\n",
      "  timesteps_since_restore: 540000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 36\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     36 |          1074.48 |      540000 | -24.9372 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-37-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -262.99919202185606\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 185\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.651\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05624999850988388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.589788556098938\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04220208153128624\n",
      "        policy_loss: 0.0011978395050391555\n",
      "        total_loss: 2085.097900390625\n",
      "        vf_explained_var: 0.9284284710884094\n",
      "        vf_loss: 2085.094482421875\n",
      "    load_time_ms: 2.602\n",
      "    num_steps_sampled: 555000\n",
      "    num_steps_trained: 554112\n",
      "    sample_time_ms: 28305.571\n",
      "    update_time_ms: 2.781\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.273809523809526\n",
      "    ram_util_percent: 24.004761904761907\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.73903316235573\n",
      "    mean_inference_ms: 0.41025544542448394\n",
      "    mean_processing_ms: 4.099720579181155\n",
      "  time_since_restore: 1103.4725904464722\n",
      "  time_this_iter_s: 28.997124433517456\n",
      "  time_total_s: 1103.4725904464722\n",
      "  timestamp: 1665272279\n",
      "  timesteps_since_restore: 555000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 555000\n",
      "  training_iteration: 37\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     37 |          1103.47 |      555000 | -262.999 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-38-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -531.246734687582\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 190\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.731\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08437500149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.2909860610961914\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0070008207112550735\n",
      "        policy_loss: 0.002046198584139347\n",
      "        total_loss: 2416.023193359375\n",
      "        vf_explained_var: 0.9064735174179077\n",
      "        vf_loss: 2416.02099609375\n",
      "    load_time_ms: 2.55\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 569088\n",
      "    sample_time_ms: 28313.378\n",
      "    update_time_ms: 2.802\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.22142857142857\n",
      "    ram_util_percent: 24.052380952380954\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.733813651698288\n",
      "    mean_inference_ms: 0.4102478955210527\n",
      "    mean_processing_ms: 4.102314095824976\n",
      "  time_since_restore: 1132.696308374405\n",
      "  time_this_iter_s: 29.22371792793274\n",
      "  time_total_s: 1132.696308374405\n",
      "  timestamp: 1665272308\n",
      "  timesteps_since_restore: 570000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 38\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     38 |           1132.7 |      570000 | -531.247 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-38-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1970.6021690913599\n",
      "  episode_reward_mean: -664.2970311070877\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 195\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.092\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04218750074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28920629620552063\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05168590322136879\n",
      "        policy_loss: -0.0056699044071137905\n",
      "        total_loss: 1277.14599609375\n",
      "        vf_explained_var: 0.9436624646186829\n",
      "        vf_loss: 1277.1495361328125\n",
      "    load_time_ms: 2.546\n",
      "    num_steps_sampled: 585000\n",
      "    num_steps_trained: 584064\n",
      "    sample_time_ms: 28274.118\n",
      "    update_time_ms: 2.822\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00487804878049\n",
      "    ram_util_percent: 24.002439024390245\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.728657800864154\n",
      "    mean_inference_ms: 0.4102414802694349\n",
      "    mean_processing_ms: 4.104983202446838\n",
      "  time_since_restore: 1161.6641063690186\n",
      "  time_this_iter_s: 28.967797994613647\n",
      "  time_total_s: 1161.6641063690186\n",
      "  timestamp: 1665272337\n",
      "  timesteps_since_restore: 585000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 585000\n",
      "  training_iteration: 39\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     39 |          1161.66 |      585000 | -664.297 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-39-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1970.6021690913599\n",
      "  episode_reward_mean: -868.3921145548921\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 200\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.585\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06328125298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.7276870012283325\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0276792012155056\n",
      "        policy_loss: 0.00042463827412575483\n",
      "        total_loss: 2005.9749755859375\n",
      "        vf_explained_var: 0.940935492515564\n",
      "        vf_loss: 2005.97314453125\n",
      "    load_time_ms: 2.522\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 599040\n",
      "    sample_time_ms: 28219.328\n",
      "    update_time_ms: 2.825\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.548780487804876\n",
      "    ram_util_percent: 24.01707317073171\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.72387701304055\n",
      "    mean_inference_ms: 0.4102381731083131\n",
      "    mean_processing_ms: 4.107709827883919\n",
      "  time_since_restore: 1190.4584584236145\n",
      "  time_this_iter_s: 28.794352054595947\n",
      "  time_total_s: 1190.4584584236145\n",
      "  timestamp: 1665272366\n",
      "  timesteps_since_restore: 600000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 40\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     40 |          1190.46 |      600000 | -868.392 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-39-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1004.9764909437494\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 205\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.116\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06328125298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21448606252670288\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01563834957778454\n",
      "        policy_loss: 0.006395771633833647\n",
      "        total_loss: 1339.6922607421875\n",
      "        vf_explained_var: 0.9593550562858582\n",
      "        vf_loss: 1339.684814453125\n",
      "    load_time_ms: 2.585\n",
      "    num_steps_sampled: 615000\n",
      "    num_steps_trained: 614016\n",
      "    sample_time_ms: 28241.34\n",
      "    update_time_ms: 2.876\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.27619047619048\n",
      "    ram_util_percent: 24.02857142857143\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.7193610217572175\n",
      "    mean_inference_ms: 0.41024750791249764\n",
      "    mean_processing_ms: 4.110396956887314\n",
      "  time_since_restore: 1219.6570491790771\n",
      "  time_this_iter_s: 29.198590755462646\n",
      "  time_total_s: 1219.6570491790771\n",
      "  timestamp: 1665272395\n",
      "  timesteps_since_restore: 615000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 615000\n",
      "  training_iteration: 41\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     41 |          1219.66 |      615000 | -1004.98 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-40-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1129.4033754711165\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 210\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.529\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06328125298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.06105500087141991\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020453613251447678\n",
      "        policy_loss: 0.006152871530503035\n",
      "        total_loss: 1456.6781005859375\n",
      "        vf_explained_var: 0.9526769518852234\n",
      "        vf_loss: 1456.6705322265625\n",
      "    load_time_ms: 2.666\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 628992\n",
      "    sample_time_ms: 28246.754\n",
      "    update_time_ms: 2.828\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.13333333333334\n",
      "    ram_util_percent: 24.035714285714285\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.714972242477609\n",
      "    mean_inference_ms: 0.4102667703850536\n",
      "    mean_processing_ms: 4.112759638254842\n",
      "  time_since_restore: 1249.1926481723785\n",
      "  time_this_iter_s: 29.53559899330139\n",
      "  time_total_s: 1249.1926481723785\n",
      "  timestamp: 1665272425\n",
      "  timesteps_since_restore: 630000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 42\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     42 |          1249.19 |      630000 |  -1129.4 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-40-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1272.8628703661407\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 215\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.488\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06328125298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4230090379714966\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.06393381953239441\n",
      "        policy_loss: 0.016252640634775162\n",
      "        total_loss: 1776.7672119140625\n",
      "        vf_explained_var: 0.9571880102157593\n",
      "        vf_loss: 1776.746826171875\n",
      "    load_time_ms: 2.495\n",
      "    num_steps_sampled: 645000\n",
      "    num_steps_trained: 643968\n",
      "    sample_time_ms: 28222.993\n",
      "    update_time_ms: 2.865\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.535714285714285\n",
      "    ram_util_percent: 24.021428571428572\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.710710896508282\n",
      "    mean_inference_ms: 0.41029234140299325\n",
      "    mean_processing_ms: 4.1149949266474035\n",
      "  time_since_restore: 1278.4761509895325\n",
      "  time_this_iter_s: 29.28350281715393\n",
      "  time_total_s: 1278.4761509895325\n",
      "  timestamp: 1665272454\n",
      "  timesteps_since_restore: 645000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 645000\n",
      "  training_iteration: 43\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     43 |          1278.48 |      645000 | -1272.86 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-41-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1463.1007726123287\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 220\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.229\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2656164169311523\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013735225424170494\n",
      "        policy_loss: 0.0019666561856865883\n",
      "        total_loss: 2097.0234375\n",
      "        vf_explained_var: 0.958125114440918\n",
      "        vf_loss: 2097.020263671875\n",
      "    load_time_ms: 2.513\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 658944\n",
      "    sample_time_ms: 27650.824\n",
      "    update_time_ms: 2.799\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34878048780487\n",
      "    ram_util_percent: 24.034146341463416\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.706523619239831\n",
      "    mean_inference_ms: 0.4103308712801107\n",
      "    mean_processing_ms: 4.117234656267319\n",
      "  time_since_restore: 1307.569804430008\n",
      "  time_this_iter_s: 29.093653440475464\n",
      "  time_total_s: 1307.569804430008\n",
      "  timestamp: 1665272483\n",
      "  timesteps_since_restore: 660000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 44\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     44 |          1307.57 |      660000 |  -1463.1 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-41-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1527.0135019540965\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 225\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.57\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36879318952560425\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03277485445141792\n",
      "        policy_loss: 0.005570645909756422\n",
      "        total_loss: 2095.740966796875\n",
      "        vf_explained_var: 0.9553706049919128\n",
      "        vf_loss: 2095.732666015625\n",
      "    load_time_ms: 2.494\n",
      "    num_steps_sampled: 675000\n",
      "    num_steps_trained: 673920\n",
      "    sample_time_ms: 27625.66\n",
      "    update_time_ms: 2.764\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.88333333333334\n",
      "    ram_util_percent: 24.040476190476188\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.702537139764517\n",
      "    mean_inference_ms: 0.4103766116046444\n",
      "    mean_processing_ms: 4.119416715702203\n",
      "  time_since_restore: 1336.502646446228\n",
      "  time_this_iter_s: 28.932842016220093\n",
      "  time_total_s: 1336.502646446228\n",
      "  timestamp: 1665272512\n",
      "  timesteps_since_restore: 675000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 675000\n",
      "  training_iteration: 45\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     45 |           1336.5 |      675000 | -1527.01 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-42-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1647.3209667320566\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 230\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.347\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7252047657966614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010624871589243412\n",
      "        policy_loss: 0.003354713786393404\n",
      "        total_loss: 2210.7548828125\n",
      "        vf_explained_var: 0.9520848393440247\n",
      "        vf_loss: 2210.75048828125\n",
      "    load_time_ms: 2.53\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 688896\n",
      "    sample_time_ms: 27663.341\n",
      "    update_time_ms: 2.743\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.61428571428572\n",
      "    ram_util_percent: 24.07857142857143\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6984352102189115\n",
      "    mean_inference_ms: 0.41042154607214454\n",
      "    mean_processing_ms: 4.1216222833891\n",
      "  time_since_restore: 1366.0715248584747\n",
      "  time_this_iter_s: 29.568878412246704\n",
      "  time_total_s: 1366.0715248584747\n",
      "  timestamp: 1665272542\n",
      "  timesteps_since_restore: 690000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 46\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     46 |          1366.07 |      690000 | -1647.32 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-42-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1755.468769158477\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 235\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.413\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.22062741219997406\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02767261676490307\n",
      "        policy_loss: 0.010604454204440117\n",
      "        total_loss: 1818.7083740234375\n",
      "        vf_explained_var: 0.958972692489624\n",
      "        vf_loss: 1818.6954345703125\n",
      "    load_time_ms: 2.511\n",
      "    num_steps_sampled: 705000\n",
      "    num_steps_trained: 703872\n",
      "    sample_time_ms: 27661.118\n",
      "    update_time_ms: 2.748\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.2609756097561\n",
      "    ram_util_percent: 24.073170731707318\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.694389782131067\n",
      "    mean_inference_ms: 0.41047489444758645\n",
      "    mean_processing_ms: 4.123517216971516\n",
      "  time_since_restore: 1395.066828250885\n",
      "  time_this_iter_s: 28.99530339241028\n",
      "  time_total_s: 1395.066828250885\n",
      "  timestamp: 1665272571\n",
      "  timesteps_since_restore: 705000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 705000\n",
      "  training_iteration: 47\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     47 |          1395.07 |      705000 | -1755.47 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1777.0561216649862\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 240\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.247\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5335463285446167\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011819726787507534\n",
      "        policy_loss: -0.0013670340413227677\n",
      "        total_loss: 1639.487548828125\n",
      "        vf_explained_var: 0.9620298743247986\n",
      "        vf_loss: 1639.488037109375\n",
      "    load_time_ms: 2.39\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 718848\n",
      "    sample_time_ms: 27633.416\n",
      "    update_time_ms: 2.74\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.458536585365856\n",
      "    ram_util_percent: 24.212195121951222\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.690595602880974\n",
      "    mean_inference_ms: 0.41053666536609\n",
      "    mean_processing_ms: 4.125229689297864\n",
      "  time_since_restore: 1424.000063419342\n",
      "  time_this_iter_s: 28.93323516845703\n",
      "  time_total_s: 1424.000063419342\n",
      "  timestamp: 1665272600\n",
      "  timesteps_since_restore: 720000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 48\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     48 |             1424 |      720000 | -1777.06 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-43-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1794.8422256410706\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 245\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.276\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1074957847595215\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.028395989909768105\n",
      "        policy_loss: 0.00541132315993309\n",
      "        total_loss: 1651.837158203125\n",
      "        vf_explained_var: 0.963881254196167\n",
      "        vf_loss: 1651.8291015625\n",
      "    load_time_ms: 2.397\n",
      "    num_steps_sampled: 735000\n",
      "    num_steps_trained: 733824\n",
      "    sample_time_ms: 27641.996\n",
      "    update_time_ms: 2.82\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.02142857142857\n",
      "    ram_util_percent: 24.121428571428574\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.686996188303593\n",
      "    mean_inference_ms: 0.4106096764153091\n",
      "    mean_processing_ms: 4.126796844229101\n",
      "  time_since_restore: 1453.0551524162292\n",
      "  time_this_iter_s: 29.055088996887207\n",
      "  time_total_s: 1453.0551524162292\n",
      "  timestamp: 1665272629\n",
      "  timesteps_since_restore: 735000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 735000\n",
      "  training_iteration: 49\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     49 |          1453.06 |      735000 | -1794.84 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-44-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1818.2600549224908\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 250\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.041\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.49374818801879883\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023193364962935448\n",
      "        policy_loss: 0.0033543400932103395\n",
      "        total_loss: 1650.416259765625\n",
      "        vf_explained_var: 0.9662081599235535\n",
      "        vf_loss: 1650.4105224609375\n",
      "    load_time_ms: 2.41\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 748800\n",
      "    sample_time_ms: 27759.908\n",
      "    update_time_ms: 2.863\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.52093023255814\n",
      "    ram_util_percent: 24.130232558139532\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.683544131404654\n",
      "    mean_inference_ms: 0.41068419974269177\n",
      "    mean_processing_ms: 4.128556256370608\n",
      "  time_since_restore: 1483.026792049408\n",
      "  time_this_iter_s: 29.97163963317871\n",
      "  time_total_s: 1483.026792049408\n",
      "  timestamp: 1665272659\n",
      "  timesteps_since_restore: 750000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 50\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     50 |          1483.03 |      750000 | -1818.26 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-44-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1832.2331338412428\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 255\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.523\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5307113528251648\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014276320114731789\n",
      "        policy_loss: 0.0025089902337640524\n",
      "        total_loss: 1374.2769775390625\n",
      "        vf_explained_var: 0.9777113795280457\n",
      "        vf_loss: 1374.27294921875\n",
      "    load_time_ms: 2.423\n",
      "    num_steps_sampled: 765000\n",
      "    num_steps_trained: 763776\n",
      "    sample_time_ms: 27753.817\n",
      "    update_time_ms: 2.817\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.59512195121951\n",
      "    ram_util_percent: 24.112195121951224\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.680365475074894\n",
      "    mean_inference_ms: 0.41076447019180434\n",
      "    mean_processing_ms: 4.130274163256522\n",
      "  time_since_restore: 1512.1491680145264\n",
      "  time_this_iter_s: 29.122375965118408\n",
      "  time_total_s: 1512.1491680145264\n",
      "  timestamp: 1665272688\n",
      "  timesteps_since_restore: 765000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 765000\n",
      "  training_iteration: 51\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     51 |          1512.15 |      765000 | -1832.23 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-45-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1824.0487343915481\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 260\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.852\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1822991371154785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01097051240503788\n",
      "        policy_loss: 0.004247209057211876\n",
      "        total_loss: 2669.737548828125\n",
      "        vf_explained_var: 0.959105908870697\n",
      "        vf_loss: 2669.732421875\n",
      "    load_time_ms: 2.372\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 778752\n",
      "    sample_time_ms: 27690.678\n",
      "    update_time_ms: 2.856\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.885714285714286\n",
      "    ram_util_percent: 24.152380952380955\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.677260799906585\n",
      "    mean_inference_ms: 0.41084483012318734\n",
      "    mean_processing_ms: 4.131864732201752\n",
      "  time_since_restore: 1541.0460464954376\n",
      "  time_this_iter_s: 28.896878480911255\n",
      "  time_total_s: 1541.0460464954376\n",
      "  timestamp: 1665272717\n",
      "  timesteps_since_restore: 780000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 52\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     52 |          1541.05 |      780000 | -1824.05 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-45-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1814.8502847986072\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 265\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.269\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7014041543006897\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.040748871862888336\n",
      "        policy_loss: -0.0010757282143458724\n",
      "        total_loss: 2134.82373046875\n",
      "        vf_explained_var: 0.9633569121360779\n",
      "        vf_loss: 2134.8212890625\n",
      "    load_time_ms: 2.555\n",
      "    num_steps_sampled: 795000\n",
      "    num_steps_trained: 793728\n",
      "    sample_time_ms: 27727.337\n",
      "    update_time_ms: 2.778\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.957142857142856\n",
      "    ram_util_percent: 24.09761904761905\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.674358543695812\n",
      "    mean_inference_ms: 0.41092595709778\n",
      "    mean_processing_ms: 4.133341871478385\n",
      "  time_since_restore: 1570.6921062469482\n",
      "  time_this_iter_s: 29.64605975151062\n",
      "  time_total_s: 1570.6921062469482\n",
      "  timestamp: 1665272746\n",
      "  timesteps_since_restore: 795000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 795000\n",
      "  training_iteration: 53\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     53 |          1570.69 |      795000 | -1814.85 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-46-16\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1962.987036055044\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 270\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.4\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14238281548023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.3282809257507324\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013363794423639774\n",
      "        policy_loss: 0.0058617317117750645\n",
      "        total_loss: 2516.27099609375\n",
      "        vf_explained_var: 0.9704315066337585\n",
      "        vf_loss: 2516.26318359375\n",
      "    load_time_ms: 2.413\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 808704\n",
      "    sample_time_ms: 27756.521\n",
      "    update_time_ms: 2.859\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.02619047619047\n",
      "    ram_util_percent: 24.140476190476193\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.671511459883636\n",
      "    mean_inference_ms: 0.41099379708847217\n",
      "    mean_processing_ms: 4.1323078740887045\n",
      "  time_since_restore: 1600.0783319473267\n",
      "  time_this_iter_s: 29.386225700378418\n",
      "  time_total_s: 1600.0783319473267\n",
      "  timestamp: 1665272776\n",
      "  timesteps_since_restore: 810000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 54\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     54 |          1600.08 |      810000 | -1962.99 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-46-45\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1992.4656539107323\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 275\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.745\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14238281548023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7137879729270935\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011148873716592789\n",
      "        policy_loss: 0.0013398046139627695\n",
      "        total_loss: 2098.861572265625\n",
      "        vf_explained_var: 0.9714082479476929\n",
      "        vf_loss: 2098.85888671875\n",
      "    load_time_ms: 2.447\n",
      "    num_steps_sampled: 825000\n",
      "    num_steps_trained: 823680\n",
      "    sample_time_ms: 27785.967\n",
      "    update_time_ms: 2.878\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.67142857142857\n",
      "    ram_util_percent: 24.0952380952381\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.668830658788054\n",
      "    mean_inference_ms: 0.4110596190177179\n",
      "    mean_processing_ms: 4.1312706789737605\n",
      "  time_since_restore: 1629.299599647522\n",
      "  time_this_iter_s: 29.221267700195312\n",
      "  time_total_s: 1629.299599647522\n",
      "  timestamp: 1665272805\n",
      "  timesteps_since_restore: 825000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 825000\n",
      "  training_iteration: 55\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     55 |           1629.3 |      825000 | -1992.47 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-47-14\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1939.4629268996523\n",
      "  episode_reward_min: -7450.783598745398\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 280\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.514\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14238281548023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.104544997215271\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014451735652983189\n",
      "        policy_loss: 0.004712485242635012\n",
      "        total_loss: 2681.9697265625\n",
      "        vf_explained_var: 0.9720291495323181\n",
      "        vf_loss: 2681.962890625\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 838656\n",
      "    sample_time_ms: 27753.979\n",
      "    update_time_ms: 2.883\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.22926829268293\n",
      "    ram_util_percent: 24.134146341463417\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6662718358923\n",
      "    mean_inference_ms: 0.41112985474081853\n",
      "    mean_processing_ms: 4.130355981290104\n",
      "  time_since_restore: 1658.5263583660126\n",
      "  time_this_iter_s: 29.2267587184906\n",
      "  time_total_s: 1658.5263583660126\n",
      "  timestamp: 1665272834\n",
      "  timesteps_since_restore: 840000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 56\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     56 |          1658.53 |      840000 | -1939.46 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-47-43\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1845.2908810742113\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 285\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1477.2\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14238281548023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.0786985531449318\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.10602562874555588\n",
      "        policy_loss: 0.02318735234439373\n",
      "        total_loss: 2453.669677734375\n",
      "        vf_explained_var: 0.9719496965408325\n",
      "        vf_loss: 2453.63134765625\n",
      "    load_time_ms: 2.511\n",
      "    num_steps_sampled: 855000\n",
      "    num_steps_trained: 853632\n",
      "    sample_time_ms: 27763.21\n",
      "    update_time_ms: 2.834\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.92857142857143\n",
      "    ram_util_percent: 24.092857142857145\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.663842875645285\n",
      "    mean_inference_ms: 0.41120353422817324\n",
      "    mean_processing_ms: 4.12946752083313\n",
      "  time_since_restore: 1687.5809915065765\n",
      "  time_this_iter_s: 29.054633140563965\n",
      "  time_total_s: 1687.5809915065765\n",
      "  timestamp: 1665272863\n",
      "  timesteps_since_restore: 855000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 855000\n",
      "  training_iteration: 57\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     57 |          1687.58 |      855000 | -1845.29 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-48-12\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1770.8201275761705\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 290\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1477.46\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.21357421576976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9430171847343445\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00766199454665184\n",
      "        policy_loss: 0.003306817961856723\n",
      "        total_loss: 2872.070068359375\n",
      "        vf_explained_var: 0.9715027809143066\n",
      "        vf_loss: 2872.065185546875\n",
      "    load_time_ms: 2.505\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 868608\n",
      "    sample_time_ms: 27774.232\n",
      "    update_time_ms: 2.828\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34390243902439\n",
      "    ram_util_percent: 24.229268292682924\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.661467818354063\n",
      "    mean_inference_ms: 0.4112676683922305\n",
      "    mean_processing_ms: 4.1285739523426885\n",
      "  time_since_restore: 1716.6267969608307\n",
      "  time_this_iter_s: 29.04580545425415\n",
      "  time_total_s: 1716.6267969608307\n",
      "  timestamp: 1665272892\n",
      "  timesteps_since_restore: 870000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 58\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     58 |          1716.63 |      870000 | -1770.82 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-48-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1750.0492604526223\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 295\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1478.014\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10678710788488388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.2971950173377991\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.11618173122406006\n",
      "        policy_loss: 0.016877248883247375\n",
      "        total_loss: 2354.943115234375\n",
      "        vf_explained_var: 0.9695175886154175\n",
      "        vf_loss: 2354.91357421875\n",
      "    load_time_ms: 2.465\n",
      "    num_steps_sampled: 885000\n",
      "    num_steps_trained: 883584\n",
      "    sample_time_ms: 27745.643\n",
      "    update_time_ms: 2.808\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.21463414634146\n",
      "    ram_util_percent: 24.17317073170732\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.659205132564696\n",
      "    mean_inference_ms: 0.411330217482694\n",
      "    mean_processing_ms: 4.12772324398501\n",
      "  time_since_restore: 1745.400494337082\n",
      "  time_this_iter_s: 28.77369737625122\n",
      "  time_total_s: 1745.400494337082\n",
      "  timestamp: 1665272921\n",
      "  timesteps_since_restore: 885000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 885000\n",
      "  training_iteration: 59\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     59 |           1745.4 |      885000 | -1750.05 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-49-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1643.5427468597793\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 300\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1478.746\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19864723086357117\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010497340932488441\n",
      "        policy_loss: 0.003018787829205394\n",
      "        total_loss: 2798.0283203125\n",
      "        vf_explained_var: 0.9713051319122314\n",
      "        vf_loss: 2798.0234375\n",
      "    load_time_ms: 2.553\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 898560\n",
      "    sample_time_ms: 27712.216\n",
      "    update_time_ms: 2.855\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.37906976744186\n",
      "    ram_util_percent: 24.167441860465118\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.657177096810889\n",
      "    mean_inference_ms: 0.411391999236989\n",
      "    mean_processing_ms: 4.126875240175978\n",
      "  time_since_restore: 1775.0464565753937\n",
      "  time_this_iter_s: 29.645962238311768\n",
      "  time_total_s: 1775.0464565753937\n",
      "  timestamp: 1665272951\n",
      "  timesteps_since_restore: 900000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 60\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     60 |          1775.05 |      900000 | -1643.54 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-49-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1696.356042119165\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 305\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.713\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.27279794216156\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014532058499753475\n",
      "        policy_loss: 0.0023699020966887474\n",
      "        total_loss: 2191.2353515625\n",
      "        vf_explained_var: 0.9841702580451965\n",
      "        vf_loss: 2191.230712890625\n",
      "    load_time_ms: 2.416\n",
      "    num_steps_sampled: 915000\n",
      "    num_steps_trained: 913536\n",
      "    sample_time_ms: 27726.635\n",
      "    update_time_ms: 2.903\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.916666666666664\n",
      "    ram_util_percent: 24.12857142857143\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.655192253703323\n",
      "    mean_inference_ms: 0.41145910287190063\n",
      "    mean_processing_ms: 4.126099613294166\n",
      "  time_since_restore: 1804.3216784000397\n",
      "  time_this_iter_s: 29.275221824645996\n",
      "  time_total_s: 1804.3216784000397\n",
      "  timestamp: 1665272980\n",
      "  timesteps_since_restore: 915000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 915000\n",
      "  training_iteration: 61\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     61 |          1804.32 |      915000 | -1696.36 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-50-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1680.3027013547864\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 310\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.691\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.2821168899536133\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013107813894748688\n",
      "        policy_loss: 0.0014974238583818078\n",
      "        total_loss: 2279.5576171875\n",
      "        vf_explained_var: 0.9777005314826965\n",
      "        vf_loss: 2279.55419921875\n",
      "    load_time_ms: 2.478\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 928512\n",
      "    sample_time_ms: 27750.658\n",
      "    update_time_ms: 2.877\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.646341463414636\n",
      "    ram_util_percent: 24.190243902439022\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.653152536538129\n",
      "    mean_inference_ms: 0.41152249489943105\n",
      "    mean_processing_ms: 4.125386698850484\n",
      "  time_since_restore: 1833.468535900116\n",
      "  time_this_iter_s: 29.146857500076294\n",
      "  time_total_s: 1833.468535900116\n",
      "  timestamp: 1665273009\n",
      "  timesteps_since_restore: 930000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 62\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     62 |          1833.47 |      930000 |  -1680.3 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-50-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1607.1807862135693\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 315\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.492\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.9898887276649475\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010449322871863842\n",
      "        policy_loss: 0.0031775448005646467\n",
      "        total_loss: 2082.80126953125\n",
      "        vf_explained_var: 0.9776167273521423\n",
      "        vf_loss: 2082.79638671875\n",
      "    load_time_ms: 2.469\n",
      "    num_steps_sampled: 945000\n",
      "    num_steps_trained: 943488\n",
      "    sample_time_ms: 27696.193\n",
      "    update_time_ms: 2.958\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.15952380952382\n",
      "    ram_util_percent: 24.16904761904762\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.651240689242943\n",
      "    mean_inference_ms: 0.411587677598947\n",
      "    mean_processing_ms: 4.12465288620989\n",
      "  time_since_restore: 1862.5683104991913\n",
      "  time_this_iter_s: 29.099774599075317\n",
      "  time_total_s: 1862.5683104991913\n",
      "  timestamp: 1665273038\n",
      "  timesteps_since_restore: 945000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 945000\n",
      "  training_iteration: 63\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     63 |          1862.57 |      945000 | -1607.18 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-51-07\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1485.4049755701476\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 320\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.367\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1134485006332397\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018898412585258484\n",
      "        policy_loss: 0.0060987588949501514\n",
      "        total_loss: 2155.045654296875\n",
      "        vf_explained_var: 0.9729171395301819\n",
      "        vf_loss: 2155.03662109375\n",
      "    load_time_ms: 2.556\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 958464\n",
      "    sample_time_ms: 27635.638\n",
      "    update_time_ms: 2.965\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.22195121951219\n",
      "    ram_util_percent: 24.17317073170732\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.64947870790002\n",
      "    mean_inference_ms: 0.4116547448117834\n",
      "    mean_processing_ms: 4.123912570589144\n",
      "  time_since_restore: 1891.3591330051422\n",
      "  time_this_iter_s: 28.790822505950928\n",
      "  time_total_s: 1891.3591330051422\n",
      "  timestamp: 1665273067\n",
      "  timesteps_since_restore: 960000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 64\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     64 |          1891.36 |      960000 |  -1485.4 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-51-37\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1396.0062109226883\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 325\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.924\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3322689533233643\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.036324601620435715\n",
      "        policy_loss: 0.0033697618637233973\n",
      "        total_loss: 2038.3165283203125\n",
      "        vf_explained_var: 0.9757378697395325\n",
      "        vf_loss: 2038.3072509765625\n",
      "    load_time_ms: 2.552\n",
      "    num_steps_sampled: 975000\n",
      "    num_steps_trained: 973440\n",
      "    sample_time_ms: 27655.695\n",
      "    update_time_ms: 2.952\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.92142857142857\n",
      "    ram_util_percent: 24.17142857142857\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.647828926206447\n",
      "    mean_inference_ms: 0.41172937312919616\n",
      "    mean_processing_ms: 4.123286897053825\n",
      "  time_since_restore: 1920.7764110565186\n",
      "  time_this_iter_s: 29.417278051376343\n",
      "  time_total_s: 1920.7764110565186\n",
      "  timestamp: 1665273097\n",
      "  timesteps_since_restore: 975000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 975000\n",
      "  training_iteration: 65\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     65 |          1920.78 |      975000 | -1396.01 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-52-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1379.3434598279068\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 330\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.077\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8931322693824768\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.07058688253164291\n",
      "        policy_loss: 0.015435976907610893\n",
      "        total_loss: 2980.332763671875\n",
      "        vf_explained_var: 0.9777279496192932\n",
      "        vf_loss: 2980.30615234375\n",
      "    load_time_ms: 2.518\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 988416\n",
      "    sample_time_ms: 27656.018\n",
      "    update_time_ms: 2.97\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.15714285714286\n",
      "    ram_util_percent: 24.18809523809524\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.646261063980285\n",
      "    mean_inference_ms: 0.41179936748079476\n",
      "    mean_processing_ms: 4.122653741685557\n",
      "  time_since_restore: 1950.0176723003387\n",
      "  time_this_iter_s: 29.24126124382019\n",
      "  time_total_s: 1950.0176723003387\n",
      "  timestamp: 1665273126\n",
      "  timesteps_since_restore: 990000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 66\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     66 |          1950.02 |      990000 | -1379.34 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-52-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1443.3046977791091\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 335\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.815\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.24027100205421448\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9352211356163025\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008084884844720364\n",
      "        policy_loss: -0.0007713447557762265\n",
      "        total_loss: 4086.717529296875\n",
      "        vf_explained_var: 0.9664185643196106\n",
      "        vf_loss: 4086.716064453125\n",
      "    load_time_ms: 2.5\n",
      "    num_steps_sampled: 1005000\n",
      "    num_steps_trained: 1003392\n",
      "    sample_time_ms: 27655.23\n",
      "    update_time_ms: 2.972\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.78048780487805\n",
      "    ram_util_percent: 24.168292682926833\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.644702932491251\n",
      "    mean_inference_ms: 0.4118644929322724\n",
      "    mean_processing_ms: 4.122086680489302\n",
      "  time_since_restore: 1979.071202993393\n",
      "  time_this_iter_s: 29.0535306930542\n",
      "  time_total_s: 1979.071202993393\n",
      "  timestamp: 1665273155\n",
      "  timesteps_since_restore: 1005000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1005000\n",
      "  training_iteration: 67\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     67 |          1979.07 |     1005000 |  -1443.3 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-53-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1543.699431703233\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 340\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.173\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.323654055595398\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014535913243889809\n",
      "        policy_loss: 0.00452587241306901\n",
      "        total_loss: 6282.7119140625\n",
      "        vf_explained_var: 0.9518312215805054\n",
      "        vf_loss: 6282.70654296875\n",
      "    load_time_ms: 2.625\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1018368\n",
      "    sample_time_ms: 27665.03\n",
      "    update_time_ms: 2.871\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.31666666666668\n",
      "    ram_util_percent: 24.199999999999996\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6432205958090265\n",
      "    mean_inference_ms: 0.41193652167656664\n",
      "    mean_processing_ms: 4.121626882430888\n",
      "  time_since_restore: 2008.2087144851685\n",
      "  time_this_iter_s: 29.137511491775513\n",
      "  time_total_s: 2008.2087144851685\n",
      "  timestamp: 1665273184\n",
      "  timesteps_since_restore: 1020000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 68\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     68 |          2008.21 |     1020000 |  -1543.7 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-53-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1598.5367797497427\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 345\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.461\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.06891930103302002\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.034609146416187286\n",
      "        policy_loss: 0.009135644882917404\n",
      "        total_loss: 3792.73046875\n",
      "        vf_explained_var: 0.9718257784843445\n",
      "        vf_loss: 3792.71630859375\n",
      "    load_time_ms: 2.538\n",
      "    num_steps_sampled: 1035000\n",
      "    num_steps_trained: 1033344\n",
      "    sample_time_ms: 27792.357\n",
      "    update_time_ms: 2.754\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.0452380952381\n",
      "    ram_util_percent: 24.214285714285715\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.64170435433812\n",
      "    mean_inference_ms: 0.4120013243773851\n",
      "    mean_processing_ms: 4.121494754899889\n",
      "  time_since_restore: 2038.2466099262238\n",
      "  time_this_iter_s: 30.037895441055298\n",
      "  time_total_s: 2038.2466099262238\n",
      "  timestamp: 1665273214\n",
      "  timesteps_since_restore: 1035000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1035000\n",
      "  training_iteration: 69\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     69 |          2038.25 |     1035000 | -1598.54 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-54-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1627.5485976016726\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 350\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.963\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2026757299900055\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013194246217608452\n",
      "        policy_loss: 0.002526839729398489\n",
      "        total_loss: 3083.585205078125\n",
      "        vf_explained_var: 0.9770655632019043\n",
      "        vf_loss: 3083.581298828125\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1048320\n",
      "    sample_time_ms: 27726.399\n",
      "    update_time_ms: 2.846\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.06428571428572\n",
      "    ram_util_percent: 24.202380952380945\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.640196673978032\n",
      "    mean_inference_ms: 0.4120589619950139\n",
      "    mean_processing_ms: 4.121157611385666\n",
      "  time_since_restore: 2067.2586171627045\n",
      "  time_this_iter_s: 29.012007236480713\n",
      "  time_total_s: 2067.2586171627045\n",
      "  timestamp: 1665273243\n",
      "  timesteps_since_restore: 1050000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 70\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     70 |          2067.26 |     1050000 | -1627.55 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-54-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1557.100542400353\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 355\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.268\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.848048210144043\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02766149304807186\n",
      "        policy_loss: 0.005472071003168821\n",
      "        total_loss: 2681.08203125\n",
      "        vf_explained_var: 0.9621966481208801\n",
      "        vf_loss: 2681.072998046875\n",
      "    load_time_ms: 2.647\n",
      "    num_steps_sampled: 1065000\n",
      "    num_steps_trained: 1063296\n",
      "    sample_time_ms: 27713.835\n",
      "    update_time_ms: 2.827\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.247619047619054\n",
      "    ram_util_percent: 24.18809523809524\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.638775797410336\n",
      "    mean_inference_ms: 0.4121152694859346\n",
      "    mean_processing_ms: 4.120821069964958\n",
      "  time_since_restore: 2096.4127728939056\n",
      "  time_this_iter_s: 29.154155731201172\n",
      "  time_total_s: 2096.4127728939056\n",
      "  timestamp: 1665273273\n",
      "  timesteps_since_restore: 1065000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1065000\n",
      "  training_iteration: 71\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     71 |          2096.41 |     1065000 |  -1557.1 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-55-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1504.751640110329\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 360\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.342\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.08287081867456436\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.22376243770122528\n",
      "        policy_loss: 0.02846589870750904\n",
      "        total_loss: 4492.29736328125\n",
      "        vf_explained_var: 0.959092378616333\n",
      "        vf_loss: 4492.2421875\n",
      "    load_time_ms: 2.596\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1078272\n",
      "    sample_time_ms: 27641.456\n",
      "    update_time_ms: 2.865\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.5375\n",
      "    ram_util_percent: 24.244999999999997\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.637346608044783\n",
      "    mean_inference_ms: 0.412169219739403\n",
      "    mean_processing_ms: 4.120528762084245\n",
      "  time_since_restore: 2124.8368389606476\n",
      "  time_this_iter_s: 28.424066066741943\n",
      "  time_total_s: 2124.8368389606476\n",
      "  timestamp: 1665273301\n",
      "  timesteps_since_restore: 1080000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 72\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     72 |          2124.84 |     1080000 | -1504.75 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-55-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1535.3853648337235\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 365\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.424\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.18020324409008026\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1623600572347641\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007445329334586859\n",
      "        policy_loss: 1.0585747077129781e-05\n",
      "        total_loss: 2328.591552734375\n",
      "        vf_explained_var: 0.9848737716674805\n",
      "        vf_loss: 2328.590087890625\n",
      "    load_time_ms: 2.556\n",
      "    num_steps_sampled: 1095000\n",
      "    num_steps_trained: 1093248\n",
      "    sample_time_ms: 27622.159\n",
      "    update_time_ms: 2.744\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.44634146341463\n",
      "    ram_util_percent: 24.19268292682927\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.635964229989829\n",
      "    mean_inference_ms: 0.41221627779817394\n",
      "    mean_processing_ms: 4.120168409084132\n",
      "  time_since_restore: 2153.7427775859833\n",
      "  time_this_iter_s: 28.905938625335693\n",
      "  time_total_s: 2153.7427775859833\n",
      "  timestamp: 1665273330\n",
      "  timesteps_since_restore: 1095000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1095000\n",
      "  training_iteration: 73\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     73 |          2153.74 |     1095000 | -1535.39 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-55-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1346.9378549661\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 370\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.438\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09010162204504013\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.424919605255127\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017055783420801163\n",
      "        policy_loss: 0.0020091894548386335\n",
      "        total_loss: 3906.638671875\n",
      "        vf_explained_var: 0.9603806138038635\n",
      "        vf_loss: 3906.63525390625\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1108224\n",
      "    sample_time_ms: 27656.205\n",
      "    update_time_ms: 2.707\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.53571428571429\n",
      "    ram_util_percent: 24.240476190476187\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.634652302975045\n",
      "    mean_inference_ms: 0.41225765444959833\n",
      "    mean_processing_ms: 4.119837657769072\n",
      "  time_since_restore: 2182.863212585449\n",
      "  time_this_iter_s: 29.120434999465942\n",
      "  time_total_s: 2182.863212585449\n",
      "  timestamp: 1665273359\n",
      "  timesteps_since_restore: 1110000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 74\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     74 |          2182.86 |     1110000 | -1346.94 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1325.5982324864922\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 375\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.68\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09010162204504013\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3788661062717438\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0099959596991539\n",
      "        policy_loss: -0.0003471083182375878\n",
      "        total_loss: 3430.6884765625\n",
      "        vf_explained_var: 0.9789103269577026\n",
      "        vf_loss: 3430.687744140625\n",
      "    load_time_ms: 2.404\n",
      "    num_steps_sampled: 1125000\n",
      "    num_steps_trained: 1123200\n",
      "    sample_time_ms: 27658.698\n",
      "    update_time_ms: 2.668\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.21666666666667\n",
      "    ram_util_percent: 24.202380952380956\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.633487369221881\n",
      "    mean_inference_ms: 0.41230371052620124\n",
      "    mean_processing_ms: 4.119520662370051\n",
      "  time_since_restore: 2212.3059737682343\n",
      "  time_this_iter_s: 29.442761182785034\n",
      "  time_total_s: 2212.3059737682343\n",
      "  timestamp: 1665273389\n",
      "  timesteps_since_restore: 1125000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1125000\n",
      "  training_iteration: 75\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     75 |          2212.31 |     1125000 |  -1325.6 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-56-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1215.7969022734956\n",
      "  episode_reward_min: -6797.021123619138\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 380\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.746\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0349434614181519\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011094636283814907\n",
      "        policy_loss: 0.0025965706445276737\n",
      "        total_loss: 2098.9150390625\n",
      "        vf_explained_var: 0.9856294393539429\n",
      "        vf_loss: 2098.912109375\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1138176\n",
      "    sample_time_ms: 27627.776\n",
      "    update_time_ms: 2.685\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.082926829268295\n",
      "    ram_util_percent: 24.236585365853657\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.632361228522145\n",
      "    mean_inference_ms: 0.41234417606944446\n",
      "    mean_processing_ms: 4.11917593005291\n",
      "  time_since_restore: 2241.229974746704\n",
      "  time_this_iter_s: 28.92400097846985\n",
      "  time_total_s: 2241.229974746704\n",
      "  timestamp: 1665273417\n",
      "  timesteps_since_restore: 1140000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 76\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     76 |          2241.23 |     1140000 |  -1215.8 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-57-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1350.2941063699932\n",
      "  episode_reward_mean: -1299.9205328159087\n",
      "  episode_reward_min: -6797.021123619138\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 385\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.074\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.997388243675232\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013290481641888618\n",
      "        policy_loss: 0.0025325173046439886\n",
      "        total_loss: 4463.45263671875\n",
      "        vf_explained_var: 0.9755052924156189\n",
      "        vf_loss: 4463.44921875\n",
      "    load_time_ms: 2.471\n",
      "    num_steps_sampled: 1155000\n",
      "    num_steps_trained: 1153152\n",
      "    sample_time_ms: 27612.578\n",
      "    update_time_ms: 2.703\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.99285714285714\n",
      "    ram_util_percent: 24.219047619047622\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.631222066355051\n",
      "    mean_inference_ms: 0.4123871431758259\n",
      "    mean_processing_ms: 4.118856707548836\n",
      "  time_since_restore: 2270.1248359680176\n",
      "  time_this_iter_s: 28.894861221313477\n",
      "  time_total_s: 2270.1248359680176\n",
      "  timestamp: 1665273446\n",
      "  timesteps_since_restore: 1155000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1155000\n",
      "  training_iteration: 77\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     77 |          2270.12 |     1155000 | -1299.92 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-57-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1350.2941063699932\n",
      "  episode_reward_mean: -1216.3572017872561\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 390\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.574\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5149365067481995\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.039941683411598206\n",
      "        policy_loss: -0.0030962007585912943\n",
      "        total_loss: 3147.349365234375\n",
      "        vf_explained_var: 0.9782958030700684\n",
      "        vf_loss: 3147.3505859375\n",
      "    load_time_ms: 2.509\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1168128\n",
      "    sample_time_ms: 27592.216\n",
      "    update_time_ms: 2.825\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.01951219512195\n",
      "    ram_util_percent: 24.226829268292683\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.630116006330648\n",
      "    mean_inference_ms: 0.4124292672199397\n",
      "    mean_processing_ms: 4.11856699269013\n",
      "  time_since_restore: 2299.066123008728\n",
      "  time_this_iter_s: 28.94128704071045\n",
      "  time_total_s: 2299.066123008728\n",
      "  timestamp: 1665273475\n",
      "  timesteps_since_restore: 1170000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 78\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     78 |          2299.07 |     1170000 | -1216.36 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-58-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1350.2941063699932\n",
      "  episode_reward_mean: -1181.6650592703515\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 395\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.048\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5619403123855591\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018223034217953682\n",
      "        policy_loss: 0.0015551141696050763\n",
      "        total_loss: 2936.881103515625\n",
      "        vf_explained_var: 0.9762338399887085\n",
      "        vf_loss: 2936.87890625\n",
      "    load_time_ms: 2.636\n",
      "    num_steps_sampled: 1185000\n",
      "    num_steps_trained: 1183104\n",
      "    sample_time_ms: 27558.854\n",
      "    update_time_ms: 2.8\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.50714285714285\n",
      "    ram_util_percent: 24.338095238095235\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.62920109567249\n",
      "    mean_inference_ms: 0.41248151031541497\n",
      "    mean_processing_ms: 4.118302959255484\n",
      "  time_since_restore: 2328.7762808799744\n",
      "  time_this_iter_s: 29.710157871246338\n",
      "  time_total_s: 2328.7762808799744\n",
      "  timestamp: 1665273505\n",
      "  timesteps_since_restore: 1185000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1185000\n",
      "  training_iteration: 79\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     79 |          2328.78 |     1185000 | -1181.67 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-58-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2263.235322337614\n",
      "  episode_reward_mean: -1131.1405425671294\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 400\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.356\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.812896192073822\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0166899673640728\n",
      "        policy_loss: -0.0001831790868891403\n",
      "        total_loss: 2929.33837890625\n",
      "        vf_explained_var: 0.9759217500686646\n",
      "        vf_loss: 2929.337890625\n",
      "    load_time_ms: 2.626\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1198080\n",
      "    sample_time_ms: 27677.271\n",
      "    update_time_ms: 2.659\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.06511627906977\n",
      "    ram_util_percent: 24.265116279069765\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.628283609913923\n",
      "    mean_inference_ms: 0.4125292786339454\n",
      "    mean_processing_ms: 4.118211449411464\n",
      "  time_since_restore: 2358.9538543224335\n",
      "  time_this_iter_s: 30.177573442459106\n",
      "  time_total_s: 2358.9538543224335\n",
      "  timestamp: 1665273535\n",
      "  timesteps_since_restore: 1200000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 80\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     80 |          2358.95 |     1200000 | -1131.14 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-59-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2263.235322337614\n",
      "  episode_reward_mean: -1014.8624565898383\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 405\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.593\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8254194259643555\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024917250499129295\n",
      "        policy_loss: 0.00222373497672379\n",
      "        total_loss: 2083.748779296875\n",
      "        vf_explained_var: 0.9825114011764526\n",
      "        vf_loss: 2083.74560546875\n",
      "    load_time_ms: 2.554\n",
      "    num_steps_sampled: 1215000\n",
      "    num_steps_trained: 1213056\n",
      "    sample_time_ms: 27689.456\n",
      "    update_time_ms: 2.624\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.945238095238096\n",
      "    ram_util_percent: 24.266666666666666\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.62739736370733\n",
      "    mean_inference_ms: 0.4125748431959476\n",
      "    mean_processing_ms: 4.11810281663075\n",
      "  time_since_restore: 2388.2311573028564\n",
      "  time_this_iter_s: 29.277302980422974\n",
      "  time_total_s: 2388.2311573028564\n",
      "  timestamp: 1665273565\n",
      "  timesteps_since_restore: 1215000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1215000\n",
      "  training_iteration: 81\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     81 |          2388.23 |     1215000 | -1014.86 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-59-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2263.235322337614\n",
      "  episode_reward_mean: -1069.6952347046788\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 410\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.398\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.808097779750824\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.3199496865272522\n",
      "        policy_loss: 0.038910288363695145\n",
      "        total_loss: 5179.810546875\n",
      "        vf_explained_var: 0.9700908064842224\n",
      "        vf_loss: 5179.7568359375\n",
      "    load_time_ms: 2.423\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1228032\n",
      "    sample_time_ms: 27757.205\n",
      "    update_time_ms: 2.581\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.57619047619047\n",
      "    ram_util_percent: 24.266666666666662\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.626478831989462\n",
      "    mean_inference_ms: 0.41261750850277035\n",
      "    mean_processing_ms: 4.1179999343943505\n",
      "  time_since_restore: 2417.3286724090576\n",
      "  time_this_iter_s: 29.097515106201172\n",
      "  time_total_s: 2417.3286724090576\n",
      "  timestamp: 1665273594\n",
      "  timesteps_since_restore: 1230000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 82\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     82 |          2417.33 |     1230000 |  -1069.7 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-00-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1072.8873881331706\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 415\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.121\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06757621467113495\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4440262019634247\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018486035987734795\n",
      "        policy_loss: 0.0022734208032488823\n",
      "        total_loss: 2788.25732421875\n",
      "        vf_explained_var: 0.9804291129112244\n",
      "        vf_loss: 2788.25390625\n",
      "    load_time_ms: 2.386\n",
      "    num_steps_sampled: 1245000\n",
      "    num_steps_trained: 1243008\n",
      "    sample_time_ms: 27890.968\n",
      "    update_time_ms: 2.697\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.16046511627906\n",
      "    ram_util_percent: 24.279069767441854\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.625627231812884\n",
      "    mean_inference_ms: 0.4126605268403466\n",
      "    mean_processing_ms: 4.118036913146782\n",
      "  time_since_restore: 2447.560133934021\n",
      "  time_this_iter_s: 30.23146152496338\n",
      "  time_total_s: 2447.560133934021\n",
      "  timestamp: 1665273624\n",
      "  timesteps_since_restore: 1245000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1245000\n",
      "  training_iteration: 83\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     83 |          2447.56 |     1245000 | -1072.89 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-00-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1162.7323584375397\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 420\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.811\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06757621467113495\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.3736580610275269\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010879043489694595\n",
      "        policy_loss: 0.0018454903038218617\n",
      "        total_loss: 3875.99365234375\n",
      "        vf_explained_var: 0.9795897603034973\n",
      "        vf_loss: 3875.991455078125\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1257984\n",
      "    sample_time_ms: 27952.719\n",
      "    update_time_ms: 2.754\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.895348837209305\n",
      "    ram_util_percent: 24.267441860465112\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.624764202128018\n",
      "    mean_inference_ms: 0.4126962837501578\n",
      "    mean_processing_ms: 4.1182108699248205\n",
      "  time_since_restore: 2477.2963902950287\n",
      "  time_this_iter_s: 29.73625636100769\n",
      "  time_total_s: 2477.2963902950287\n",
      "  timestamp: 1665273654\n",
      "  timesteps_since_restore: 1260000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 84\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     84 |           2477.3 |     1260000 | -1162.73 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-01-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1240.4845996441977\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 425\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.354\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06757621467113495\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19314377009868622\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009139331988990307\n",
      "        policy_loss: -0.0003545279905665666\n",
      "        total_loss: 6355.0546875\n",
      "        vf_explained_var: 0.9592911005020142\n",
      "        vf_loss: 6355.05517578125\n",
      "    load_time_ms: 2.568\n",
      "    num_steps_sampled: 1275000\n",
      "    num_steps_trained: 1272960\n",
      "    sample_time_ms: 27873.397\n",
      "    update_time_ms: 2.846\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.25853658536586\n",
      "    ram_util_percent: 24.26829268292683\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.623830316594058\n",
      "    mean_inference_ms: 0.41272566607209316\n",
      "    mean_processing_ms: 4.11832603612715\n",
      "  time_since_restore: 2505.9441890716553\n",
      "  time_this_iter_s: 28.647798776626587\n",
      "  time_total_s: 2505.9441890716553\n",
      "  timestamp: 1665273683\n",
      "  timesteps_since_restore: 1275000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1275000\n",
      "  training_iteration: 85\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     85 |          2505.94 |     1275000 | -1240.48 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-01-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1264.4583999048148\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 430\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.033\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.033788107335567474\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4460644721984863\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0098287183791399\n",
      "        policy_loss: 0.002172253793105483\n",
      "        total_loss: 5743.85986328125\n",
      "        vf_explained_var: 0.9693247675895691\n",
      "        vf_loss: 5743.857421875\n",
      "    load_time_ms: 2.522\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1287936\n",
      "    sample_time_ms: 27900.705\n",
      "    update_time_ms: 2.863\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00731707317074\n",
      "    ram_util_percent: 24.287804878048778\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.622879477121413\n",
      "    mean_inference_ms: 0.41275208407975045\n",
      "    mean_processing_ms: 4.1184102999157775\n",
      "  time_since_restore: 2535.157905817032\n",
      "  time_this_iter_s: 29.213716745376587\n",
      "  time_total_s: 2535.157905817032\n",
      "  timestamp: 1665273712\n",
      "  timesteps_since_restore: 1290000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 86\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     86 |          2535.16 |     1290000 | -1264.46 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-02-21\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1137.0350168708862\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 435\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.524\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.016894053667783737\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.166917324066162\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023554105311632156\n",
      "        policy_loss: 0.0023250493686646223\n",
      "        total_loss: 2347.670654296875\n",
      "        vf_explained_var: 0.9792936444282532\n",
      "        vf_loss: 2347.66796875\n",
      "    load_time_ms: 2.397\n",
      "    num_steps_sampled: 1305000\n",
      "    num_steps_trained: 1302912\n",
      "    sample_time_ms: 27937.159\n",
      "    update_time_ms: 2.82\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.38095238095238\n",
      "    ram_util_percent: 24.29523809523809\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.622045861554236\n",
      "    mean_inference_ms: 0.41277879178279114\n",
      "    mean_processing_ms: 4.118502520123163\n",
      "  time_since_restore: 2564.440548658371\n",
      "  time_this_iter_s: 29.28264284133911\n",
      "  time_total_s: 2564.440548658371\n",
      "  timestamp: 1665273741\n",
      "  timesteps_since_restore: 1305000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1305000\n",
      "  training_iteration: 87\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     87 |          2564.44 |     1305000 | -1137.04 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-02-50\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1072.5851958114433\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 440\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.789\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.016894053667783737\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4312853217124939\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01877225935459137\n",
      "        policy_loss: 0.000625555869191885\n",
      "        total_loss: 4533.39306640625\n",
      "        vf_explained_var: 0.9743164777755737\n",
      "        vf_loss: 4533.392578125\n",
      "    load_time_ms: 2.233\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1317888\n",
      "    sample_time_ms: 27959.998\n",
      "    update_time_ms: 2.828\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.93571428571428\n",
      "    ram_util_percent: 24.30952380952381\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.621219524822948\n",
      "    mean_inference_ms: 0.4127961959813982\n",
      "    mean_processing_ms: 4.118555760192853\n",
      "  time_since_restore: 2593.6007521152496\n",
      "  time_this_iter_s: 29.160203456878662\n",
      "  time_total_s: 2593.6007521152496\n",
      "  timestamp: 1665273770\n",
      "  timesteps_since_restore: 1320000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 88\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     88 |           2593.6 |     1320000 | -1072.59 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-03-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -994.0837233174545\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 445\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.548\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.016894053667783737\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1237246990203857\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.07027580589056015\n",
      "        policy_loss: 0.0005361157818697393\n",
      "        total_loss: 3330.48388671875\n",
      "        vf_explained_var: 0.9840324521064758\n",
      "        vf_loss: 3330.482177734375\n",
      "    load_time_ms: 2.202\n",
      "    num_steps_sampled: 1335000\n",
      "    num_steps_trained: 1332864\n",
      "    sample_time_ms: 27896.071\n",
      "    update_time_ms: 2.81\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.119512195121956\n",
      "    ram_util_percent: 24.399999999999995\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.620453602580143\n",
      "    mean_inference_ms: 0.4128161820084811\n",
      "    mean_processing_ms: 4.118350489021236\n",
      "  time_since_restore: 2622.6685638427734\n",
      "  time_this_iter_s: 29.067811727523804\n",
      "  time_total_s: 2622.6685638427734\n",
      "  timestamp: 1665273799\n",
      "  timesteps_since_restore: 1335000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1335000\n",
      "  training_iteration: 89\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     89 |          2622.67 |     1335000 | -994.084 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-03-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -959.6790556692515\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 450\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.953\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.28530678153038025\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016675032675266266\n",
      "        policy_loss: 0.0012183149810880423\n",
      "        total_loss: 5623.73974609375\n",
      "        vf_explained_var: 0.969857931137085\n",
      "        vf_loss: 5623.7373046875\n",
      "    load_time_ms: 2.208\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1347840\n",
      "    sample_time_ms: 27793.801\n",
      "    update_time_ms: 2.821\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.80714285714286\n",
      "    ram_util_percent: 24.31904761904762\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.619705383496139\n",
      "    mean_inference_ms: 0.4128338873086125\n",
      "    mean_processing_ms: 4.118130406385417\n",
      "  time_since_restore: 2651.8176307678223\n",
      "  time_this_iter_s: 29.149066925048828\n",
      "  time_total_s: 2651.8176307678223\n",
      "  timestamp: 1665273829\n",
      "  timesteps_since_restore: 1350000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 90\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     90 |          2651.82 |     1350000 | -959.679 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-04-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1066.957102715363\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 455\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.19\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6355162858963013\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01650075986981392\n",
      "        policy_loss: 0.0014366336399689317\n",
      "        total_loss: 4339.79736328125\n",
      "        vf_explained_var: 0.977160632610321\n",
      "        vf_loss: 4339.79541015625\n",
      "    load_time_ms: 2.269\n",
      "    num_steps_sampled: 1365000\n",
      "    num_steps_trained: 1362816\n",
      "    sample_time_ms: 27788.215\n",
      "    update_time_ms: 2.904\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.15714285714285\n",
      "    ram_util_percent: 24.369047619047613\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.618939753996901\n",
      "    mean_inference_ms: 0.41285260425875747\n",
      "    mean_processing_ms: 4.117950541398691\n",
      "  time_since_restore: 2681.0428171157837\n",
      "  time_this_iter_s: 29.225186347961426\n",
      "  time_total_s: 2681.0428171157837\n",
      "  timestamp: 1665273858\n",
      "  timesteps_since_restore: 1365000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1365000\n",
      "  training_iteration: 91\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     91 |          2681.04 |     1365000 | -1066.96 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-04-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -978.7637187619772\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 460\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.884\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8607137799263\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.039683688431978226\n",
      "        policy_loss: 0.004265520256012678\n",
      "        total_loss: 5037.36767578125\n",
      "        vf_explained_var: 0.9618366360664368\n",
      "        vf_loss: 5037.36181640625\n",
      "    load_time_ms: 2.392\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1377792\n",
      "    sample_time_ms: 27824.312\n",
      "    update_time_ms: 2.894\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.780952380952385\n",
      "    ram_util_percent: 24.333333333333332\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.618338055923379\n",
      "    mean_inference_ms: 0.41287272278647463\n",
      "    mean_processing_ms: 4.117790367046256\n",
      "  time_since_restore: 2710.4996354579926\n",
      "  time_this_iter_s: 29.456818342208862\n",
      "  time_total_s: 2710.4996354579926\n",
      "  timestamp: 1665273887\n",
      "  timesteps_since_restore: 1380000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 92\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     92 |           2710.5 |     1380000 | -978.764 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-05-16\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1055.3252169441719\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 465\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.171\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.1694693565368652\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01278998889029026\n",
      "        policy_loss: 0.0036625086795538664\n",
      "        total_loss: 7786.6787109375\n",
      "        vf_explained_var: 0.960544764995575\n",
      "        vf_loss: 7786.67529296875\n",
      "    load_time_ms: 2.481\n",
      "    num_steps_sampled: 1395000\n",
      "    num_steps_trained: 1392768\n",
      "    sample_time_ms: 27695.559\n",
      "    update_time_ms: 2.862\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.75853658536585\n",
      "    ram_util_percent: 24.37073170731707\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.617772997778211\n",
      "    mean_inference_ms: 0.4128977506061277\n",
      "    mean_processing_ms: 4.117620266924131\n",
      "  time_since_restore: 2739.4671897888184\n",
      "  time_this_iter_s: 28.967554330825806\n",
      "  time_total_s: 2739.4671897888184\n",
      "  timestamp: 1665273916\n",
      "  timesteps_since_restore: 1395000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1395000\n",
      "  training_iteration: 93\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     93 |          2739.47 |     1395000 | -1055.33 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-05-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1099.7615214984298\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 470\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.887\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4456946551799774\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01528334990143776\n",
      "        policy_loss: 0.0012774090282619\n",
      "        total_loss: 5059.5634765625\n",
      "        vf_explained_var: 0.9692041277885437\n",
      "        vf_loss: 5059.56103515625\n",
      "    load_time_ms: 2.484\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1407744\n",
      "    sample_time_ms: 27648.878\n",
      "    update_time_ms: 2.843\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.30476190476191\n",
      "    ram_util_percent: 24.364285714285714\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.617235603031214\n",
      "    mean_inference_ms: 0.4129275729249891\n",
      "    mean_processing_ms: 4.117420011938783\n",
      "  time_since_restore: 2768.74352312088\n",
      "  time_this_iter_s: 29.276333332061768\n",
      "  time_total_s: 2768.74352312088\n",
      "  timestamp: 1665273946\n",
      "  timesteps_since_restore: 1410000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 94\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     94 |          2768.74 |     1410000 | -1099.76 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-06-15\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1106.0601510916756\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 475\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.64\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5146192908287048\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026105094701051712\n",
      "        policy_loss: 0.0005025003920309246\n",
      "        total_loss: 4274.2919921875\n",
      "        vf_explained_var: 0.9779508709907532\n",
      "        vf_loss: 4274.291015625\n",
      "    load_time_ms: 2.455\n",
      "    num_steps_sampled: 1425000\n",
      "    num_steps_trained: 1422720\n",
      "    sample_time_ms: 27682.054\n",
      "    update_time_ms: 2.838\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.6219512195122\n",
      "    ram_util_percent: 24.39512195121951\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.616620585871333\n",
      "    mean_inference_ms: 0.41295588171825814\n",
      "    mean_processing_ms: 4.117196417199374\n",
      "  time_since_restore: 2797.7398715019226\n",
      "  time_this_iter_s: 28.99634838104248\n",
      "  time_total_s: 2797.7398715019226\n",
      "  timestamp: 1665273975\n",
      "  timesteps_since_restore: 1425000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1425000\n",
      "  training_iteration: 95\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     95 |          2797.74 |     1425000 | -1106.06 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-06-44\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1116.84102316599\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 480\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.439\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8432796597480774\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013970511965453625\n",
      "        policy_loss: 0.0013001176994293928\n",
      "        total_loss: 4018.2099609375\n",
      "        vf_explained_var: 0.9740858674049377\n",
      "        vf_loss: 4018.208984375\n",
      "    load_time_ms: 2.448\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1437696\n",
      "    sample_time_ms: 27678.052\n",
      "    update_time_ms: 2.719\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34047619047618\n",
      "    ram_util_percent: 24.388095238095236\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.616006356778933\n",
      "    mean_inference_ms: 0.4129869700141948\n",
      "    mean_processing_ms: 4.1169811176130455\n",
      "  time_since_restore: 2826.890300512314\n",
      "  time_this_iter_s: 29.150429010391235\n",
      "  time_total_s: 2826.890300512314\n",
      "  timestamp: 1665274004\n",
      "  timesteps_since_restore: 1440000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 96\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     96 |          2826.89 |     1440000 | -1116.84 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-07-13\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1107.065118037445\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 485\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.358\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.376842498779297\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01408358197659254\n",
      "        policy_loss: 0.004214771091938019\n",
      "        total_loss: 5271.771484375\n",
      "        vf_explained_var: 0.9773116111755371\n",
      "        vf_loss: 5271.7666015625\n",
      "    load_time_ms: 2.575\n",
      "    num_steps_sampled: 1455000\n",
      "    num_steps_trained: 1452672\n",
      "    sample_time_ms: 27647.256\n",
      "    update_time_ms: 2.78\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.75121951219512\n",
      "    ram_util_percent: 24.397560975609757\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.615436395434574\n",
      "    mean_inference_ms: 0.4130147908395112\n",
      "    mean_processing_ms: 4.11680357957954\n",
      "  time_since_restore: 2855.846254348755\n",
      "  time_this_iter_s: 28.95595383644104\n",
      "  time_total_s: 2855.846254348755\n",
      "  timestamp: 1665274033\n",
      "  timesteps_since_restore: 1455000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1455000\n",
      "  training_iteration: 97\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     97 |          2855.85 |     1455000 | -1107.07 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-07-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1135.0522104188042\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 490\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.716\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.457065224647522\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016824068501591682\n",
      "        policy_loss: -0.00010781015589600429\n",
      "        total_loss: 6190.90478515625\n",
      "        vf_explained_var: 0.9712573289871216\n",
      "        vf_loss: 6190.904296875\n",
      "    load_time_ms: 2.579\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1467648\n",
      "    sample_time_ms: 27653.829\n",
      "    update_time_ms: 2.774\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.59285714285714\n",
      "    ram_util_percent: 24.38095238095238\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.614928832718096\n",
      "    mean_inference_ms: 0.413041593528869\n",
      "    mean_processing_ms: 4.116582579432514\n",
      "  time_since_restore: 2885.0860941410065\n",
      "  time_this_iter_s: 29.239839792251587\n",
      "  time_total_s: 2885.0860941410065\n",
      "  timestamp: 1665274062\n",
      "  timesteps_since_restore: 1470000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 98\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     98 |          2885.09 |     1470000 | -1135.05 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-08-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1145.8055458351268\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 495\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.586\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5346613526344299\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.047078538686037064\n",
      "        policy_loss: -0.0001362111943308264\n",
      "        total_loss: 4071.994873046875\n",
      "        vf_explained_var: 0.9742745161056519\n",
      "        vf_loss: 4071.993896484375\n",
      "    load_time_ms: 2.641\n",
      "    num_steps_sampled: 1485000\n",
      "    num_steps_trained: 1482624\n",
      "    sample_time_ms: 27688.379\n",
      "    update_time_ms: 2.901\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.55\n",
      "    ram_util_percent: 24.511904761904763\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6143297682504265\n",
      "    mean_inference_ms: 0.41306229453780574\n",
      "    mean_processing_ms: 4.116454317768105\n",
      "  time_since_restore: 2914.490220785141\n",
      "  time_this_iter_s: 29.40412664413452\n",
      "  time_total_s: 2914.490220785141\n",
      "  timestamp: 1665274091\n",
      "  timesteps_since_restore: 1485000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1485000\n",
      "  training_iteration: 99\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     99 |          2914.49 |     1485000 | -1145.81 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1083.5306336457922\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 500\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.541\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03801162168383598\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.692762017250061\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03342410549521446\n",
      "        policy_loss: 0.004095843061804771\n",
      "        total_loss: 2646.354248046875\n",
      "        vf_explained_var: 0.9727556705474854\n",
      "        vf_loss: 2646.34912109375\n",
      "    load_time_ms: 2.611\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1497600\n",
      "    sample_time_ms: 27762.694\n",
      "    update_time_ms: 2.872\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.127906976744185\n",
      "    ram_util_percent: 24.444186046511632\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.613803361673012\n",
      "    mean_inference_ms: 0.41309183873977173\n",
      "    mean_processing_ms: 4.116190039670774\n",
      "  time_since_restore: 2944.381718635559\n",
      "  time_this_iter_s: 29.89149785041809\n",
      "  time_total_s: 2944.381718635559\n",
      "  timestamp: 1665274121\n",
      "  timesteps_since_restore: 1500000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 100\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    100 |          2944.38 |     1500000 | -1083.53 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-09-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1068.1257062109723\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 505\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.152\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03801162168383598\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3296489715576172\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013097870163619518\n",
      "        policy_loss: 0.001454950892366469\n",
      "        total_loss: 2499.485595703125\n",
      "        vf_explained_var: 0.9798266291618347\n",
      "        vf_loss: 2499.4833984375\n",
      "    load_time_ms: 2.564\n",
      "    num_steps_sampled: 1515000\n",
      "    num_steps_trained: 1512576\n",
      "    sample_time_ms: 27731.759\n",
      "    update_time_ms: 2.889\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.0390243902439\n",
      "    ram_util_percent: 24.38780487804878\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6132359090590915\n",
      "    mean_inference_ms: 0.4131198780951124\n",
      "    mean_processing_ms: 4.115918059297952\n",
      "  time_since_restore: 2973.303131580353\n",
      "  time_this_iter_s: 28.9214129447937\n",
      "  time_total_s: 2973.303131580353\n",
      "  timestamp: 1665274150\n",
      "  timesteps_since_restore: 1515000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1515000\n",
      "  training_iteration: 101\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    101 |           2973.3 |     1515000 | -1068.13 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-09-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1026.0753300720828\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 510\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.383\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03801162168383598\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.20896804332733154\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01642485521733761\n",
      "        policy_loss: 0.001751026837155223\n",
      "        total_loss: 3862.204345703125\n",
      "        vf_explained_var: 0.9791273474693298\n",
      "        vf_loss: 3862.201904296875\n",
      "    load_time_ms: 2.563\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1527552\n",
      "    sample_time_ms: 27700.117\n",
      "    update_time_ms: 2.985\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.919047619047625\n",
      "    ram_util_percent: 24.37142857142857\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.612721741776707\n",
      "    mean_inference_ms: 0.41314864070523205\n",
      "    mean_processing_ms: 4.115606900402228\n",
      "  time_since_restore: 3002.446583032608\n",
      "  time_this_iter_s: 29.14345145225525\n",
      "  time_total_s: 3002.446583032608\n",
      "  timestamp: 1665274180\n",
      "  timesteps_since_restore: 1530000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 102\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    102 |          3002.45 |     1530000 | -1026.08 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-10-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -973.1172966662795\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 515\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.114\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03801162168383598\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.550955891609192\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04918600618839264\n",
      "        policy_loss: 0.006843113340437412\n",
      "        total_loss: 3389.434814453125\n",
      "        vf_explained_var: 0.9743605852127075\n",
      "        vf_loss: 3389.42626953125\n",
      "    load_time_ms: 2.528\n",
      "    num_steps_sampled: 1545000\n",
      "    num_steps_trained: 1542528\n",
      "    sample_time_ms: 27804.665\n",
      "    update_time_ms: 3.003\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.78372093023256\n",
      "    ram_util_percent: 24.406976744186046\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.612220755990965\n",
      "    mean_inference_ms: 0.41317654056976716\n",
      "    mean_processing_ms: 4.115254173786068\n",
      "  time_since_restore: 3032.4468619823456\n",
      "  time_this_iter_s: 30.00027894973755\n",
      "  time_total_s: 3032.4468619823456\n",
      "  timestamp: 1665274210\n",
      "  timesteps_since_restore: 1545000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1545000\n",
      "  training_iteration: 103\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    103 |          3032.45 |     1545000 | -973.117 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-10-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -890.56837859654\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 520\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.063\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0315355062484741\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015799839049577713\n",
      "        policy_loss: 0.0024094178806990385\n",
      "        total_loss: 4196.25732421875\n",
      "        vf_explained_var: 0.9807722568511963\n",
      "        vf_loss: 4196.25390625\n",
      "    load_time_ms: 2.433\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1557504\n",
      "    sample_time_ms: 27763.307\n",
      "    update_time_ms: 3.001\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.12682926829268\n",
      "    ram_util_percent: 24.37073170731707\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.611725380295792\n",
      "    mean_inference_ms: 0.41320727988344935\n",
      "    mean_processing_ms: 4.114794529471978\n",
      "  time_since_restore: 3061.3078916072845\n",
      "  time_this_iter_s: 28.861029624938965\n",
      "  time_total_s: 3061.3078916072845\n",
      "  timestamp: 1665274238\n",
      "  timesteps_since_restore: 1560000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 104\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    104 |          3061.31 |     1560000 | -890.568 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-11-08\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -906.2964870946442\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 525\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.443\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0246442556381226\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02368396706879139\n",
      "        policy_loss: 0.0009363742428831756\n",
      "        total_loss: 6184.32763671875\n",
      "        vf_explained_var: 0.9737696647644043\n",
      "        vf_loss: 6184.3251953125\n",
      "    load_time_ms: 2.502\n",
      "    num_steps_sampled: 1575000\n",
      "    num_steps_trained: 1572480\n",
      "    sample_time_ms: 27767.183\n",
      "    update_time_ms: 2.983\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.64390243902439\n",
      "    ram_util_percent: 24.382926829268293\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.611327785876933\n",
      "    mean_inference_ms: 0.4132401730880676\n",
      "    mean_processing_ms: 4.114352870988591\n",
      "  time_since_restore: 3090.336881160736\n",
      "  time_this_iter_s: 29.028989553451538\n",
      "  time_total_s: 3090.336881160736\n",
      "  timestamp: 1665274268\n",
      "  timesteps_since_restore: 1575000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1575000\n",
      "  training_iteration: 105\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    105 |          3090.34 |     1575000 | -906.296 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-11-36\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -775.117329257706\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 530\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.377\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.6787952184677124\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020935634151101112\n",
      "        policy_loss: 0.0017429315485060215\n",
      "        total_loss: 4265.12451171875\n",
      "        vf_explained_var: 0.964768648147583\n",
      "        vf_loss: 4265.12158203125\n",
      "    load_time_ms: 2.579\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1587456\n",
      "    sample_time_ms: 27742.86\n",
      "    update_time_ms: 3.074\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.647619047619045\n",
      "    ram_util_percent: 24.36904761904762\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.610924656745879\n",
      "    mean_inference_ms: 0.4132712657656342\n",
      "    mean_processing_ms: 4.113916889287072\n",
      "  time_since_restore: 3119.255133628845\n",
      "  time_this_iter_s: 28.91825246810913\n",
      "  time_total_s: 3119.255133628845\n",
      "  timestamp: 1665274296\n",
      "  timesteps_since_restore: 1590000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 106\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    106 |          3119.26 |     1590000 | -775.117 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-12-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -774.3465833524283\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 535\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.309\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3559075593948364\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02046525664627552\n",
      "        policy_loss: 0.00021659984486177564\n",
      "        total_loss: 4622.64111328125\n",
      "        vf_explained_var: 0.9776289463043213\n",
      "        vf_loss: 4622.638671875\n",
      "    load_time_ms: 2.581\n",
      "    num_steps_sampled: 1605000\n",
      "    num_steps_trained: 1602432\n",
      "    sample_time_ms: 27756.017\n",
      "    update_time_ms: 3.047\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.50487804878049\n",
      "    ram_util_percent: 24.4390243902439\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.610486107921224\n",
      "    mean_inference_ms: 0.4133019768702538\n",
      "    mean_processing_ms: 4.113518356882286\n",
      "  time_since_restore: 3148.3614687919617\n",
      "  time_this_iter_s: 29.106335163116455\n",
      "  time_total_s: 3148.3614687919617\n",
      "  timestamp: 1665274326\n",
      "  timesteps_since_restore: 1605000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1605000\n",
      "  training_iteration: 107\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    107 |          3148.36 |     1605000 | -774.347 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-12-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -732.1406269215627\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 540\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.795\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.19983336329460144\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024851800873875618\n",
      "        policy_loss: 0.00487114954739809\n",
      "        total_loss: 4279.40234375\n",
      "        vf_explained_var: 0.9780691266059875\n",
      "        vf_loss: 4279.396484375\n",
      "    load_time_ms: 2.753\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1617408\n",
      "    sample_time_ms: 27761.399\n",
      "    update_time_ms: 3.039\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.99285714285715\n",
      "    ram_util_percent: 24.38095238095238\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.610103842661124\n",
      "    mean_inference_ms: 0.4133355652252865\n",
      "    mean_processing_ms: 4.113089423403107\n",
      "  time_since_restore: 3177.6512031555176\n",
      "  time_this_iter_s: 29.289734363555908\n",
      "  time_total_s: 3177.6512031555176\n",
      "  timestamp: 1665274355\n",
      "  timesteps_since_restore: 1620000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 108\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    108 |          3177.65 |     1620000 | -732.141 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-13-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -738.2907670319129\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 545\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.777\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1907923221588135\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01335362158715725\n",
      "        policy_loss: 0.0007291707443073392\n",
      "        total_loss: 6226.07373046875\n",
      "        vf_explained_var: 0.9580186009407043\n",
      "        vf_loss: 6226.07275390625\n",
      "    load_time_ms: 2.797\n",
      "    num_steps_sampled: 1635000\n",
      "    num_steps_trained: 1632384\n",
      "    sample_time_ms: 27729.307\n",
      "    update_time_ms: 3.048\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.863414634146345\n",
      "    ram_util_percent: 24.470731707317075\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.609745593438416\n",
      "    mean_inference_ms: 0.41337108909180764\n",
      "    mean_processing_ms: 4.112675436873548\n",
      "  time_since_restore: 3206.7446949481964\n",
      "  time_this_iter_s: 29.093491792678833\n",
      "  time_total_s: 3206.7446949481964\n",
      "  timestamp: 1665274384\n",
      "  timesteps_since_restore: 1635000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1635000\n",
      "  training_iteration: 109\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    109 |          3206.74 |     1635000 | -738.291 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-13-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -706.9916580433859\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 550\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.277\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.091225028038025\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02456888183951378\n",
      "        policy_loss: 0.0034188162535429\n",
      "        total_loss: 3945.32666015625\n",
      "        vf_explained_var: 0.9742348790168762\n",
      "        vf_loss: 3945.321533203125\n",
      "    load_time_ms: 2.813\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1647360\n",
      "    sample_time_ms: 27656.415\n",
      "    update_time_ms: 3.095\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.84523809523809\n",
      "    ram_util_percent: 24.469047619047622\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.609390750824523\n",
      "    mean_inference_ms: 0.4134064535551198\n",
      "    mean_processing_ms: 4.112338673093251\n",
      "  time_since_restore: 3235.9027197360992\n",
      "  time_this_iter_s: 29.158024787902832\n",
      "  time_total_s: 3235.9027197360992\n",
      "  timestamp: 1665274413\n",
      "  timesteps_since_restore: 1650000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 110\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    110 |           3235.9 |     1650000 | -706.992 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -658.7625136028649\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 555\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.211\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.722289502620697\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012634229846298695\n",
      "        policy_loss: -0.0009680307703092694\n",
      "        total_loss: 5830.93994140625\n",
      "        vf_explained_var: 0.9719670414924622\n",
      "        vf_loss: 5830.94140625\n",
      "    load_time_ms: 2.721\n",
      "    num_steps_sampled: 1665000\n",
      "    num_steps_trained: 1662336\n",
      "    sample_time_ms: 27741.422\n",
      "    update_time_ms: 3.059\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.33953488372093\n",
      "    ram_util_percent: 24.444186046511632\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.608976947903485\n",
      "    mean_inference_ms: 0.41343649853305264\n",
      "    mean_processing_ms: 4.1121156685435265\n",
      "  time_since_restore: 3265.6723737716675\n",
      "  time_this_iter_s: 29.769654035568237\n",
      "  time_total_s: 3265.6723737716675\n",
      "  timestamp: 1665274443\n",
      "  timesteps_since_restore: 1665000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1665000\n",
      "  training_iteration: 111\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    111 |          3265.67 |     1665000 | -658.763 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-14-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -682.8020698440298\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 560\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.184\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8114820122718811\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.040801290422677994\n",
      "        policy_loss: 0.004419150296598673\n",
      "        total_loss: 5460.3984375\n",
      "        vf_explained_var: 0.9734519720077515\n",
      "        vf_loss: 5460.3916015625\n",
      "    load_time_ms: 2.667\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1677312\n",
      "    sample_time_ms: 27729.79\n",
      "    update_time_ms: 2.997\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.81707317073171\n",
      "    ram_util_percent: 24.39268292682927\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6085706876889345\n",
      "    mean_inference_ms: 0.4134681975584168\n",
      "    mean_processing_ms: 4.111861871979146\n",
      "  time_since_restore: 3294.6982595920563\n",
      "  time_this_iter_s: 29.025885820388794\n",
      "  time_total_s: 3294.6982595920563\n",
      "  timestamp: 1665274472\n",
      "  timesteps_since_restore: 1680000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 112\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    112 |           3294.7 |     1680000 | -682.802 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-15-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -532.2382736600273\n",
      "  episode_reward_min: -7216.611501805993\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 565\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.4083263874053955\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024414852261543274\n",
      "        policy_loss: 0.002980123506858945\n",
      "        total_loss: 4854.11181640625\n",
      "        vf_explained_var: 0.9762009978294373\n",
      "        vf_loss: 4854.10693359375\n",
      "    load_time_ms: 2.699\n",
      "    num_steps_sampled: 1695000\n",
      "    num_steps_trained: 1692288\n",
      "    sample_time_ms: 27705.504\n",
      "    update_time_ms: 3.024\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.604651162790695\n",
      "    ram_util_percent: 24.434883720930234\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.608161590812867\n",
      "    mean_inference_ms: 0.41349584845710263\n",
      "    mean_processing_ms: 4.111761617340572\n",
      "  time_since_restore: 3324.4720265865326\n",
      "  time_this_iter_s: 29.77376699447632\n",
      "  time_total_s: 3324.4720265865326\n",
      "  timestamp: 1665274502\n",
      "  timesteps_since_restore: 1695000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1695000\n",
      "  training_iteration: 113\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    113 |          3324.47 |     1695000 | -532.238 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-15-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -572.6309161026587\n",
      "  episode_reward_min: -7216.611501805993\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 570\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.249\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.014012090861797333\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023895220831036568\n",
      "        policy_loss: 0.002019602572545409\n",
      "        total_loss: 6279.8505859375\n",
      "        vf_explained_var: 0.9663018584251404\n",
      "        vf_loss: 6279.8466796875\n",
      "    load_time_ms: 2.819\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1707264\n",
      "    sample_time_ms: 27691.182\n",
      "    update_time_ms: 3.014\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.099999999999994\n",
      "    ram_util_percent: 24.397560975609753\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.607689734870681\n",
      "    mean_inference_ms: 0.4135200446196779\n",
      "    mean_processing_ms: 4.1116849671463545\n",
      "  time_since_restore: 3353.186223745346\n",
      "  time_this_iter_s: 28.714197158813477\n",
      "  time_total_s: 3353.186223745346\n",
      "  timestamp: 1665274531\n",
      "  timesteps_since_restore: 1710000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 114\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    114 |          3353.19 |     1710000 | -572.631 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-16-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -466.8823175016477\n",
      "  episode_reward_min: -7216.611501805993\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 575\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.307\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.642006754875183\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030634930357336998\n",
      "        policy_loss: 0.004697473719716072\n",
      "        total_loss: 3694.657958984375\n",
      "        vf_explained_var: 0.977961003780365\n",
      "        vf_loss: 3694.650634765625\n",
      "    load_time_ms: 2.754\n",
      "    num_steps_sampled: 1725000\n",
      "    num_steps_trained: 1722240\n",
      "    sample_time_ms: 27777.12\n",
      "    update_time_ms: 3.046\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.7952380952381\n",
      "    ram_util_percent: 24.430952380952384\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.607266935375819\n",
      "    mean_inference_ms: 0.4135414378829111\n",
      "    mean_processing_ms: 4.111694972137034\n",
      "  time_since_restore: 3383.0750257968903\n",
      "  time_this_iter_s: 29.88880205154419\n",
      "  time_total_s: 3383.0750257968903\n",
      "  timestamp: 1665274561\n",
      "  timesteps_since_restore: 1725000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1725000\n",
      "  training_iteration: 115\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    115 |          3383.08 |     1725000 | -466.882 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-16-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -441.50114755512527\n",
      "  episode_reward_min: -7216.611501805993\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 580\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.037\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3438079357147217\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017958056181669235\n",
      "        policy_loss: 0.00404729600995779\n",
      "        total_loss: 4874.68212890625\n",
      "        vf_explained_var: 0.9610697031021118\n",
      "        vf_loss: 4874.6767578125\n",
      "    load_time_ms: 2.556\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1737216\n",
      "    sample_time_ms: 28367.652\n",
      "    update_time_ms: 3.045\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.934\n",
      "    ram_util_percent: 24.392000000000003\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.606907962149798\n",
      "    mean_inference_ms: 0.41356563601017776\n",
      "    mean_processing_ms: 4.1124295466365615\n",
      "  time_since_restore: 3417.8935997486115\n",
      "  time_this_iter_s: 34.81857395172119\n",
      "  time_total_s: 3417.8935997486115\n",
      "  timestamp: 1665274595\n",
      "  timesteps_since_restore: 1740000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 116\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    116 |          3417.89 |     1740000 | -441.501 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-17-05\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -326.92364108050225\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 585\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.497\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8024796843528748\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02799306996166706\n",
      "        policy_loss: 0.0028724470175802708\n",
      "        total_loss: 7330.7373046875\n",
      "        vf_explained_var: 0.9478491544723511\n",
      "        vf_loss: 7330.732421875\n",
      "    load_time_ms: 2.548\n",
      "    num_steps_sampled: 1755000\n",
      "    num_steps_trained: 1752192\n",
      "    sample_time_ms: 28368.845\n",
      "    update_time_ms: 3.072\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00714285714285\n",
      "    ram_util_percent: 24.509523809523813\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.606505478591894\n",
      "    mean_inference_ms: 0.4135880717224043\n",
      "    mean_processing_ms: 4.113210108178541\n",
      "  time_since_restore: 3446.996555328369\n",
      "  time_this_iter_s: 29.10295557975769\n",
      "  time_total_s: 3446.996555328369\n",
      "  timestamp: 1665274625\n",
      "  timesteps_since_restore: 1755000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1755000\n",
      "  training_iteration: 117\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    117 |             3447 |     1755000 | -326.924 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-17-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -250.33394932087242\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 590\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.607\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0807507038116455\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019083630293607712\n",
      "        policy_loss: 0.0037646328564733267\n",
      "        total_loss: 4081.593017578125\n",
      "        vf_explained_var: 0.9708542227745056\n",
      "        vf_loss: 4081.587646484375\n",
      "    load_time_ms: 2.517\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1767168\n",
      "    sample_time_ms: 28389.776\n",
      "    update_time_ms: 3.058\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.878571428571426\n",
      "    ram_util_percent: 24.48333333333333\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.606136048919354\n",
      "    mean_inference_ms: 0.4136101476116002\n",
      "    mean_processing_ms: 4.114014198085135\n",
      "  time_since_restore: 3476.49649643898\n",
      "  time_this_iter_s: 29.499941110610962\n",
      "  time_total_s: 3476.49649643898\n",
      "  timestamp: 1665274654\n",
      "  timesteps_since_restore: 1770000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 118\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    118 |           3476.5 |     1770000 | -250.334 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-18-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -214.3125481062305\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 595\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.46\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.4621456861495972\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009518875740468502\n",
      "        policy_loss: 0.002183140954002738\n",
      "        total_loss: 4240.62109375\n",
      "        vf_explained_var: 0.9627314805984497\n",
      "        vf_loss: 4240.61767578125\n",
      "    load_time_ms: 2.437\n",
      "    num_steps_sampled: 1785000\n",
      "    num_steps_trained: 1782144\n",
      "    sample_time_ms: 28401.408\n",
      "    update_time_ms: 3.053\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.29047619047619\n",
      "    ram_util_percent: 24.547619047619047\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6057786606336535\n",
      "    mean_inference_ms: 0.41363048647979084\n",
      "    mean_processing_ms: 4.114775363848158\n",
      "  time_since_restore: 3505.7239265441895\n",
      "  time_this_iter_s: 29.22743010520935\n",
      "  time_total_s: 3505.7239265441895\n",
      "  timestamp: 1665274683\n",
      "  timesteps_since_restore: 1785000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1785000\n",
      "  training_iteration: 119\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    119 |          3505.72 |     1785000 | -214.313 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-18-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -248.34365217397152\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 600\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.766\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.127180814743042\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025934217497706413\n",
      "        policy_loss: 0.004408563021570444\n",
      "        total_loss: 4658.91845703125\n",
      "        vf_explained_var: 0.967108964920044\n",
      "        vf_loss: 4658.91357421875\n",
      "    load_time_ms: 2.498\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1797120\n",
      "    sample_time_ms: 28424.851\n",
      "    update_time_ms: 3.081\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.13809523809524\n",
      "    ram_util_percent: 24.56904761904762\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.60541344198285\n",
      "    mean_inference_ms: 0.4136462847737591\n",
      "    mean_processing_ms: 4.115514716642043\n",
      "  time_since_restore: 3535.120398044586\n",
      "  time_this_iter_s: 29.39647150039673\n",
      "  time_total_s: 3535.120398044586\n",
      "  timestamp: 1665274713\n",
      "  timesteps_since_restore: 1800000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 120\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    120 |          3535.12 |     1800000 | -248.344 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-19-05\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -233.69260696647547\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 605\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.737\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3914910554885864\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018928954377770424\n",
      "        policy_loss: 0.0016813043039292097\n",
      "        total_loss: 5782.2138671875\n",
      "        vf_explained_var: 0.9582907557487488\n",
      "        vf_loss: 5782.2109375\n",
      "    load_time_ms: 2.592\n",
      "    num_steps_sampled: 1815000\n",
      "    num_steps_trained: 1812096\n",
      "    sample_time_ms: 28632.404\n",
      "    update_time_ms: 3.088\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.177777777777784\n",
      "    ram_util_percent: 24.488888888888887\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.605115267661921\n",
      "    mean_inference_ms: 0.4136695532553567\n",
      "    mean_processing_ms: 4.11655447643646\n",
      "  time_since_restore: 3566.956563949585\n",
      "  time_this_iter_s: 31.83616590499878\n",
      "  time_total_s: 3566.956563949585\n",
      "  timestamp: 1665274745\n",
      "  timesteps_since_restore: 1815000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1815000\n",
      "  training_iteration: 121\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    121 |          3566.96 |     1815000 | -233.693 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-19-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -272.89578988422437\n",
      "  episode_reward_min: -5230.271423256226\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 610\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.694\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5194271206855774\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010956435464322567\n",
      "        policy_loss: -0.0009797611273825169\n",
      "        total_loss: 6418.654296875\n",
      "        vf_explained_var: 0.9618275761604309\n",
      "        vf_loss: 6418.654296875\n",
      "    load_time_ms: 2.617\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1827072\n",
      "    sample_time_ms: 28625.617\n",
      "    update_time_ms: 3.0\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.5390243902439\n",
      "    ram_util_percent: 24.636585365853655\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.604798031331761\n",
      "    mean_inference_ms: 0.41369379739908374\n",
      "    mean_processing_ms: 4.117602159654835\n",
      "  time_since_restore: 3595.9035654067993\n",
      "  time_this_iter_s: 28.947001457214355\n",
      "  time_total_s: 3595.9035654067993\n",
      "  timestamp: 1665274774\n",
      "  timesteps_since_restore: 1830000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 122\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    122 |           3595.9 |     1830000 | -272.896 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-20-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -309.1162525806457\n",
      "  episode_reward_min: -5230.271423256226\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 615\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.822\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1301732063293457\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0188137199729681\n",
      "        policy_loss: 0.002994529902935028\n",
      "        total_loss: 4141.87744140625\n",
      "        vf_explained_var: 0.9795982241630554\n",
      "        vf_loss: 4141.873046875\n",
      "    load_time_ms: 2.57\n",
      "    num_steps_sampled: 1845000\n",
      "    num_steps_trained: 1842048\n",
      "    sample_time_ms: 28615.243\n",
      "    update_time_ms: 2.947\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.32093023255814\n",
      "    ram_util_percent: 24.548837209302324\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.604414768633935\n",
      "    mean_inference_ms: 0.4137139191198095\n",
      "    mean_processing_ms: 4.118671837197956\n",
      "  time_since_restore: 3625.572982311249\n",
      "  time_this_iter_s: 29.669416904449463\n",
      "  time_total_s: 3625.572982311249\n",
      "  timestamp: 1665274803\n",
      "  timesteps_since_restore: 1845000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1845000\n",
      "  training_iteration: 123\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    123 |          3625.57 |     1845000 | -309.116 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-20-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -333.3973356658798\n",
      "  episode_reward_min: -5230.271423256226\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 620\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.896\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.09128948301076889\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01526044961065054\n",
      "        policy_loss: -0.0013523886445909739\n",
      "        total_loss: 4682.70654296875\n",
      "        vf_explained_var: 0.976188063621521\n",
      "        vf_loss: 4682.70703125\n",
      "    load_time_ms: 2.466\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1857024\n",
      "    sample_time_ms: 28718.831\n",
      "    update_time_ms: 2.962\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.64523809523809\n",
      "    ram_util_percent: 24.492857142857144\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.604102081319154\n",
      "    mean_inference_ms: 0.41373632210339395\n",
      "    mean_processing_ms: 4.119754466893311\n",
      "  time_since_restore: 3655.3227796554565\n",
      "  time_this_iter_s: 29.749797344207764\n",
      "  time_total_s: 3655.3227796554565\n",
      "  timestamp: 1665274833\n",
      "  timesteps_since_restore: 1860000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 124\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    124 |          3655.32 |     1860000 | -333.397 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-21-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -286.83314640107056\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 625\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.972\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.02393629215657711\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0201624296605587\n",
      "        policy_loss: 0.004428813699632883\n",
      "        total_loss: 7794.986328125\n",
      "        vf_explained_var: 0.9607923030853271\n",
      "        vf_loss: 7794.98046875\n",
      "    load_time_ms: 2.519\n",
      "    num_steps_sampled: 1875000\n",
      "    num_steps_trained: 1872000\n",
      "    sample_time_ms: 28733.911\n",
      "    update_time_ms: 2.951\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.94418604651163\n",
      "    ram_util_percent: 24.539534883720926\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.603761953472316\n",
      "    mean_inference_ms: 0.4137585458939919\n",
      "    mean_processing_ms: 4.12097776333285\n",
      "  time_since_restore: 3685.3535900115967\n",
      "  time_this_iter_s: 30.030810356140137\n",
      "  time_total_s: 3685.3535900115967\n",
      "  timestamp: 1665274863\n",
      "  timesteps_since_restore: 1875000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1875000\n",
      "  training_iteration: 125\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    125 |          3685.35 |     1875000 | -286.833 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-21-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -274.69306888813605\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 630\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.636\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.8453298807144165\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029890988022089005\n",
      "        policy_loss: 0.0013420976465567946\n",
      "        total_loss: 2749.57861328125\n",
      "        vf_explained_var: 0.9818205833435059\n",
      "        vf_loss: 2749.57568359375\n",
      "    load_time_ms: 2.638\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1886976\n",
      "    sample_time_ms: 28141.049\n",
      "    update_time_ms: 2.944\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.331707317073175\n",
      "    ram_util_percent: 24.490243902439026\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.603471636823789\n",
      "    mean_inference_ms: 0.41378233361148714\n",
      "    mean_processing_ms: 4.122176016263388\n",
      "  time_since_restore: 3714.251203775406\n",
      "  time_this_iter_s: 28.897613763809204\n",
      "  time_total_s: 3714.251203775406\n",
      "  timestamp: 1665274892\n",
      "  timesteps_since_restore: 1890000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 126\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    126 |          3714.25 |     1890000 | -274.693 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-22-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -315.75902365300135\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 635\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.247\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7555730938911438\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007832398638129234\n",
      "        policy_loss: 0.001212835544720292\n",
      "        total_loss: 5810.8740234375\n",
      "        vf_explained_var: 0.9586175084114075\n",
      "        vf_loss: 5810.87255859375\n",
      "    load_time_ms: 2.642\n",
      "    num_steps_sampled: 1905000\n",
      "    num_steps_trained: 1901952\n",
      "    sample_time_ms: 28101.57\n",
      "    update_time_ms: 2.959\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.353658536585364\n",
      "    ram_util_percent: 24.507317073170732\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.603129529901477\n",
      "    mean_inference_ms: 0.41380347564880354\n",
      "    mean_processing_ms: 4.12335273188731\n",
      "  time_since_restore: 3742.9559092521667\n",
      "  time_this_iter_s: 28.704705476760864\n",
      "  time_total_s: 3742.9559092521667\n",
      "  timestamp: 1665274921\n",
      "  timesteps_since_restore: 1905000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1905000\n",
      "  training_iteration: 127\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    127 |          3742.96 |     1905000 | -315.759 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-22-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -315.3231404242886\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 640\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.652\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02138153836131096\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.41942593455314636\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013690865598618984\n",
      "        policy_loss: 0.0020902249962091446\n",
      "        total_loss: 4551.16064453125\n",
      "        vf_explained_var: 0.9781675934791565\n",
      "        vf_loss: 4551.15771484375\n",
      "    load_time_ms: 2.64\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1916928\n",
      "    sample_time_ms: 28089.729\n",
      "    update_time_ms: 2.985\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00952380952381\n",
      "    ram_util_percent: 24.469047619047622\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.602794854849637\n",
      "    mean_inference_ms: 0.413825286620731\n",
      "    mean_processing_ms: 4.124536436230338\n",
      "  time_since_restore: 3772.3318383693695\n",
      "  time_this_iter_s: 29.37592911720276\n",
      "  time_total_s: 3772.3318383693695\n",
      "  timestamp: 1665274950\n",
      "  timesteps_since_restore: 1920000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 128\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    128 |          3772.33 |     1920000 | -315.323 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-23-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -330.6076730161777\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 645\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.547\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02138153836131096\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.6612853407859802\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02198360115289688\n",
      "        policy_loss: -0.0010069701820611954\n",
      "        total_loss: 5714.85693359375\n",
      "        vf_explained_var: 0.9644346237182617\n",
      "        vf_loss: 5714.85693359375\n",
      "    load_time_ms: 2.668\n",
      "    num_steps_sampled: 1935000\n",
      "    num_steps_trained: 1931904\n",
      "    sample_time_ms: 28110.038\n",
      "    update_time_ms: 3.07\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.16428571428572\n",
      "    ram_util_percent: 24.473809523809525\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.602470688865662\n",
      "    mean_inference_ms: 0.41384672882160756\n",
      "    mean_processing_ms: 4.125726238479571\n",
      "  time_since_restore: 3801.7624838352203\n",
      "  time_this_iter_s: 29.43064546585083\n",
      "  time_total_s: 3801.7624838352203\n",
      "  timestamp: 1665274980\n",
      "  timesteps_since_restore: 1935000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1935000\n",
      "  training_iteration: 129\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    129 |          3801.76 |     1935000 | -330.608 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-23-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -314.10846412988246\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 650\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.387\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02138153836131096\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.2480989694595337\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.1222262755036354\n",
      "        policy_loss: 0.00821064691990614\n",
      "        total_loss: 3343.060791015625\n",
      "        vf_explained_var: 0.9829971194267273\n",
      "        vf_loss: 3343.04931640625\n",
      "    load_time_ms: 2.612\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1946880\n",
      "    sample_time_ms: 28112.867\n",
      "    update_time_ms: 3.09\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.64418604651163\n",
      "    ram_util_percent: 24.64883720930233\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.602206092743847\n",
      "    mean_inference_ms: 0.4138695706579771\n",
      "    mean_processing_ms: 4.1268871870782835\n",
      "  time_since_restore: 3831.1851184368134\n",
      "  time_this_iter_s: 29.422634601593018\n",
      "  time_total_s: 3831.1851184368134\n",
      "  timestamp: 1665275009\n",
      "  timesteps_since_restore: 1950000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 130\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    130 |          3831.19 |     1950000 | -314.108 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-23-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -340.4421743929058\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 655\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.709\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.03370589390397072\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014017399400472641\n",
      "        policy_loss: 0.0013976864283904433\n",
      "        total_loss: 4129.19970703125\n",
      "        vf_explained_var: 0.9810900688171387\n",
      "        vf_loss: 4129.19775390625\n",
      "    load_time_ms: 2.617\n",
      "    num_steps_sampled: 1965000\n",
      "    num_steps_trained: 1961856\n",
      "    sample_time_ms: 27850.946\n",
      "    update_time_ms: 3.12\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.60487804878049\n",
      "    ram_util_percent: 24.62682926829269\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.601987726852476\n",
      "    mean_inference_ms: 0.41389312658875643\n",
      "    mean_processing_ms: 4.127953855407854\n",
      "  time_since_restore: 3860.405657052994\n",
      "  time_this_iter_s: 29.22053861618042\n",
      "  time_total_s: 3860.405657052994\n",
      "  timestamp: 1665275039\n",
      "  timesteps_since_restore: 1965000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1965000\n",
      "  training_iteration: 131\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    131 |          3860.41 |     1965000 | -340.442 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -365.79721099470095\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 660\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.49\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.13655047118663788\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020603565499186516\n",
      "        policy_loss: 0.0018962122267112136\n",
      "        total_loss: 4042.813232421875\n",
      "        vf_explained_var: 0.9818778038024902\n",
      "        vf_loss: 4042.810546875\n",
      "    load_time_ms: 2.69\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1976832\n",
      "    sample_time_ms: 27942.894\n",
      "    update_time_ms: 3.219\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.75581395348837\n",
      "    ram_util_percent: 24.493023255813956\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.601792042073988\n",
      "    mean_inference_ms: 0.41391734413514647\n",
      "    mean_processing_ms: 4.129134891989152\n",
      "  time_since_restore: 3890.271917104721\n",
      "  time_this_iter_s: 29.866260051727295\n",
      "  time_total_s: 3890.271917104721\n",
      "  timestamp: 1665275068\n",
      "  timesteps_since_restore: 1980000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 132\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    132 |          3890.27 |     1980000 | -365.797 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-24-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -406.44315767286406\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 665\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.786\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4127935767173767\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022565145045518875\n",
      "        policy_loss: 0.00254058837890625\n",
      "        total_loss: 8158.41357421875\n",
      "        vf_explained_var: 0.9559457898139954\n",
      "        vf_loss: 8158.41015625\n",
      "    load_time_ms: 2.668\n",
      "    num_steps_sampled: 1995000\n",
      "    num_steps_trained: 1991808\n",
      "    sample_time_ms: 27920.055\n",
      "    update_time_ms: 3.231\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.85476190476191\n",
      "    ram_util_percent: 24.5\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.601587850072211\n",
      "    mean_inference_ms: 0.4139414640199077\n",
      "    mean_processing_ms: 4.130220652291611\n",
      "  time_since_restore: 3919.706416606903\n",
      "  time_this_iter_s: 29.434499502182007\n",
      "  time_total_s: 3919.706416606903\n",
      "  timestamp: 1665275098\n",
      "  timesteps_since_restore: 1995000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1995000\n",
      "  training_iteration: 133\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    133 |          3919.71 |     1995000 | -406.443 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-25-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -362.36126510107766\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 670\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.196\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.939169704914093\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01781870424747467\n",
      "        policy_loss: 0.0015701611991971731\n",
      "        total_loss: 6468.8408203125\n",
      "        vf_explained_var: 0.9580222964286804\n",
      "        vf_loss: 6468.8388671875\n",
      "    load_time_ms: 2.786\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2006784\n",
      "    sample_time_ms: 27843.826\n",
      "    update_time_ms: 3.226\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.77317073170732\n",
      "    ram_util_percent: 24.52926829268293\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6013993041540875\n",
      "    mean_inference_ms: 0.4139660602102761\n",
      "    mean_processing_ms: 4.131309069285754\n",
      "  time_since_restore: 3948.7092945575714\n",
      "  time_this_iter_s: 29.002877950668335\n",
      "  time_total_s: 3948.7092945575714\n",
      "  timestamp: 1665275127\n",
      "  timesteps_since_restore: 2010000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 134\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    134 |          3948.71 |     2010000 | -362.361 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-25-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -364.9206270928317\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 675\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.075\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.8007339239120483\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.041017599403858185\n",
      "        policy_loss: 0.009157867170870304\n",
      "        total_loss: 4110.2666015625\n",
      "        vf_explained_var: 0.9717850685119629\n",
      "        vf_loss: 4110.25634765625\n",
      "    load_time_ms: 2.757\n",
      "    num_steps_sampled: 2025000\n",
      "    num_steps_trained: 2021760\n",
      "    sample_time_ms: 27934.544\n",
      "    update_time_ms: 3.21\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.291111111111114\n",
      "    ram_util_percent: 24.55555555555555\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.60119374563582\n",
      "    mean_inference_ms: 0.4139883996797817\n",
      "    mean_processing_ms: 4.132495892168871\n",
      "  time_since_restore: 3979.6456735134125\n",
      "  time_this_iter_s: 30.936378955841064\n",
      "  time_total_s: 3979.6456735134125\n",
      "  timestamp: 1665275158\n",
      "  timesteps_since_restore: 2025000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2025000\n",
      "  training_iteration: 135\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    135 |          3979.65 |     2025000 | -364.921 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-26-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -463.6783490399857\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 680\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.549\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.048108458518981934\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.137397289276123\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011613890528678894\n",
      "        policy_loss: 0.0006970480317249894\n",
      "        total_loss: 8842.4384765625\n",
      "        vf_explained_var: 0.9620862603187561\n",
      "        vf_loss: 8842.435546875\n",
      "    load_time_ms: 2.642\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2036736\n",
      "    sample_time_ms: 28000.426\n",
      "    update_time_ms: 3.22\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.37380952380953\n",
      "    ram_util_percent: 24.55714285714286\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.601001482599136\n",
      "    mean_inference_ms: 0.41401068029746235\n",
      "    mean_processing_ms: 4.132942987047096\n",
      "  time_since_restore: 4009.196026802063\n",
      "  time_this_iter_s: 29.550353288650513\n",
      "  time_total_s: 4009.196026802063\n",
      "  timestamp: 1665275187\n",
      "  timesteps_since_restore: 2040000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 136\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    136 |           4009.2 |     2040000 | -463.678 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-26-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -425.75658810240105\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 685\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.494\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.048108458518981934\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.2202695608139038\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.032547395676374435\n",
      "        policy_loss: 0.0038417335599660873\n",
      "        total_loss: 4574.52099609375\n",
      "        vf_explained_var: 0.9622170329093933\n",
      "        vf_loss: 4574.515625\n",
      "    load_time_ms: 2.653\n",
      "    num_steps_sampled: 2055000\n",
      "    num_steps_trained: 2051712\n",
      "    sample_time_ms: 28091.656\n",
      "    update_time_ms: 3.229\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.530952380952385\n",
      "    ram_util_percent: 24.523809523809526\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.60084956197632\n",
      "    mean_inference_ms: 0.41403135312977285\n",
      "    mean_processing_ms: 4.133378830337071\n",
      "  time_since_restore: 4038.8226342201233\n",
      "  time_this_iter_s: 29.626607418060303\n",
      "  time_total_s: 4038.8226342201233\n",
      "  timestamp: 1665275217\n",
      "  timesteps_since_restore: 2055000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2055000\n",
      "  training_iteration: 137\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    137 |          4038.82 |     2055000 | -425.757 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-27-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -443.2208777393199\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 690\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.748\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.048108458518981934\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33957600593566895\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2059952020645142\n",
      "        policy_loss: 0.1090601310133934\n",
      "        total_loss: 5531.68310546875\n",
      "        vf_explained_var: 0.9669268727302551\n",
      "        vf_loss: 5531.515625\n",
      "    load_time_ms: 2.635\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2066688\n",
      "    sample_time_ms: 28070.534\n",
      "    update_time_ms: 3.161\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.41428571428571\n",
      "    ram_util_percent: 24.564285714285717\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600696688736571\n",
      "    mean_inference_ms: 0.4140522493745782\n",
      "    mean_processing_ms: 4.133812772866338\n",
      "  time_since_restore: 4067.9983863830566\n",
      "  time_this_iter_s: 29.17575216293335\n",
      "  time_total_s: 4067.9983863830566\n",
      "  timestamp: 1665275246\n",
      "  timesteps_since_restore: 2070000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 138\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    138 |             4068 |     2070000 | -443.221 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-27-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -545.0487220704886\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 695\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.252\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0721626877784729\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9841999411582947\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001832595095038414\n",
      "        policy_loss: -0.001014543347992003\n",
      "        total_loss: 12828.6064453125\n",
      "        vf_explained_var: 0.9147266745567322\n",
      "        vf_loss: 12828.6064453125\n",
      "    load_time_ms: 2.579\n",
      "    num_steps_sampled: 2085000\n",
      "    num_steps_trained: 2081664\n",
      "    sample_time_ms: 28042.586\n",
      "    update_time_ms: 3.051\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.75365853658536\n",
      "    ram_util_percent: 24.573170731707318\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600549311915443\n",
      "    mean_inference_ms: 0.41407279578218814\n",
      "    mean_processing_ms: 4.134217752410624\n",
      "  time_since_restore: 4097.133095979691\n",
      "  time_this_iter_s: 29.13470959663391\n",
      "  time_total_s: 4097.133095979691\n",
      "  timestamp: 1665275276\n",
      "  timesteps_since_restore: 2085000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2085000\n",
      "  training_iteration: 139\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    139 |          4097.13 |     2085000 | -545.049 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-28-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -667.5094238768147\n",
      "  episode_reward_min: -5663.576779273668\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 700\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.3\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03608134388923645\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.9201149940490723\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002317895647138357\n",
      "        policy_loss: 0.0003936747962143272\n",
      "        total_loss: 8298.9052734375\n",
      "        vf_explained_var: 0.9592844247817993\n",
      "        vf_loss: 8298.904296875\n",
      "    load_time_ms: 2.581\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2096640\n",
      "    sample_time_ms: 28053.463\n",
      "    update_time_ms: 3.008\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.87906976744186\n",
      "    ram_util_percent: 24.625581395348835\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.60041081459956\n",
      "    mean_inference_ms: 0.4140923289330711\n",
      "    mean_processing_ms: 4.134628285420682\n",
      "  time_since_restore: 4126.664918661118\n",
      "  time_this_iter_s: 29.531822681427002\n",
      "  time_total_s: 4126.664918661118\n",
      "  timestamp: 1665275305\n",
      "  timesteps_since_restore: 2100000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 140\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    140 |          4126.66 |     2100000 | -667.509 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-28-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -788.4322924356742\n",
      "  episode_reward_min: -5663.576779273668\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 705\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.575\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.018040671944618225\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0700119733810425\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007846910506486893\n",
      "        policy_loss: -0.0015746726421639323\n",
      "        total_loss: 11183.2763671875\n",
      "        vf_explained_var: 0.9275637269020081\n",
      "        vf_loss: 11183.2763671875\n",
      "    load_time_ms: 2.631\n",
      "    num_steps_sampled: 2115000\n",
      "    num_steps_trained: 2111616\n",
      "    sample_time_ms: 28066.459\n",
      "    update_time_ms: 3.017\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.730952380952374\n",
      "    ram_util_percent: 24.571428571428573\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600225052670536\n",
      "    mean_inference_ms: 0.41410465743761415\n",
      "    mean_processing_ms: 4.134791727991211\n",
      "  time_since_restore: 4156.028628349304\n",
      "  time_this_iter_s: 29.363709688186646\n",
      "  time_total_s: 4156.028628349304\n",
      "  timestamp: 1665275334\n",
      "  timesteps_since_restore: 2115000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2115000\n",
      "  training_iteration: 141\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    141 |          4156.03 |     2115000 | -788.432 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-29-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -791.6770136289699\n",
      "  episode_reward_min: -5663.576779273668\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 710\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.291\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.009020335972309113\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.163979172706604\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010056531056761742\n",
      "        policy_loss: -0.001747257192619145\n",
      "        total_loss: 12356.345703125\n",
      "        vf_explained_var: 0.912399411201477\n",
      "        vf_loss: 12356.345703125\n",
      "    load_time_ms: 2.665\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2126592\n",
      "    sample_time_ms: 27964.792\n",
      "    update_time_ms: 3.004\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.25121951219512\n",
      "    ram_util_percent: 24.573170731707318\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6000562427301155\n",
      "    mean_inference_ms: 0.4141133967610675\n",
      "    mean_processing_ms: 4.134961237152949\n",
      "  time_since_restore: 4184.885762214661\n",
      "  time_this_iter_s: 28.857133865356445\n",
      "  time_total_s: 4184.885762214661\n",
      "  timestamp: 1665275363\n",
      "  timesteps_since_restore: 2130000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 142\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    142 |          4184.89 |     2130000 | -791.677 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-29-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -929.0647965125041\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 715\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.314\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.009020335972309113\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.8851028680801392\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010745520703494549\n",
      "        policy_loss: -0.0005985460011288524\n",
      "        total_loss: 12801.076171875\n",
      "        vf_explained_var: 0.9255713224411011\n",
      "        vf_loss: 12801.0771484375\n",
      "    load_time_ms: 2.558\n",
      "    num_steps_sampled: 2145000\n",
      "    num_steps_trained: 2141568\n",
      "    sample_time_ms: 27933.484\n",
      "    update_time_ms: 3.027\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.16341463414634\n",
      "    ram_util_percent: 24.573170731707318\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599899843852498\n",
      "    mean_inference_ms: 0.41412408754640984\n",
      "    mean_processing_ms: 4.135066624216551\n",
      "  time_since_restore: 4214.006501913071\n",
      "  time_this_iter_s: 29.120739698410034\n",
      "  time_total_s: 4214.006501913071\n",
      "  timestamp: 1665275393\n",
      "  timesteps_since_restore: 2145000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2145000\n",
      "  training_iteration: 143\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    143 |          4214.01 |     2145000 | -929.065 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-30-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -1085.6496126884713\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 720\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.869\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.009020335972309113\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 3.1751787662506104\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005936908069998026\n",
      "        policy_loss: 0.00011150513455504552\n",
      "        total_loss: 14388.396484375\n",
      "        vf_explained_var: 0.9164915084838867\n",
      "        vf_loss: 14388.3984375\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2156544\n",
      "    sample_time_ms: 27968.294\n",
      "    update_time_ms: 3.021\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.98809523809524\n",
      "    ram_util_percent: 24.609523809523807\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599715033751196\n",
      "    mean_inference_ms: 0.41413529177540304\n",
      "    mean_processing_ms: 4.1351721281430205\n",
      "  time_since_restore: 4243.361526012421\n",
      "  time_this_iter_s: 29.355024099349976\n",
      "  time_total_s: 4243.361526012421\n",
      "  timestamp: 1665275422\n",
      "  timesteps_since_restore: 2160000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 144\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    144 |          4243.36 |     2160000 | -1085.65 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-30-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -1126.8758901141944\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 725\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.493\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.004510167986154556\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.932579755783081\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006915210280567408\n",
      "        policy_loss: -0.0005713237915188074\n",
      "        total_loss: 11446.794921875\n",
      "        vf_explained_var: 0.8895868062973022\n",
      "        vf_loss: 11446.7978515625\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 2175000\n",
      "    num_steps_trained: 2171520\n",
      "    sample_time_ms: 27816.439\n",
      "    update_time_ms: 3.022\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.80714285714286\n",
      "    ram_util_percent: 24.60238095238096\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599565768318886\n",
      "    mean_inference_ms: 0.41414431203022145\n",
      "    mean_processing_ms: 4.135168744433745\n",
      "  time_since_restore: 4272.8041779994965\n",
      "  time_this_iter_s: 29.442651987075806\n",
      "  time_total_s: 4272.8041779994965\n",
      "  timestamp: 1665275451\n",
      "  timesteps_since_restore: 2175000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2175000\n",
      "  training_iteration: 145\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    145 |           4272.8 |     2175000 | -1126.88 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-31-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -1318.8937809751476\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 730\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.206\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.002255083993077278\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.045476198196411\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01267511211335659\n",
      "        policy_loss: 0.00044150077155791223\n",
      "        total_loss: 14996.4609375\n",
      "        vf_explained_var: 0.8774191737174988\n",
      "        vf_loss: 14996.4609375\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2186496\n",
      "    sample_time_ms: 28390.457\n",
      "    update_time_ms: 3.025\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.119607843137256\n",
      "    ram_util_percent: 24.572549019607834\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599395042909751\n",
      "    mean_inference_ms: 0.41415407703301615\n",
      "    mean_processing_ms: 4.135875896244492\n",
      "  time_since_restore: 4308.091898679733\n",
      "  time_this_iter_s: 35.287720680236816\n",
      "  time_total_s: 4308.091898679733\n",
      "  timestamp: 1665275487\n",
      "  timesteps_since_restore: 2190000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 146\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    146 |          4308.09 |     2190000 | -1318.89 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-31-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -1407.6420335298117\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 735\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.774\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.002255083993077278\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0557630062103271\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011994288302958012\n",
      "        policy_loss: -0.0023702376056462526\n",
      "        total_loss: 13250.8369140625\n",
      "        vf_explained_var: 0.8713727593421936\n",
      "        vf_loss: 13250.8388671875\n",
      "    load_time_ms: 2.304\n",
      "    num_steps_sampled: 2205000\n",
      "    num_steps_trained: 2201472\n",
      "    sample_time_ms: 28323.638\n",
      "    update_time_ms: 2.893\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.81219512195122\n",
      "    ram_util_percent: 24.62926829268293\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599262288310877\n",
      "    mean_inference_ms: 0.41416514321813686\n",
      "    mean_processing_ms: 4.136587314091486\n",
      "  time_since_restore: 4337.054119586945\n",
      "  time_this_iter_s: 28.962220907211304\n",
      "  time_total_s: 4337.054119586945\n",
      "  timestamp: 1665275516\n",
      "  timesteps_since_restore: 2205000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2205000\n",
      "  training_iteration: 147\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    147 |          4337.05 |     2205000 | -1407.64 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-32-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1451.2730002371982\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 740\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.055\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.002255083993077278\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.34298476576805115\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026841143146157265\n",
      "        policy_loss: 0.0005412781029008329\n",
      "        total_loss: 15626.0205078125\n",
      "        vf_explained_var: 0.7796371579170227\n",
      "        vf_loss: 15626.0185546875\n",
      "    load_time_ms: 2.349\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2216448\n",
      "    sample_time_ms: 28400.851\n",
      "    update_time_ms: 2.955\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.54883720930233\n",
      "    ram_util_percent: 24.618604651162787\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599158234579604\n",
      "    mean_inference_ms: 0.41417689909084243\n",
      "    mean_processing_ms: 4.13732445918991\n",
      "  time_since_restore: 4366.996723413467\n",
      "  time_this_iter_s: 29.942603826522827\n",
      "  time_total_s: 4366.996723413467\n",
      "  timestamp: 1665275546\n",
      "  timesteps_since_restore: 2220000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 148\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    148 |             4367 |     2220000 | -1451.27 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-32-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1496.5372983094871\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 745\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.66\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.002255083993077278\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.22729328274726868\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05730970948934555\n",
      "        policy_loss: -0.007348787039518356\n",
      "        total_loss: 19164.1640625\n",
      "        vf_explained_var: 0.6334642171859741\n",
      "        vf_loss: 19164.16796875\n",
      "    load_time_ms: 2.424\n",
      "    num_steps_sampled: 2235000\n",
      "    num_steps_trained: 2231424\n",
      "    sample_time_ms: 28443.1\n",
      "    update_time_ms: 2.989\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.94285714285714\n",
      "    ram_util_percent: 24.62619047619048\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.59904346089881\n",
      "    mean_inference_ms: 0.41418966520939465\n",
      "    mean_processing_ms: 4.13806755779374\n",
      "  time_since_restore: 4396.560938119888\n",
      "  time_this_iter_s: 29.5642147064209\n",
      "  time_total_s: 4396.560938119888\n",
      "  timestamp: 1665275575\n",
      "  timesteps_since_restore: 2235000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2235000\n",
      "  training_iteration: 149\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    149 |          4396.56 |     2235000 | -1496.54 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-33-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1579.941426140573\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 750\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.156\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.003382625989615917\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.10784763097763062\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.06456905603408813\n",
      "        policy_loss: -0.005394523963332176\n",
      "        total_loss: 18940.5625\n",
      "        vf_explained_var: 0.5870441794395447\n",
      "        vf_loss: 18940.56640625\n",
      "    load_time_ms: 2.481\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2246400\n",
      "    sample_time_ms: 28404.099\n",
      "    update_time_ms: 2.923\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34285714285714\n",
      "    ram_util_percent: 24.685714285714283\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.5989022105501105\n",
      "    mean_inference_ms: 0.4142029327847766\n",
      "    mean_processing_ms: 4.1387924873462145\n",
      "  time_since_restore: 4425.697472572327\n",
      "  time_this_iter_s: 29.136534452438354\n",
      "  time_total_s: 4425.697472572327\n",
      "  timestamp: 1665275605\n",
      "  timesteps_since_restore: 2250000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 150\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    150 |           4425.7 |     2250000 | -1579.94 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-33-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1610.202028506972\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 755\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.13\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.005073938984423876\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.1529041826725006\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05043758079409599\n",
      "        policy_loss: -0.003804660402238369\n",
      "        total_loss: 17540.533203125\n",
      "        vf_explained_var: 0.5616912245750427\n",
      "        vf_loss: 17540.537109375\n",
      "    load_time_ms: 2.435\n",
      "    num_steps_sampled: 2265000\n",
      "    num_steps_trained: 2261376\n",
      "    sample_time_ms: 28391.622\n",
      "    update_time_ms: 2.865\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34285714285714\n",
      "    ram_util_percent: 24.62619047619048\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598780666573027\n",
      "    mean_inference_ms: 0.414217807015232\n",
      "    mean_processing_ms: 4.139505126893971\n",
      "  time_since_restore: 4454.915128469467\n",
      "  time_this_iter_s: 29.217655897140503\n",
      "  time_total_s: 4454.915128469467\n",
      "  timestamp: 1665275634\n",
      "  timesteps_since_restore: 2265000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2265000\n",
      "  training_iteration: 151\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    151 |          4454.92 |     2265000 |  -1610.2 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-34-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1664.473935500487\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 760\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.32\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.007610908709466457\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.1259537935256958\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02458787150681019\n",
      "        policy_loss: -0.002807941287755966\n",
      "        total_loss: 17133.642578125\n",
      "        vf_explained_var: 0.5334187746047974\n",
      "        vf_loss: 17133.646484375\n",
      "    load_time_ms: 2.337\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2276352\n",
      "    sample_time_ms: 28466.499\n",
      "    update_time_ms: 2.789\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.28095238095238\n",
      "    ram_util_percent: 24.635714285714286\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598679679754497\n",
      "    mean_inference_ms: 0.41423185489683917\n",
      "    mean_processing_ms: 4.140112971842593\n",
      "  time_since_restore: 4484.530905485153\n",
      "  time_this_iter_s: 29.615777015686035\n",
      "  time_total_s: 4484.530905485153\n",
      "  timestamp: 1665275663\n",
      "  timesteps_since_restore: 2280000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 152\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    152 |          4484.53 |     2280000 | -1664.47 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-34-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1725.9490217705104\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 765\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.297\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.007610908709466457\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.2456514537334442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05699871852993965\n",
      "        policy_loss: -0.0033833638299256563\n",
      "        total_loss: 15692.4326171875\n",
      "        vf_explained_var: 0.5481157898902893\n",
      "        vf_loss: 15692.4345703125\n",
      "    load_time_ms: 2.475\n",
      "    num_steps_sampled: 2295000\n",
      "    num_steps_trained: 2291328\n",
      "    sample_time_ms: 28506.513\n",
      "    update_time_ms: 2.813\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.66428571428571\n",
      "    ram_util_percent: 24.67142857142857\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598590828524638\n",
      "    mean_inference_ms: 0.4142472823315876\n",
      "    mean_processing_ms: 4.1406918739750775\n",
      "  time_since_restore: 4514.063265323639\n",
      "  time_this_iter_s: 29.532359838485718\n",
      "  time_total_s: 4514.063265323639\n",
      "  timestamp: 1665275693\n",
      "  timesteps_since_restore: 2295000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2295000\n",
      "  training_iteration: 153\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    153 |          4514.06 |     2295000 | -1725.95 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-35-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1807.2222500470168\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 770\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.01\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.011416362598538399\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.09796711802482605\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04054972529411316\n",
      "        policy_loss: -0.0020543753635138273\n",
      "        total_loss: 14467.3623046875\n",
      "        vf_explained_var: 0.5246385931968689\n",
      "        vf_loss: 14467.36328125\n",
      "    load_time_ms: 2.546\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2306304\n",
      "    sample_time_ms: 28491.652\n",
      "    update_time_ms: 2.804\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.292857142857144\n",
      "    ram_util_percent: 24.669047619047618\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598546235055701\n",
      "    mean_inference_ms: 0.4142626217610924\n",
      "    mean_processing_ms: 4.14125376445213\n",
      "  time_since_restore: 4543.258025407791\n",
      "  time_this_iter_s: 29.19476008415222\n",
      "  time_total_s: 4543.258025407791\n",
      "  timestamp: 1665275722\n",
      "  timesteps_since_restore: 2310000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 154\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    154 |          4543.26 |     2310000 | -1807.22 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-35-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 949.7323704405056\n",
      "  episode_reward_mean: -1940.9835344858034\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 775\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.047\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.017124544829130173\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.14931339025497437\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015556865371763706\n",
      "        policy_loss: 0.000505601754412055\n",
      "        total_loss: 13889.236328125\n",
      "        vf_explained_var: 0.5023787021636963\n",
      "        vf_loss: 13889.2353515625\n",
      "    load_time_ms: 2.725\n",
      "    num_steps_sampled: 2325000\n",
      "    num_steps_trained: 2321280\n",
      "    sample_time_ms: 28463.559\n",
      "    update_time_ms: 2.849\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.654761904761905\n",
      "    ram_util_percent: 24.676190476190477\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598526013559214\n",
      "    mean_inference_ms: 0.41428003158423926\n",
      "    mean_processing_ms: 4.141627605572811\n",
      "  time_since_restore: 4572.42258810997\n",
      "  time_this_iter_s: 29.164562702178955\n",
      "  time_total_s: 4572.42258810997\n",
      "  timestamp: 1665275752\n",
      "  timesteps_since_restore: 2325000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2325000\n",
      "  training_iteration: 155\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    155 |          4572.42 |     2325000 | -1940.98 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-36-21\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 949.7323704405056\n",
      "  episode_reward_mean: -1968.641163497926\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 780\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.674\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.017124544829130173\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.06898795813322067\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0358881950378418\n",
      "        policy_loss: -0.003627411788329482\n",
      "        total_loss: 12602.833984375\n",
      "        vf_explained_var: 0.4964130222797394\n",
      "        vf_loss: 12602.8369140625\n",
      "    load_time_ms: 2.796\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2336256\n",
      "    sample_time_ms: 27914.746\n",
      "    update_time_ms: 2.862\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.25\n",
      "    ram_util_percent: 24.72142857142857\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598508474091682\n",
      "    mean_inference_ms: 0.41429718079192596\n",
      "    mean_processing_ms: 4.14201118023251\n",
      "  time_since_restore: 4602.248920917511\n",
      "  time_this_iter_s: 29.826332807540894\n",
      "  time_total_s: 4602.248920917511\n",
      "  timestamp: 1665275781\n",
      "  timesteps_since_restore: 2340000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 156\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    156 |          4602.25 |     2340000 | -1968.64 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-36-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 949.7323704405056\n",
      "  episode_reward_mean: -2096.7324093039574\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 785\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1490.03\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.017124544829130173\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.26043593883514404\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008108356967568398\n",
      "        policy_loss: 0.0008498912793584168\n",
      "        total_loss: 11786.0703125\n",
      "        vf_explained_var: 0.4949008822441101\n",
      "        vf_loss: 11786.0703125\n",
      "    load_time_ms: 2.838\n",
      "    num_steps_sampled: 2355000\n",
      "    num_steps_trained: 2351232\n",
      "    sample_time_ms: 27941.923\n",
      "    update_time_ms: 2.917\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.07619047619048\n",
      "    ram_util_percent: 24.70952380952381\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598501787828901\n",
      "    mean_inference_ms: 0.414316794745698\n",
      "    mean_processing_ms: 4.142347271141818\n",
      "  time_since_restore: 4631.487166404724\n",
      "  time_this_iter_s: 29.238245487213135\n",
      "  time_total_s: 4631.487166404724\n",
      "  timestamp: 1665275811\n",
      "  timesteps_since_restore: 2355000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2355000\n",
      "  training_iteration: 157\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:36:51,169\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 210.0x the scale of `vf_clip_param`. This means that it will take more than 210.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    157 |          4631.49 |     2355000 | -2096.73 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-37-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 331.67387782218276\n",
      "  episode_reward_mean: -2197.224686903223\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 790\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.828\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.008562272414565086\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.33438655734062195\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.037462808191776276\n",
      "        policy_loss: -0.0026380172930657864\n",
      "        total_loss: 10757.484375\n",
      "        vf_explained_var: 0.49246394634246826\n",
      "        vf_loss: 10757.4873046875\n",
      "    load_time_ms: 2.771\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2366208\n",
      "    sample_time_ms: 28440.462\n",
      "    update_time_ms: 2.945\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.784000000000002\n",
      "    ram_util_percent: 24.682000000000002\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598481427205419\n",
      "    mean_inference_ms: 0.4143376545012803\n",
      "    mean_processing_ms: 4.143285012278902\n",
      "  time_since_restore: 4666.412700176239\n",
      "  time_this_iter_s: 34.92553377151489\n",
      "  time_total_s: 4666.412700176239\n",
      "  timestamp: 1665275846\n",
      "  timesteps_since_restore: 2370000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 158\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:37:26,139\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 220.0x the scale of `vf_clip_param`. This means that it will take more than 220.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    158 |          4666.41 |     2370000 | -2197.22 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 331.67387782218276\n",
      "  episode_reward_mean: -2233.834935649191\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 795\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.027\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.008562272414565086\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.04618608579039574\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05279072746634483\n",
      "        policy_loss: -0.005566587671637535\n",
      "        total_loss: 9678.7841796875\n",
      "        vf_explained_var: 0.4616768956184387\n",
      "        vf_loss: 9678.7919921875\n",
      "    load_time_ms: 2.749\n",
      "    num_steps_sampled: 2385000\n",
      "    num_steps_trained: 2381184\n",
      "    sample_time_ms: 28418.806\n",
      "    update_time_ms: 2.941\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.27857142857143\n",
      "    ram_util_percent: 24.740476190476187\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598470715582391\n",
      "    mean_inference_ms: 0.41435908720158154\n",
      "    mean_processing_ms: 4.144230264020688\n",
      "  time_since_restore: 4695.752468585968\n",
      "  time_this_iter_s: 29.339768409729004\n",
      "  time_total_s: 4695.752468585968\n",
      "  timestamp: 1665275875\n",
      "  timesteps_since_restore: 2385000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2385000\n",
      "  training_iteration: 159\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:37:55,522\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 223.0x the scale of `vf_clip_param`. This means that it will take more than 223.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    159 |          4695.75 |     2385000 | -2233.83 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-38-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 331.67387782218276\n",
      "  episode_reward_mean: -2250.0042873356315\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 800\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.876\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01284340862184763\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.330886572599411\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021007783710956573\n",
      "        policy_loss: -0.0001833121059462428\n",
      "        total_loss: 9045.1630859375\n",
      "        vf_explained_var: 0.4418555498123169\n",
      "        vf_loss: 9045.162109375\n",
      "    load_time_ms: 2.735\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2396160\n",
      "    sample_time_ms: 28472.017\n",
      "    update_time_ms: 2.971\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.26428571428571\n",
      "    ram_util_percent: 24.835714285714282\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598434227937273\n",
      "    mean_inference_ms: 0.4143825465783586\n",
      "    mean_processing_ms: 4.1451695863933296\n",
      "  time_since_restore: 4725.429888486862\n",
      "  time_this_iter_s: 29.677419900894165\n",
      "  time_total_s: 4725.429888486862\n",
      "  timestamp: 1665275905\n",
      "  timesteps_since_restore: 2400000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 160\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:38:25,240\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 225.0x the scale of `vf_clip_param`. This means that it will take more than 225.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    160 |          4725.43 |     2400000 |    -2250 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-38-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -168.72296340351065\n",
      "  episode_reward_mean: -2290.863914347413\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 805\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1491.005\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01284340862184763\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.0653565302491188\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026273924857378006\n",
      "        policy_loss: 0.002766192890703678\n",
      "        total_loss: 8216.9013671875\n",
      "        vf_explained_var: 0.41166889667510986\n",
      "        vf_loss: 8216.8994140625\n",
      "    load_time_ms: 2.79\n",
      "    num_steps_sampled: 2415000\n",
      "    num_steps_trained: 2411136\n",
      "    sample_time_ms: 28558.23\n",
      "    update_time_ms: 2.895\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.29302325581395\n",
      "    ram_util_percent: 24.765116279069765\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598416180894682\n",
      "    mean_inference_ms: 0.41440654535225624\n",
      "    mean_processing_ms: 4.1461576695962385\n",
      "  time_since_restore: 4755.521234035492\n",
      "  time_this_iter_s: 30.09134554862976\n",
      "  time_total_s: 4755.521234035492\n",
      "  timestamp: 1665275935\n",
      "  timesteps_since_restore: 2415000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2415000\n",
      "  training_iteration: 161\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:38:55,379\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 229.0x the scale of `vf_clip_param`. This means that it will take more than 229.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    161 |          4755.52 |     2415000 | -2290.86 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-39-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -168.72296340351065\n",
      "  episode_reward_mean: -2319.2740197297026\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 810\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.936\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01284340862184763\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.1910860240459442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04495931416749954\n",
      "        policy_loss: -0.003344633849337697\n",
      "        total_loss: 7738.68017578125\n",
      "        vf_explained_var: 0.3935202360153198\n",
      "        vf_loss: 7738.68212890625\n",
      "    load_time_ms: 2.81\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2426112\n",
      "    sample_time_ms: 28534.946\n",
      "    update_time_ms: 2.977\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.97857142857142\n",
      "    ram_util_percent: 24.766666666666662\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598408795985491\n",
      "    mean_inference_ms: 0.4144320737755476\n",
      "    mean_processing_ms: 4.147142108471573\n",
      "  time_since_restore: 4784.894551038742\n",
      "  time_this_iter_s: 29.373317003250122\n",
      "  time_total_s: 4784.894551038742\n",
      "  timestamp: 1665275964\n",
      "  timesteps_since_restore: 2430000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 162\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:39:24,791\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 232.0x the scale of `vf_clip_param`. This means that it will take more than 232.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    162 |          4784.89 |     2430000 | -2319.27 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-39-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -168.72296340351065\n",
      "  episode_reward_mean: -2325.759047897289\n",
      "  episode_reward_min: -5344.3064949363625\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 815\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.903\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2154727727174759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022165970876812935\n",
      "        policy_loss: -0.0008467144216410816\n",
      "        total_loss: 7048.935546875\n",
      "        vf_explained_var: 0.3413122594356537\n",
      "        vf_loss: 7048.93603515625\n",
      "    load_time_ms: 2.674\n",
      "    num_steps_sampled: 2445000\n",
      "    num_steps_trained: 2441088\n",
      "    sample_time_ms: 28516.275\n",
      "    update_time_ms: 2.97\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.80714285714286\n",
      "    ram_util_percent: 24.76904761904762\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.59841167793677\n",
      "    mean_inference_ms: 0.414456916576874\n",
      "    mean_processing_ms: 4.148125222223958\n",
      "  time_since_restore: 4814.218566656113\n",
      "  time_this_iter_s: 29.324015617370605\n",
      "  time_total_s: 4814.218566656113\n",
      "  timestamp: 1665275994\n",
      "  timesteps_since_restore: 2445000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2445000\n",
      "  training_iteration: 163\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:39:54,160\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 233.0x the scale of `vf_clip_param`. This means that it will take more than 233.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    163 |          4814.22 |     2445000 | -2325.76 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-40-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -168.72296340351065\n",
      "  episode_reward_mean: -2270.3796074728943\n",
      "  episode_reward_min: -4723.489998307621\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 820\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.585\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.005081459414213896\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011867215856909752\n",
      "        policy_loss: 0.00045722670620307326\n",
      "        total_loss: 6378.578125\n",
      "        vf_explained_var: 0.3975961208343506\n",
      "        vf_loss: 6378.57763671875\n",
      "    load_time_ms: 2.651\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2456064\n",
      "    sample_time_ms: 29031.049\n",
      "    update_time_ms: 2.961\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.369387755102043\n",
      "    ram_util_percent: 24.751020408163264\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598445315850919\n",
      "    mean_inference_ms: 0.4144815459188944\n",
      "    mean_processing_ms: 4.149553498724559\n",
      "  time_since_restore: 4848.557833909988\n",
      "  time_this_iter_s: 34.33926725387573\n",
      "  time_total_s: 4848.557833909988\n",
      "  timestamp: 1665276028\n",
      "  timesteps_since_restore: 2460000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 164\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:40:28,548\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 227.0x the scale of `vf_clip_param`. This means that it will take more than 227.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    164 |          4848.56 |     2460000 | -2270.38 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-40-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1004.0313367372298\n",
      "  episode_reward_mean: -2323.759033855797\n",
      "  episode_reward_min: -4723.489998307621\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 825\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.84\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.022156784310936928\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01921439915895462\n",
      "        policy_loss: 0.000602418149355799\n",
      "        total_loss: 5535.71923828125\n",
      "        vf_explained_var: 0.3999291658401489\n",
      "        vf_loss: 5535.7177734375\n",
      "    load_time_ms: 2.474\n",
      "    num_steps_sampled: 2475000\n",
      "    num_steps_trained: 2471040\n",
      "    sample_time_ms: 29093.333\n",
      "    update_time_ms: 2.923\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.60697674418604\n",
      "    ram_util_percent: 24.77209302325581\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.59849120122431\n",
      "    mean_inference_ms: 0.41450863354872064\n",
      "    mean_processing_ms: 4.1509768388290675\n",
      "  time_since_restore: 4878.325911283493\n",
      "  time_this_iter_s: 29.76807737350464\n",
      "  time_total_s: 4878.325911283493\n",
      "  timestamp: 1665276058\n",
      "  timesteps_since_restore: 2475000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2475000\n",
      "  training_iteration: 165\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:40:58,359\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 232.0x the scale of `vf_clip_param`. This means that it will take more than 232.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    165 |          4878.33 |     2475000 | -2323.76 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-41-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1004.0313367372298\n",
      "  episode_reward_mean: -2300.8919400975424\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 830\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.892\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19329829514026642\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030243339017033577\n",
      "        policy_loss: -0.0003315714711789042\n",
      "        total_loss: 4979.9287109375\n",
      "        vf_explained_var: 0.4366035759449005\n",
      "        vf_loss: 4979.9287109375\n",
      "    load_time_ms: 2.388\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2486016\n",
      "    sample_time_ms: 29020.503\n",
      "    update_time_ms: 2.864\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.07560975609756\n",
      "    ram_util_percent: 24.773170731707314\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598590374527539\n",
      "    mean_inference_ms: 0.41453447133212834\n",
      "    mean_processing_ms: 4.151711865789816\n",
      "  time_since_restore: 4907.41340470314\n",
      "  time_this_iter_s: 29.087493419647217\n",
      "  time_total_s: 4907.41340470314\n",
      "  timestamp: 1665276087\n",
      "  timesteps_since_restore: 2490000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 166\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:41:27,491\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 230.0x the scale of `vf_clip_param`. This means that it will take more than 230.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    166 |          4907.41 |     2490000 | -2300.89 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-41-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1004.0313367372298\n",
      "  episode_reward_mean: -2332.650146312571\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 835\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.011\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.14328129589557648\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016347669064998627\n",
      "        policy_loss: 0.0016411039978265762\n",
      "        total_loss: 4548.50732421875\n",
      "        vf_explained_var: 0.4839540123939514\n",
      "        vf_loss: 4548.505859375\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 2505000\n",
      "    num_steps_trained: 2500992\n",
      "    sample_time_ms: 29007.15\n",
      "    update_time_ms: 2.968\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.2452380952381\n",
      "    ram_util_percent: 24.814285714285717\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598711567757855\n",
      "    mean_inference_ms: 0.4145607264572588\n",
      "    mean_processing_ms: 4.15243628876064\n",
      "  time_since_restore: 4936.500764846802\n",
      "  time_this_iter_s: 29.0873601436615\n",
      "  time_total_s: 4936.500764846802\n",
      "  timestamp: 1665276116\n",
      "  timesteps_since_restore: 2505000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2505000\n",
      "  training_iteration: 167\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:41:56,622\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 233.0x the scale of `vf_clip_param`. This means that it will take more than 233.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    167 |           4936.5 |     2505000 | -2332.65 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-42-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1103.140363387535\n",
      "  episode_reward_mean: -2402.6335178958516\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 840\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.252\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.26088207960128784\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02775290608406067\n",
      "        policy_loss: 0.005442923866212368\n",
      "        total_loss: 4408.01123046875\n",
      "        vf_explained_var: 0.3879912495613098\n",
      "        vf_loss: 4408.00537109375\n",
      "    load_time_ms: 2.378\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2515968\n",
      "    sample_time_ms: 28483.256\n",
      "    update_time_ms: 2.938\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.845238095238095\n",
      "    ram_util_percent: 24.809523809523803\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598796452531365\n",
      "    mean_inference_ms: 0.4145865939454888\n",
      "    mean_processing_ms: 4.15316145656306\n",
      "  time_since_restore: 4966.199636936188\n",
      "  time_this_iter_s: 29.698872089385986\n",
      "  time_total_s: 4966.199636936188\n",
      "  timestamp: 1665276146\n",
      "  timesteps_since_restore: 2520000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 168\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:42:26,362\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 240.0x the scale of `vf_clip_param`. This means that it will take more than 240.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    168 |           4966.2 |     2520000 | -2402.63 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1230.743773462393\n",
      "  episode_reward_mean: -2483.861428648229\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 845\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.378\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.16403000056743622\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02657071314752102\n",
      "        policy_loss: 0.005339247640222311\n",
      "        total_loss: 3721.5537109375\n",
      "        vf_explained_var: 0.5928465723991394\n",
      "        vf_loss: 3721.5478515625\n",
      "    load_time_ms: 2.379\n",
      "    num_steps_sampled: 2535000\n",
      "    num_steps_trained: 2530944\n",
      "    sample_time_ms: 28521.769\n",
      "    update_time_ms: 2.931\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.574418604651164\n",
      "    ram_util_percent: 24.813953488372093\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.598895786957919\n",
      "    mean_inference_ms: 0.4146107145135195\n",
      "    mean_processing_ms: 4.1538911390490485\n",
      "  time_since_restore: 4995.925312280655\n",
      "  time_this_iter_s: 29.725675344467163\n",
      "  time_total_s: 4995.925312280655\n",
      "  timestamp: 1665276176\n",
      "  timesteps_since_restore: 2535000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2535000\n",
      "  training_iteration: 169\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:42:56,131\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 248.0x the scale of `vf_clip_param`. This means that it will take more than 248.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    169 |          4995.93 |     2535000 | -2483.86 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-43-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1514.2423555665912\n",
      "  episode_reward_mean: -2553.263482844099\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 850\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.829\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.17122262716293335\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03199290111660957\n",
      "        policy_loss: 0.006445098202675581\n",
      "        total_loss: 3623.298828125\n",
      "        vf_explained_var: 0.5443859100341797\n",
      "        vf_loss: 3623.2919921875\n",
      "    load_time_ms: 2.269\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2545920\n",
      "    sample_time_ms: 28481.265\n",
      "    update_time_ms: 2.983\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.214285714285715\n",
      "    ram_util_percent: 24.883333333333333\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.59900140511342\n",
      "    mean_inference_ms: 0.4146340350309604\n",
      "    mean_processing_ms: 4.154610921523528\n",
      "  time_since_restore: 5025.202634096146\n",
      "  time_this_iter_s: 29.277321815490723\n",
      "  time_total_s: 5025.202634096146\n",
      "  timestamp: 1665276205\n",
      "  timesteps_since_restore: 2550000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 170\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:43:25,448\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 255.0x the scale of `vf_clip_param`. This means that it will take more than 255.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    170 |           5025.2 |     2550000 | -2553.26 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-44-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1724.3917387173487\n",
      "  episode_reward_mean: -2613.7860583043152\n",
      "  episode_reward_min: -3440.0462255857474\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 855\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.312\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.33030346035957336\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025763558223843575\n",
      "        policy_loss: 0.006514173466712236\n",
      "        total_loss: 3541.632568359375\n",
      "        vf_explained_var: 0.4889925420284271\n",
      "        vf_loss: 3541.62548828125\n",
      "    load_time_ms: 2.283\n",
      "    num_steps_sampled: 2565000\n",
      "    num_steps_trained: 2560896\n",
      "    sample_time_ms: 29027.392\n",
      "    update_time_ms: 3.11\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.049999999999997\n",
      "    ram_util_percent: 24.721999999999998\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599084031318937\n",
      "    mean_inference_ms: 0.41465579546192166\n",
      "    mean_processing_ms: 4.155944595950255\n",
      "  time_since_restore: 5060.751228570938\n",
      "  time_this_iter_s: 35.54859447479248\n",
      "  time_total_s: 5060.751228570938\n",
      "  timestamp: 1665276241\n",
      "  timesteps_since_restore: 2565000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2565000\n",
      "  training_iteration: 171\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:44:01,127\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 261.0x the scale of `vf_clip_param`. This means that it will take more than 261.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    171 |          5060.75 |     2565000 | -2613.79 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-44-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1724.3917387173487\n",
      "  episode_reward_mean: -2659.347269146316\n",
      "  episode_reward_min: -3440.0462255857474\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 860\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.754\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.28467294573783875\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.027947647497057915\n",
      "        policy_loss: 0.0033167183864861727\n",
      "        total_loss: 3080.940673828125\n",
      "        vf_explained_var: 0.5869052410125732\n",
      "        vf_loss: 3080.9365234375\n",
      "    load_time_ms: 2.237\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2575872\n",
      "    sample_time_ms: 29116.921\n",
      "    update_time_ms: 3.116\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.89772727272727\n",
      "    ram_util_percent: 24.775\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599132627444876\n",
      "    mean_inference_ms: 0.41467717775001356\n",
      "    mean_processing_ms: 4.157338064334209\n",
      "  time_since_restore: 5091.02382850647\n",
      "  time_this_iter_s: 30.272599935531616\n",
      "  time_total_s: 5091.02382850647\n",
      "  timestamp: 1665276271\n",
      "  timesteps_since_restore: 2580000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 172\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:44:31,446\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 266.0x the scale of `vf_clip_param`. This means that it will take more than 266.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    172 |          5091.02 |     2580000 | -2659.35 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-45-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1796.5016225818085\n",
      "  episode_reward_mean: -2716.5967835605184\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 865\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.405\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.20867598056793213\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03481322154402733\n",
      "        policy_loss: 0.001790590351447463\n",
      "        total_loss: 2932.638427734375\n",
      "        vf_explained_var: 0.61077880859375\n",
      "        vf_loss: 2932.635986328125\n",
      "    load_time_ms: 2.355\n",
      "    num_steps_sampled: 2595000\n",
      "    num_steps_trained: 2590848\n",
      "    sample_time_ms: 29127.172\n",
      "    update_time_ms: 3.08\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.916666666666664\n",
      "    ram_util_percent: 24.77857142857143\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599174754874134\n",
      "    mean_inference_ms: 0.41469717929282224\n",
      "    mean_processing_ms: 4.158752309522901\n",
      "  time_since_restore: 5120.467552900314\n",
      "  time_this_iter_s: 29.443724393844604\n",
      "  time_total_s: 5120.467552900314\n",
      "  timestamp: 1665276300\n",
      "  timesteps_since_restore: 2595000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2595000\n",
      "  training_iteration: 173\n",
      "  trial_id: a95f16f0\n",
      "  \u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:45:00,931\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 272.0x the scale of `vf_clip_param`. This means that it will take more than 272.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    173 |          5120.47 |     2595000 |  -2716.6 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-45-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -2022.7375143059926\n",
      "  episode_reward_mean: -2762.6763548838867\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 870\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.231\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.13759182393550873\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016564728692173958\n",
      "        policy_loss: 0.0036327873822301626\n",
      "        total_loss: 2733.45556640625\n",
      "        vf_explained_var: 0.7621610164642334\n",
      "        vf_loss: 2733.4521484375\n",
      "    load_time_ms: 2.379\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2605824\n",
      "    sample_time_ms: 28629.022\n",
      "    update_time_ms: 3.111\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.47857142857142\n",
      "    ram_util_percent: 24.764285714285712\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599227408881489\n",
      "    mean_inference_ms: 0.4147170382494865\n",
      "    mean_processing_ms: 4.16016943404186\n",
      "  time_since_restore: 5149.823895215988\n",
      "  time_this_iter_s: 29.356342315673828\n",
      "  time_total_s: 5149.823895215988\n",
      "  timestamp: 1665276330\n",
      "  timesteps_since_restore: 2610000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 174\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:45:30,329\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 276.0x the scale of `vf_clip_param`. This means that it will take more than 276.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    174 |          5149.82 |     2610000 | -2762.68 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-46-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -2083.295757788571\n",
      "  episode_reward_mean: -2790.134524687485\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 875\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.686\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4362913966178894\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029987171292304993\n",
      "        policy_loss: 0.001499005127698183\n",
      "        total_loss: 2220.6787109375\n",
      "        vf_explained_var: 0.7162125706672668\n",
      "        vf_loss: 2220.6767578125\n",
      "    load_time_ms: 2.492\n",
      "    num_steps_sampled: 2625000\n",
      "    num_steps_trained: 2620800\n",
      "    sample_time_ms: 28636.156\n",
      "    update_time_ms: 3.105\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.114285714285714\n",
      "    ram_util_percent: 24.77857142857143\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599262255111073\n",
      "    mean_inference_ms: 0.41473560806041493\n",
      "    mean_processing_ms: 4.1616304371091415\n",
      "  time_since_restore: 5179.658919811249\n",
      "  time_this_iter_s: 29.83502459526062\n",
      "  time_total_s: 5179.658919811249\n",
      "  timestamp: 1665276360\n",
      "  timesteps_since_restore: 2625000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2625000\n",
      "  training_iteration: 175\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:46:00,206\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 279.0x the scale of `vf_clip_param`. This means that it will take more than 279.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    175 |          5179.66 |     2625000 | -2790.13 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-46-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -2083.295757788571\n",
      "  episode_reward_mean: -2827.4890381428118\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 880\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.571\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.03228828310966492\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012687338516116142\n",
      "        policy_loss: 0.003817146411165595\n",
      "        total_loss: 2339.45068359375\n",
      "        vf_explained_var: 0.7646926045417786\n",
      "        vf_loss: 2339.446533203125\n",
      "    load_time_ms: 2.628\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2635776\n",
      "    sample_time_ms: 28719.711\n",
      "    update_time_ms: 3.168\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.20697674418604\n",
      "    ram_util_percent: 24.799999999999997\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599288814193304\n",
      "    mean_inference_ms: 0.4147527629445991\n",
      "    mean_processing_ms: 4.163090521638867\n",
      "  time_since_restore: 5209.573093891144\n",
      "  time_this_iter_s: 29.91417407989502\n",
      "  time_total_s: 5209.573093891144\n",
      "  timestamp: 1665276390\n",
      "  timesteps_since_restore: 2640000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 176\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:46:30,163\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 283.0x the scale of `vf_clip_param`. This means that it will take more than 283.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    176 |          5209.57 |     2640000 | -2827.49 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-46-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2839.3972432315577\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 885\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.013\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7416759133338928\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.031866151839494705\n",
      "        policy_loss: 0.004936711862683296\n",
      "        total_loss: 1701.363037109375\n",
      "        vf_explained_var: 0.7751567959785461\n",
      "        vf_loss: 1701.357421875\n",
      "    load_time_ms: 2.714\n",
      "    num_steps_sampled: 2655000\n",
      "    num_steps_trained: 2650752\n",
      "    sample_time_ms: 28729.601\n",
      "    update_time_ms: 3.104\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.02857142857143\n",
      "    ram_util_percent: 24.776190476190475\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.59931116313977\n",
      "    mean_inference_ms: 0.41476901707228875\n",
      "    mean_processing_ms: 4.164558206459979\n",
      "  time_since_restore: 5238.763829946518\n",
      "  time_this_iter_s: 29.190736055374146\n",
      "  time_total_s: 5238.763829946518\n",
      "  timestamp: 1665276419\n",
      "  timesteps_since_restore: 2655000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2655000\n",
      "  training_iteration: 177\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:46:59,396\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 284.0x the scale of `vf_clip_param`. This means that it will take more than 284.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    177 |          5238.76 |     2655000 |  -2839.4 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-47-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2872.1740650907436\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 890\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.507\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.24108535051345825\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030683482065796852\n",
      "        policy_loss: 0.003615394700318575\n",
      "        total_loss: 1777.502685546875\n",
      "        vf_explained_var: 0.8177247047424316\n",
      "        vf_loss: 1777.49853515625\n",
      "    load_time_ms: 2.71\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2665728\n",
      "    sample_time_ms: 28696.81\n",
      "    update_time_ms: 3.137\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.602380952380955\n",
      "    ram_util_percent: 24.766666666666662\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599373164786772\n",
      "    mean_inference_ms: 0.4147849299647089\n",
      "    mean_processing_ms: 4.1654088921947015\n",
      "  time_since_restore: 5268.120190858841\n",
      "  time_this_iter_s: 29.356360912322998\n",
      "  time_total_s: 5268.120190858841\n",
      "  timestamp: 1665276448\n",
      "  timesteps_since_restore: 2670000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 178\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:47:28,798\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 287.0x the scale of `vf_clip_param`. This means that it will take more than 287.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    178 |          5268.12 |     2670000 | -2872.17 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-47-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2890.5013105987764\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 895\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.955\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5663248896598816\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.046338245272636414\n",
      "        policy_loss: -0.0005553254741244018\n",
      "        total_loss: 1813.369140625\n",
      "        vf_explained_var: 0.7924387454986572\n",
      "        vf_loss: 1813.368896484375\n",
      "    load_time_ms: 2.653\n",
      "    num_steps_sampled: 2685000\n",
      "    num_steps_trained: 2680704\n",
      "    sample_time_ms: 28632.949\n",
      "    update_time_ms: 3.192\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.33414634146341\n",
      "    ram_util_percent: 24.809756097560978\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599417728115829\n",
      "    mean_inference_ms: 0.4148055389231287\n",
      "    mean_processing_ms: 4.166244491373986\n",
      "  time_since_restore: 5297.2217898368835\n",
      "  time_this_iter_s: 29.101598978042603\n",
      "  time_total_s: 5297.2217898368835\n",
      "  timestamp: 1665276477\n",
      "  timesteps_since_restore: 2685000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2685000\n",
      "  training_iteration: 179\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:47:57,944\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 289.0x the scale of `vf_clip_param`. This means that it will take more than 289.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    179 |          5297.22 |     2685000 |  -2890.5 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-48-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2902.446647953793\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 900\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.056\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.028897669166326523\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.1546245813369751\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02446637861430645\n",
      "        policy_loss: 0.0022756322287023067\n",
      "        total_loss: 1607.4617919921875\n",
      "        vf_explained_var: 0.8388937711715698\n",
      "        vf_loss: 1607.45849609375\n",
      "    load_time_ms: 2.601\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2695680\n",
      "    sample_time_ms: 28655.638\n",
      "    update_time_ms: 3.185\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.44418604651163\n",
      "    ram_util_percent: 24.862790697674416\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599499180149728\n",
      "    mean_inference_ms: 0.4148248138271719\n",
      "    mean_processing_ms: 4.167059080807658\n",
      "  time_since_restore: 5326.724836111069\n",
      "  time_this_iter_s: 29.50304627418518\n",
      "  time_total_s: 5326.724836111069\n",
      "  timestamp: 1665276507\n",
      "  timesteps_since_restore: 2700000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 180\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:48:27,489\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 290.0x the scale of `vf_clip_param`. This means that it will take more than 290.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    180 |          5326.72 |     2700000 | -2902.45 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-48-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2903.293528460168\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 905\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.42\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.028897669166326523\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8669230937957764\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0682063102722168\n",
      "        policy_loss: 0.004827696830034256\n",
      "        total_loss: 1379.620361328125\n",
      "        vf_explained_var: 0.8151764869689941\n",
      "        vf_loss: 1379.61376953125\n",
      "    load_time_ms: 2.431\n",
      "    num_steps_sampled: 2715000\n",
      "    num_steps_trained: 2710656\n",
      "    sample_time_ms: 28024.569\n",
      "    update_time_ms: 3.128\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.23170731707317\n",
      "    ram_util_percent: 24.824390243902442\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599562827809026\n",
      "    mean_inference_ms: 0.41484348134823135\n",
      "    mean_processing_ms: 4.167807442377699\n",
      "  time_since_restore: 5355.974029779434\n",
      "  time_this_iter_s: 29.24919366836548\n",
      "  time_total_s: 5355.974029779434\n",
      "  timestamp: 1665276536\n",
      "  timesteps_since_restore: 2715000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2715000\n",
      "  training_iteration: 181\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:48:56,788\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 290.0x the scale of `vf_clip_param`. This means that it will take more than 290.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    181 |          5355.97 |     2715000 | -2903.29 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-49-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2916.34222254144\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 910\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.345\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.043346501886844635\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.3626382052898407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04892020672559738\n",
      "        policy_loss: -0.004429658874869347\n",
      "        total_loss: 1471.9439697265625\n",
      "        vf_explained_var: 0.8233503699302673\n",
      "        vf_loss: 1471.9464111328125\n",
      "    load_time_ms: 2.53\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2725632\n",
      "    sample_time_ms: 27899.715\n",
      "    update_time_ms: 3.141\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.349999999999994\n",
      "    ram_util_percent: 24.81428571428571\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599641436780945\n",
      "    mean_inference_ms: 0.41486211163768155\n",
      "    mean_processing_ms: 4.168552268845514\n",
      "  time_since_restore: 5384.998537540436\n",
      "  time_this_iter_s: 29.024507761001587\n",
      "  time_total_s: 5384.998537540436\n",
      "  timestamp: 1665276565\n",
      "  timesteps_since_restore: 2730000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 182\n",
      "  trial_id: a95f16f0\n",
      "  \u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:49:25,862\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 292.0x the scale of `vf_clip_param`. This means that it will take more than 292.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    182 |             5385 |     2730000 | -2916.34 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-49-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2903.7567243490253\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 915\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.791\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06501975655555725\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5669554471969604\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024949120357632637\n",
      "        policy_loss: 0.0037160352803766727\n",
      "        total_loss: 1405.1654052734375\n",
      "        vf_explained_var: 0.8521865010261536\n",
      "        vf_loss: 1405.16015625\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 2745000\n",
      "    num_steps_trained: 2740608\n",
      "    sample_time_ms: 27870.873\n",
      "    update_time_ms: 3.243\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.639024390243904\n",
      "    ram_util_percent: 24.819512195121952\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599725182960738\n",
      "    mean_inference_ms: 0.41488220126655356\n",
      "    mean_processing_ms: 4.1692804189315815\n",
      "  time_since_restore: 5414.139310121536\n",
      "  time_this_iter_s: 29.140772581100464\n",
      "  time_total_s: 5414.139310121536\n",
      "  timestamp: 1665276595\n",
      "  timesteps_since_restore: 2745000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2745000\n",
      "  training_iteration: 183\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:49:55,051\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 290.0x the scale of `vf_clip_param`. This means that it will take more than 290.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    183 |          5414.14 |     2745000 | -2903.76 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-50-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2888.7417283876757\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 920\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.958\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06501975655555725\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.21450923383235931\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05325677990913391\n",
      "        policy_loss: 0.0027410604525357485\n",
      "        total_loss: 1252.860595703125\n",
      "        vf_explained_var: 0.8712721467018127\n",
      "        vf_loss: 1252.8546142578125\n",
      "    load_time_ms: 2.517\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2755584\n",
      "    sample_time_ms: 27893.096\n",
      "    update_time_ms: 3.238\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.181395348837206\n",
      "    ram_util_percent: 24.858139534883723\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599833409820961\n",
      "    mean_inference_ms: 0.4149012969174473\n",
      "    mean_processing_ms: 4.169552177517096\n",
      "  time_since_restore: 5443.719420433044\n",
      "  time_this_iter_s: 29.58011031150818\n",
      "  time_total_s: 5443.719420433044\n",
      "  timestamp: 1665276624\n",
      "  timesteps_since_restore: 2760000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 184\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:50:24,681\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 289.0x the scale of `vf_clip_param`. This means that it will take more than 289.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    184 |          5443.72 |     2760000 | -2888.74 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-50-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2893.2488982327545\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 925\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.816\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09752963483333588\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.0021572643890976906\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.12715552747249603\n",
      "        policy_loss: 0.012293278239667416\n",
      "        total_loss: 1865.1329345703125\n",
      "        vf_explained_var: 0.895842432975769\n",
      "        vf_loss: 1865.1080322265625\n",
      "    load_time_ms: 2.533\n",
      "    num_steps_sampled: 2775000\n",
      "    num_steps_trained: 2770560\n",
      "    sample_time_ms: 27840.442\n",
      "    update_time_ms: 3.232\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.56904761904762\n",
      "    ram_util_percent: 24.864285714285714\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599906793615738\n",
      "    mean_inference_ms: 0.4149192718101704\n",
      "    mean_processing_ms: 4.169819924417821\n",
      "  time_since_restore: 5473.026577234268\n",
      "  time_this_iter_s: 29.307156801223755\n",
      "  time_total_s: 5473.026577234268\n",
      "  timestamp: 1665276654\n",
      "  timesteps_since_restore: 2775000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2775000\n",
      "  training_iteration: 185\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:50:54,032\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 289.0x the scale of `vf_clip_param`. This means that it will take more than 289.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    185 |          5473.03 |     2775000 | -2893.25 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-51-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2876.748519859343\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 930\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.16\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.178558811545372\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025109291076660156\n",
      "        policy_loss: 0.0014107426395639777\n",
      "        total_loss: 1283.2623291015625\n",
      "        vf_explained_var: 0.8595194816589355\n",
      "        vf_loss: 1283.2572021484375\n",
      "    load_time_ms: 2.489\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2785536\n",
      "    sample_time_ms: 27790.145\n",
      "    update_time_ms: 3.265\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.56190476190476\n",
      "    ram_util_percent: 24.838095238095235\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599986808953189\n",
      "    mean_inference_ms: 0.4149374689446009\n",
      "    mean_processing_ms: 4.170094426887482\n",
      "  time_since_restore: 5502.441032648087\n",
      "  time_this_iter_s: 29.41445541381836\n",
      "  time_total_s: 5502.441032648087\n",
      "  timestamp: 1665276683\n",
      "  timesteps_since_restore: 2790000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 186\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:51:23,491\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 288.0x the scale of `vf_clip_param`. This means that it will take more than 288.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    186 |          5502.44 |     2790000 | -2876.75 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-51-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2882.053539137801\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 935\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.963\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.02109302394092083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016904085874557495\n",
      "        policy_loss: 0.0005983602604828775\n",
      "        total_loss: 1294.55517578125\n",
      "        vf_explained_var: 0.9042912125587463\n",
      "        vf_loss: 1294.5521240234375\n",
      "    load_time_ms: 2.433\n",
      "    num_steps_sampled: 2805000\n",
      "    num_steps_trained: 2800512\n",
      "    sample_time_ms: 27815.884\n",
      "    update_time_ms: 3.287\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.97142857142857\n",
      "    ram_util_percent: 24.873809523809523\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600057682463838\n",
      "    mean_inference_ms: 0.4149554215730833\n",
      "    mean_processing_ms: 4.170370662122095\n",
      "  time_since_restore: 5531.8867337703705\n",
      "  time_this_iter_s: 29.445701122283936\n",
      "  time_total_s: 5531.8867337703705\n",
      "  timestamp: 1665276712\n",
      "  timesteps_since_restore: 2805000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2805000\n",
      "  training_iteration: 187\n",
      "  trial_id: a95f16f0\n",
      "  \u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:51:52,979\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 288.0x the scale of `vf_clip_param`. This means that it will take more than 288.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    187 |          5531.89 |     2805000 | -2882.05 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-52-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2861.0674335480585\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 940\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.777\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7721999883651733\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011358455754816532\n",
      "        policy_loss: 0.0011059717508032918\n",
      "        total_loss: 1062.0225830078125\n",
      "        vf_explained_var: 0.8488186597824097\n",
      "        vf_loss: 1062.0196533203125\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2815488\n",
      "    sample_time_ms: 27836.191\n",
      "    update_time_ms: 3.257\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.07142857142858\n",
      "    ram_util_percent: 24.888095238095236\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600129567573859\n",
      "    mean_inference_ms: 0.41497353968363854\n",
      "    mean_processing_ms: 4.170620298961435\n",
      "  time_since_restore: 5561.464542388916\n",
      "  time_this_iter_s: 29.577808618545532\n",
      "  time_total_s: 5561.464542388916\n",
      "  timestamp: 1665276742\n",
      "  timesteps_since_restore: 2820000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 188\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:52:22,605\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 286.0x the scale of `vf_clip_param`. This means that it will take more than 286.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    188 |          5561.46 |     2820000 | -2861.07 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-52-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2845.689865415141\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 945\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.771\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7997622489929199\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010404490865767002\n",
      "        policy_loss: 0.002300113206729293\n",
      "        total_loss: 833.3055419921875\n",
      "        vf_explained_var: 0.8489974737167358\n",
      "        vf_loss: 833.3016967773438\n",
      "    load_time_ms: 2.578\n",
      "    num_steps_sampled: 2835000\n",
      "    num_steps_trained: 2830464\n",
      "    sample_time_ms: 27810.929\n",
      "    update_time_ms: 3.164\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.31219512195121\n",
      "    ram_util_percent: 24.914634146341463\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600172969586525\n",
      "    mean_inference_ms: 0.4149907430347175\n",
      "    mean_processing_ms: 4.170821998918188\n",
      "  time_since_restore: 5590.313106775284\n",
      "  time_this_iter_s: 28.848564386367798\n",
      "  time_total_s: 5590.313106775284\n",
      "  timestamp: 1665276771\n",
      "  timesteps_since_restore: 2835000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2835000\n",
      "  training_iteration: 189\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:52:51,497\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 285.0x the scale of `vf_clip_param`. This means that it will take more than 285.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    189 |          5590.31 |     2835000 | -2845.69 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-53-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2832.012314896479\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 950\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.949\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7793335318565369\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03947479650378227\n",
      "        policy_loss: 0.01128850132226944\n",
      "        total_loss: 851.459228515625\n",
      "        vf_explained_var: 0.8720625638961792\n",
      "        vf_loss: 851.4420776367188\n",
      "    load_time_ms: 2.696\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2845440\n",
      "    sample_time_ms: 28389.141\n",
      "    update_time_ms: 3.12\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.298039215686277\n",
      "    ram_util_percent: 24.91568627450981\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600186949823665\n",
      "    mean_inference_ms: 0.4150070495823472\n",
      "    mean_processing_ms: 4.171616792359069\n",
      "  time_since_restore: 5625.600764274597\n",
      "  time_this_iter_s: 35.287657499313354\n",
      "  time_total_s: 5625.600764274597\n",
      "  timestamp: 1665276806\n",
      "  timesteps_since_restore: 2850000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 190\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:53:26,834\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 283.0x the scale of `vf_clip_param`. This means that it will take more than 283.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    190 |           5625.6 |     2850000 | -2832.01 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-53-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2831.9631363280046\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 955\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.108\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.05008396878838539\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0485977940261364\n",
      "        policy_loss: 0.003743192180991173\n",
      "        total_loss: 1313.6019287109375\n",
      "        vf_explained_var: 0.8735475540161133\n",
      "        vf_loss: 1313.5911865234375\n",
      "    load_time_ms: 2.817\n",
      "    num_steps_sampled: 2865000\n",
      "    num_steps_trained: 2860416\n",
      "    sample_time_ms: 28393.274\n",
      "    update_time_ms: 3.151\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.13095238095238\n",
      "    ram_util_percent: 24.923809523809524\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600212864007991\n",
      "    mean_inference_ms: 0.4150244171218253\n",
      "    mean_processing_ms: 4.17179163634971\n",
      "  time_since_restore: 5654.874876499176\n",
      "  time_this_iter_s: 29.274112224578857\n",
      "  time_total_s: 5654.874876499176\n",
      "  timestamp: 1665276836\n",
      "  timesteps_since_restore: 2865000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2865000\n",
      "  training_iteration: 191\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:53:56,243\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 283.0x the scale of `vf_clip_param`. This means that it will take more than 283.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    191 |          5654.87 |     2865000 | -2831.96 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-54-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2800.951115698572\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 960\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.689\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.21944166719913483\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.48574793338775635\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012826258316636086\n",
      "        policy_loss: 0.0007155776838771999\n",
      "        total_loss: 807.7327880859375\n",
      "        vf_explained_var: 0.918988823890686\n",
      "        vf_loss: 807.7293090820312\n",
      "    load_time_ms: 2.763\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2875392\n",
      "    sample_time_ms: 28432.22\n",
      "    update_time_ms: 3.156\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.75476190476191\n",
      "    ram_util_percent: 24.91190476190476\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600262323604616\n",
      "    mean_inference_ms: 0.41504186142149524\n",
      "    mean_processing_ms: 4.171892755007912\n",
      "  time_since_restore: 5684.294137239456\n",
      "  time_this_iter_s: 29.41926074028015\n",
      "  time_total_s: 5684.294137239456\n",
      "  timestamp: 1665276865\n",
      "  timesteps_since_restore: 2880000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 192\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:54:25,702\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 280.0x the scale of `vf_clip_param`. This means that it will take more than 280.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    192 |          5684.29 |     2880000 | -2800.95 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-54-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2757.138908173802\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 965\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.969\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.21944166719913483\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8928055763244629\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025531597435474396\n",
      "        policy_loss: 0.0036266231909394264\n",
      "        total_loss: 854.1825561523438\n",
      "        vf_explained_var: 0.9065285921096802\n",
      "        vf_loss: 854.1732788085938\n",
      "    load_time_ms: 2.703\n",
      "    num_steps_sampled: 2895000\n",
      "    num_steps_trained: 2890368\n",
      "    sample_time_ms: 28430.832\n",
      "    update_time_ms: 3.078\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.27804878048781\n",
      "    ram_util_percent: 24.921951219512195\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600312708208804\n",
      "    mean_inference_ms: 0.4150608790647731\n",
      "    mean_processing_ms: 4.171951755599631\n",
      "  time_since_restore: 5713.43232011795\n",
      "  time_this_iter_s: 29.138182878494263\n",
      "  time_total_s: 5713.43232011795\n",
      "  timestamp: 1665276894\n",
      "  timesteps_since_restore: 2895000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2895000\n",
      "  training_iteration: 193\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:54:54,884\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 276.0x the scale of `vf_clip_param`. This means that it will take more than 276.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    193 |          5713.43 |     2895000 | -2757.14 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-55-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2736.776014816758\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 970\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.21944166719913483\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.20848050713539124\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05804290249943733\n",
      "        policy_loss: 0.008949519135057926\n",
      "        total_loss: 1353.9375\n",
      "        vf_explained_var: 0.8919000029563904\n",
      "        vf_loss: 1353.915283203125\n",
      "    load_time_ms: 2.691\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2905344\n",
      "    sample_time_ms: 28352.17\n",
      "    update_time_ms: 3.06\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.52439024390244\n",
      "    ram_util_percent: 24.924390243902437\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6003350699794\n",
      "    mean_inference_ms: 0.4150792313824003\n",
      "    mean_processing_ms: 4.172010778018048\n",
      "  time_since_restore: 5742.220996856689\n",
      "  time_this_iter_s: 28.788676738739014\n",
      "  time_total_s: 5742.220996856689\n",
      "  timestamp: 1665276923\n",
      "  timesteps_since_restore: 2910000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 194\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:55:23,720\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 274.0x the scale of `vf_clip_param`. This means that it will take more than 274.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    194 |          5742.22 |     2910000 | -2736.78 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-55-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2731.349799802271\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 975\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.459\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.32916250824928284\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.06891806423664093\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008932922035455704\n",
      "        policy_loss: 0.0015652332222089171\n",
      "        total_loss: 970.53369140625\n",
      "        vf_explained_var: 0.9288906455039978\n",
      "        vf_loss: 970.529296875\n",
      "    load_time_ms: 2.561\n",
      "    num_steps_sampled: 2925000\n",
      "    num_steps_trained: 2920320\n",
      "    sample_time_ms: 28352.857\n",
      "    update_time_ms: 3.101\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.82380952380952\n",
      "    ram_util_percent: 24.91428571428571\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600356484641459\n",
      "    mean_inference_ms: 0.4150975704730602\n",
      "    mean_processing_ms: 4.172028477721401\n",
      "  time_since_restore: 5771.54360127449\n",
      "  time_this_iter_s: 29.322604417800903\n",
      "  time_total_s: 5771.54360127449\n",
      "  timestamp: 1665276953\n",
      "  timesteps_since_restore: 2925000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2925000\n",
      "  training_iteration: 195\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:55:53,089\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 273.0x the scale of `vf_clip_param`. This means that it will take more than 273.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    195 |          5771.54 |     2925000 | -2731.35 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-56-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2698.8833979763544\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 980\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.025\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16458125412464142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7241774797439575\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.07190393656492233\n",
      "        policy_loss: 0.022564150393009186\n",
      "        total_loss: 1188.767578125\n",
      "        vf_explained_var: 0.8365371823310852\n",
      "        vf_loss: 1188.7332763671875\n",
      "    load_time_ms: 2.589\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2935296\n",
      "    sample_time_ms: 28354.731\n",
      "    update_time_ms: 3.045\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.03333333333334\n",
      "    ram_util_percent: 24.973809523809525\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.6003497208209225\n",
      "    mean_inference_ms: 0.41511560092936667\n",
      "    mean_processing_ms: 4.172044604467548\n",
      "  time_since_restore: 5800.982078552246\n",
      "  time_this_iter_s: 29.438477277755737\n",
      "  time_total_s: 5800.982078552246\n",
      "  timestamp: 1665276982\n",
      "  timesteps_since_restore: 2940000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 196\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:56:22,572\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 270.0x the scale of `vf_clip_param`. This means that it will take more than 270.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    196 |          5800.98 |     2940000 | -2698.88 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-56-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2723.524393307351\n",
      "  episode_reward_min: -4864.129066137782\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 985\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1490.005\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.24687188863754272\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8173016309738159\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.028134247288107872\n",
      "        policy_loss: 0.0063261487521231174\n",
      "        total_loss: 1321.5992431640625\n",
      "        vf_explained_var: 0.9388377070426941\n",
      "        vf_loss: 1321.586181640625\n",
      "    load_time_ms: 2.56\n",
      "    num_steps_sampled: 2955000\n",
      "    num_steps_trained: 2950272\n",
      "    sample_time_ms: 28350.114\n",
      "    update_time_ms: 3.074\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.78333333333333\n",
      "    ram_util_percent: 24.91190476190476\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600333274985896\n",
      "    mean_inference_ms: 0.4151329317550166\n",
      "    mean_processing_ms: 4.172083826839593\n",
      "  time_since_restore: 5830.401330947876\n",
      "  time_this_iter_s: 29.419252395629883\n",
      "  time_total_s: 5830.401330947876\n",
      "  timestamp: 1665277012\n",
      "  timesteps_since_restore: 2955000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2955000\n",
      "  training_iteration: 197\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:56:52,040\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 272.0x the scale of `vf_clip_param`. This means that it will take more than 272.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    197 |           5830.4 |     2955000 | -2723.52 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-57-21\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2711.553457120202\n",
      "  episode_reward_min: -4864.129066137782\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 990\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1491.865\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.24687188863754272\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1674611121416092\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013069824315607548\n",
      "        policy_loss: 0.0024218023754656315\n",
      "        total_loss: 1397.3636474609375\n",
      "        vf_explained_var: 0.8998199701309204\n",
      "        vf_loss: 1397.358154296875\n",
      "    load_time_ms: 2.536\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2965248\n",
      "    sample_time_ms: 28342.85\n",
      "    update_time_ms: 3.104\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.65581395348838\n",
      "    ram_util_percent: 24.94651162790698\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600297466269579\n",
      "    mean_inference_ms: 0.41514842664056606\n",
      "    mean_processing_ms: 4.172136514037383\n",
      "  time_since_restore: 5859.925055980682\n",
      "  time_this_iter_s: 29.523725032806396\n",
      "  time_total_s: 5859.925055980682\n",
      "  timestamp: 1665277041\n",
      "  timesteps_since_restore: 2970000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 198\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:57:21,611\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 271.0x the scale of `vf_clip_param`. This means that it will take more than 271.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    198 |          5859.93 |     2970000 | -2711.55 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-57-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1086.908541912825\n",
      "  episode_reward_mean: -2677.1728743147796\n",
      "  episode_reward_min: -4864.129066137782\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 995\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1492.329\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.24687188863754272\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.26606693863868713\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.1147492453455925\n",
      "        policy_loss: 0.012722477316856384\n",
      "        total_loss: 1280.7760009765625\n",
      "        vf_explained_var: 0.8874762058258057\n",
      "        vf_loss: 1280.73486328125\n",
      "    load_time_ms: 2.366\n",
      "    num_steps_sampled: 2985000\n",
      "    num_steps_trained: 2980224\n",
      "    sample_time_ms: 28414.594\n",
      "    update_time_ms: 3.196\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.70238095238095\n",
      "    ram_util_percent: 24.969047619047622\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600296382745667\n",
      "    mean_inference_ms: 0.4151586884383201\n",
      "    mean_processing_ms: 4.17219015677569\n",
      "  time_since_restore: 5889.494956254959\n",
      "  time_this_iter_s: 29.569900274276733\n",
      "  time_total_s: 5889.494956254959\n",
      "  timestamp: 1665277071\n",
      "  timesteps_since_restore: 2985000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2985000\n",
      "  training_iteration: 199\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:57:51,233\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 268.0x the scale of `vf_clip_param`. This means that it will take more than 268.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    199 |          5889.49 |     2985000 | -2677.17 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-58-20\n",
      "  done: true\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1086.908541912825\n",
      "  episode_reward_mean: -2682.8721921558877\n",
      "  episode_reward_min: -4864.129066137782\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 1000\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1490.493\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.3703078329563141\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7362141609191895\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0041462150402367115\n",
      "        policy_loss: -0.0002459384559188038\n",
      "        total_loss: 1239.998046875\n",
      "        vf_explained_var: 0.9404228925704956\n",
      "        vf_loss: 1239.9969482421875\n",
      "    load_time_ms: 2.375\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 2995200\n",
      "    sample_time_ms: 27833.434\n",
      "    update_time_ms: 3.164\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.84285714285714\n",
      "    ram_util_percent: 25.059523809523803\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.600286435432724\n",
      "    mean_inference_ms: 0.41516980309590024\n",
      "    mean_processing_ms: 4.17224885766545\n",
      "  time_since_restore: 5918.953051567078\n",
      "  time_this_iter_s: 29.45809531211853\n",
      "  time_total_s: 5918.953051567078\n",
      "  timestamp: 1665277100\n",
      "  timesteps_since_restore: 3000000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 200\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:58:20,746\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 268.0x the scale of `vf_clip_param`. This means that it will take more than 268.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 TERMINATED)\n",
      "+--------------------------------------+------------+-------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status     | loc   |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+------------+-------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | TERMINATED |       |    200 |          5918.95 |     3000000 | -2682.87 |\n",
      "+--------------------------------------+------------+-------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 TERMINATED)\n",
      "+--------------------------------------+------------+-------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status     | loc   |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+------------+-------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | TERMINATED |       |    200 |          5918.95 |     3000000 | -2682.87 |\n",
      "+--------------------------------------+------------+-------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python examples/train.py singleagent_ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e948b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
