{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0068132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "def read_column_from_csv(file_path, column_index):\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        column_data = [row[column_index] for row in reader]\n",
    "    return column_data\n",
    "\n",
    "def write_row_to_csv(file_path, row_data):\n",
    "    with open(file_path, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row_data)\n",
    "\n",
    "directory_path = './progress_gpt' # Change this to the path of the directory containing the csv files\n",
    "column_index = 2 # Change this to the index of the column you want to extract (0 for the first column)\n",
    "aggregate_file = 'aggregate_gpt.csv'\n",
    "\n",
    "# Remove the aggregate file if it already exists to start fresh\n",
    "if os.path.exists(aggregate_file):\n",
    "    os.remove(aggregate_file)\n",
    "\n",
    "# Iterate through all csv files in the directory\n",
    "for file_path in glob.glob(os.path.join(directory_path, '*.csv')):\n",
    "    # Read the specified column from the current csv file\n",
    "    column_data = read_column_from_csv(file_path, column_index)\n",
    "\n",
    "    # Write the column data as a row in the aggregate csv\n",
    "    write_row_to_csv(aggregate_file, column_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5a6d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data saved to normalized_human.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def normalize_row(row):\n",
    "    row_min = min(row)\n",
    "    row_max = max(row)\n",
    "    normalized_row = [(value - row_min) / (row_max - row_min) for value in row]\n",
    "    return normalized_row\n",
    "\n",
    "def read_and_normalize_csv(input_filename, output_filename):\n",
    "    with open(input_filename, 'r') as input_file, open(output_filename, 'w', newline='') as output_file:\n",
    "        csv_reader = csv.reader(input_file)\n",
    "        csv_writer = csv.writer(output_file)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            numerical_row = list(map(float, row))\n",
    "            normalized_row = normalize_row(numerical_row)\n",
    "            csv_writer.writerow(normalized_row)\n",
    "\n",
    "input_filename = \"aggregate_human.csv\"\n",
    "output_filename = \"normalized_human.csv\"\n",
    "\n",
    "if not os.path.exists(input_filename):\n",
    "    print(f\"{input_filename} does not exist. Please provide a valid CSV file.\")\n",
    "else:\n",
    "    read_and_normalize_csv(input_filename, output_filename)\n",
    "    print(f\"Normalized data saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feef6fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column averages saved to avgs_norm_gpt.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def column_averages(data):\n",
    "    num_columns = len(data[0])\n",
    "    num_rows = len(data)\n",
    "    column_sums = [0] * num_columns\n",
    "\n",
    "    for row in data:\n",
    "        for i, value in enumerate(row):\n",
    "            column_sums[i] += value\n",
    "\n",
    "    return [column_sum / num_rows for column_sum in column_sums]\n",
    "\n",
    "def read_and_calculate_averages(input_filename, output_filename):\n",
    "    data = []\n",
    "\n",
    "    with open(input_filename, 'r') as input_file:\n",
    "        csv_reader = csv.reader(input_file)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            numerical_row = list(map(float, row))\n",
    "            data.append(numerical_row)\n",
    "\n",
    "    averages = column_averages(data)\n",
    "\n",
    "    with open(output_filename, 'w', newline='') as output_file:\n",
    "        csv_writer = csv.writer(output_file)\n",
    "        csv_writer.writerow(averages)\n",
    "\n",
    "input_filename = \"normalized_gpt.csv\"\n",
    "output_filename = \"avgs_norm_gpt.csv\"\n",
    "\n",
    "if not os.path.exists(input_filename):\n",
    "    print(f\"{input_filename} does not exist. Please provide a valid CSV file.\")\n",
    "else:\n",
    "    read_and_calculate_averages(input_filename, output_filename)\n",
    "    print(f\"Column averages saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "625a1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array: [0.25320591 0.30373804 0.31127672 0.3158001  0.29989693 0.28989786\n",
      " 0.28395617 0.28995295 0.30085289 0.29915524 0.30837586 0.30157995\n",
      " 0.3007419  0.29693495 0.3033967  0.30924945 0.32418713 0.32194088\n",
      " 0.31919812 0.32368586 0.31255106 0.3148458  0.3250725  0.33717601\n",
      " 0.33523201 0.34334021 0.33594499 0.34059239 0.34400703 0.35182389\n",
      " 0.37096982 0.38178048 0.36767078 0.3807188  0.39468364 0.39396182\n",
      " 0.39736933 0.40857354 0.41652653 0.42232859 0.43118962 0.4370648\n",
      " 0.45470283 0.43630826 0.44312319 0.45103001 0.46135792 0.45682421\n",
      " 0.45247723 0.45421484 0.45629535 0.46577271 0.47525175 0.49843026\n",
      " 0.4907559  0.50757657 0.52407931 0.53870861 0.55158865 0.56308937\n",
      " 0.56654046 0.56895232 0.57392707 0.5694719  0.55422243 0.54848402\n",
      " 0.54398693 0.53320391 0.53578749 0.5321571  0.53090859 0.53147156\n",
      " 0.53631513 0.53736988 0.57605774 0.57543452 0.57658974 0.59446216\n",
      " 0.59433887 0.60998145 0.61438871 0.61310531 0.60971451 0.62830591\n",
      " 0.63039026 0.63210961 0.63272552 0.62779431 0.62924094 0.62913089\n",
      " 0.63850886 0.63765973 0.63488694 0.6235506  0.61203672 0.61592362\n",
      " 0.61676685 0.60839203 0.60987069 0.59141472 0.58149223 0.58982074\n",
      " 0.59484139 0.59328586 0.60075594 0.60277152 0.60285847 0.61288618\n",
      " 0.62004684 0.63104087 0.63830174 0.63715145 0.63362915 0.63876172\n",
      " 0.64125478 0.64325904 0.64357383 0.64664441 0.64176935 0.63573572\n",
      " 0.62389995 0.62943193 0.62540084 0.61450084 0.60955861 0.60814367\n",
      " 0.60226895 0.60092635 0.59968991 0.60693281 0.61639569 0.60721922\n",
      " 0.60606252 0.61258367 0.6187413  0.62552132 0.62824883 0.63271183\n",
      " 0.63052342 0.62703886 0.63439133 0.63631893 0.64918351 0.64814635\n",
      " 0.63942451 0.62986413 0.63938546 0.6461373  0.64558152 0.64681292\n",
      " 0.63840891 0.63757141 0.63764405 0.64247034 0.65710688 0.66840987\n",
      " 0.66617283 0.65674546 0.65899726 0.66116244 0.66259607 0.65822897\n",
      " 0.65913337 0.65724468 0.65696731 0.64912373 0.65052735 0.65481518\n",
      " 0.66280435 0.66982196 0.67712181 0.69104296 0.69055185 0.69583133\n",
      " 0.69563271 0.70964824 0.7185646  0.720747   0.73206707 0.72962353\n",
      " 0.73343754 0.74134037 0.73777817 0.73896886 0.73011257 0.72588944\n",
      " 0.71636068 0.7215506  0.71732328 0.72429293 0.71757281 0.70557218\n",
      " 0.70854338 0.70781175 0.71420531 0.71778471 0.72682278 0.72810009\n",
      " 0.72522688 0.72889777]\n",
      "Shape of the numpy array: (200,)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_csv_to_numpy_array(input_filename):\n",
    "    with open(input_filename, 'r') as input_file:\n",
    "        csv_reader = csv.reader(input_file)\n",
    "        row = next(csv_reader)\n",
    "        numerical_row = list(map(float, row))\n",
    "        numpy_array = np.array(numerical_row)\n",
    "    return numpy_array\n",
    "\n",
    "input_filename = \"avgs_norm_gpt.csv\"\n",
    "\n",
    "if not os.path.exists(input_filename):\n",
    "    print(f\"{input_filename} does not exist. Please provide a valid CSV file.\")\n",
    "else:\n",
    "    numpy_array = read_csv_to_numpy_array(input_filename)\n",
    "    print(\"Numpy array:\", numpy_array)\n",
    "    print(\"Shape of the numpy array:\", numpy_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a23d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column variances saved to var_norm_human.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_csv_to_numpy_array(input_filename):\n",
    "    data = []\n",
    "\n",
    "    with open(input_filename, 'r') as input_file:\n",
    "        csv_reader = csv.reader(input_file)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            numerical_row = list(map(float, row))\n",
    "            data.append(numerical_row)\n",
    "\n",
    "    numpy_array = np.array(data)\n",
    "    return numpy_array\n",
    "\n",
    "def column_variances(numpy_array):\n",
    "    return np.var(numpy_array, axis=0)\n",
    "\n",
    "def save_variances_to_csv(output_filename, variances):\n",
    "    with open(output_filename, 'w', newline='') as output_file:\n",
    "        csv_writer = csv.writer(output_file)\n",
    "        csv_writer.writerow(variances)\n",
    "\n",
    "input_filename = \"normalized_human.csv\"\n",
    "output_filename = \"var_norm_human.csv\"\n",
    "\n",
    "if not os.path.exists(input_filename):\n",
    "    print(f\"{input_filename} does not exist. Please provide a valid CSV file.\")\n",
    "else:\n",
    "    numpy_array = read_csv_to_numpy_array(input_filename)\n",
    "    variances = column_variances(numpy_array)\n",
    "    save_variances_to_csv(output_filename, variances)\n",
    "    print(f\"Column variances saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c869dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def aggregate_last_value(folder_path):\n",
    "    aggregate_data = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Get the value in the last row of the first column\n",
    "            last_value = df.iloc[-1, 0]\n",
    "            aggregate_data.append(last_value)\n",
    "\n",
    "    # Convert list to DataFrame and save as csv file\n",
    "    df_aggregate = pd.DataFrame(aggregate_data)\n",
    "    df_aggregate.to_csv(\"rollout_results_human.csv\", index=False, header=False)\n",
    "\n",
    "# Use the function, for example:\n",
    "aggregate_last_value('./bn_results_human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57d837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
