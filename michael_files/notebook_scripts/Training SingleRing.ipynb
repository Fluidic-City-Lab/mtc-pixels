{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1375af72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'num_workers': 5, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'gamma': 0.999, 'lr': 5e-05, 'train_batch_size': 15000, 'model': {'_use_default_native_models': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': [[16, [8, 8], 4], [32, [4, 4], 2], [256, [11, 11], 1]], 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'horizon': 3000, 'soft_horizon': False, 'no_done_at_end': False, 'env': None, 'observation_space': None, 'action_space': None, 'env_config': {}, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'simple_optimizer': -1, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.97, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.02, 'vf_share_layers': -1}\n",
      "2022-12-28 22:38:37,277\tINFO services.py:1247 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 10.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/4.93 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
=======
<<<<<<< HEAD
      "{'num_workers': 5, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'gamma': 0.999, 'lr': 5e-05, 'train_batch_size': 15000, 'model': {'_use_default_native_models': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': [[16, [8, 8], 4], [32, [4, 4], 2], [256, [11, 11], 1]], 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'horizon': 3000, 'soft_horizon': False, 'no_done_at_end': False, 'env': None, 'observation_space': None, 'action_space': None, 'env_config': {}, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'simple_optimizer': -1, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.97, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.02, 'vf_share_layers': -1}\n",
      "2022-10-08 11:06:21,535\tINFO services.py:1247 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 7.9/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
>>>>>>> 880e1f0d2279beb47f60394537ff7c97daa2a155
      "Number of trials: 1/1 (1 PENDING)\n",
      "+-----------------------------------------+----------+-------+\n",
      "| Trial name                              | status   | loc   |\n",
      "|-----------------------------------------+----------+-------|\n",
<<<<<<< HEAD
      "| PPO_WaveAttenuationPOEnv-v0_a96cc_00000 | PENDING  |       |\n",
      "+-----------------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=20479)\u001b[0m 2022-12-28 22:38:39,390\tINFO trainer.py:720 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=20479)\u001b[0m 2022-12-28 22:38:42,289\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=20481)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=20481)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=20481)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=20481)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=20481)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=20482)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=20482)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=20482)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=20482)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=20482)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=20480)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=20480)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=20480)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=20480)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=20480)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=20478)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=20478)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=20478)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=20478)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=20478)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=20483)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=20483)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=20483)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=20483)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=20483)\u001b[0m -----------------------\n",
      "^C\n"
=======
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | PENDING  |       |\n",
      "+-----------------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:06:23,547\tINFO trainer.py:706 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:06:23,547\tINFO trainer.py:720 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m WARNING:tensorflow:From /home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:06:28,083\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 15000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-07-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -4451.277460946896\n",
      "  episode_reward_mean: -4871.770239477724\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 5\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.341774344444275\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007584212347865105\n",
      "          model: {}\n",
      "          policy_loss: -0.004909635987132788\n",
      "          total_loss: 1369.8017578125\n",
      "          vf_explained_var: -0.011073783971369267\n",
      "          vf_loss: 1369.80517578125\n",
      "    num_agent_steps_sampled: 15000\n",
      "    num_agent_steps_trained: 15000\n",
=======
      "{'num_workers': 5, 'num_envs_per_worker': 1, 'sample_batch_size': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 15000, 'model': {'conv_filters': [[16, [8, 8], 4], [32, [4, 4], 2], [256, [11, 11], 1]], 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_preprocessor': None, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}}, 'optimizer': {}, 'gamma': 0.999, 'horizon': 3000, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': None, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_config': {}, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_gae': True, 'lambda': 0.97, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.02, 'simple_optimizer': False}\n",
      "2022-10-08 18:19:30,383\tWARNING services.py:597 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2022-10-08 18:19:30,384\tINFO resource_spec.py:216 -- Starting Ray with 3.47 GiB memory available for workers and up to 14.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2022-10-08 18:19:30,774\tINFO ray_trial_executor.py:121 -- Trial PPO_WaveAttenuationPOEnv-v0_a95f16f0: Setting up new remote runner.\n",
      "== Status ==\n",
      "Memory usage on this node: 5.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+-------+\n",
      "| Trial name                           | status   | loc   |\n",
      "|--------------------------------------+----------+-------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  |       |\n",
      "+--------------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:19:32,013\tINFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:19:32,242\tINFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:19:35,210\tWARNING util.py:45 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-20-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -4308.520413878485\n",
      "  episode_reward_mean: -4791.254351807184\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 5\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1629.473\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.3442256450653076\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006892228964716196\n",
      "        policy_loss: -0.003897586837410927\n",
      "        total_loss: 1316.4261474609375\n",
      "        vf_explained_var: -0.0077028037048876286\n",
      "        vf_loss: 1316.4288330078125\n",
      "    load_time_ms: 32.076\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 14976\n",
      "    sample_time_ms: 40648.224\n",
      "    update_time_ms: 383.297\n",
      "  iterations_since_restore: 1\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.32833333333333\n",
      "    ram_util_percent: 30.651666666666678\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.814516129032256\n",
      "    ram_util_percent: 23.47258064516129\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07771617847456609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 6.794011501501656\n",
      "    mean_inference_ms: 0.575144121703288\n",
      "    mean_raw_obs_processing_ms: 5.295433929784025\n",
      "  time_since_restore: 41.61117625236511\n",
      "  time_this_iter_s: 41.61117625236511\n",
      "  time_total_s: 41.61117625236511\n",
      "  timers:\n",
      "    learn_throughput: 6118.003\n",
      "    learn_time_ms: 2451.78\n",
      "    load_throughput: 427492.916\n",
      "    load_time_ms: 35.088\n",
      "    sample_throughput: 383.766\n",
      "    sample_time_ms: 39086.363\n",
      "    update_time_ms: 1.287\n",
      "  timestamp: 1665245229\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 1\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |      1 |          41.6112 | 15000 | -4871.77 |             -4451.28 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:07:09,696\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 487.0x the scale of `vf_clip_param`. This means that it will take more than 487.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-07-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -4253.512683653694\n",
      "  episode_reward_mean: -4830.491924483691\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 10\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.249494194984436\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016148926690220833\n",
      "          model: {}\n",
      "          policy_loss: -0.007274187169969082\n",
      "          total_loss: 1286.61376953125\n",
      "          vf_explained_var: 0.005556122865527868\n",
      "          vf_loss: 1286.619384765625\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_agent_steps_trained: 30000\n",
=======
      "    mean_env_wait_ms: 8.475484422189876\n",
      "    mean_inference_ms: 0.42545160664117\n",
      "    mean_processing_ms: 4.003199590360749\n",
      "  time_since_restore: 42.71963930130005\n",
      "  time_this_iter_s: 42.71963930130005\n",
      "  time_total_s: 42.71963930130005\n",
      "  timestamp: 1665271217\n",
      "  timesteps_since_restore: 15000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 1\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      1 |          42.7196 |       15000 | -4791.25 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:20:17,990\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 479.0x the scale of `vf_clip_param`. This means that it will take more than 479.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-20-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -4208.272494727222\n",
      "  episode_reward_mean: -4628.656669907699\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 10\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1559.956\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2421236038208008\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01674901507794857\n",
      "        policy_loss: -0.005388439167290926\n",
      "        total_loss: 1077.4542236328125\n",
      "        vf_explained_var: 0.005058943759649992\n",
      "        vf_loss: 1077.4578857421875\n",
      "    load_time_ms: 17.307\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 29952\n",
      "    sample_time_ms: 33759.095\n",
      "    update_time_ms: 193.568\n",
      "  iterations_since_restore: 2\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.258333333333333\n",
      "    ram_util_percent: 29.988888888888887\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.4\n",
      "    ram_util_percent: 23.872500000000002\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07661464104117958\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.984540309263639\n",
      "    mean_inference_ms: 0.5644528726106277\n",
      "    mean_raw_obs_processing_ms: 4.746694715401001\n",
      "  time_since_restore: 66.91795325279236\n",
      "  time_this_iter_s: 25.306777000427246\n",
      "  time_total_s: 66.91795325279236\n",
      "  timers:\n",
      "    learn_throughput: 6553.791\n",
      "    learn_time_ms: 2288.752\n",
      "    load_throughput: 826138.271\n",
      "    load_time_ms: 18.157\n",
      "    sample_throughput: 481.875\n",
      "    sample_time_ms: 31128.423\n",
      "    update_time_ms: 1.812\n",
      "  timestamp: 1665245255\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 2\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:07:35,056\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 483.0x the scale of `vf_clip_param`. This means that it will take more than 483.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |      2 |           66.918 | 30000 | -4830.49 |             -4253.51 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 45000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-08-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -3278.176325684843\n",
      "  episode_reward_mean: -4494.425412059954\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 15\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0543112754821777\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01967926323413849\n",
      "          model: {}\n",
      "          policy_loss: -0.0078841932117939\n",
      "          total_loss: 754.5277709960938\n",
      "          vf_explained_var: -0.001294097863137722\n",
      "          vf_loss: 754.5335693359375\n",
      "    num_agent_steps_sampled: 45000\n",
      "    num_agent_steps_trained: 45000\n",
=======
      "    mean_env_wait_ms: 7.451943298391852\n",
      "    mean_inference_ms: 0.41952452857907263\n",
      "    mean_processing_ms: 4.008166476618732\n",
      "  time_since_restore: 71.09197354316711\n",
      "  time_this_iter_s: 28.372334241867065\n",
      "  time_total_s: 71.09197354316711\n",
      "  timestamp: 1665271246\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 2\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      2 |           71.092 |       30000 | -4628.66 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:20:46,376\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 463.0x the scale of `vf_clip_param`. This means that it will take more than 463.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-21-15\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -2595.4884319116973\n",
      "  episode_reward_mean: -4190.385255333463\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 15\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1536.269\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.052616000175476\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023625820875167847\n",
      "        policy_loss: -0.008808670565485954\n",
      "        total_loss: 540.90966796875\n",
      "        vf_explained_var: -0.002125317696481943\n",
      "        vf_loss: 540.9161376953125\n",
      "    load_time_ms: 12.626\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 45000\n",
      "    num_steps_trained: 44928\n",
      "    sample_time_ms: 31868.67\n",
      "    update_time_ms: 130.126\n",
      "  iterations_since_restore: 3\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.38611111111111\n",
      "    ram_util_percent: 29.55833333333333\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.11666666666667\n",
      "    ram_util_percent: 23.90714285714286\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07517656985763516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.515110906309667\n",
      "    mean_inference_ms: 0.5523494116031133\n",
      "    mean_raw_obs_processing_ms: 4.459282890651863\n",
      "  time_since_restore: 91.86627650260925\n",
      "  time_this_iter_s: 24.948323249816895\n",
      "  time_total_s: 91.86627650260925\n",
      "  timers:\n",
      "    learn_throughput: 6504.678\n",
      "    learn_time_ms: 2306.033\n",
      "    load_throughput: 1202663.982\n",
      "    load_time_ms: 12.472\n",
      "    sample_throughput: 530.291\n",
      "    sample_time_ms: 28286.354\n",
      "    update_time_ms: 1.567\n",
      "  timestamp: 1665245280\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45000\n",
      "  training_iteration: 3\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |      3 |          91.8663 | 45000 | -4494.43 |             -3278.18 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:08:00,033\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 449.0x the scale of `vf_clip_param`. This means that it will take more than 449.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-08-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1434.4733010522928\n",
      "  episode_reward_mean: -4126.488410151578\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 20\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8779413104057312\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01506874617189169\n",
      "          model: {}\n",
      "          policy_loss: -0.005208146758377552\n",
      "          total_loss: 494.8333435058594\n",
      "          vf_explained_var: -0.0022465260699391365\n",
      "          vf_loss: 494.8370361328125\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
=======
      "    mean_env_wait_ms: 6.902586012546457\n",
      "    mean_inference_ms: 0.41658212308824305\n",
      "    mean_processing_ms: 4.031025404747281\n",
      "  time_since_restore: 100.68068790435791\n",
      "  time_this_iter_s: 29.588714361190796\n",
      "  time_total_s: 100.68068790435791\n",
      "  timestamp: 1665271275\n",
      "  timesteps_since_restore: 45000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 45000\n",
      "  training_iteration: 3\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      3 |          100.681 |       45000 | -4190.39 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:21:15,978\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 419.0x the scale of `vf_clip_param`. This means that it will take more than 419.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-21-44\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1895.624576232851\n",
      "  episode_reward_mean: -3816.7076858807945\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 20\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1522.093\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8770983815193176\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030317027121782303\n",
      "        policy_loss: -0.011822238564491272\n",
      "        total_loss: 338.8348388671875\n",
      "        vf_explained_var: -0.0029835139866918325\n",
      "        vf_loss: 338.8436584472656\n",
      "    load_time_ms: 10.134\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 59904\n",
      "    sample_time_ms: 30779.57\n",
      "    update_time_ms: 98.31\n",
      "  iterations_since_restore: 4\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.868571428571432\n",
      "    ram_util_percent: 29.65714285714286\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.0047619047619\n",
      "    ram_util_percent: 23.802380952380947\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07404071439738298\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.205088118312567\n",
      "    mean_inference_ms: 0.5431260232869615\n",
      "    mean_raw_obs_processing_ms: 4.261580388067466\n",
      "  time_since_restore: 116.5483078956604\n",
      "  time_this_iter_s: 24.682031393051147\n",
      "  time_total_s: 116.5483078956604\n",
      "  timers:\n",
      "    learn_throughput: 6600.493\n",
      "    learn_time_ms: 2272.558\n",
      "    load_throughput: 1496798.568\n",
      "    load_time_ms: 10.021\n",
      "    sample_throughput: 558.88\n",
      "    sample_time_ms: 26839.372\n",
      "    update_time_ms: 1.447\n",
      "  timestamp: 1665245304\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 4\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |      4 |          116.548 | 60000 | -4126.49 |             -1434.47 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:08:24,734\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 413.0x the scale of `vf_clip_param`. This means that it will take more than 413.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 75000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-08-50\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -380.9965406985417\n",
      "  episode_reward_mean: -3661.2843195558025\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 25\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.6273290514945984\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01933143101632595\n",
      "          model: {}\n",
      "          policy_loss: -0.005876941606402397\n",
      "          total_loss: 228.4927978515625\n",
      "          vf_explained_var: -0.0012384632136672735\n",
      "          vf_loss: 228.4967803955078\n",
      "    num_agent_steps_sampled: 75000\n",
      "    num_agent_steps_trained: 75000\n",
=======
      "    mean_env_wait_ms: 6.550412844423571\n",
      "    mean_inference_ms: 0.4147886900298743\n",
      "    mean_processing_ms: 4.038714732234208\n",
      "  time_since_restore: 129.6833565235138\n",
      "  time_this_iter_s: 29.002668619155884\n",
      "  time_total_s: 129.6833565235138\n",
      "  timestamp: 1665271304\n",
      "  timesteps_since_restore: 60000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 4\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      4 |          129.683 |       60000 | -3816.71 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:21:44,992\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 382.0x the scale of `vf_clip_param`. This means that it will take more than 382.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-22-14\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1253.4037722725268\n",
      "  episode_reward_mean: -3419.4400972806243\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 25\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1512.889\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6654890179634094\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029795963317155838\n",
      "        policy_loss: -0.010364901274442673\n",
      "        total_loss: 208.9837188720703\n",
      "        vf_explained_var: -0.0015159437898546457\n",
      "        vf_loss: 208.99111938476562\n",
      "    load_time_ms: 8.645\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 75000\n",
      "    num_steps_trained: 74880\n",
      "    sample_time_ms: 30201.061\n",
      "    update_time_ms: 79.208\n",
      "  iterations_since_restore: 5\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.610810810810808\n",
      "    ram_util_percent: 29.654054054054054\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.98809523809524\n",
      "    ram_util_percent: 23.778571428571425\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07319424462662133\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.987859114328826\n",
      "    mean_inference_ms: 0.5363613260552949\n",
      "    mean_raw_obs_processing_ms: 4.1272362846246065\n",
      "  time_since_restore: 142.17425179481506\n",
      "  time_this_iter_s: 25.625943899154663\n",
      "  time_total_s: 142.17425179481506\n",
      "  timers:\n",
      "    learn_throughput: 6567.403\n",
      "    learn_time_ms: 2284.008\n",
      "    load_throughput: 1803774.147\n",
      "    load_time_ms: 8.316\n",
      "    sample_throughput: 574.082\n",
      "    sample_time_ms: 26128.658\n",
      "    update_time_ms: 1.417\n",
      "  timestamp: 1665245330\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 75000\n",
      "  training_iteration: 5\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:08:50,401\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 366.0x the scale of `vf_clip_param`. This means that it will take more than 366.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |      5 |          142.174 | 75000 | -3661.28 |             -380.997 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n"
=======
      "    mean_env_wait_ms: 6.304432452077715\n",
      "    mean_inference_ms: 0.41366008320987213\n",
      "    mean_processing_ms: 4.044481479776111\n",
      "  time_since_restore: 159.0576252937317\n",
      "  time_this_iter_s: 29.374268770217896\n",
      "  time_total_s: 159.0576252937317\n",
      "  timestamp: 1665271334\n",
      "  timesteps_since_restore: 75000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 75000\n",
      "  training_iteration: 5\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      5 |          159.058 |       75000 | -3419.44 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:22:14,381\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 342.0x the scale of `vf_clip_param`. This means that it will take more than 342.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 90000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-09-15\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -380.9965406985417\n",
      "  episode_reward_mean: -3276.8286467113185\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 30\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.4705983102321625\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025821451097726822\n",
      "          model: {}\n",
      "          policy_loss: -0.00890158861875534\n",
      "          total_loss: 148.8064727783203\n",
      "          vf_explained_var: -0.0010976934572681785\n",
      "          vf_loss: 148.81280517578125\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_agent_steps_trained: 90000\n",
=======
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-22-43\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -75.4403302279076\n",
      "  episode_reward_mean: -3102.2214896321993\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 30\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1507.495\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5612450838088989\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025660399347543716\n",
      "        policy_loss: -0.0067628794349730015\n",
      "        total_loss: 187.9198455810547\n",
      "        vf_explained_var: -0.0007813924457877874\n",
      "        vf_loss: 187.9240264892578\n",
      "    load_time_ms: 7.714\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 89856\n",
      "    sample_time_ms: 29775.809\n",
      "    update_time_ms: 66.406\n",
      "  iterations_since_restore: 6\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.70277777777778\n",
      "    ram_util_percent: 29.57222222222222\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.08048780487804\n",
      "    ram_util_percent: 23.76829268292683\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07253199647621944\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.825929896047159\n",
      "    mean_inference_ms: 0.5310913989683318\n",
      "    mean_raw_obs_processing_ms: 4.029542059040027\n",
      "  time_since_restore: 167.4935610294342\n",
      "  time_this_iter_s: 25.31930923461914\n",
      "  time_total_s: 167.4935610294342\n",
      "  timers:\n",
      "    learn_throughput: 6551.194\n",
      "    learn_time_ms: 2289.659\n",
      "    load_throughput: 2107878.761\n",
      "    load_time_ms: 7.116\n",
      "    sample_throughput: 585.803\n",
      "    sample_time_ms: 25605.896\n",
      "    update_time_ms: 1.355\n",
      "  timestamp: 1665245355\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 6\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |      6 |          167.494 | 90000 | -3276.83 |             -380.997 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:09:15,749\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 328.0x the scale of `vf_clip_param`. This means that it will take more than 328.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 105000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-09-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 394.6188524098183\n",
      "  episode_reward_mean: -2931.113242200976\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 35\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.3524196743965149\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010033023543655872\n",
      "          model: {}\n",
      "          policy_loss: -0.002121981931850314\n",
      "          total_loss: 200.10047912597656\n",
      "          vf_explained_var: -0.0003548931854311377\n",
      "          vf_loss: 200.1016082763672\n",
      "    num_agent_steps_sampled: 105000\n",
      "    num_agent_steps_trained: 105000\n",
=======
      "    mean_env_wait_ms: 6.119682145826426\n",
      "    mean_inference_ms: 0.41279126095939833\n",
      "    mean_processing_ms: 4.049050981886834\n",
      "  time_since_restore: 188.19899106025696\n",
      "  time_this_iter_s: 29.14136576652527\n",
      "  time_total_s: 188.19899106025696\n",
      "  timestamp: 1665271363\n",
      "  timesteps_since_restore: 90000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 6\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      6 |          188.199 |       90000 | -3102.22 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:22:43,534\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 310.0x the scale of `vf_clip_param`. This means that it will take more than 310.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-23-12\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -75.4403302279076\n",
      "  episode_reward_mean: -2847.6012428021577\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 35\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1501.764\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5034546852111816\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013377774506807327\n",
      "        policy_loss: -0.006963650695979595\n",
      "        total_loss: 222.30563354492188\n",
      "        vf_explained_var: -0.0002723830402828753\n",
      "        vf_loss: 222.31124877929688\n",
      "    load_time_ms: 7.11\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 105000\n",
      "    num_steps_trained: 104832\n",
      "    sample_time_ms: 29431.305\n",
      "    update_time_ms: 57.382\n",
      "  iterations_since_restore: 7\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.36857142857143\n",
      "    ram_util_percent: 29.52857142857143\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.614634146341466\n",
      "    ram_util_percent: 23.9\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07197192320864576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.699133283837605\n",
      "    mean_inference_ms: 0.5267667014197618\n",
      "    mean_raw_obs_processing_ms: 3.9502795223641947\n",
      "  time_since_restore: 192.12981367111206\n",
      "  time_this_iter_s: 24.636252641677856\n",
      "  time_total_s: 192.12981367111206\n",
      "  timers:\n",
      "    learn_throughput: 6668.363\n",
      "    learn_time_ms: 2249.428\n",
      "    load_throughput: 2392747.464\n",
      "    load_time_ms: 6.269\n",
      "    sample_throughput: 595.725\n",
      "    sample_time_ms: 25179.41\n",
      "    update_time_ms: 1.336\n",
      "  timestamp: 1665245380\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 105000\n",
      "  training_iteration: 7\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:09:40,406\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 293.0x the scale of `vf_clip_param`. This means that it will take more than 293.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |      7 |           192.13 | 105000 | -2931.11 |              394.619 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 5.974767154397457\n",
      "    mean_inference_ms: 0.4123751311212596\n",
      "    mean_processing_ms: 4.051315016808043\n",
      "  time_since_restore: 217.0427794456482\n",
      "  time_this_iter_s: 28.843788385391235\n",
      "  time_total_s: 217.0427794456482\n",
      "  timestamp: 1665271392\n",
      "  timesteps_since_restore: 105000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 105000\n",
      "  training_iteration: 7\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:23:12,391\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 285.0x the scale of `vf_clip_param`. This means that it will take more than 285.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      7 |          217.043 |      105000 |  -2847.6 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 120000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-10-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 394.6188524098183\n",
      "  episode_reward_mean: -2669.026640889981\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 40\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.27780571579933167\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02375359833240509\n",
      "          model: {}\n",
      "          policy_loss: -0.006877324543893337\n",
      "          total_loss: 167.58682250976562\n",
      "          vf_explained_var: -0.0003093083796557039\n",
      "          vf_loss: 167.59132385253906\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
=======
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-23-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 262.1442709570502\n",
      "  episode_reward_mean: -2620.7263871796736\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 40\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1499.066\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39999547600746155\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011474714614450932\n",
      "        policy_loss: -0.003726875176653266\n",
      "        total_loss: 179.338623046875\n",
      "        vf_explained_var: -0.00018425985763315111\n",
      "        vf_loss: 179.34121704101562\n",
      "    load_time_ms: 6.473\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 119808\n",
      "    sample_time_ms: 29165.867\n",
      "    update_time_ms: 50.603\n",
      "  iterations_since_restore: 8\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.095454545454547\n",
      "    ram_util_percent: 29.513636363636355\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.7\n",
      "    ram_util_percent: 23.797560975609755\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07150777177227122\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.596481665328148\n",
      "    mean_inference_ms: 0.5231757275625231\n",
      "    mean_raw_obs_processing_ms: 3.9143586331720526\n",
      "  time_since_restore: 222.79076099395752\n",
      "  time_this_iter_s: 30.66094732284546\n",
      "  time_total_s: 222.79076099395752\n",
      "  timers:\n",
      "    learn_throughput: 6631.754\n",
      "    learn_time_ms: 2261.845\n",
      "    load_throughput: 2667962.598\n",
      "    load_time_ms: 5.622\n",
      "    sample_throughput: 586.629\n",
      "    sample_time_ms: 25569.828\n",
      "    update_time_ms: 1.308\n",
      "  timestamp: 1665245411\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 8\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |      8 |          222.791 | 120000 | -2669.03 |              394.619 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:10:11,096\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 267.0x the scale of `vf_clip_param`. This means that it will take more than 267.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 135000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-10-36\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 394.6188524098183\n",
      "  episode_reward_mean: -2434.1935187684535\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 45\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.1865028738975525\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010962553322315216\n",
      "          model: {}\n",
      "          policy_loss: -0.00290653295814991\n",
      "          total_loss: 182.6697998046875\n",
      "          vf_explained_var: -0.00011125690798508003\n",
      "          vf_loss: 182.67166137695312\n",
      "    num_agent_steps_sampled: 135000\n",
      "    num_agent_steps_trained: 135000\n",
=======
      "    mean_env_wait_ms: 5.8573476549413765\n",
      "    mean_inference_ms: 0.41226974864685834\n",
      "    mean_processing_ms: 4.0518225722087395\n",
      "  time_since_restore: 245.84161353111267\n",
      "  time_this_iter_s: 28.798834085464478\n",
      "  time_total_s: 245.84161353111267\n",
      "  timestamp: 1665271421\n",
      "  timesteps_since_restore: 120000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 8\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      8 |          245.842 |      120000 | -2620.73 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:23:41,203\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 262.0x the scale of `vf_clip_param`. This means that it will take more than 262.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-24-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1114.7475962357853\n",
      "  episode_reward_mean: -2447.6646587658147\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 45\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1496.221\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10000000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3545260727405548\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009492599405348301\n",
      "        policy_loss: -0.0029712854884564877\n",
      "        total_loss: 328.2466735839844\n",
      "        vf_explained_var: -6.93635010975413e-05\n",
      "        vf_loss: 328.2486877441406\n",
      "    load_time_ms: 6.081\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 135000\n",
      "    num_steps_trained: 134784\n",
      "    sample_time_ms: 28986.333\n",
      "    update_time_ms: 45.336\n",
      "  iterations_since_restore: 9\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.902777777777782\n",
      "    ram_util_percent: 29.5\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00714285714286\n",
      "    ram_util_percent: 23.871428571428574\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07112601524655845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.512019086800138\n",
      "    mean_inference_ms: 0.5202145936889301\n",
      "    mean_raw_obs_processing_ms: 3.8810717629773985\n",
      "  time_since_restore: 248.0309615135193\n",
      "  time_this_iter_s: 25.240200519561768\n",
      "  time_total_s: 248.0309615135193\n",
      "  timers:\n",
      "    learn_throughput: 6701.413\n",
      "    learn_time_ms: 2238.334\n",
      "    load_throughput: 2918566.259\n",
      "    load_time_ms: 5.14\n",
      "    sample_throughput: 592.779\n",
      "    sample_time_ms: 25304.56\n",
      "    update_time_ms: 1.277\n",
      "  timestamp: 1665245436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 135000\n",
      "  training_iteration: 9\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:10:36,370\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 243.0x the scale of `vf_clip_param`. This means that it will take more than 243.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |      9 |          248.031 | 135000 | -2434.19 |              394.619 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 5.759576711646084\n",
      "    mean_inference_ms: 0.41211092998903615\n",
      "    mean_processing_ms: 4.052900437825875\n",
      "  time_since_restore: 274.87696743011475\n",
      "  time_this_iter_s: 29.035353899002075\n",
      "  time_total_s: 274.87696743011475\n",
      "  timestamp: 1665271450\n",
      "  timesteps_since_restore: 135000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 135000\n",
      "  training_iteration: 9\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:24:10,253\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 245.0x the scale of `vf_clip_param`. This means that it will take more than 245.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |      9 |          274.877 |      135000 | -2447.66 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 150000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-11-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 836.7291370672203\n",
      "  episode_reward_mean: -2244.093677732202\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 50\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.09252399951219559\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022129399701952934\n",
      "          model: {}\n",
      "          policy_loss: -0.005880167242139578\n",
      "          total_loss: 197.5752410888672\n",
      "          vf_explained_var: -7.184143032645807e-05\n",
      "          vf_loss: 197.5789031982422\n",
      "    num_agent_steps_sampled: 150000\n",
      "    num_agent_steps_trained: 150000\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-24-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1114.7475962357853\n",
      "  episode_reward_mean: -2258.088965377811\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 50\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1495.783\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.15614110231399536\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026136763393878937\n",
      "        policy_loss: -0.005501579027622938\n",
      "        total_loss: 229.5237274169922\n",
      "        vf_explained_var: -5.039903771830723e-05\n",
      "        vf_loss: 229.52793884277344\n",
      "    load_time_ms: 5.726\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 149760\n",
      "    sample_time_ms: 28857.829\n",
      "    update_time_ms: 41.052\n",
      "  iterations_since_restore: 10\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.458333333333332\n",
      "    ram_util_percent: 29.450000000000003\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.516666666666666\n",
      "    ram_util_percent: 23.83095238095238\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0707990646023774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.440924521271298\n",
      "    mean_inference_ms: 0.5176797140421295\n",
      "    mean_raw_obs_processing_ms: 3.8505391936020943\n",
      "  time_since_restore: 273.3842542171478\n",
      "  time_this_iter_s: 25.35329270362854\n",
      "  time_total_s: 273.3842542171478\n",
      "  timers:\n",
      "    learn_throughput: 6710.85\n",
      "    learn_time_ms: 2235.186\n",
      "    load_throughput: 3158821.314\n",
      "    load_time_ms: 4.749\n",
      "    sample_throughput: 597.9\n",
      "    sample_time_ms: 25087.818\n",
      "    update_time_ms: 1.258\n",
      "  timestamp: 1665245461\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 10\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     10 |          273.384 | 150000 | -2244.09 |              836.729 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:11:01,750\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 224.0x the scale of `vf_clip_param`. This means that it will take more than 224.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 165000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-11-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 836.7291370672203\n",
      "  episode_reward_mean: -2079.7323944721384\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 55\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.035413019359111786\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01666215807199478\n",
      "          model: {}\n",
      "          policy_loss: -0.0042555551044642925\n",
      "          total_loss: 158.869384765625\n",
      "          vf_explained_var: -3.3262447686865926e-05\n",
      "          vf_loss: 158.87197875976562\n",
      "    num_agent_steps_sampled: 165000\n",
      "    num_agent_steps_trained: 165000\n",
=======
      "    mean_env_wait_ms: 5.678011063961877\n",
      "    mean_inference_ms: 0.41196430333261796\n",
      "    mean_processing_ms: 4.053785216845164\n",
      "  time_since_restore: 304.08096265792847\n",
      "  time_this_iter_s: 29.20399522781372\n",
      "  time_total_s: 304.08096265792847\n",
      "  timestamp: 1665271479\n",
      "  timesteps_since_restore: 150000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 10\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     10 |          304.081 |      150000 | -2258.09 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:24:39,470\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 226.0x the scale of `vf_clip_param`. This means that it will take more than 226.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -2022.7947092007557\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 55\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.117\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.10236494988203049\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01100603211671114\n",
      "        policy_loss: -0.0006883026799187064\n",
      "        total_loss: 266.5414733886719\n",
      "        vf_explained_var: -1.7171232684631832e-05\n",
      "        vf_loss: 266.5416259765625\n",
      "    load_time_ms: 2.753\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 165000\n",
      "    num_steps_trained: 164736\n",
      "    sample_time_ms: 27628.649\n",
      "    update_time_ms: 2.945\n",
      "  iterations_since_restore: 11\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.41111111111111\n",
      "    ram_util_percent: 29.46944444444445\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.214285714285715\n",
      "    ram_util_percent: 23.8547619047619\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07052227246912209\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.380167209525007\n",
      "    mean_inference_ms: 0.5155073545381734\n",
      "    mean_raw_obs_processing_ms: 3.8207740109653843\n",
      "  time_since_restore: 298.3936023712158\n",
      "  time_this_iter_s: 25.009348154067993\n",
      "  time_total_s: 298.3936023712158\n",
      "  timers:\n",
      "    learn_throughput: 6828.424\n",
      "    learn_time_ms: 2196.7\n",
      "    load_throughput: 11096629.451\n",
      "    load_time_ms: 1.352\n",
      "    sample_throughput: 639.039\n",
      "    sample_time_ms: 23472.762\n",
      "    update_time_ms: 1.231\n",
      "  timestamp: 1665245486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 165000\n",
      "  training_iteration: 11\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     11 |          298.394 | 165000 | -2079.73 |              836.729 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 5.608717909668454\n",
      "    mean_inference_ms: 0.4118085447684999\n",
      "    mean_processing_ms: 4.055278919438012\n",
      "  time_since_restore: 333.9306254386902\n",
      "  time_this_iter_s: 29.84966278076172\n",
      "  time_total_s: 333.9306254386902\n",
      "  timestamp: 1665271509\n",
      "  timesteps_since_restore: 165000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 165000\n",
      "  training_iteration: 11\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     11 |          333.931 |      165000 | -2022.79 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 18:25:09,333\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 202.0x the scale of `vf_clip_param`. This means that it will take more than 202.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:11:26,787\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 208.0x the scale of `vf_clip_param`. This means that it will take more than 208.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-11-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 836.7291370672203\n",
      "  episode_reward_mean: -1908.079843682146\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 60\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.12950114905834198\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014329571276903152\n",
      "          model: {}\n",
      "          policy_loss: -0.003081752685829997\n",
      "          total_loss: 189.4532928466797\n",
      "          vf_explained_var: -1.8719934814726003e-05\n",
      "          vf_loss: 189.45492553710938\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_agent_steps_trained: 180000\n",
=======
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-25-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -1917.6939519085572\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 60\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.979\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.13771802186965942\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026905473321676254\n",
      "        policy_loss: -0.00506002688780427\n",
      "        total_loss: 228.8725128173828\n",
      "        vf_explained_var: -1.2128781236242503e-05\n",
      "        vf_loss: 228.87625122070312\n",
      "    load_time_ms: 2.825\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 179712\n",
      "    sample_time_ms: 27809.099\n",
      "    update_time_ms: 2.796\n",
      "  iterations_since_restore: 12\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.134285714285713\n",
      "    ram_util_percent: 29.485714285714284\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.851162790697686\n",
      "    ram_util_percent: 23.765116279069765\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07028168457627393\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.327514089482232\n",
      "    mean_inference_ms: 0.513639704297114\n",
      "    mean_raw_obs_processing_ms: 3.7927470405907537\n",
      "  time_since_restore: 322.96194100379944\n",
      "  time_this_iter_s: 24.568338632583618\n",
      "  time_total_s: 322.96194100379944\n",
      "  timers:\n",
      "    learn_throughput: 6907.036\n",
      "    learn_time_ms: 2171.698\n",
      "    load_throughput: 9878092.666\n",
      "    load_time_ms: 1.519\n",
      "    sample_throughput: 640.365\n",
      "    sample_time_ms: 23424.131\n",
      "    update_time_ms: 1.121\n",
      "  timestamp: 1665245511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 12\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     12 |          322.962 | 180000 | -1908.08 |              836.729 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 195000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-12-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1036.7424025706484\n",
      "  episode_reward_mean: -1766.030130489457\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 65\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.1164080947637558\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005917334463447332\n",
      "          model: {}\n",
      "          policy_loss: 0.0006517797010019422\n",
      "          total_loss: 391.9528503417969\n",
      "          vf_explained_var: -4.2609681258909404e-06\n",
      "          vf_loss: 391.95159912109375\n",
      "    num_agent_steps_sampled: 195000\n",
      "    num_agent_steps_trained: 195000\n",
=======
      "    mean_env_wait_ms: 5.548404777544189\n",
      "    mean_inference_ms: 0.41167761918346435\n",
      "    mean_processing_ms: 4.058719231113796\n",
      "  time_since_restore: 364.0953333377838\n",
      "  time_this_iter_s: 30.164707899093628\n",
      "  time_total_s: 364.0953333377838\n",
      "  timestamp: 1665271539\n",
      "  timesteps_since_restore: 180000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 12\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     12 |          364.095 |      180000 | -1917.69 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-26-08\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -1763.016387971157\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 65\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.133\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.12103245407342911\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016364462673664093\n",
      "        policy_loss: -0.001606381731107831\n",
      "        total_loss: 281.37225341796875\n",
      "        vf_explained_var: -4.677690867538331e-06\n",
      "        vf_loss: 281.3730773925781\n",
      "    load_time_ms: 2.737\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 195000\n",
      "    num_steps_trained: 194688\n",
      "    sample_time_ms: 27784.435\n",
      "    update_time_ms: 2.711\n",
      "  iterations_since_restore: 13\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.605405405405406\n",
      "    ram_util_percent: 29.451351351351352\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.03333333333333\n",
      "    ram_util_percent: 23.866666666666664\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.07006302993831949\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.281121911981654\n",
      "    mean_inference_ms: 0.5119590291394273\n",
      "    mean_raw_obs_processing_ms: 3.769674755744623\n",
      "  time_since_restore: 349.36421370506287\n",
      "  time_this_iter_s: 26.402272701263428\n",
      "  time_total_s: 349.36421370506287\n",
      "  timers:\n",
      "    learn_throughput: 6935.708\n",
      "    learn_time_ms: 2162.721\n",
      "    load_throughput: 8577893.517\n",
      "    load_time_ms: 1.749\n",
      "    sample_throughput: 636.191\n",
      "    sample_time_ms: 23577.814\n",
      "    update_time_ms: 1.123\n",
      "  timestamp: 1665245537\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 195000\n",
      "  training_iteration: 13\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     13 |          349.364 | 195000 | -1766.03 |              1036.74 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 210000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-12-44\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1036.7424025706484\n",
      "  episode_reward_mean: -1609.5255244499149\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 70\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.05000000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.32194969058036804\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00857594609260559\n",
      "          model: {}\n",
      "          policy_loss: -0.0004412175330799073\n",
      "          total_loss: 334.00390625\n",
      "          vf_explained_var: -2.7407947982283076e-06\n",
      "          vf_loss: 334.00396728515625\n",
      "    num_agent_steps_sampled: 210000\n",
      "    num_agent_steps_trained: 210000\n",
=======
      "    mean_env_wait_ms: 5.495605771588499\n",
      "    mean_inference_ms: 0.41154511761819396\n",
      "    mean_processing_ms: 4.061547097785623\n",
      "  time_since_restore: 393.4271273612976\n",
      "  time_this_iter_s: 29.331794023513794\n",
      "  time_total_s: 393.4271273612976\n",
      "  timestamp: 1665271568\n",
      "  timesteps_since_restore: 195000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 195000\n",
      "  training_iteration: 13\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     13 |          393.427 |      195000 | -1763.02 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-26-37\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -1735.7444647588334\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 70\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1478.873\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25704774260520935\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01513621211051941\n",
      "        policy_loss: -0.004745267331600189\n",
      "        total_loss: 243.4720916748047\n",
      "        vf_explained_var: -3.484579337964533e-06\n",
      "        vf_loss: 243.47607421875\n",
      "    load_time_ms: 2.739\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 209664\n",
      "    sample_time_ms: 27782.92\n",
      "    update_time_ms: 2.685\n",
      "  iterations_since_restore: 14\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.80263157894737\n",
      "    ram_util_percent: 29.494736842105254\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.87380952380953\n",
      "    ram_util_percent: 23.788095238095234\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06986427514558065\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.240117817085741\n",
      "    mean_inference_ms: 0.5104417696423387\n",
      "    mean_raw_obs_processing_ms: 3.7504485591227055\n",
      "  time_since_restore: 375.728378534317\n",
      "  time_this_iter_s: 26.36416482925415\n",
      "  time_total_s: 375.728378534317\n",
      "  timers:\n",
      "    learn_throughput: 6895.86\n",
      "    learn_time_ms: 2175.218\n",
      "    load_throughput: 9420462.679\n",
      "    load_time_ms: 1.592\n",
      "    sample_throughput: 632.012\n",
      "    sample_time_ms: 23733.744\n",
      "    update_time_ms: 1.118\n",
      "  timestamp: 1665245564\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 14\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     14 |          375.728 | 210000 | -1609.53 |              1036.74 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n"
=======
      "    mean_env_wait_ms: 5.448432195726135\n",
      "    mean_inference_ms: 0.4114858220053565\n",
      "    mean_processing_ms: 4.063891517205699\n",
      "  time_since_restore: 422.41189193725586\n",
      "  time_this_iter_s: 28.984764575958252\n",
      "  time_total_s: 422.41189193725586\n",
      "  timestamp: 1665271597\n",
      "  timesteps_since_restore: 210000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 14\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     14 |          422.412 |      210000 | -1735.74 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 225000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-13-14\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1036.7424025706484\n",
      "  episode_reward_mean: -1478.2613789708328\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 75\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02500000037252903\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.42045727372169495\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027907175943255424\n",
      "          model: {}\n",
      "          policy_loss: -0.003507411340251565\n",
      "          total_loss: 321.8483581542969\n",
      "          vf_explained_var: -1.2868489420725382e-06\n",
      "          vf_loss: 321.8511657714844\n",
      "    num_agent_steps_sampled: 225000\n",
      "    num_agent_steps_trained: 225000\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-27-07\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1361.6598840780696\n",
      "  episode_reward_mean: -1580.7181060844052\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 75\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.727\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.44527119398117065\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019096767529845238\n",
      "        policy_loss: -0.0028846324421465397\n",
      "        total_loss: 254.23687744140625\n",
      "        vf_explained_var: -1.4936822481104173e-06\n",
      "        vf_loss: 254.23883056640625\n",
      "    load_time_ms: 2.676\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 225000\n",
      "    num_steps_trained: 224640\n",
      "    sample_time_ms: 27764.271\n",
      "    update_time_ms: 2.709\n",
      "  iterations_since_restore: 15\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.093023255813957\n",
      "    ram_util_percent: 29.54186046511628\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.09512195121951\n",
      "    ram_util_percent: 23.87560975609756\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06968139470240482\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2033081532744285\n",
      "    mean_inference_ms: 0.5090489300176968\n",
      "    mean_raw_obs_processing_ms: 3.740202622904748\n",
      "  time_since_restore: 405.76492166519165\n",
      "  time_this_iter_s: 30.036543130874634\n",
      "  time_total_s: 405.76492166519165\n",
      "  timers:\n",
      "    learn_throughput: 6926.476\n",
      "    learn_time_ms: 2165.603\n",
      "    load_throughput: 9654951.429\n",
      "    load_time_ms: 1.554\n",
      "    sample_throughput: 620.236\n",
      "    sample_time_ms: 24184.332\n",
      "    update_time_ms: 1.23\n",
      "  timestamp: 1665245594\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 225000\n",
      "  training_iteration: 15\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     15 |          405.765 | 225000 | -1478.26 |              1036.74 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 240000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-13-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1343.0997189489685\n",
      "  episode_reward_mean: -1355.0589879557144\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 80\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02500000037252903\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.5071533918380737\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013239492662250996\n",
      "          model: {}\n",
      "          policy_loss: 0.0003341707633808255\n",
      "          total_loss: 186.49647521972656\n",
      "          vf_explained_var: -1.0311093774362234e-06\n",
      "          vf_loss: 186.49581909179688\n",
      "    num_agent_steps_sampled: 240000\n",
      "    num_agent_steps_trained: 240000\n",
=======
      "    mean_env_wait_ms: 5.40652557686741\n",
      "    mean_inference_ms: 0.41142543237699614\n",
      "    mean_processing_ms: 4.065666934966527\n",
      "  time_since_restore: 451.6066608428955\n",
      "  time_this_iter_s: 29.19476890563965\n",
      "  time_total_s: 451.6066608428955\n",
      "  timestamp: 1665271627\n",
      "  timesteps_since_restore: 225000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 225000\n",
      "  training_iteration: 15\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     15 |          451.607 |      225000 | -1580.72 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-27-36\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2150.9826131076466\n",
      "  episode_reward_mean: -1429.2042073408497\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 80\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.806\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.6660086512565613\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030962293967604637\n",
      "        policy_loss: -0.004540848545730114\n",
      "        total_loss: 253.2337188720703\n",
      "        vf_explained_var: -7.600866069878975e-07\n",
      "        vf_loss: 253.23672485351562\n",
      "    load_time_ms: 2.69\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 239616\n",
      "    sample_time_ms: 27769.877\n",
      "    update_time_ms: 2.8\n",
      "  iterations_since_restore: 16\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.881081081081085\n",
      "    ram_util_percent: 29.648648648648656\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.25238095238095\n",
      "    ram_util_percent: 23.87142857142857\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0695096936313875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.170044377915031\n",
      "    mean_inference_ms: 0.5077613183389836\n",
      "    mean_raw_obs_processing_ms: 3.73031321478487\n",
      "  time_since_restore: 431.3379261493683\n",
      "  time_this_iter_s: 25.573004484176636\n",
      "  time_total_s: 431.3379261493683\n",
      "  timers:\n",
      "    learn_throughput: 7068.499\n",
      "    learn_time_ms: 2122.091\n",
      "    load_throughput: 9626587.101\n",
      "    load_time_ms: 1.558\n",
      "    sample_throughput: 618.474\n",
      "    sample_time_ms: 24253.239\n",
      "    update_time_ms: 1.226\n",
      "  timestamp: 1665245619\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 16\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     16 |          431.338 | 240000 | -1355.06 |               1343.1 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 5.3690243859228115\n",
      "    mean_inference_ms: 0.4113758185645554\n",
      "    mean_processing_ms: 4.067037053210127\n",
      "  time_since_restore: 480.8058223724365\n",
      "  time_this_iter_s: 29.199161529541016\n",
      "  time_total_s: 480.8058223724365\n",
      "  timestamp: 1665271656\n",
      "  timesteps_since_restore: 240000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 16\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     16 |          480.806 |      240000 |  -1429.2 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 255000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-14-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1764.6841561171912\n",
      "  episode_reward_mean: -1214.8410185758337\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 85\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02500000037252903\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.740768551826477\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016712147742509842\n",
      "          model: {}\n",
      "          policy_loss: -0.0014623756287619472\n",
      "          total_loss: 183.29299926757812\n",
      "          vf_explained_var: -5.49177855191374e-07\n",
      "          vf_loss: 183.29403686523438\n",
      "    num_agent_steps_sampled: 255000\n",
      "    num_agent_steps_trained: 255000\n",
=======
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-28-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2150.9826131076466\n",
      "  episode_reward_mean: -1255.8452811399284\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 85\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.556\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.9721755385398865\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011220017448067665\n",
      "        policy_loss: -0.001499361009337008\n",
      "        total_loss: 317.94952392578125\n",
      "        vf_explained_var: -3.8819436554149434e-07\n",
      "        vf_loss: 317.95050048828125\n",
      "    load_time_ms: 2.607\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 255000\n",
      "    num_steps_trained: 254592\n",
      "    sample_time_ms: 27887.381\n",
      "    update_time_ms: 2.712\n",
      "  iterations_since_restore: 17\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.931428571428572\n",
      "    ram_util_percent: 29.625714285714288\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.127906976744185\n",
      "    ram_util_percent: 23.92093023255814\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0693536309054961\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.14018541345124\n",
      "    mean_inference_ms: 0.5066017305087622\n",
      "    mean_raw_obs_processing_ms: 3.719816666737813\n",
      "  time_since_restore: 456.38084292411804\n",
      "  time_this_iter_s: 25.042916774749756\n",
      "  time_total_s: 456.38084292411804\n",
      "  timers:\n",
      "    learn_throughput: 6979.036\n",
      "    learn_time_ms: 2149.294\n",
      "    load_throughput: 9675292.96\n",
      "    load_time_ms: 1.55\n",
      "    sample_throughput: 618.139\n",
      "    sample_time_ms: 24266.39\n",
      "    update_time_ms: 1.271\n",
      "  timestamp: 1665245644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 255000\n",
      "  training_iteration: 17\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     17 |          456.381 | 255000 | -1214.84 |              1764.68 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 270000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-14-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1764.6841561171912\n",
      "  episode_reward_mean: -1084.2562650727798\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 90\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02500000037252903\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.6398365497589111\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.1154956966638565\n",
      "          model: {}\n",
      "          policy_loss: -0.0255147535353899\n",
      "          total_loss: 224.1824951171875\n",
      "          vf_explained_var: -2.5268295189562195e-07\n",
      "          vf_loss: 224.2051239013672\n",
      "    num_agent_steps_sampled: 270000\n",
      "    num_agent_steps_trained: 270000\n",
=======
      "    mean_env_wait_ms: 5.335660286937466\n",
      "    mean_inference_ms: 0.4113421434827349\n",
      "    mean_processing_ms: 4.068359651679277\n",
      "  time_since_restore: 510.8505461215973\n",
      "  time_this_iter_s: 30.044723749160767\n",
      "  time_total_s: 510.8505461215973\n",
      "  timestamp: 1665271686\n",
      "  timesteps_since_restore: 255000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 255000\n",
      "  training_iteration: 17\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     17 |          510.851 |      255000 | -1255.85 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-28-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2150.9826131076466\n",
      "  episode_reward_mean: -1114.6940064592045\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 90\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.573\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05000000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8819290399551392\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007236755918711424\n",
      "        policy_loss: -0.00027255943859927356\n",
      "        total_loss: 268.6373596191406\n",
      "        vf_explained_var: -2.384185791015625e-07\n",
      "        vf_loss: 268.63726806640625\n",
      "    load_time_ms: 2.748\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 269568\n",
      "    sample_time_ms: 27951.423\n",
      "    update_time_ms: 2.724\n",
      "  iterations_since_restore: 18\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.57045454545454\n",
      "    ram_util_percent: 29.588636363636365\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.13333333333334\n",
      "    ram_util_percent: 23.95714285714286\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06921093372154444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.113248114225494\n",
      "    mean_inference_ms: 0.5055528594931269\n",
      "    mean_raw_obs_processing_ms: 3.715005665288361\n",
      "  time_since_restore: 487.15186500549316\n",
      "  time_this_iter_s: 30.771022081375122\n",
      "  time_total_s: 487.15186500549316\n",
      "  timers:\n",
      "    learn_throughput: 6938.377\n",
      "    learn_time_ms: 2161.889\n",
      "    load_throughput: 9381831.196\n",
      "    load_time_ms: 1.599\n",
      "    sample_throughput: 618.184\n",
      "    sample_time_ms: 24264.638\n",
      "    update_time_ms: 1.292\n",
      "  timestamp: 1665245675\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 18\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.2/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     18 |          487.152 | 270000 | -1084.26 |              1764.68 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 285000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-15-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -1039.7955941213786\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 95\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.03750000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.2704432010650635\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014583451673388481\n",
      "          model: {}\n",
      "          policy_loss: 0.00033210936817340553\n",
      "          total_loss: 1008.1634521484375\n",
      "          vf_explained_var: -2.4453187918993535e-08\n",
      "          vf_loss: 1008.1624755859375\n",
      "    num_agent_steps_sampled: 285000\n",
      "    num_agent_steps_trained: 285000\n",
=======
      "    mean_env_wait_ms: 5.305567245917672\n",
      "    mean_inference_ms: 0.4113129106258181\n",
      "    mean_processing_ms: 4.069466303462186\n",
      "  time_since_restore: 540.2915470600128\n",
      "  time_this_iter_s: 29.441000938415527\n",
      "  time_total_s: 540.2915470600128\n",
      "  timestamp: 1665271715\n",
      "  timesteps_since_restore: 270000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 18\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     18 |          540.292 |      270000 | -1114.69 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-29-05\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -990.7253668556045\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 95\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.238\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.9742282032966614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.027607323601841927\n",
      "        policy_loss: -0.001836832845583558\n",
      "        total_loss: 307.25146484375\n",
      "        vf_explained_var: -9.271833789625816e-08\n",
      "        vf_loss: 307.25262451171875\n",
      "    load_time_ms: 2.751\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 285000\n",
      "    num_steps_trained: 284544\n",
      "    sample_time_ms: 27970.467\n",
      "    update_time_ms: 2.691\n",
      "  iterations_since_restore: 19\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.60810810810811\n",
      "    ram_util_percent: 29.681081081081075\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.42142857142858\n",
      "    ram_util_percent: 23.878571428571426\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06907644414460958\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.088613390315169\n",
      "    mean_inference_ms: 0.5045669059044199\n",
      "    mean_raw_obs_processing_ms: 3.7104999427139433\n",
      "  time_since_restore: 512.8783168792725\n",
      "  time_this_iter_s: 25.726451873779297\n",
      "  time_total_s: 512.8783168792725\n",
      "  timers:\n",
      "    learn_throughput: 6970.06\n",
      "    learn_time_ms: 2152.062\n",
      "    load_throughput: 8917094.465\n",
      "    load_time_ms: 1.682\n",
      "    sample_throughput: 616.709\n",
      "    sample_time_ms: 24322.666\n",
      "    update_time_ms: 1.351\n",
      "  timestamp: 1665245701\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 285000\n",
      "  training_iteration: 19\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     19 |          512.878 | 285000 |  -1039.8 |              1979.82 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-15-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -1010.2761771240278\n",
      "  episode_reward_min: -5227.059352675403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 100\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.03750000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.1847551167011261\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009991643019020557\n",
      "          model: {}\n",
      "          policy_loss: -0.001692836987785995\n",
      "          total_loss: 628.7777709960938\n",
      "          vf_explained_var: -4.7887493082043875e-08\n",
      "          vf_loss: 628.7791748046875\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_agent_steps_trained: 300000\n",
=======
      "    mean_env_wait_ms: 5.27831947652698\n",
      "    mean_inference_ms: 0.4112848069201737\n",
      "    mean_processing_ms: 4.070266254369737\n",
      "  time_since_restore: 569.5235981941223\n",
      "  time_this_iter_s: 29.232051134109497\n",
      "  time_total_s: 569.5235981941223\n",
      "  timestamp: 1665271745\n",
      "  timesteps_since_restore: 285000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 285000\n",
      "  training_iteration: 19\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     19 |          569.524 |      285000 | -990.725 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-29-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -911.7950380860152\n",
      "  episode_reward_min: -5296.5181944119695\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 100\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.323\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.6666787266731262\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026881108060479164\n",
      "        policy_loss: -0.0039021591655910015\n",
      "        total_loss: 215.7240753173828\n",
      "        vf_explained_var: -8.609559642991371e-08\n",
      "        vf_loss: 215.72727966308594\n",
      "    load_time_ms: 2.83\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 299520\n",
      "    sample_time_ms: 27940.609\n",
      "    update_time_ms: 2.737\n",
      "  iterations_since_restore: 20\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.754285714285718\n",
      "    ram_util_percent: 29.731428571428577\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.02439024390243\n",
      "    ram_util_percent: 23.86829268292683\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06895259163395959\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.0659068495374955\n",
      "    mean_inference_ms: 0.5036619202195793\n",
      "    mean_raw_obs_processing_ms: 3.7053744654968943\n",
      "  time_since_restore: 537.5269577503204\n",
      "  time_this_iter_s: 24.648640871047974\n",
      "  time_total_s: 537.5269577503204\n",
      "  timers:\n",
      "    learn_throughput: 6996.859\n",
      "    learn_time_ms: 2143.819\n",
      "    load_throughput: 8991133.85\n",
      "    load_time_ms: 1.668\n",
      "    sample_throughput: 618.284\n",
      "    sample_time_ms: 24260.693\n",
      "    update_time_ms: 1.342\n",
      "  timestamp: 1665245726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 20\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     20 |          537.527 | 300000 | -1010.28 |              1979.82 |             -5227.06 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 315000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-15-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -833.3724642534627\n",
      "  episode_reward_min: -5088.450841511557\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 105\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.01875000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.15268583595752716\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.031605809926986694\n",
      "          model: {}\n",
      "          policy_loss: -0.0011577539844438434\n",
      "          total_loss: 1202.5113525390625\n",
      "          vf_explained_var: -5.094414223805188e-09\n",
      "          vf_loss: 1202.5118408203125\n",
      "    num_agent_steps_sampled: 315000\n",
      "    num_agent_steps_trained: 315000\n",
=======
      "    mean_env_wait_ms: 5.253148457608845\n",
      "    mean_inference_ms: 0.4112597154316226\n",
      "    mean_processing_ms: 4.070894931782129\n",
      "  time_since_restore: 598.4107913970947\n",
      "  time_this_iter_s: 28.887193202972412\n",
      "  time_total_s: 598.4107913970947\n",
      "  timestamp: 1665271773\n",
      "  timesteps_since_restore: 300000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 20\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     20 |          598.411 |      300000 | -911.795 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-30-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -604.8625944410849\n",
      "  episode_reward_min: -5133.911588643235\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 105\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.202\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.144898772239685\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.033596329391002655\n",
      "        policy_loss: -0.0046270666643977165\n",
      "        total_loss: 307.9708557128906\n",
      "        vf_explained_var: -4.5340286192185886e-08\n",
      "        vf_loss: 307.9745788574219\n",
      "    load_time_ms: 2.928\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 315000\n",
      "    num_steps_trained: 314496\n",
      "    sample_time_ms: 27876.498\n",
      "    update_time_ms: 2.742\n",
      "  iterations_since_restore: 21\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.443181818181817\n",
      "    ram_util_percent: 29.609090909090913\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.28780487804878\n",
      "    ram_util_percent: 23.892682926829266\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06839647241832467\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.9074973169729117\n",
      "    mean_inference_ms: 0.4992209030848455\n",
      "    mean_raw_obs_processing_ms: 3.624163815960616\n",
      "  time_since_restore: 568.1779489517212\n",
      "  time_this_iter_s: 30.650991201400757\n",
      "  time_total_s: 568.1779489517212\n",
      "  timers:\n",
      "    learn_throughput: 6875.183\n",
      "    learn_time_ms: 2181.76\n",
      "    load_throughput: 8066589.738\n",
      "    load_time_ms: 1.86\n",
      "    sample_throughput: 605.17\n",
      "    sample_time_ms: 24786.411\n",
      "    update_time_ms: 1.342\n",
      "  timestamp: 1665245756\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 315000\n",
      "  training_iteration: 21\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     21 |          568.178 | 315000 | -833.372 |              1979.82 |             -5088.45 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n"
=======
      "    mean_env_wait_ms: 5.067777979086083\n",
      "    mean_inference_ms: 0.4105118524346444\n",
      "    mean_processing_ms: 4.0748174886049915\n",
      "  time_since_restore: 627.6291782855988\n",
      "  time_this_iter_s: 29.21838688850403\n",
      "  time_total_s: 627.6291782855988\n",
      "  timestamp: 1665271803\n",
      "  timesteps_since_restore: 315000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 315000\n",
      "  training_iteration: 21\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     21 |          627.629 |      315000 | -604.863 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 330000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-16-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -624.5173161875059\n",
      "  episode_reward_min: -4326.450438316295\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 110\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.01875000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.1690373569726944\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0342976450920105\n",
      "          model: {}\n",
      "          policy_loss: -0.0052382368594408035\n",
      "          total_loss: 856.84521484375\n",
      "          vf_explained_var: -1.5283243115504774e-08\n",
      "          vf_loss: 856.849609375\n",
      "    num_agent_steps_sampled: 330000\n",
      "    num_agent_steps_trained: 330000\n",
=======
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-30-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -319.59679259949263\n",
      "  episode_reward_min: -4210.348871694206\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 110\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.681\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0963475704193115\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03217914700508118\n",
      "        policy_loss: -0.0034363085869699717\n",
      "        total_loss: 377.84210205078125\n",
      "        vf_explained_var: -1.2736035337468365e-08\n",
      "        vf_loss: 377.8447570800781\n",
      "    load_time_ms: 2.84\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 329472\n",
      "    sample_time_ms: 27872.248\n",
      "    update_time_ms: 2.825\n",
      "  iterations_since_restore: 22\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.082608695652176\n",
      "    ram_util_percent: 29.613043478260874\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.47441860465116\n",
      "    ram_util_percent: 23.87441860465116\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06794680196810986\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.8295311938044114\n",
      "    mean_inference_ms: 0.4958334178134759\n",
      "    mean_raw_obs_processing_ms: 3.600545384918634\n",
      "  time_since_restore: 599.9546086788177\n",
      "  time_this_iter_s: 31.776659727096558\n",
      "  time_total_s: 599.9546086788177\n",
      "  timers:\n",
      "    learn_throughput: 6790.02\n",
      "    learn_time_ms: 2209.125\n",
      "    load_throughput: 8019701.721\n",
      "    load_time_ms: 1.87\n",
      "    sample_throughput: 588.716\n",
      "    sample_time_ms: 25479.16\n",
      "    update_time_ms: 1.637\n",
      "  timestamp: 1665245788\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 22\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     22 |          599.955 | 330000 | -624.517 |              1979.82 |             -4326.45 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 345000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-17-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -432.5003114742191\n",
      "  episode_reward_min: -3804.402633930361\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 115\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.01875000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.5304223299026489\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03891260549426079\n",
      "          model: {}\n",
      "          policy_loss: -0.007116771303117275\n",
      "          total_loss: 912.8582763671875\n",
      "          vf_explained_var: -8.151062935723985e-09\n",
      "          vf_loss: 912.8646240234375\n",
      "    num_agent_steps_sampled: 345000\n",
      "    num_agent_steps_trained: 345000\n",
=======
      "    mean_env_wait_ms: 4.98464230560202\n",
      "    mean_inference_ms: 0.4103541778043633\n",
      "    mean_processing_ms: 4.078504803862877\n",
      "  time_since_restore: 657.7460916042328\n",
      "  time_this_iter_s: 30.116913318634033\n",
      "  time_total_s: 657.7460916042328\n",
      "  timestamp: 1665271833\n",
      "  timesteps_since_restore: 330000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 22\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     22 |          657.746 |      330000 | -319.597 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-31-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -102.54571991842141\n",
      "  episode_reward_min: -3362.1349047244466\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 115\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.317\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0031050443649292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0322035551071167\n",
      "        policy_loss: -0.002848793985322118\n",
      "        total_loss: 496.5315856933594\n",
      "        vf_explained_var: -1.1207711203553572e-08\n",
      "        vf_loss: 496.5336608886719\n",
      "    load_time_ms: 2.873\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 345000\n",
      "    num_steps_trained: 344448\n",
      "    sample_time_ms: 27892.953\n",
      "    update_time_ms: 2.871\n",
      "  iterations_since_restore: 23\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.172727272727272\n",
      "    ram_util_percent: 29.627272727272725\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.853488372093025\n",
      "    ram_util_percent: 23.93255813953488\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06765621996815599\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.7812139577264747\n",
      "    mean_inference_ms: 0.4937142605628986\n",
      "    mean_raw_obs_processing_ms: 3.5951797743674208\n",
      "  time_since_restore: 631.2270705699921\n",
      "  time_this_iter_s: 31.272461891174316\n",
      "  time_total_s: 631.2270705699921\n",
      "  timers:\n",
      "    learn_throughput: 6848.118\n",
      "    learn_time_ms: 2190.383\n",
      "    load_throughput: 9070988.206\n",
      "    load_time_ms: 1.654\n",
      "    sample_throughput: 577.251\n",
      "    sample_time_ms: 25985.226\n",
      "    update_time_ms: 1.627\n",
      "  timestamp: 1665245820\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 345000\n",
      "  training_iteration: 23\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     23 |          631.227 | 345000 |   -432.5 |              1979.82 |              -3804.4 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 360000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-17-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -281.10882836726114\n",
      "  episode_reward_min: -3426.338972530315\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 120\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.01875000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.6562395691871643\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02252059057354927\n",
      "          model: {}\n",
      "          policy_loss: -0.0017917229561135173\n",
      "          total_loss: 1199.7799072265625\n",
      "          vf_explained_var: 2.547207111902594e-09\n",
      "          vf_loss: 1199.78125\n",
      "    num_agent_steps_sampled: 360000\n",
      "    num_agent_steps_trained: 360000\n",
=======
      "    mean_env_wait_ms: 4.9324359339414885\n",
      "    mean_inference_ms: 0.4103356927650054\n",
      "    mean_processing_ms: 4.079092924632403\n",
      "  time_since_restore: 687.2925012111664\n",
      "  time_this_iter_s: 29.546409606933594\n",
      "  time_total_s: 687.2925012111664\n",
      "  timestamp: 1665271862\n",
      "  timesteps_since_restore: 345000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 345000\n",
      "  training_iteration: 23\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     23 |          687.293 |      345000 | -102.546 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-31-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 84.66621717797645\n",
      "  episode_reward_min: -2783.560989605884\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 120\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.906\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1678290367126465\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02695666439831257\n",
      "        policy_loss: -0.0006163036450743675\n",
      "        total_loss: 431.3108825683594\n",
      "        vf_explained_var: -1.0698269825581974e-08\n",
      "        vf_loss: 431.31085205078125\n",
      "    load_time_ms: 2.876\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 359424\n",
      "    sample_time_ms: 27905.954\n",
      "    update_time_ms: 2.823\n",
      "  iterations_since_restore: 24\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.294444444444444\n",
      "    ram_util_percent: 29.669444444444448\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.84878048780487\n",
      "    ram_util_percent: 23.89268292682927\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06744684472048959\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.747718808153633\n",
      "    mean_inference_ms: 0.4922166772926986\n",
      "    mean_raw_obs_processing_ms: 3.5993028955329716\n",
      "  time_since_restore: 656.5639405250549\n",
      "  time_this_iter_s: 25.336869955062866\n",
      "  time_total_s: 656.5639405250549\n",
      "  timers:\n",
      "    learn_throughput: 6911.2\n",
      "    learn_time_ms: 2170.39\n",
      "    load_throughput: 9043476.261\n",
      "    load_time_ms: 1.659\n",
      "    sample_throughput: 579.089\n",
      "    sample_time_ms: 25902.739\n",
      "    update_time_ms: 1.626\n",
      "  timestamp: 1665245845\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 24\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     24 |          656.564 | 360000 | -281.109 |              1979.82 |             -3426.34 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n"
=======
      "    mean_env_wait_ms: 4.895452560492289\n",
      "    mean_inference_ms: 0.41037144851800045\n",
      "    mean_processing_ms: 4.080372494466766\n",
      "  time_since_restore: 716.41277384758\n",
      "  time_this_iter_s: 29.120272636413574\n",
      "  time_total_s: 716.41277384758\n",
      "  timestamp: 1665271892\n",
      "  timesteps_since_restore: 360000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 24\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     24 |          716.413 |      360000 |  84.6662 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 375000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-18-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -252.0180719301339\n",
      "  episode_reward_min: -6471.328111909182\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 125\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.01875000074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.20292820036411285\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.042317215353250504\n",
      "          model: {}\n",
      "          policy_loss: -0.003234497271478176\n",
      "          total_loss: 1894.1748046875\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 1894.1771240234375\n",
      "    num_agent_steps_sampled: 375000\n",
      "    num_agent_steps_trained: 375000\n",
=======
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-32-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 146.37486129384519\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 125\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.149\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.19539299607276917\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012731901369988918\n",
      "        policy_loss: 0.0009902429301291704\n",
      "        total_loss: 1214.624755859375\n",
      "        vf_explained_var: -6.113296979748384e-09\n",
      "        vf_loss: 1214.6236572265625\n",
      "    load_time_ms: 2.941\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 375000\n",
      "    num_steps_trained: 374400\n",
      "    sample_time_ms: 27907.757\n",
      "    update_time_ms: 2.831\n",
      "  iterations_since_restore: 25\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.91698113207547\n",
      "    ram_util_percent: 29.654716981132076\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.390476190476186\n",
      "    ram_util_percent: 23.938095238095237\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0672773172551496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.721751515350894\n",
      "    mean_inference_ms: 0.4910219032854707\n",
      "    mean_raw_obs_processing_ms: 3.6134327625391642\n",
      "  time_since_restore: 693.2920804023743\n",
      "  time_this_iter_s: 36.728139877319336\n",
      "  time_total_s: 693.2920804023743\n",
      "  timers:\n",
      "    learn_throughput: 6759.928\n",
      "    learn_time_ms: 2218.959\n",
      "    load_throughput: 8909265.474\n",
      "    load_time_ms: 1.684\n",
      "    sample_throughput: 565.532\n",
      "    sample_time_ms: 26523.688\n",
      "    update_time_ms: 1.531\n",
      "  timestamp: 1665245882\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 375000\n",
      "  training_iteration: 25\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     25 |          693.292 | 375000 | -252.018 |              1979.82 |             -6471.33 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 390000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-18-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -164.82259319169034\n",
      "  episode_reward_min: -6471.328111909182\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 130\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.0052398443222046\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03852811083197594\n",
      "          model: {}\n",
      "          policy_loss: 0.00047436929889954627\n",
      "          total_loss: 1419.784423828125\n",
      "          vf_explained_var: -1.0188828669654981e-09\n",
      "          vf_loss: 1419.7828369140625\n",
      "    num_agent_steps_sampled: 390000\n",
      "    num_agent_steps_trained: 390000\n",
=======
      "    mean_env_wait_ms: 4.866792455096052\n",
      "    mean_inference_ms: 0.41041082602009543\n",
      "    mean_processing_ms: 4.081312454833599\n",
      "  time_since_restore: 745.6298134326935\n",
      "  time_this_iter_s: 29.217039585113525\n",
      "  time_total_s: 745.6298134326935\n",
      "  timestamp: 1665271921\n",
      "  timesteps_since_restore: 375000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 375000\n",
      "  training_iteration: 25\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     25 |           745.63 |      375000 |  146.375 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-32-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 226.9748364868977\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 130\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.688\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7585897445678711\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029231322929263115\n",
      "        policy_loss: -0.0013191142352297902\n",
      "        total_loss: 1218.2537841796875\n",
      "        vf_explained_var: -2.2924863785078742e-08\n",
      "        vf_loss: 1218.254150390625\n",
      "    load_time_ms: 2.842\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 389376\n",
      "    sample_time_ms: 27977.183\n",
      "    update_time_ms: 2.818\n",
      "  iterations_since_restore: 26\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.22972972972973\n",
      "    ram_util_percent: 29.751351351351342\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.81860465116279\n",
      "    ram_util_percent: 23.90232558139535\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06713624340422257\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.700873290301983\n",
      "    mean_inference_ms: 0.49004704467009175\n",
      "    mean_raw_obs_processing_ms: 3.62898774253499\n",
      "  time_since_restore: 719.3613746166229\n",
      "  time_this_iter_s: 26.069294214248657\n",
      "  time_total_s: 719.3613746166229\n",
      "  timers:\n",
      "    learn_throughput: 6570.81\n",
      "    learn_time_ms: 2282.824\n",
      "    load_throughput: 8933808.557\n",
      "    load_time_ms: 1.679\n",
      "    sample_throughput: 565.859\n",
      "    sample_time_ms: 26508.364\n",
      "    update_time_ms: 1.716\n",
      "  timestamp: 1665245908\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 26\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     26 |          719.361 | 390000 | -164.823 |              1979.82 |             -6471.33 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 4.844346003529898\n",
      "    mean_inference_ms: 0.4104943113985277\n",
      "    mean_processing_ms: 4.082017719666616\n",
      "  time_since_restore: 775.5276658535004\n",
      "  time_this_iter_s: 29.897852420806885\n",
      "  time_total_s: 775.5276658535004\n",
      "  timestamp: 1665271951\n",
      "  timesteps_since_restore: 390000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 26\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     26 |          775.528 |      390000 |  226.975 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 405000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-19-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -187.70155488887926\n",
      "  episode_reward_min: -6471.328111909182\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 135\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.19849418103694916\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011470411904156208\n",
      "          model: {}\n",
      "          policy_loss: 0.001363390707410872\n",
      "          total_loss: 1897.8197021484375\n",
      "          vf_explained_var: -1.7830450005362763e-08\n",
      "          vf_loss: 1897.818115234375\n",
      "    num_agent_steps_sampled: 405000\n",
      "    num_agent_steps_trained: 405000\n",
=======
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-33-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 346.53740662600933\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 135\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.484\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.2142467498779297\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026433037593960762\n",
      "        policy_loss: -0.0023595283273607492\n",
      "        total_loss: 528.091796875\n",
      "        vf_explained_var: 0.007976763881742954\n",
      "        vf_loss: 528.093505859375\n",
      "    load_time_ms: 2.777\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 405000\n",
      "    num_steps_trained: 404352\n",
      "    sample_time_ms: 27967.121\n",
      "    update_time_ms: 2.883\n",
      "  iterations_since_restore: 27\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.57173913043478\n",
      "    ram_util_percent: 29.69782608695652\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.66428571428572\n",
      "    ram_util_percent: 23.93809523809524\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06702440298163988\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.6836410697180724\n",
      "    mean_inference_ms: 0.48926597936976196\n",
      "    mean_raw_obs_processing_ms: 3.6499410030146633\n",
      "  time_since_restore: 751.3305974006653\n",
      "  time_this_iter_s: 31.96922278404236\n",
      "  time_total_s: 751.3305974006653\n",
      "  timers:\n",
      "    learn_throughput: 6432.015\n",
      "    learn_time_ms: 2332.084\n",
      "    load_throughput: 8055538.341\n",
      "    load_time_ms: 1.862\n",
      "    sample_throughput: 552.464\n",
      "    sample_time_ms: 27151.076\n",
      "    update_time_ms: 1.665\n",
      "  timestamp: 1665245940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 405000\n",
      "  training_iteration: 27\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     27 |          751.331 | 405000 | -187.702 |              1979.82 |             -6471.33 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 420000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-19-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -251.63524983528433\n",
      "  episode_reward_min: -7307.768976759082\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 140\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7098292708396912\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.034076135605573654\n",
      "          model: {}\n",
      "          policy_loss: 0.0001882843644125387\n",
      "          total_loss: 2217.23779296875\n",
      "          vf_explained_var: -6.113296979748384e-09\n",
      "          vf_loss: 2217.236572265625\n",
      "    num_agent_steps_sampled: 420000\n",
      "    num_agent_steps_trained: 420000\n",
=======
      "    mean_env_wait_ms: 4.826277563593099\n",
      "    mean_inference_ms: 0.41050419809733335\n",
      "    mean_processing_ms: 4.0832681110311055\n",
      "  time_since_restore: 805.4596519470215\n",
      "  time_this_iter_s: 29.931986093521118\n",
      "  time_total_s: 805.4596519470215\n",
      "  timestamp: 1665271981\n",
      "  timesteps_since_restore: 405000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 405000\n",
      "  training_iteration: 27\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     27 |           805.46 |      405000 |  346.537 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-33-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 381.2403436317934\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 140\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.452\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4376133680343628\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026094552129507065\n",
      "        policy_loss: 0.0009768957970663905\n",
      "        total_loss: 760.359130859375\n",
      "        vf_explained_var: 0.5551092624664307\n",
      "        vf_loss: 760.357421875\n",
      "    load_time_ms: 2.757\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 419328\n",
      "    sample_time_ms: 27936.623\n",
      "    update_time_ms: 2.833\n",
      "  iterations_since_restore: 28\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.358333333333334\n",
      "    ram_util_percent: 29.752777777777776\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.057142857142864\n",
      "    ram_util_percent: 23.954761904761902\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0669284439588703\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.6691612081890796\n",
      "    mean_inference_ms: 0.48861661412477053\n",
      "    mean_raw_obs_processing_ms: 3.6604273041509248\n",
      "  time_since_restore: 776.5812032222748\n",
      "  time_this_iter_s: 25.250605821609497\n",
      "  time_total_s: 776.5812032222748\n",
      "  timers:\n",
      "    learn_throughput: 6479.047\n",
      "    learn_time_ms: 2315.155\n",
      "    load_throughput: 8203429.257\n",
      "    load_time_ms: 1.829\n",
      "    sample_throughput: 563.569\n",
      "    sample_time_ms: 26616.077\n",
      "    update_time_ms: 1.686\n",
      "  timestamp: 1665245965\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 28\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     28 |          776.581 | 420000 | -251.635 |              1979.82 |             -7307.77 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 435000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-19-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -261.4224791555314\n",
      "  episode_reward_min: -7307.768976759082\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 145\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.22507379949092865\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03294586390256882\n",
      "          model: {}\n",
      "          policy_loss: -0.0016913700383156538\n",
      "          total_loss: 1505.9193115234375\n",
      "          vf_explained_var: 1.0188828669654981e-09\n",
      "          vf_loss: 1505.9200439453125\n",
      "    num_agent_steps_sampled: 435000\n",
      "    num_agent_steps_trained: 435000\n",
=======
      "    mean_env_wait_ms: 4.811319949342764\n",
      "    mean_inference_ms: 0.4104235933721295\n",
      "    mean_processing_ms: 4.085098857820824\n",
      "  time_since_restore: 834.5948858261108\n",
      "  time_this_iter_s: 29.135233879089355\n",
      "  time_total_s: 834.5948858261108\n",
      "  timestamp: 1665272010\n",
      "  timesteps_since_restore: 420000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 28\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     28 |          834.595 |      420000 |   381.24 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-33-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 434.2930465944985\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 145\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.104\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.6761203408241272\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021178705617785454\n",
      "        policy_loss: 0.0003945417411159724\n",
      "        total_loss: 741.3009033203125\n",
      "        vf_explained_var: 0.7156456708908081\n",
      "        vf_loss: 741.2998657226562\n",
      "    load_time_ms: 2.729\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 435000\n",
      "    num_steps_trained: 434304\n",
      "    sample_time_ms: 27949.502\n",
      "    update_time_ms: 2.794\n",
      "  iterations_since_restore: 29\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.56744186046512\n",
      "    ram_util_percent: 29.706976744186054\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.98095238095238\n",
      "    ram_util_percent: 23.93809523809524\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06684093060098237\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.6564766096851566\n",
      "    mean_inference_ms: 0.4880413474318112\n",
      "    mean_raw_obs_processing_ms: 3.6748997532678978\n",
      "  time_since_restore: 806.6433324813843\n",
      "  time_this_iter_s: 30.062129259109497\n",
      "  time_total_s: 806.6433324813843\n",
      "  timers:\n",
      "    learn_throughput: 6411.136\n",
      "    learn_time_ms: 2339.679\n",
      "    load_throughput: 8488775.552\n",
      "    load_time_ms: 1.767\n",
      "    sample_throughput: 555.044\n",
      "    sample_time_ms: 27024.87\n",
      "    update_time_ms: 1.9\n",
      "  timestamp: 1665245995\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 435000\n",
      "  training_iteration: 29\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     29 |          806.643 | 435000 | -261.422 |              1979.82 |             -7307.77 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 450000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-20-20\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -310.66458969509824\n",
      "  episode_reward_min: -7307.768976759082\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 150\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.375104159116745\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03263954445719719\n",
      "          model: {}\n",
      "          policy_loss: -0.0026295389980077744\n",
      "          total_loss: 1545.81787109375\n",
      "          vf_explained_var: -6.113296979748384e-09\n",
      "          vf_loss: 1545.8194580078125\n",
      "    num_agent_steps_sampled: 450000\n",
      "    num_agent_steps_trained: 450000\n",
=======
      "    mean_env_wait_ms: 4.799016883960666\n",
      "    mean_inference_ms: 0.41037060817395643\n",
      "    mean_processing_ms: 4.086666191679509\n",
      "  time_since_restore: 863.9618046283722\n",
      "  time_this_iter_s: 29.366918802261353\n",
      "  time_total_s: 863.9618046283722\n",
      "  timestamp: 1665272039\n",
      "  timesteps_since_restore: 435000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 435000\n",
      "  training_iteration: 29\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     29 |          863.962 |      435000 |  434.293 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-34-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 442.4934132689977\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 150\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.898\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02500000037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.40116938948631287\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.10207802802324295\n",
      "        policy_loss: -0.015542691573500633\n",
      "        total_loss: 725.0808715820312\n",
      "        vf_explained_var: 0.8073306679725647\n",
      "        vf_loss: 725.0936889648438\n",
      "    load_time_ms: 2.635\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 449280\n",
      "    sample_time_ms: 27994.89\n",
      "    update_time_ms: 2.713\n",
      "  iterations_since_restore: 30\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.391428571428573\n",
      "    ram_util_percent: 29.84285714285714\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.49047619047619\n",
      "    ram_util_percent: 23.914285714285715\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06676273645708478\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.645204409086932\n",
      "    mean_inference_ms: 0.4875428442571173\n",
      "    mean_raw_obs_processing_ms: 3.6903148609709904\n",
      "  time_since_restore: 831.446578502655\n",
      "  time_this_iter_s: 24.803246021270752\n",
      "  time_total_s: 831.446578502655\n",
      "  timers:\n",
      "    learn_throughput: 6397.014\n",
      "    learn_time_ms: 2344.844\n",
      "    load_throughput: 8442187.752\n",
      "    load_time_ms: 1.777\n",
      "    sample_throughput: 554.843\n",
      "    sample_time_ms: 27034.696\n",
      "    update_time_ms: 2.05\n",
      "  timestamp: 1665246020\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 30\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     30 |          831.447 | 450000 | -310.665 |              1979.82 |             -7307.77 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 465000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-20-45\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -338.7343819399349\n",
      "  episode_reward_min: -7307.768976759082\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 155\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.27902987599372864\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02392977476119995\n",
      "          model: {}\n",
      "          policy_loss: 0.0010287296026945114\n",
      "          total_loss: 1826.441162109375\n",
      "          vf_explained_var: -1.1207711203553572e-08\n",
      "          vf_loss: 1826.439453125\n",
      "    num_agent_steps_sampled: 465000\n",
      "    num_agent_steps_trained: 465000\n",
=======
      "    mean_env_wait_ms: 4.788177884166082\n",
      "    mean_inference_ms: 0.41033501534282857\n",
      "    mean_processing_ms: 4.088195657846636\n",
      "  time_since_restore: 893.3194561004639\n",
      "  time_this_iter_s: 29.357651472091675\n",
      "  time_total_s: 893.3194561004639\n",
      "  timestamp: 1665272069\n",
      "  timesteps_since_restore: 450000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 30\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     30 |          893.319 |      450000 |  442.493 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-34-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 397.1359986847118\n",
      "  episode_reward_min: -4566.985028499519\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 155\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.795\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.3714442551136017\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011444581672549248\n",
      "        policy_loss: 0.0007020886987447739\n",
      "        total_loss: 886.865234375\n",
      "        vf_explained_var: 0.8329453468322754\n",
      "        vf_loss: 886.8641357421875\n",
      "    load_time_ms: 2.511\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 465000\n",
      "    num_steps_trained: 464256\n",
      "    sample_time_ms: 27971.535\n",
      "    update_time_ms: 2.718\n",
      "  iterations_since_restore: 31\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.394594594594594\n",
      "    ram_util_percent: 29.767567567567564\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.58292682926829\n",
      "    ram_util_percent: 23.9390243902439\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06668936326698667\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.6352056175508114\n",
      "    mean_inference_ms: 0.48710019538436156\n",
      "    mean_raw_obs_processing_ms: 3.707128217554143\n",
      "  time_since_restore: 856.7197952270508\n",
      "  time_this_iter_s: 25.273216724395752\n",
      "  time_total_s: 856.7197952270508\n",
      "  timers:\n",
      "    learn_throughput: 6445.069\n",
      "    learn_time_ms: 2327.361\n",
      "    load_throughput: 9422437.885\n",
      "    load_time_ms: 1.592\n",
      "    sample_throughput: 565.721\n",
      "    sample_time_ms: 26514.854\n",
      "    update_time_ms: 2.059\n",
      "  timestamp: 1665246045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 465000\n",
      "  training_iteration: 31\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     31 |           856.72 | 465000 | -338.734 |              1979.82 |             -7307.77 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
=======
      "    mean_env_wait_ms: 4.77840273976982\n",
      "    mean_inference_ms: 0.4103177498276605\n",
      "    mean_processing_ms: 4.089274791768024\n",
      "  time_since_restore: 922.2919692993164\n",
      "  time_this_iter_s: 28.97251319885254\n",
      "  time_total_s: 922.2919692993164\n",
      "  timestamp: 1665272098\n",
      "  timesteps_since_restore: 465000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 465000\n",
      "  training_iteration: 31\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     31 |          922.292 |      465000 |  397.136 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 480000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-21-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -409.8345745236721\n",
      "  episode_reward_min: -7307.768976759082\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 160\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.1628149151802063\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018877895548939705\n",
      "          model: {}\n",
      "          policy_loss: 0.0006154166767373681\n",
      "          total_loss: 2151.952392578125\n",
      "          vf_explained_var: 4.0755314678619925e-09\n",
      "          vf_loss: 2151.951171875\n",
      "    num_agent_steps_sampled: 480000\n",
      "    num_agent_steps_trained: 480000\n",
=======
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-35-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 288.136902244383\n",
      "  episode_reward_min: -7735.964549449847\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 160\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.315\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.6021498441696167\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023407192900776863\n",
      "        policy_loss: -0.0003280425735283643\n",
      "        total_loss: 2164.168212890625\n",
      "        vf_explained_var: 0.8373757600784302\n",
      "        vf_loss: 2164.16796875\n",
      "    load_time_ms: 2.507\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 479232\n",
      "    sample_time_ms: 27906.97\n",
      "    update_time_ms: 2.717\n",
      "  iterations_since_restore: 32\n",
<<<<<<< HEAD
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.386111111111113\n",
      "    ram_util_percent: 29.761111111111106\n",
      "  pid: 307\n",
=======
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.607142857142854\n",
      "    ram_util_percent: 23.93809523809524\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06662085345045855\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.6262898356382185\n",
      "    mean_inference_ms: 0.486692284433771\n",
      "    mean_raw_obs_processing_ms: 3.724965695910047\n",
      "  time_since_restore: 882.3072845935822\n",
      "  time_this_iter_s: 25.587489366531372\n",
      "  time_total_s: 882.3072845935822\n",
      "  timers:\n",
      "    learn_throughput: 6423.41\n",
      "    learn_time_ms: 2335.208\n",
      "    load_throughput: 10595779.511\n",
      "    load_time_ms: 1.416\n",
      "    sample_throughput: 579.403\n",
      "    sample_time_ms: 25888.709\n",
      "    update_time_ms: 1.739\n",
      "  timestamp: 1665246071\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 32\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     32 |          882.307 | 480000 | -409.835 |              1979.82 |             -7307.77 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 495000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-21-36\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -402.1378313091908\n",
      "  episode_reward_min: -7307.768976759082\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 165\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.9996374845504761\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026634713634848595\n",
      "          model: {}\n",
      "          policy_loss: -0.0011769250268116593\n",
      "          total_loss: 1361.2147216796875\n",
      "          vf_explained_var: -7.641621557752387e-09\n",
      "          vf_loss: 1361.215087890625\n",
      "    num_agent_steps_sampled: 495000\n",
      "    num_agent_steps_trained: 495000\n",
      "    num_steps_sampled: 495000\n",
      "    num_steps_trained: 495000\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.061111111111114\n",
      "    ram_util_percent: 29.763888888888882\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.76993166836668\n",
      "    mean_inference_ms: 0.41030298628771356\n",
      "    mean_processing_ms: 4.089096718916428\n",
      "  time_since_restore: 951.7783026695251\n",
      "  time_this_iter_s: 29.48633337020874\n",
      "  time_total_s: 951.7783026695251\n",
      "  timestamp: 1665272127\n",
      "  timesteps_since_restore: 480000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 32\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     32 |          951.778 |      480000 |  288.137 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-35-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 239.6607914164302\n",
      "  episode_reward_min: -7735.964549449847\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 165\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.302\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.12797172367572784\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018186938017606735\n",
      "        policy_loss: -0.0006287434371188283\n",
      "        total_loss: 930.6474609375\n",
      "        vf_explained_var: 0.8931397199630737\n",
      "        vf_loss: 930.6474609375\n",
      "    load_time_ms: 2.546\n",
      "    num_steps_sampled: 495000\n",
      "    num_steps_trained: 494208\n",
      "    sample_time_ms: 27904.643\n",
      "    update_time_ms: 2.714\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.15476190476191\n",
      "    ram_util_percent: 23.96666666666667\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.762318238536111\n",
      "    mean_inference_ms: 0.41030713209785946\n",
      "    mean_processing_ms: 4.0891238118195465\n",
      "  time_since_restore: 981.3012747764587\n",
      "  time_this_iter_s: 29.522972106933594\n",
      "  time_total_s: 981.3012747764587\n",
      "  timestamp: 1665272157\n",
      "  timesteps_since_restore: 495000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 495000\n",
      "  training_iteration: 33\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     33 |          981.301 |      495000 |  239.661 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-36-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 283.48924994885715\n",
      "  episode_reward_min: -7735.964549449847\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 170\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.951\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.3942350447177887\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010172453708946705\n",
      "        policy_loss: 0.001523479470051825\n",
      "        total_loss: 746.2391967773438\n",
      "        vf_explained_var: 0.9138190746307373\n",
      "        vf_loss: 746.2373046875\n",
      "    load_time_ms: 2.544\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 509184\n",
      "    sample_time_ms: 28474.725\n",
      "    update_time_ms: 2.803\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.72\n",
      "    ram_util_percent: 23.925999999999995\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.755892276356957\n",
      "    mean_inference_ms: 0.4102908844556432\n",
      "    mean_processing_ms: 4.0916743037360135\n",
      "  time_since_restore: 1016.1197714805603\n",
      "  time_this_iter_s: 34.81849670410156\n",
      "  time_total_s: 1016.1197714805603\n",
      "  timestamp: 1665272191\n",
      "  timesteps_since_restore: 510000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 34\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     34 |          1016.12 |      510000 |  283.489 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-37-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: 184.57267226614783\n",
      "  episode_reward_min: -7735.964549449847\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 175\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.784\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3882080614566803\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.5299168825149536\n",
      "        policy_loss: 0.024248411878943443\n",
      "        total_loss: 1102.139892578125\n",
      "        vf_explained_var: 0.9181990623474121\n",
      "        vf_loss: 1102.095703125\n",
      "    load_time_ms: 2.536\n",
      "    num_steps_sampled: 525000\n",
      "    num_steps_trained: 524160\n",
      "    sample_time_ms: 28471.37\n",
      "    update_time_ms: 2.789\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.019047619047626\n",
      "    ram_util_percent: 23.98095238095238\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06656129650010612\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.6184578250844783\n",
      "    mean_inference_ms: 0.486344558614959\n",
      "    mean_raw_obs_processing_ms: 3.7415665349882845\n",
      "  time_since_restore: 907.4149901866913\n",
      "  time_this_iter_s: 25.10770559310913\n",
      "  time_total_s: 907.4149901866913\n",
      "  timers:\n",
      "    learn_throughput: 6392.918\n",
      "    learn_time_ms: 2346.346\n",
      "    load_throughput: 10737372.427\n",
      "    load_time_ms: 1.397\n",
      "    sample_throughput: 593.799\n",
      "    sample_time_ms: 25261.07\n",
      "    update_time_ms: 1.81\n",
      "  timestamp: 1665246096\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 495000\n",
      "  training_iteration: 33\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     33 |          907.415 | 495000 | -402.138 |              1979.82 |             -7307.77 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 510000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-22-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1979.8174690336782\n",
      "  episode_reward_mean: -557.4930000033139\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 170\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.117516040802002\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020257214084267616\n",
      "          model: {}\n",
      "          policy_loss: 0.00627477839589119\n",
      "          total_loss: 2544.312255859375\n",
      "          vf_explained_var: 3.5660898678457897e-09\n",
      "          vf_loss: 2544.304931640625\n",
      "    num_agent_steps_sampled: 510000\n",
      "    num_agent_steps_trained: 510000\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.602702702702704\n",
      "    ram_util_percent: 29.748648648648643\n",
      "  pid: 307\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06650740560987267\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.611232277089232\n",
      "    mean_inference_ms: 0.4860400496441904\n",
      "    mean_raw_obs_processing_ms: 3.7575136965862015\n",
      "  time_since_restore: 933.3561308383942\n",
      "  time_this_iter_s: 25.94114065170288\n",
      "  time_total_s: 933.3561308383942\n",
      "  timers:\n",
      "    learn_throughput: 6391.168\n",
      "    learn_time_ms: 2346.989\n",
      "    load_throughput: 9462685.939\n",
      "    load_time_ms: 1.585\n",
      "    sample_throughput: 592.414\n",
      "    sample_time_ms: 25320.134\n",
      "    update_time_ms: 1.918\n",
      "  timestamp: 1665246122\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 34\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     34 |          933.356 | 510000 | -557.493 |              1979.82 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 525000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-22-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -543.7378684784742\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 175\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02812499925494194\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.5641729831695557\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05120677128434181\n",
      "          model: {}\n",
      "          policy_loss: -0.004104150924831629\n",
      "          total_loss: 1299.706787109375\n",
      "          vf_explained_var: -1.3245476715439963e-08\n",
      "          vf_loss: 1299.7095947265625\n",
      "    num_agent_steps_sampled: 525000\n",
      "    num_agent_steps_trained: 525000\n",
      "    num_steps_sampled: 525000\n",
      "    num_steps_trained: 525000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.370270270270264\n",
      "    ram_util_percent: 29.75945945945945\n",
      "  pid: 307\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06646152121454012\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.604960639355324\n",
      "    mean_inference_ms: 0.485798424315493\n",
      "    mean_raw_obs_processing_ms: 3.767966165063234\n",
      "  time_since_restore: 959.4018466472626\n",
      "  time_this_iter_s: 26.045715808868408\n",
      "  time_total_s: 959.4018466472626\n",
      "  timers:\n",
      "    learn_throughput: 6484.219\n",
      "    learn_time_ms: 2313.309\n",
      "    load_throughput: 9638680.618\n",
      "    load_time_ms: 1.556\n",
      "    sample_throughput: 617.648\n",
      "    sample_time_ms: 24285.667\n",
      "    update_time_ms: 1.875\n",
      "  timestamp: 1665246148\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 525000\n",
      "  training_iteration: 35\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.749942927717289\n",
      "    mean_inference_ms: 0.41028416634534814\n",
      "    mean_processing_ms: 4.09440706999572\n",
      "  time_since_restore: 1045.2915048599243\n",
      "  time_this_iter_s: 29.171733379364014\n",
      "  time_total_s: 1045.2915048599243\n",
      "  timestamp: 1665272221\n",
      "  timesteps_since_restore: 525000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 525000\n",
      "  training_iteration: 35\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     35 |          1045.29 |      525000 |  184.573 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     35 |          959.402 | 525000 | -543.738 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 540000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-22-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -605.3536748391249\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 180\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.04218750074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.53215092420578\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015026749111711979\n",
      "          model: {}\n",
      "          policy_loss: 0.0006222102674655616\n",
      "          total_loss: 1738.21630859375\n",
      "          vf_explained_var: -5.603855601776786e-09\n",
      "          vf_loss: 1738.21533203125\n",
      "    num_agent_steps_sampled: 540000\n",
      "    num_agent_steps_trained: 540000\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.784210526315793\n",
      "    ram_util_percent: 29.768421052631574\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-37-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -24.9372359540199\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 180\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.249\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05624999850988388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.7038577795028687\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01243900042027235\n",
      "        policy_loss: 0.0003519220044836402\n",
      "        total_loss: 2154.837646484375\n",
      "        vf_explained_var: 0.9186643958091736\n",
      "        vf_loss: 2154.836669921875\n",
      "    load_time_ms: 2.52\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 539136\n",
      "    sample_time_ms: 28399.602\n",
      "    update_time_ms: 2.759\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.21463414634146\n",
      "    ram_util_percent: 23.965853658536584\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06642440372354008\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.599383544492815\n",
      "    mean_inference_ms: 0.4856109283408002\n",
      "    mean_raw_obs_processing_ms: 3.7789680471356437\n",
      "  time_since_restore: 985.429559469223\n",
      "  time_this_iter_s: 26.02771282196045\n",
      "  time_total_s: 985.429559469223\n",
      "  timers:\n",
      "    learn_throughput: 6655.173\n",
      "    learn_time_ms: 2253.886\n",
      "    load_throughput: 9572102.789\n",
      "    load_time_ms: 1.567\n",
      "    sample_throughput: 616.214\n",
      "    sample_time_ms: 24342.211\n",
      "    update_time_ms: 1.698\n",
      "  timestamp: 1665246174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 36\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     36 |           985.43 | 540000 | -605.354 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 555000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-23-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -701.7527792559529\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 185\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.04218750074505806\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.40416282415390015\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.07278131693601608\n",
      "          model: {}\n",
      "          policy_loss: 0.00245867483317852\n",
      "          total_loss: 1828.0992431640625\n",
      "          vf_explained_var: -5.603855601776786e-09\n",
      "          vf_loss: 1828.0936279296875\n",
      "    num_agent_steps_sampled: 555000\n",
      "    num_agent_steps_trained: 555000\n",
      "    num_steps_sampled: 555000\n",
      "    num_steps_trained: 555000\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.73714285714286\n",
      "    ram_util_percent: 29.811428571428568\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.744458660116098\n",
      "    mean_inference_ms: 0.41027434663641793\n",
      "    mean_processing_ms: 4.097169478656246\n",
      "  time_since_restore: 1074.4754660129547\n",
      "  time_this_iter_s: 29.183961153030396\n",
      "  time_total_s: 1074.4754660129547\n",
      "  timestamp: 1665272250\n",
      "  timesteps_since_restore: 540000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 36\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     36 |          1074.48 |      540000 | -24.9372 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-37-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -262.99919202185606\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 185\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.651\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.05624999850988388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.589788556098938\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04220208153128624\n",
      "        policy_loss: 0.0011978395050391555\n",
      "        total_loss: 2085.097900390625\n",
      "        vf_explained_var: 0.9284284710884094\n",
      "        vf_loss: 2085.094482421875\n",
      "    load_time_ms: 2.602\n",
      "    num_steps_sampled: 555000\n",
      "    num_steps_trained: 554112\n",
      "    sample_time_ms: 28305.571\n",
      "    update_time_ms: 2.781\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.273809523809526\n",
      "    ram_util_percent: 24.004761904761907\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06639087675050287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5941168385269675\n",
      "    mean_inference_ms: 0.48544399796621723\n",
      "    mean_raw_obs_processing_ms: 3.7906145871787045\n",
      "  time_since_restore: 1010.2706711292267\n",
      "  time_this_iter_s: 24.841111660003662\n",
      "  time_total_s: 1010.2706711292267\n",
      "  timers:\n",
      "    learn_throughput: 6903.362\n",
      "    learn_time_ms: 2172.854\n",
      "    load_throughput: 9899074.832\n",
      "    load_time_ms: 1.515\n",
      "    sample_throughput: 632.615\n",
      "    sample_time_ms: 23711.087\n",
      "    update_time_ms: 1.687\n",
      "  timestamp: 1665246199\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 555000\n",
      "  training_iteration: 37\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     37 |          1010.27 | 555000 | -701.753 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 570000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-23-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -779.2775203911734\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 190\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.06328125298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.7493948936462402\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.047352008521556854\n",
      "          model: {}\n",
      "          policy_loss: 0.0035044958349317312\n",
      "          total_loss: 1885.765380859375\n",
      "          vf_explained_var: -1.4773800849354757e-08\n",
      "          vf_loss: 1885.7586669921875\n",
      "    num_agent_steps_sampled: 570000\n",
      "    num_agent_steps_trained: 570000\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.74666666666667\n",
      "    ram_util_percent: 29.78666666666668\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.73903316235573\n",
      "    mean_inference_ms: 0.41025544542448394\n",
      "    mean_processing_ms: 4.099720579181155\n",
      "  time_since_restore: 1103.4725904464722\n",
      "  time_this_iter_s: 28.997124433517456\n",
      "  time_total_s: 1103.4725904464722\n",
      "  timestamp: 1665272279\n",
      "  timesteps_since_restore: 555000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 555000\n",
      "  training_iteration: 37\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     37 |          1103.47 |      555000 | -262.999 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-38-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2161.665529645647\n",
      "  episode_reward_mean: -531.246734687582\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 190\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.731\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08437500149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.2909860610961914\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0070008207112550735\n",
      "        policy_loss: 0.002046198584139347\n",
      "        total_loss: 2416.023193359375\n",
      "        vf_explained_var: 0.9064735174179077\n",
      "        vf_loss: 2416.02099609375\n",
      "    load_time_ms: 2.55\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 569088\n",
      "    sample_time_ms: 28313.378\n",
      "    update_time_ms: 2.802\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.22142857142857\n",
      "    ram_util_percent: 24.052380952380954\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06635896291630246\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.589065835096905\n",
      "    mean_inference_ms: 0.4852868625871909\n",
      "    mean_raw_obs_processing_ms: 3.800212954517346\n",
      "  time_since_restore: 1042.0340704917908\n",
      "  time_this_iter_s: 31.763399362564087\n",
      "  time_total_s: 1042.0340704917908\n",
      "  timers:\n",
      "    learn_throughput: 6886.295\n",
      "    learn_time_ms: 2178.24\n",
      "    load_throughput: 9431053.815\n",
      "    load_time_ms: 1.59\n",
      "    sample_throughput: 615.867\n",
      "    sample_time_ms: 24355.922\n",
      "    update_time_ms: 1.781\n",
      "  timestamp: 1665246231\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 38\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     38 |          1042.03 | 570000 | -779.278 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 4.733813651698288\n",
      "    mean_inference_ms: 0.4102478955210527\n",
      "    mean_processing_ms: 4.102314095824976\n",
      "  time_since_restore: 1132.696308374405\n",
      "  time_this_iter_s: 29.22371792793274\n",
      "  time_total_s: 1132.696308374405\n",
      "  timestamp: 1665272308\n",
      "  timesteps_since_restore: 570000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 38\n",
      "  trial_id: a95f16f0\n",
      "  \n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 585000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-24-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -896.626217554708\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 195\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09492187201976776\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2045072317123413\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.034119922667741776\n",
      "          model: {}\n",
      "          policy_loss: 0.006482519209384918\n",
      "          total_loss: 2254.073486328125\n",
      "          vf_explained_var: -1.528324244937096e-09\n",
      "          vf_loss: 2254.0634765625\n",
      "    num_agent_steps_sampled: 585000\n",
      "    num_agent_steps_trained: 585000\n",
      "    num_steps_sampled: 585000\n",
      "    num_steps_trained: 585000\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.762162162162163\n",
      "    ram_util_percent: 29.84594594594595\n",
      "  pid: 307\n",
=======
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     38 |           1132.7 |      570000 | -531.247 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-38-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1970.6021690913599\n",
      "  episode_reward_mean: -664.2970311070877\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 195\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.092\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04218750074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28920629620552063\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05168590322136879\n",
      "        policy_loss: -0.0056699044071137905\n",
      "        total_loss: 1277.14599609375\n",
      "        vf_explained_var: 0.9436624646186829\n",
      "        vf_loss: 1277.1495361328125\n",
      "    load_time_ms: 2.546\n",
      "    num_steps_sampled: 585000\n",
      "    num_steps_trained: 584064\n",
      "    sample_time_ms: 28274.118\n",
      "    update_time_ms: 2.822\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00487804878049\n",
      "    ram_util_percent: 24.002439024390245\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06633237912809652\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5843268573881266\n",
      "    mean_inference_ms: 0.4851694164088758\n",
      "    mean_raw_obs_processing_ms: 3.809320430321831\n",
      "  time_since_restore: 1067.3953568935394\n",
      "  time_this_iter_s: 25.361286401748657\n",
      "  time_total_s: 1067.3953568935394\n",
      "  timers:\n",
      "    learn_throughput: 6838.916\n",
      "    learn_time_ms: 2193.33\n",
      "    load_throughput: 9608356.878\n",
      "    load_time_ms: 1.561\n",
      "    sample_throughput: 628.364\n",
      "    sample_time_ms: 23871.509\n",
      "    update_time_ms: 1.521\n",
      "  timestamp: 1665246257\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 585000\n",
      "  training_iteration: 39\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     39 |           1067.4 | 585000 | -896.626 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 600000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-24-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -969.2625074352809\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 200\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09492187201976776\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.15661288797855377\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0233453381806612\n",
      "          model: {}\n",
      "          policy_loss: 0.0008890045573934913\n",
      "          total_loss: 1810.4990234375\n",
      "          vf_explained_var: -2.0377657339309962e-09\n",
      "          vf_loss: 1810.4959716796875\n",
      "    num_agent_steps_sampled: 600000\n",
      "    num_agent_steps_trained: 600000\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.650000000000002\n",
      "    ram_util_percent: 29.84722222222222\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.728657800864154\n",
      "    mean_inference_ms: 0.4102414802694349\n",
      "    mean_processing_ms: 4.104983202446838\n",
      "  time_since_restore: 1161.6641063690186\n",
      "  time_this_iter_s: 28.967797994613647\n",
      "  time_total_s: 1161.6641063690186\n",
      "  timestamp: 1665272337\n",
      "  timesteps_since_restore: 585000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 585000\n",
      "  training_iteration: 39\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     39 |          1161.66 |      585000 | -664.297 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-39-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1970.6021690913599\n",
      "  episode_reward_mean: -868.3921145548921\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 200\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.585\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06328125298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.7276870012283325\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0276792012155056\n",
      "        policy_loss: 0.00042463827412575483\n",
      "        total_loss: 2005.9749755859375\n",
      "        vf_explained_var: 0.940935492515564\n",
      "        vf_loss: 2005.97314453125\n",
      "    load_time_ms: 2.522\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 599040\n",
      "    sample_time_ms: 28219.328\n",
      "    update_time_ms: 2.825\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.548780487804876\n",
      "    ram_util_percent: 24.01707317073171\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06630680876361153\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5798966904635443\n",
      "    mean_inference_ms: 0.4850609309378369\n",
      "    mean_raw_obs_processing_ms: 3.8189187647973792\n",
      "  time_since_restore: 1092.5483605861664\n",
      "  time_this_iter_s: 25.153003692626953\n",
      "  time_total_s: 1092.5483605861664\n",
      "  timers:\n",
      "    learn_throughput: 6817.889\n",
      "    learn_time_ms: 2200.094\n",
      "    load_throughput: 9354212.138\n",
      "    load_time_ms: 1.604\n",
      "    sample_throughput: 627.619\n",
      "    sample_time_ms: 23899.853\n",
      "    update_time_ms: 1.388\n",
      "  timestamp: 1665246282\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 40\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     40 |          1092.55 | 600000 | -969.263 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
=======
      "    mean_env_wait_ms: 4.72387701304055\n",
      "    mean_inference_ms: 0.4102381731083131\n",
      "    mean_processing_ms: 4.107709827883919\n",
      "  time_since_restore: 1190.4584584236145\n",
      "  time_this_iter_s: 28.794352054595947\n",
      "  time_total_s: 1190.4584584236145\n",
      "  timestamp: 1665272366\n",
      "  timesteps_since_restore: 600000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 40\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     40 |          1190.46 |      600000 | -868.392 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 615000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-25-12\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -945.2783820944851\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 205\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09492187201976776\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.47183477878570557\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.044227395206689835\n",
      "          model: {}\n",
      "          policy_loss: 0.004643541295081377\n",
      "          total_loss: 1941.15576171875\n",
      "          vf_explained_var: -7.641621557752387e-09\n",
      "          vf_loss: 1941.1466064453125\n",
      "    num_agent_steps_sampled: 615000\n",
      "    num_agent_steps_trained: 615000\n",
      "    num_steps_sampled: 615000\n",
      "    num_steps_trained: 615000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.467441860465115\n",
      "    ram_util_percent: 29.888372093023257\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-39-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1004.9764909437494\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 205\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.116\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06328125298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21448606252670288\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01563834957778454\n",
      "        policy_loss: 0.006395771633833647\n",
      "        total_loss: 1339.6922607421875\n",
      "        vf_explained_var: 0.9593550562858582\n",
      "        vf_loss: 1339.684814453125\n",
      "    load_time_ms: 2.585\n",
      "    num_steps_sampled: 615000\n",
      "    num_steps_trained: 614016\n",
      "    sample_time_ms: 28241.34\n",
      "    update_time_ms: 2.876\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.27619047619048\n",
      "    ram_util_percent: 24.02857142857143\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06628072136658196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.575809865944525\n",
      "    mean_inference_ms: 0.4849565651489528\n",
      "    mean_raw_obs_processing_ms: 3.826820387211896\n",
      "  time_since_restore: 1122.8908605575562\n",
      "  time_this_iter_s: 30.34249997138977\n",
      "  time_total_s: 1122.8908605575562\n",
      "  timers:\n",
      "    learn_throughput: 6846.355\n",
      "    learn_time_ms: 2190.947\n",
      "    load_throughput: 8331950.735\n",
      "    load_time_ms: 1.8\n",
      "    sample_throughput: 614.372\n",
      "    sample_time_ms: 24415.16\n",
      "    update_time_ms: 1.638\n",
      "  timestamp: 1665246312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 615000\n",
      "  training_iteration: 41\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     41 |          1122.89 | 615000 | -945.278 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 630000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-25-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1000.8671805019396\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 210\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.14238281548023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.3165137469768524\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008419708348810673\n",
      "          model: {}\n",
      "          policy_loss: 0.0009574752184562385\n",
      "          total_loss: 2037.0953369140625\n",
      "          vf_explained_var: -1.4773800849354757e-08\n",
      "          vf_loss: 2037.09326171875\n",
      "    num_agent_steps_sampled: 630000\n",
      "    num_agent_steps_trained: 630000\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.786486486486485\n",
      "    ram_util_percent: 29.900000000000006\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.7193610217572175\n",
      "    mean_inference_ms: 0.41024750791249764\n",
      "    mean_processing_ms: 4.110396956887314\n",
      "  time_since_restore: 1219.6570491790771\n",
      "  time_this_iter_s: 29.198590755462646\n",
      "  time_total_s: 1219.6570491790771\n",
      "  timestamp: 1665272395\n",
      "  timesteps_since_restore: 615000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 615000\n",
      "  training_iteration: 41\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     41 |          1219.66 |      615000 | -1004.98 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-40-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1129.4033754711165\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 210\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.529\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06328125298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.06105500087141991\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020453613251447678\n",
      "        policy_loss: 0.006152871530503035\n",
      "        total_loss: 1456.6781005859375\n",
      "        vf_explained_var: 0.9526769518852234\n",
      "        vf_loss: 1456.6705322265625\n",
      "    load_time_ms: 2.666\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 628992\n",
      "    sample_time_ms: 28246.754\n",
      "    update_time_ms: 2.828\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.13333333333334\n",
      "    ram_util_percent: 24.035714285714285\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06625777890068817\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.572074583163265\n",
      "    mean_inference_ms: 0.48486578355578275\n",
      "    mean_raw_obs_processing_ms: 3.831415444542888\n",
      "  time_since_restore: 1148.760927438736\n",
      "  time_this_iter_s: 25.87006688117981\n",
      "  time_total_s: 1148.760927438736\n",
      "  timers:\n",
      "    learn_throughput: 6700.104\n",
      "    learn_time_ms: 2238.771\n",
      "    load_throughput: 8391964.786\n",
      "    load_time_ms: 1.787\n",
      "    sample_throughput: 614.875\n",
      "    sample_time_ms: 24395.19\n",
      "    update_time_ms: 1.909\n",
      "  timestamp: 1665246338\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 42\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.714972242477609\n",
      "    mean_inference_ms: 0.4102667703850536\n",
      "    mean_processing_ms: 4.112759638254842\n",
      "  time_since_restore: 1249.1926481723785\n",
      "  time_this_iter_s: 29.53559899330139\n",
      "  time_total_s: 1249.1926481723785\n",
      "  timestamp: 1665272425\n",
      "  timesteps_since_restore: 630000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 42\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     42 |          1249.19 |      630000 |  -1129.4 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     42 |          1148.76 | 630000 | -1000.87 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 645000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-26-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1153.7186941679718\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 215\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.07119140774011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.662552833557129\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.051863737404346466\n",
      "          model: {}\n",
      "          policy_loss: -0.0005233330884948373\n",
      "          total_loss: 2574.174560546875\n",
      "          vf_explained_var: 9.16994569166718e-09\n",
      "          vf_loss: 2574.171142578125\n",
      "    num_agent_steps_sampled: 645000\n",
      "    num_agent_steps_trained: 645000\n",
      "    num_steps_sampled: 645000\n",
      "    num_steps_trained: 645000\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.41666666666667\n",
      "    ram_util_percent: 29.94166666666667\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-40-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1272.8628703661407\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 215\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.488\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06328125298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4230090379714966\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.06393381953239441\n",
      "        policy_loss: 0.016252640634775162\n",
      "        total_loss: 1776.7672119140625\n",
      "        vf_explained_var: 0.9571880102157593\n",
      "        vf_loss: 1776.746826171875\n",
      "    load_time_ms: 2.495\n",
      "    num_steps_sampled: 645000\n",
      "    num_steps_trained: 643968\n",
      "    sample_time_ms: 28222.993\n",
      "    update_time_ms: 2.865\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.535714285714285\n",
      "    ram_util_percent: 24.021428571428572\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06623563757877324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.568524535905829\n",
      "    mean_inference_ms: 0.48478461188880645\n",
      "    mean_raw_obs_processing_ms: 3.8327153751348355\n",
      "  time_since_restore: 1173.8651118278503\n",
      "  time_this_iter_s: 25.10418438911438\n",
      "  time_total_s: 1173.8651118278503\n",
      "  timers:\n",
      "    learn_throughput: 6664.035\n",
      "    learn_time_ms: 2250.888\n",
      "    load_throughput: 8352081.563\n",
      "    load_time_ms: 1.796\n",
      "    sample_throughput: 615.181\n",
      "    sample_time_ms: 24383.074\n",
      "    update_time_ms: 1.837\n",
      "  timestamp: 1665246363\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 645000\n",
      "  training_iteration: 43\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     43 |          1173.87 | 645000 | -1153.72 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 660000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-26-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1241.4017124174989\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 220\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10678710788488388\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.2582852840423584\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02585858479142189\n",
      "          model: {}\n",
      "          policy_loss: 0.0017101162811741233\n",
      "          total_loss: 2049.490478515625\n",
      "          vf_explained_var: 6.622738357719982e-09\n",
      "          vf_loss: 2049.485595703125\n",
      "    num_agent_steps_sampled: 660000\n",
      "    num_agent_steps_trained: 660000\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.35833333333333\n",
      "    ram_util_percent: 29.950000000000003\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.710710896508282\n",
      "    mean_inference_ms: 0.41029234140299325\n",
      "    mean_processing_ms: 4.1149949266474035\n",
      "  time_since_restore: 1278.4761509895325\n",
      "  time_this_iter_s: 29.28350281715393\n",
      "  time_total_s: 1278.4761509895325\n",
      "  timestamp: 1665272454\n",
      "  timesteps_since_restore: 645000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 645000\n",
      "  training_iteration: 43\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     43 |          1278.48 |      645000 | -1272.86 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-41-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1463.1007726123287\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 220\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.229\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.2656164169311523\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013735225424170494\n",
      "        policy_loss: 0.0019666561856865883\n",
      "        total_loss: 2097.0234375\n",
      "        vf_explained_var: 0.958125114440918\n",
      "        vf_loss: 2097.020263671875\n",
      "    load_time_ms: 2.513\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 658944\n",
      "    sample_time_ms: 27650.824\n",
      "    update_time_ms: 2.799\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34878048780487\n",
      "    ram_util_percent: 24.034146341463416\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06621416851060528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.565008960483427\n",
      "    mean_inference_ms: 0.4847093579367368\n",
      "    mean_raw_obs_processing_ms: 3.834715966231754\n",
      "  time_since_restore: 1198.8811838626862\n",
      "  time_this_iter_s: 25.016072034835815\n",
      "  time_total_s: 1198.8811838626862\n",
      "  timers:\n",
      "    learn_throughput: 6604.498\n",
      "    learn_time_ms: 2271.179\n",
      "    load_throughput: 9106042.755\n",
      "    load_time_ms: 1.647\n",
      "    sample_throughput: 618.029\n",
      "    sample_time_ms: 24270.697\n",
      "    update_time_ms: 1.76\n",
      "  timestamp: 1665246388\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 44\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     44 |          1198.88 | 660000 |  -1241.4 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 675000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-26-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1310.4335233457134\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 225\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10678710788488388\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1086300611495972\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.07039123773574829\n",
      "          model: {}\n",
      "          policy_loss: 0.009093414060771465\n",
      "          total_loss: 2466.316162109375\n",
      "          vf_explained_var: -5.094414223805188e-09\n",
      "          vf_loss: 2466.299560546875\n",
      "    num_agent_steps_sampled: 675000\n",
      "    num_agent_steps_trained: 675000\n",
      "    num_steps_sampled: 675000\n",
      "    num_steps_trained: 675000\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.245714285714282\n",
      "    ram_util_percent: 29.92\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.706523619239831\n",
      "    mean_inference_ms: 0.4103308712801107\n",
      "    mean_processing_ms: 4.117234656267319\n",
      "  time_since_restore: 1307.569804430008\n",
      "  time_this_iter_s: 29.093653440475464\n",
      "  time_total_s: 1307.569804430008\n",
      "  timestamp: 1665272483\n",
      "  timesteps_since_restore: 660000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 44\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     44 |          1307.57 |      660000 |  -1463.1 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-41-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1527.0135019540965\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 225\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.57\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36879318952560425\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03277485445141792\n",
      "        policy_loss: 0.005570645909756422\n",
      "        total_loss: 2095.740966796875\n",
      "        vf_explained_var: 0.9553706049919128\n",
      "        vf_loss: 2095.732666015625\n",
      "    load_time_ms: 2.494\n",
      "    num_steps_sampled: 675000\n",
      "    num_steps_trained: 673920\n",
      "    sample_time_ms: 27625.66\n",
      "    update_time_ms: 2.764\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.88333333333334\n",
      "    ram_util_percent: 24.040476190476188\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06619404751450812\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.561629539334993\n",
      "    mean_inference_ms: 0.48463761873763966\n",
      "    mean_raw_obs_processing_ms: 3.82975151778491\n",
      "  time_since_restore: 1223.4750275611877\n",
      "  time_this_iter_s: 24.593843698501587\n",
      "  time_total_s: 1223.4750275611877\n",
      "  timers:\n",
      "    learn_throughput: 6629.765\n",
      "    learn_time_ms: 2262.524\n",
      "    load_throughput: 9051152.352\n",
      "    load_time_ms: 1.657\n",
      "    sample_throughput: 621.531\n",
      "    sample_time_ms: 24133.943\n",
      "    update_time_ms: 1.763\n",
      "  timestamp: 1665246413\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 675000\n",
      "  training_iteration: 45\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     45 |          1223.48 | 675000 | -1310.43 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 690000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-27-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1436.2369824765974\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 230\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.16018065810203552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.743571400642395\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028430551290512085\n",
      "          model: {}\n",
      "          policy_loss: 0.013742971234023571\n",
      "          total_loss: 2531.99951171875\n",
      "          vf_explained_var: -7.641621557752387e-09\n",
      "          vf_loss: 2531.981201171875\n",
      "    num_agent_steps_sampled: 690000\n",
      "    num_agent_steps_trained: 690000\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.10857142857143\n",
      "    ram_util_percent: 29.962857142857143\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.702537139764517\n",
      "    mean_inference_ms: 0.4103766116046444\n",
      "    mean_processing_ms: 4.119416715702203\n",
      "  time_since_restore: 1336.502646446228\n",
      "  time_this_iter_s: 28.932842016220093\n",
      "  time_total_s: 1336.502646446228\n",
      "  timestamp: 1665272512\n",
      "  timesteps_since_restore: 675000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 675000\n",
      "  training_iteration: 45\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     45 |           1336.5 |      675000 | -1527.01 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-42-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1647.3209667320566\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 230\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.347\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7252047657966614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010624871589243412\n",
      "        policy_loss: 0.003354713786393404\n",
      "        total_loss: 2210.7548828125\n",
      "        vf_explained_var: 0.9520848393440247\n",
      "        vf_loss: 2210.75048828125\n",
      "    load_time_ms: 2.53\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 688896\n",
      "    sample_time_ms: 27663.341\n",
      "    update_time_ms: 2.743\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.61428571428572\n",
      "    ram_util_percent: 24.07857142857143\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06617384429370106\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.558231155622902\n",
      "    mean_inference_ms: 0.4845686712104642\n",
      "    mean_raw_obs_processing_ms: 3.824989118370532\n",
      "  time_since_restore: 1248.1178138256073\n",
      "  time_this_iter_s: 24.642786264419556\n",
      "  time_total_s: 1248.1178138256073\n",
      "  timers:\n",
      "    learn_throughput: 6563.096\n",
      "    learn_time_ms: 2285.507\n",
      "    load_throughput: 8293618.424\n",
      "    load_time_ms: 1.809\n",
      "    sample_throughput: 625.729\n",
      "    sample_time_ms: 23972.053\n",
      "    update_time_ms: 1.755\n",
      "  timestamp: 1665246438\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 46\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     46 |          1248.12 | 690000 | -1436.24 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 705000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-27-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1439.9156290296457\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 235\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.16018065810203552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.19514359533786774\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01812095381319523\n",
      "          model: {}\n",
      "          policy_loss: 0.008307283744215965\n",
      "          total_loss: 1888.0706787109375\n",
      "          vf_explained_var: 2.0377657339309962e-09\n",
      "          vf_loss: 1888.0595703125\n",
      "    num_agent_steps_sampled: 705000\n",
      "    num_agent_steps_trained: 705000\n",
      "    num_steps_sampled: 705000\n",
      "    num_steps_trained: 705000\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.737142857142857\n",
      "    ram_util_percent: 29.954285714285717\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.6984352102189115\n",
      "    mean_inference_ms: 0.41042154607214454\n",
      "    mean_processing_ms: 4.1216222833891\n",
      "  time_since_restore: 1366.0715248584747\n",
      "  time_this_iter_s: 29.568878412246704\n",
      "  time_total_s: 1366.0715248584747\n",
      "  timestamp: 1665272542\n",
      "  timesteps_since_restore: 690000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 46\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     46 |          1366.07 |      690000 | -1647.32 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-42-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1755.468769158477\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 235\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.413\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.22062741219997406\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02767261676490307\n",
      "        policy_loss: 0.010604454204440117\n",
      "        total_loss: 1818.7083740234375\n",
      "        vf_explained_var: 0.958972692489624\n",
      "        vf_loss: 1818.6954345703125\n",
      "    load_time_ms: 2.511\n",
      "    num_steps_sampled: 705000\n",
      "    num_steps_trained: 703872\n",
      "    sample_time_ms: 27661.118\n",
      "    update_time_ms: 2.748\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.2609756097561\n",
      "    ram_util_percent: 24.073170731707318\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06615328970339411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.554930249062177\n",
      "    mean_inference_ms: 0.48449358519737046\n",
      "    mean_raw_obs_processing_ms: 3.817514018496291\n",
      "  time_since_restore: 1272.8203501701355\n",
      "  time_this_iter_s: 24.7025363445282\n",
      "  time_total_s: 1272.8203501701355\n",
      "  timers:\n",
      "    learn_throughput: 6569.587\n",
      "    learn_time_ms: 2283.249\n",
      "    load_throughput: 8951858.966\n",
      "    load_time_ms: 1.676\n",
      "    sample_throughput: 626.03\n",
      "    sample_time_ms: 23960.508\n",
      "    update_time_ms: 1.823\n",
      "  timestamp: 1665246462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 705000\n",
      "  training_iteration: 47\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     47 |          1272.82 | 705000 | -1439.92 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 720000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-28-07\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1316.4807107592815\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 240\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.16018065810203552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.6789898872375488\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.044577572494745255\n",
      "          model: {}\n",
      "          policy_loss: 0.002835844876244664\n",
      "          total_loss: 1459.60693359375\n",
      "          vf_explained_var: -3.5660898678457897e-09\n",
      "          vf_loss: 1459.5970458984375\n",
      "    num_agent_steps_sampled: 720000\n",
      "    num_agent_steps_trained: 720000\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.769444444444446\n",
      "    ram_util_percent: 29.958333333333332\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.694389782131067\n",
      "    mean_inference_ms: 0.41047489444758645\n",
      "    mean_processing_ms: 4.123517216971516\n",
      "  time_since_restore: 1395.066828250885\n",
      "  time_this_iter_s: 28.99530339241028\n",
      "  time_total_s: 1395.066828250885\n",
      "  timestamp: 1665272571\n",
      "  timesteps_since_restore: 705000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 705000\n",
      "  training_iteration: 47\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     47 |          1395.07 |      705000 | -1755.47 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1777.0561216649862\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 240\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.247\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5335463285446167\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011819726787507534\n",
      "        policy_loss: -0.0013670340413227677\n",
      "        total_loss: 1639.487548828125\n",
      "        vf_explained_var: 0.9620298743247986\n",
      "        vf_loss: 1639.488037109375\n",
      "    load_time_ms: 2.39\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 718848\n",
      "    sample_time_ms: 27633.416\n",
      "    update_time_ms: 2.74\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.458536585365856\n",
      "    ram_util_percent: 24.212195121951222\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06613372050193286\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5518366453542285\n",
      "    mean_inference_ms: 0.48442155083612415\n",
      "    mean_raw_obs_processing_ms: 3.8103118899532906\n",
      "  time_since_restore: 1297.5121099948883\n",
      "  time_this_iter_s: 24.691759824752808\n",
      "  time_total_s: 1297.5121099948883\n",
      "  timers:\n",
      "    learn_throughput: 6571.472\n",
      "    learn_time_ms: 2282.594\n",
      "    load_throughput: 9287652.79\n",
      "    load_time_ms: 1.615\n",
      "    sample_throughput: 645.018\n",
      "    sample_time_ms: 23255.178\n",
      "    update_time_ms: 1.68\n",
      "  timestamp: 1665246487\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 48\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     48 |          1297.51 | 720000 | -1316.48 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 735000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-28-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1314.2569757268682\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 245\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.24027100205421448\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.6086551547050476\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02731219492852688\n",
      "          model: {}\n",
      "          policy_loss: 0.00933505967259407\n",
      "          total_loss: 1973.837890625\n",
      "          vf_explained_var: -5.094414223805188e-09\n",
      "          vf_loss: 1973.8221435546875\n",
      "    num_agent_steps_sampled: 735000\n",
      "    num_agent_steps_trained: 735000\n",
      "    num_steps_sampled: 735000\n",
      "    num_steps_trained: 735000\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.85135135135135\n",
      "    ram_util_percent: 29.945945945945947\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.690595602880974\n",
      "    mean_inference_ms: 0.41053666536609\n",
      "    mean_processing_ms: 4.125229689297864\n",
      "  time_since_restore: 1424.000063419342\n",
      "  time_this_iter_s: 28.93323516845703\n",
      "  time_total_s: 1424.000063419342\n",
      "  timestamp: 1665272600\n",
      "  timesteps_since_restore: 720000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 48\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     48 |             1424 |      720000 | -1777.06 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-43-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1982.9986866756678\n",
      "  episode_reward_mean: -1794.8422256410706\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 245\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.276\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1074957847595215\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.028395989909768105\n",
      "        policy_loss: 0.00541132315993309\n",
      "        total_loss: 1651.837158203125\n",
      "        vf_explained_var: 0.963881254196167\n",
      "        vf_loss: 1651.8291015625\n",
      "    load_time_ms: 2.397\n",
      "    num_steps_sampled: 735000\n",
      "    num_steps_trained: 733824\n",
      "    sample_time_ms: 27641.996\n",
      "    update_time_ms: 2.82\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.02142857142857\n",
      "    ram_util_percent: 24.121428571428574\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06611391657905244\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.548937690374755\n",
      "    mean_inference_ms: 0.4843460373180516\n",
      "    mean_raw_obs_processing_ms: 3.801273076735894\n",
      "  time_since_restore: 1323.247163772583\n",
      "  time_this_iter_s: 25.735053777694702\n",
      "  time_total_s: 1323.247163772583\n",
      "  timers:\n",
      "    learn_throughput: 6703.097\n",
      "    learn_time_ms: 2237.772\n",
      "    load_throughput: 9299733.932\n",
      "    load_time_ms: 1.613\n",
      "    sample_throughput: 642.754\n",
      "    sample_time_ms: 23337.094\n",
      "    update_time_ms: 1.667\n",
      "  timestamp: 1665246513\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 735000\n",
      "  training_iteration: 49\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.3/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     49 |          1323.25 | 735000 | -1314.26 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 750000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-28-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1301.016964118617\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 250\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.24027100205421448\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.09809242188930511\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019569048658013344\n",
      "          model: {}\n",
      "          policy_loss: 0.00019594721379689872\n",
      "          total_loss: 2082.056396484375\n",
      "          vf_explained_var: 2.547207111902594e-09\n",
      "          vf_loss: 2082.05126953125\n",
      "    num_agent_steps_sampled: 750000\n",
      "    num_agent_steps_trained: 750000\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.499999999999993\n",
      "    ram_util_percent: 29.958333333333332\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.686996188303593\n",
      "    mean_inference_ms: 0.4106096764153091\n",
      "    mean_processing_ms: 4.126796844229101\n",
      "  time_since_restore: 1453.0551524162292\n",
      "  time_this_iter_s: 29.055088996887207\n",
      "  time_total_s: 1453.0551524162292\n",
      "  timestamp: 1665272629\n",
      "  timesteps_since_restore: 735000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 735000\n",
      "  training_iteration: 49\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     49 |          1453.06 |      735000 | -1794.84 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-44-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1818.2600549224908\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 250\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.041\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.49374818801879883\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023193364962935448\n",
      "        policy_loss: 0.0033543400932103395\n",
      "        total_loss: 1650.416259765625\n",
      "        vf_explained_var: 0.9662081599235535\n",
      "        vf_loss: 1650.4105224609375\n",
      "    load_time_ms: 2.41\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 748800\n",
      "    sample_time_ms: 27759.908\n",
      "    update_time_ms: 2.863\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.52093023255814\n",
      "    ram_util_percent: 24.130232558139532\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0660954323033027\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5463318398354766\n",
      "    mean_inference_ms: 0.4842770159704235\n",
      "    mean_raw_obs_processing_ms: 3.792733657258995\n",
      "  time_since_restore: 1348.822538614273\n",
      "  time_this_iter_s: 25.575374841690063\n",
      "  time_total_s: 1348.822538614273\n",
      "  timers:\n",
      "    learn_throughput: 6615.119\n",
      "    learn_time_ms: 2267.533\n",
      "    load_throughput: 8503921.171\n",
      "    load_time_ms: 1.764\n",
      "    sample_throughput: 642.422\n",
      "    sample_time_ms: 23349.131\n",
      "    update_time_ms: 1.948\n",
      "  timestamp: 1665246539\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 50\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     50 |          1348.82 | 750000 | -1301.02 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 765000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1312.3080264658918\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 255\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.24027100205421448\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.0023126222658902407\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0073457094840705395\n",
      "          model: {}\n",
      "          policy_loss: 0.0011287028901278973\n",
      "          total_loss: 1904.5986328125\n",
      "          vf_explained_var: -1.7830450005362763e-08\n",
      "          vf_loss: 1904.595947265625\n",
      "    num_agent_steps_sampled: 765000\n",
      "    num_agent_steps_trained: 765000\n",
      "    num_steps_sampled: 765000\n",
      "    num_steps_trained: 765000\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.367441860465114\n",
      "    ram_util_percent: 29.92093023255814\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.683544131404654\n",
      "    mean_inference_ms: 0.41068419974269177\n",
      "    mean_processing_ms: 4.128556256370608\n",
      "  time_since_restore: 1483.026792049408\n",
      "  time_this_iter_s: 29.97163963317871\n",
      "  time_total_s: 1483.026792049408\n",
      "  timestamp: 1665272659\n",
      "  timesteps_since_restore: 750000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 50\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     50 |          1483.03 |      750000 | -1818.26 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-44-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1832.2331338412428\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 255\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.523\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5307113528251648\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014276320114731789\n",
      "        policy_loss: 0.0025089902337640524\n",
      "        total_loss: 1374.2769775390625\n",
      "        vf_explained_var: 0.9777113795280457\n",
      "        vf_loss: 1374.27294921875\n",
      "    load_time_ms: 2.423\n",
      "    num_steps_sampled: 765000\n",
      "    num_steps_trained: 763776\n",
      "    sample_time_ms: 27753.817\n",
      "    update_time_ms: 2.817\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.59512195121951\n",
      "    ram_util_percent: 24.112195121951224\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06607699462672952\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.54375210461898\n",
      "    mean_inference_ms: 0.48420490015633155\n",
      "    mean_raw_obs_processing_ms: 3.7866926214941445\n",
      "  time_since_restore: 1378.8991639614105\n",
      "  time_this_iter_s: 30.07662534713745\n",
      "  time_total_s: 1378.8991639614105\n",
      "  timers:\n",
      "    learn_throughput: 6633.378\n",
      "    learn_time_ms: 2261.291\n",
      "    load_throughput: 9577931.706\n",
      "    load_time_ms: 1.566\n",
      "    sample_throughput: 642.972\n",
      "    sample_time_ms: 23329.166\n",
      "    update_time_ms: 1.876\n",
      "  timestamp: 1665246569\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 765000\n",
      "  training_iteration: 51\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     51 |           1378.9 | 765000 | -1312.31 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 780000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-29-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1366.5867708731218\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 260\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.12013550102710724\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1953285932540894\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.09249120950698853\n",
      "          model: {}\n",
      "          policy_loss: 0.01079965103417635\n",
      "          total_loss: 2194.1552734375\n",
      "          vf_explained_var: -1.171715258152517e-08\n",
      "          vf_loss: 2194.133056640625\n",
      "    num_agent_steps_sampled: 780000\n",
      "    num_agent_steps_trained: 780000\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.93714285714286\n",
      "    ram_util_percent: 30.011428571428574\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.680365475074894\n",
      "    mean_inference_ms: 0.41076447019180434\n",
      "    mean_processing_ms: 4.130274163256522\n",
      "  time_since_restore: 1512.1491680145264\n",
      "  time_this_iter_s: 29.122375965118408\n",
      "  time_total_s: 1512.1491680145264\n",
      "  timestamp: 1665272688\n",
      "  timesteps_since_restore: 765000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 765000\n",
      "  training_iteration: 51\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     51 |          1512.15 |      765000 | -1832.23 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-45-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1824.0487343915481\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 260\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.852\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.1822991371154785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01097051240503788\n",
      "        policy_loss: 0.004247209057211876\n",
      "        total_loss: 2669.737548828125\n",
      "        vf_explained_var: 0.959105908870697\n",
      "        vf_loss: 2669.732421875\n",
      "    load_time_ms: 2.372\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 778752\n",
      "    sample_time_ms: 27690.678\n",
      "    update_time_ms: 2.856\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.885714285714286\n",
      "    ram_util_percent: 24.152380952380955\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06605945843633435\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5411421790443245\n",
      "    mean_inference_ms: 0.4841298833132809\n",
      "    mean_raw_obs_processing_ms: 3.7811497488539607\n",
      "  time_since_restore: 1403.5665836334229\n",
      "  time_this_iter_s: 24.66741967201233\n",
      "  time_total_s: 1403.5665836334229\n",
      "  timers:\n",
      "    learn_throughput: 6864.265\n",
      "    learn_time_ms: 2185.23\n",
      "    load_throughput: 9337552.317\n",
      "    load_time_ms: 1.606\n",
      "    sample_throughput: 644.183\n",
      "    sample_time_ms: 23285.291\n",
      "    update_time_ms: 1.835\n",
      "  timestamp: 1665246593\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 52\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     52 |          1403.57 | 780000 | -1366.59 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 795000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-30-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1579.0757126543308\n",
      "  episode_reward_min: -8324.169161384283\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 265\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.18020324409008026\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.1270041465759277\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017975520342588425\n",
      "          model: {}\n",
      "          policy_loss: 0.010701111517846584\n",
      "          total_loss: 3022.4658203125\n",
      "          vf_explained_var: 1.528324244937096e-09\n",
      "          vf_loss: 3022.45166015625\n",
      "    num_agent_steps_sampled: 795000\n",
      "    num_agent_steps_trained: 795000\n",
      "    num_steps_sampled: 795000\n",
      "    num_steps_trained: 795000\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.521621621621623\n",
      "    ram_util_percent: 30.143243243243248\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.677260799906585\n",
      "    mean_inference_ms: 0.41084483012318734\n",
      "    mean_processing_ms: 4.131864732201752\n",
      "  time_since_restore: 1541.0460464954376\n",
      "  time_this_iter_s: 28.896878480911255\n",
      "  time_total_s: 1541.0460464954376\n",
      "  timestamp: 1665272717\n",
      "  timesteps_since_restore: 780000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 52\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     52 |          1541.05 |      780000 | -1824.05 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-45-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1814.8502847986072\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 265\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.269\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09492187201976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7014041543006897\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.040748871862888336\n",
      "        policy_loss: -0.0010757282143458724\n",
      "        total_loss: 2134.82373046875\n",
      "        vf_explained_var: 0.9633569121360779\n",
      "        vf_loss: 2134.8212890625\n",
      "    load_time_ms: 2.555\n",
      "    num_steps_sampled: 795000\n",
      "    num_steps_trained: 793728\n",
      "    sample_time_ms: 27727.337\n",
      "    update_time_ms: 2.778\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.957142857142856\n",
      "    ram_util_percent: 24.09761904761905\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0660422272571874\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5385525912496183\n",
      "    mean_inference_ms: 0.4840589793897659\n",
      "    mean_raw_obs_processing_ms: 3.776135865009756\n",
      "  time_since_restore: 1429.4148030281067\n",
      "  time_this_iter_s: 25.848219394683838\n",
      "  time_total_s: 1429.4148030281067\n",
      "  timers:\n",
      "    learn_throughput: 7057.171\n",
      "    learn_time_ms: 2125.497\n",
      "    load_throughput: 9399070.768\n",
      "    load_time_ms: 1.596\n",
      "    sample_throughput: 640.501\n",
      "    sample_time_ms: 23419.157\n",
      "    update_time_ms: 1.836\n",
      "  timestamp: 1665246619\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 795000\n",
      "  training_iteration: 53\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     53 |          1429.41 | 795000 | -1579.08 |              2530.81 |             -8324.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 810000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-30-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2530.805184574418\n",
      "  episode_reward_mean: -1573.5630241435988\n",
      "  episode_reward_min: -7392.237639384751\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 270\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.18020324409008026\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2372386455535889\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01712283492088318\n",
      "          model: {}\n",
      "          policy_loss: 0.007951853796839714\n",
      "          total_loss: 2621.585693359375\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 2621.57421875\n",
      "    num_agent_steps_sampled: 810000\n",
      "    num_agent_steps_trained: 810000\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.325641025641026\n",
      "    ram_util_percent: 30.053846153846145\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.674358543695812\n",
      "    mean_inference_ms: 0.41092595709778\n",
      "    mean_processing_ms: 4.133341871478385\n",
      "  time_since_restore: 1570.6921062469482\n",
      "  time_this_iter_s: 29.64605975151062\n",
      "  time_total_s: 1570.6921062469482\n",
      "  timestamp: 1665272746\n",
      "  timesteps_since_restore: 795000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 795000\n",
      "  training_iteration: 53\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     53 |          1570.69 |      795000 | -1814.85 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-46-16\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1962.987036055044\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 270\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.4\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14238281548023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.3282809257507324\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013363794423639774\n",
      "        policy_loss: 0.0058617317117750645\n",
      "        total_loss: 2516.27099609375\n",
      "        vf_explained_var: 0.9704315066337585\n",
      "        vf_loss: 2516.26318359375\n",
      "    load_time_ms: 2.413\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 808704\n",
      "    sample_time_ms: 27756.521\n",
      "    update_time_ms: 2.859\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.02619047619047\n",
      "    ram_util_percent: 24.140476190476193\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06602671646323435\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5361776250331207\n",
      "    mean_inference_ms: 0.483995903213305\n",
      "    mean_raw_obs_processing_ms: 3.7711273074445817\n",
      "  time_since_restore: 1456.1588382720947\n",
      "  time_this_iter_s: 26.744035243988037\n",
      "  time_total_s: 1456.1588382720947\n",
      "  timers:\n",
      "    learn_throughput: 7014.911\n",
      "    learn_time_ms: 2138.302\n",
      "    load_throughput: 8592302.86\n",
      "    load_time_ms: 1.746\n",
      "    sample_throughput: 636.16\n",
      "    sample_time_ms: 23578.971\n",
      "    update_time_ms: 1.813\n",
      "  timestamp: 1665246646\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 54\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     54 |          1456.16 | 810000 | -1573.56 |              2530.81 |             -7392.24 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 825000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-31-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1659.0327647555462\n",
      "  episode_reward_min: -7392.237639384751\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 275\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.18020324409008026\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.4852977991104126\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015464474447071552\n",
      "          model: {}\n",
      "          policy_loss: 0.003783897962421179\n",
      "          total_loss: 2259.993896484375\n",
      "          vf_explained_var: -4.0755314678619925e-09\n",
      "          vf_loss: 2259.98681640625\n",
      "    num_agent_steps_sampled: 825000\n",
      "    num_agent_steps_trained: 825000\n",
      "    num_steps_sampled: 825000\n",
      "    num_steps_trained: 825000\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.608333333333334\n",
      "    ram_util_percent: 30.05833333333333\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.671511459883636\n",
      "    mean_inference_ms: 0.41099379708847217\n",
      "    mean_processing_ms: 4.1323078740887045\n",
      "  time_since_restore: 1600.0783319473267\n",
      "  time_this_iter_s: 29.386225700378418\n",
      "  time_total_s: 1600.0783319473267\n",
      "  timestamp: 1665272776\n",
      "  timesteps_since_restore: 810000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 54\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     54 |          1600.08 |      810000 | -1962.99 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-46-45\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1992.4656539107323\n",
      "  episode_reward_min: -7898.59005402186\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 275\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.745\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14238281548023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7137879729270935\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011148873716592789\n",
      "        policy_loss: 0.0013398046139627695\n",
      "        total_loss: 2098.861572265625\n",
      "        vf_explained_var: 0.9714082479476929\n",
      "        vf_loss: 2098.85888671875\n",
      "    load_time_ms: 2.447\n",
      "    num_steps_sampled: 825000\n",
      "    num_steps_trained: 823680\n",
      "    sample_time_ms: 27785.967\n",
      "    update_time_ms: 2.878\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.67142857142857\n",
      "    ram_util_percent: 24.0952380952381\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06601063853346734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5337624322403047\n",
      "    mean_inference_ms: 0.48392701817844785\n",
      "    mean_raw_obs_processing_ms: 3.766160421746232\n",
      "  time_since_restore: 1481.2898523807526\n",
      "  time_this_iter_s: 25.131014108657837\n",
      "  time_total_s: 1481.2898523807526\n",
      "  timers:\n",
      "    learn_throughput: 6930.48\n",
      "    learn_time_ms: 2164.352\n",
      "    load_throughput: 8557126.341\n",
      "    load_time_ms: 1.753\n",
      "    sample_throughput: 635.428\n",
      "    sample_time_ms: 23606.154\n",
      "    update_time_ms: 2.045\n",
      "  timestamp: 1665246671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 825000\n",
      "  training_iteration: 55\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     55 |          1481.29 | 825000 | -1659.03 |              2314.45 |             -7392.24 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 840000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-31-36\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1772.9961188808586\n",
      "  episode_reward_min: -7392.237639384751\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 280\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.18020324409008026\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.668113350868225\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010119098238646984\n",
      "          model: {}\n",
      "          policy_loss: 0.003140100045129657\n",
      "          total_loss: 2555.914794921875\n",
      "          vf_explained_var: 4.0755314678619925e-09\n",
      "          vf_loss: 2555.909912109375\n",
      "    num_agent_steps_sampled: 840000\n",
      "    num_agent_steps_trained: 840000\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.705714285714286\n",
      "    ram_util_percent: 30.05142857142857\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.668830658788054\n",
      "    mean_inference_ms: 0.4110596190177179\n",
      "    mean_processing_ms: 4.1312706789737605\n",
      "  time_since_restore: 1629.299599647522\n",
      "  time_this_iter_s: 29.221267700195312\n",
      "  time_total_s: 1629.299599647522\n",
      "  timestamp: 1665272805\n",
      "  timesteps_since_restore: 825000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 825000\n",
      "  training_iteration: 55\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     55 |           1629.3 |      825000 | -1992.47 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-47-14\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1939.4629268996523\n",
      "  episode_reward_min: -7450.783598745398\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 280\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.514\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14238281548023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.104544997215271\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014451735652983189\n",
      "        policy_loss: 0.004712485242635012\n",
      "        total_loss: 2681.9697265625\n",
      "        vf_explained_var: 0.9720291495323181\n",
      "        vf_loss: 2681.962890625\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 838656\n",
      "    sample_time_ms: 27753.979\n",
      "    update_time_ms: 2.883\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.22926829268293\n",
      "    ram_util_percent: 24.134146341463417\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0659942077258813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.531345602210022\n",
      "    mean_inference_ms: 0.483854319688773\n",
      "    mean_raw_obs_processing_ms: 3.7610286123651986\n",
      "  time_since_restore: 1506.0928206443787\n",
      "  time_this_iter_s: 24.8029682636261\n",
      "  time_total_s: 1506.0928206443787\n",
      "  timers:\n",
      "    learn_throughput: 7001.247\n",
      "    learn_time_ms: 2142.476\n",
      "    load_throughput: 9191584.853\n",
      "    load_time_ms: 1.632\n",
      "    sample_throughput: 634.405\n",
      "    sample_time_ms: 23644.201\n",
      "    update_time_ms: 2.048\n",
      "  timestamp: 1665246696\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 56\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     56 |          1506.09 | 840000 |    -1773 |              2314.45 |             -7392.24 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 855000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-32-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1866.9593611574614\n",
      "  episode_reward_min: -7392.237639384751\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 285\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.18020324409008026\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2936674356460571\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022197339683771133\n",
      "          model: {}\n",
      "          policy_loss: 0.004499238450080156\n",
      "          total_loss: 2717.63134765625\n",
      "          vf_explained_var: 1.0188828669654981e-09\n",
      "          vf_loss: 2717.62255859375\n",
      "    num_agent_steps_sampled: 855000\n",
      "    num_agent_steps_trained: 855000\n",
      "    num_steps_sampled: 855000\n",
      "    num_steps_trained: 855000\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.140000000000004\n",
      "    ram_util_percent: 30.071428571428573\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.6662718358923\n",
      "    mean_inference_ms: 0.41112985474081853\n",
      "    mean_processing_ms: 4.130355981290104\n",
      "  time_since_restore: 1658.5263583660126\n",
      "  time_this_iter_s: 29.2267587184906\n",
      "  time_total_s: 1658.5263583660126\n",
      "  timestamp: 1665272834\n",
      "  timesteps_since_restore: 840000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 56\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     56 |          1658.53 |      840000 | -1939.46 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-47-43\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1845.2908810742113\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 285\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1477.2\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14238281548023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.0786985531449318\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.10602562874555588\n",
      "        policy_loss: 0.02318735234439373\n",
      "        total_loss: 2453.669677734375\n",
      "        vf_explained_var: 0.9719496965408325\n",
      "        vf_loss: 2453.63134765625\n",
      "    load_time_ms: 2.511\n",
      "    num_steps_sampled: 855000\n",
      "    num_steps_trained: 853632\n",
      "    sample_time_ms: 27763.21\n",
      "    update_time_ms: 2.834\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.92857142857143\n",
      "    ram_util_percent: 24.092857142857145\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06597782071491766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.528974664368204\n",
      "    mean_inference_ms: 0.4837796170962065\n",
      "    mean_raw_obs_processing_ms: 3.756152164897228\n",
      "  time_since_restore: 1530.4614255428314\n",
      "  time_this_iter_s: 24.36860489845276\n",
      "  time_total_s: 1530.4614255428314\n",
      "  timers:\n",
      "    learn_throughput: 6933.967\n",
      "    learn_time_ms: 2163.264\n",
      "    load_throughput: 9098668.055\n",
      "    load_time_ms: 1.649\n",
      "    sample_throughput: 635.864\n",
      "    sample_time_ms: 23589.941\n",
      "    update_time_ms: 2.067\n",
      "  timestamp: 1665246721\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 855000\n",
      "  training_iteration: 57\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     57 |          1530.46 | 855000 | -1866.96 |              2314.45 |             -7392.24 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 870000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-32-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1874.6494453706175\n",
      "  episode_reward_min: -7392.237639384751\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 290\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.18020324409008026\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.8911212086677551\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03219042718410492\n",
      "          model: {}\n",
      "          policy_loss: 0.00859933439642191\n",
      "          total_loss: 2230.451171875\n",
      "          vf_explained_var: -3.5660898678457897e-09\n",
      "          vf_loss: 2230.436767578125\n",
      "    num_agent_steps_sampled: 870000\n",
      "    num_agent_steps_trained: 870000\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 870000\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.46111111111111\n",
      "    ram_util_percent: 30.063888888888886\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.663842875645285\n",
      "    mean_inference_ms: 0.41120353422817324\n",
      "    mean_processing_ms: 4.12946752083313\n",
      "  time_since_restore: 1687.5809915065765\n",
      "  time_this_iter_s: 29.054633140563965\n",
      "  time_total_s: 1687.5809915065765\n",
      "  timestamp: 1665272863\n",
      "  timesteps_since_restore: 855000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 855000\n",
      "  training_iteration: 57\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     57 |          1687.58 |      855000 | -1845.29 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-48-12\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1770.8201275761705\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 290\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1477.46\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.21357421576976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9430171847343445\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00766199454665184\n",
      "        policy_loss: 0.003306817961856723\n",
      "        total_loss: 2872.070068359375\n",
      "        vf_explained_var: 0.9715027809143066\n",
      "        vf_loss: 2872.065185546875\n",
      "    load_time_ms: 2.505\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 868608\n",
      "    sample_time_ms: 27774.232\n",
      "    update_time_ms: 2.828\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34390243902439\n",
      "    ram_util_percent: 24.229268292682924\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06596239373036808\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5266873830112098\n",
      "    mean_inference_ms: 0.48370782786495753\n",
      "    mean_raw_obs_processing_ms: 3.7486975459055634\n",
      "  time_since_restore: 1555.359935760498\n",
      "  time_this_iter_s: 24.898510217666626\n",
      "  time_total_s: 1555.359935760498\n",
      "  timers:\n",
      "    learn_throughput: 6953.228\n",
      "    learn_time_ms: 2157.271\n",
      "    load_throughput: 9214470.254\n",
      "    load_time_ms: 1.628\n",
      "    sample_throughput: 635.154\n",
      "    sample_time_ms: 23616.302\n",
      "    update_time_ms: 2.141\n",
      "  timestamp: 1665246746\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 58\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     58 |          1555.36 | 870000 | -1874.65 |              2314.45 |             -7392.24 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 885000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-32-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1891.0693748230394\n",
      "  episode_reward_min: -7392.237639384751\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 295\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.18020324409008026\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.7963279485702515\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03079260140657425\n",
      "          model: {}\n",
      "          policy_loss: 0.009731899946928024\n",
      "          total_loss: 2727.724365234375\n",
      "          vf_explained_var: -6.113296979748384e-09\n",
      "          vf_loss: 2727.70947265625\n",
      "    num_agent_steps_sampled: 885000\n",
      "    num_agent_steps_trained: 885000\n",
      "    num_steps_sampled: 885000\n",
      "    num_steps_trained: 885000\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.609302325581396\n",
      "    ram_util_percent: 29.999999999999996\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.661467818354063\n",
      "    mean_inference_ms: 0.4112676683922305\n",
      "    mean_processing_ms: 4.1285739523426885\n",
      "  time_since_restore: 1716.6267969608307\n",
      "  time_this_iter_s: 29.04580545425415\n",
      "  time_total_s: 1716.6267969608307\n",
      "  timestamp: 1665272892\n",
      "  timesteps_since_restore: 870000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 58\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     58 |          1716.63 |      870000 | -1770.82 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-48-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1750.0492604526223\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 295\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1478.014\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.10678710788488388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.2971950173377991\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.11618173122406006\n",
      "        policy_loss: 0.016877248883247375\n",
      "        total_loss: 2354.943115234375\n",
      "        vf_explained_var: 0.9695175886154175\n",
      "        vf_loss: 2354.91357421875\n",
      "    load_time_ms: 2.465\n",
      "    num_steps_sampled: 885000\n",
      "    num_steps_trained: 883584\n",
      "    sample_time_ms: 27745.643\n",
      "    update_time_ms: 2.808\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.21463414634146\n",
      "    ram_util_percent: 24.17317073170732\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06594802588712512\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5244921674904277\n",
      "    mean_inference_ms: 0.4836427295399963\n",
      "    mean_raw_obs_processing_ms: 3.743023540452685\n",
      "  time_since_restore: 1585.9987597465515\n",
      "  time_this_iter_s: 30.638823986053467\n",
      "  time_total_s: 1585.9987597465515\n",
      "  timers:\n",
      "    learn_throughput: 6684.531\n",
      "    learn_time_ms: 2243.987\n",
      "    load_throughput: 9279023.052\n",
      "    load_time_ms: 1.617\n",
      "    sample_throughput: 624.481\n",
      "    sample_time_ms: 24019.95\n",
      "    update_time_ms: 2.164\n",
      "  timestamp: 1665246776\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 885000\n",
      "  training_iteration: 59\n",
      "  trial_id: 26f87_00000\n",
=======
      "    mean_env_wait_ms: 4.659205132564696\n",
      "    mean_inference_ms: 0.411330217482694\n",
      "    mean_processing_ms: 4.12772324398501\n",
      "  time_since_restore: 1745.400494337082\n",
      "  time_this_iter_s: 28.77369737625122\n",
      "  time_total_s: 1745.400494337082\n",
      "  timestamp: 1665272921\n",
      "  timesteps_since_restore: 885000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 885000\n",
      "  training_iteration: 59\n",
      "  trial_id: a95f16f0\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
<<<<<<< HEAD
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     59 |             1586 | 885000 | -1891.07 |              2314.45 |             -7392.24 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 900000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-33-21\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1888.9605817735128\n",
      "  episode_reward_min: -7830.841784933431\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 300\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.18020324409008026\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.5835145711898804\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012178235687315464\n",
      "          model: {}\n",
      "          policy_loss: -0.0007285999017767608\n",
      "          total_loss: 2310.578369140625\n",
      "          vf_explained_var: -6.622738357719982e-09\n",
      "          vf_loss: 2310.57666015625\n",
      "    num_agent_steps_sampled: 900000\n",
      "    num_agent_steps_trained: 900000\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.625714285714285\n",
      "    ram_util_percent: 30.06857142857143\n",
      "  pid: 307\n",
=======
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     59 |           1745.4 |      885000 | -1750.05 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-49-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1643.5427468597793\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 300\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1478.746\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19864723086357117\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010497340932488441\n",
      "        policy_loss: 0.003018787829205394\n",
      "        total_loss: 2798.0283203125\n",
      "        vf_explained_var: 0.9713051319122314\n",
      "        vf_loss: 2798.0234375\n",
      "    load_time_ms: 2.553\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 898560\n",
      "    sample_time_ms: 27712.216\n",
      "    update_time_ms: 2.855\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.37906976744186\n",
      "    ram_util_percent: 24.167441860465118\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.065934718084772\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.522426218530711\n",
      "    mean_inference_ms: 0.4835820253708333\n",
      "    mean_raw_obs_processing_ms: 3.7373230170750382\n",
      "  time_since_restore: 1610.1737430095673\n",
      "  time_this_iter_s: 24.174983263015747\n",
      "  time_total_s: 1610.1737430095673\n",
      "  timers:\n",
      "    learn_throughput: 6896.163\n",
      "    learn_time_ms: 2175.123\n",
      "    load_throughput: 10616520.14\n",
      "    load_time_ms: 1.413\n",
      "    sample_throughput: 626.324\n",
      "    sample_time_ms: 23949.276\n",
      "    update_time_ms: 1.873\n",
      "  timestamp: 1665246801\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 60\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     60 |          1610.17 | 900000 | -1888.96 |              2314.45 |             -7830.84 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 915000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-33-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1909.8782944471545\n",
      "  episode_reward_min: -7830.841784933431\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 305\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.18020324409008026\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.4192226529121399\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.049653731286525726\n",
      "          model: {}\n",
      "          policy_loss: 0.011204802431166172\n",
      "          total_loss: 2400.2421875\n",
      "          vf_explained_var: -4.0755314678619925e-09\n",
      "          vf_loss: 2400.22216796875\n",
      "    num_agent_steps_sampled: 915000\n",
      "    num_agent_steps_trained: 915000\n",
      "    num_steps_sampled: 915000\n",
      "    num_steps_trained: 915000\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.680555555555557\n",
      "    ram_util_percent: 30.063888888888886\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.657177096810889\n",
      "    mean_inference_ms: 0.411391999236989\n",
      "    mean_processing_ms: 4.126875240175978\n",
      "  time_since_restore: 1775.0464565753937\n",
      "  time_this_iter_s: 29.645962238311768\n",
      "  time_total_s: 1775.0464565753937\n",
      "  timestamp: 1665272951\n",
      "  timesteps_since_restore: 900000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 60\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     60 |          1775.05 |      900000 | -1643.54 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-49-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1696.356042119165\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 305\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.713\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.27279794216156\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014532058499753475\n",
      "        policy_loss: 0.0023699020966887474\n",
      "        total_loss: 2191.2353515625\n",
      "        vf_explained_var: 0.9841702580451965\n",
      "        vf_loss: 2191.230712890625\n",
      "    load_time_ms: 2.416\n",
      "    num_steps_sampled: 915000\n",
      "    num_steps_trained: 913536\n",
      "    sample_time_ms: 27726.635\n",
      "    update_time_ms: 2.903\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.916666666666664\n",
      "    ram_util_percent: 24.12857142857143\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06592250296028176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5204306708525688\n",
      "    mean_inference_ms: 0.48352772953094425\n",
      "    mean_raw_obs_processing_ms: 3.729832422673806\n",
      "  time_since_restore: 1635.3706846237183\n",
      "  time_this_iter_s: 25.196941614151\n",
      "  time_total_s: 1635.3706846237183\n",
      "  timers:\n",
      "    learn_throughput: 6945.878\n",
      "    learn_time_ms: 2159.554\n",
      "    load_throughput: 10508879.535\n",
      "    load_time_ms: 1.427\n",
      "    sample_throughput: 638.924\n",
      "    sample_time_ms: 23476.96\n",
      "    update_time_ms: 1.714\n",
      "  timestamp: 1665246826\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 915000\n",
      "  training_iteration: 61\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.655192253703323\n",
      "    mean_inference_ms: 0.41145910287190063\n",
      "    mean_processing_ms: 4.126099613294166\n",
      "  time_since_restore: 1804.3216784000397\n",
      "  time_this_iter_s: 29.275221824645996\n",
      "  time_total_s: 1804.3216784000397\n",
      "  timestamp: 1665272980\n",
      "  timesteps_since_restore: 915000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 915000\n",
      "  training_iteration: 61\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     61 |          1804.32 |      915000 | -1696.36 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     61 |          1635.37 | 915000 | -1909.88 |              2314.45 |             -7830.84 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 930000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-34-12\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1965.8576839286052\n",
      "  episode_reward_min: -7932.104803961036\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 310\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2703048586845398\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.8697011470794678\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.032859474420547485\n",
      "          model: {}\n",
      "          policy_loss: 0.021845409646630287\n",
      "          total_loss: 2955.571044921875\n",
      "          vf_explained_var: -7.1321797356915795e-09\n",
      "          vf_loss: 2955.5400390625\n",
      "    num_agent_steps_sampled: 930000\n",
      "    num_agent_steps_trained: 930000\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 930000\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.456756756756757\n",
      "    ram_util_percent: 30.05405405405405\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-50-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1680.3027013547864\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 310\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.691\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.2821168899536133\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013107813894748688\n",
      "        policy_loss: 0.0014974238583818078\n",
      "        total_loss: 2279.5576171875\n",
      "        vf_explained_var: 0.9777005314826965\n",
      "        vf_loss: 2279.55419921875\n",
      "    load_time_ms: 2.478\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 928512\n",
      "    sample_time_ms: 27750.658\n",
      "    update_time_ms: 2.877\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.646341463414636\n",
      "    ram_util_percent: 24.190243902439022\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06591031905079947\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5185413959344136\n",
      "    mean_inference_ms: 0.483472968358785\n",
      "    mean_raw_obs_processing_ms: 3.7227598727720412\n",
      "  time_since_restore: 1661.4893848896027\n",
      "  time_this_iter_s: 26.1187002658844\n",
      "  time_total_s: 1661.4893848896027\n",
      "  timers:\n",
      "    learn_throughput: 6852.775\n",
      "    learn_time_ms: 2188.894\n",
      "    load_throughput: 10823079.305\n",
      "    load_time_ms: 1.386\n",
      "    sample_throughput: 635.787\n",
      "    sample_time_ms: 23592.801\n",
      "    update_time_ms: 1.527\n",
      "  timestamp: 1665246852\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 62\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     62 |          1661.49 | 930000 | -1965.86 |              2314.45 |              -7932.1 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 945000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-34-43\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1898.9270329881242\n",
      "  episode_reward_min: -7932.104803961036\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 315\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2703048586845398\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.12453088909387589\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02456216886639595\n",
      "          model: {}\n",
      "          policy_loss: 0.003911240957677364\n",
      "          total_loss: 2628.7255859375\n",
      "          vf_explained_var: -4.58497284583359e-09\n",
      "          vf_loss: 2628.715576171875\n",
      "    num_agent_steps_sampled: 945000\n",
      "    num_agent_steps_trained: 945000\n",
      "    num_steps_sampled: 945000\n",
      "    num_steps_trained: 945000\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.96888888888889\n",
      "    ram_util_percent: 30.015555555555547\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.653152536538129\n",
      "    mean_inference_ms: 0.41152249489943105\n",
      "    mean_processing_ms: 4.125386698850484\n",
      "  time_since_restore: 1833.468535900116\n",
      "  time_this_iter_s: 29.146857500076294\n",
      "  time_total_s: 1833.468535900116\n",
      "  timestamp: 1665273009\n",
      "  timesteps_since_restore: 930000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 62\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     62 |          1833.47 |      930000 |  -1680.3 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-50-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1607.1807862135693\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 315\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.492\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.9898887276649475\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010449322871863842\n",
      "        policy_loss: 0.0031775448005646467\n",
      "        total_loss: 2082.80126953125\n",
      "        vf_explained_var: 0.9776167273521423\n",
      "        vf_loss: 2082.79638671875\n",
      "    load_time_ms: 2.469\n",
      "    num_steps_sampled: 945000\n",
      "    num_steps_trained: 943488\n",
      "    sample_time_ms: 27696.193\n",
      "    update_time_ms: 2.958\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.15952380952382\n",
      "    ram_util_percent: 24.16904761904762\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06589828559153536\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.516700206743082\n",
      "    mean_inference_ms: 0.4834197580196239\n",
      "    mean_raw_obs_processing_ms: 3.7176042008530636\n",
      "  time_since_restore: 1692.632432937622\n",
      "  time_this_iter_s: 31.14304804801941\n",
      "  time_total_s: 1692.632432937622\n",
      "  timers:\n",
      "    learn_throughput: 6705.251\n",
      "    learn_time_ms: 2237.053\n",
      "    load_throughput: 9306612.23\n",
      "    load_time_ms: 1.612\n",
      "    sample_throughput: 623.084\n",
      "    sample_time_ms: 24073.807\n",
      "    update_time_ms: 1.525\n",
      "  timestamp: 1665246883\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 945000\n",
      "  training_iteration: 63\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     63 |          1692.63 | 945000 | -1898.93 |              2314.45 |              -7932.1 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 960000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-35-15\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1951.6888279532004\n",
      "  episode_reward_min: -7932.104803961036\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 320\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2703048586845398\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.883129358291626\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027466384693980217\n",
      "          model: {}\n",
      "          policy_loss: 0.012448156252503395\n",
      "          total_loss: 2747.301513671875\n",
      "          vf_explained_var: -9.679387069638778e-09\n",
      "          vf_loss: 2747.28125\n",
      "    num_agent_steps_sampled: 960000\n",
      "    num_agent_steps_trained: 960000\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.680000000000003\n",
      "    ram_util_percent: 30.108888888888895\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.651240689242943\n",
      "    mean_inference_ms: 0.411587677598947\n",
      "    mean_processing_ms: 4.12465288620989\n",
      "  time_since_restore: 1862.5683104991913\n",
      "  time_this_iter_s: 29.099774599075317\n",
      "  time_total_s: 1862.5683104991913\n",
      "  timestamp: 1665273038\n",
      "  timesteps_since_restore: 945000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 945000\n",
      "  training_iteration: 63\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     63 |          1862.57 |      945000 | -1607.18 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-51-07\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1485.4049755701476\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 320\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.367\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1134485006332397\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018898412585258484\n",
      "        policy_loss: 0.0060987588949501514\n",
      "        total_loss: 2155.045654296875\n",
      "        vf_explained_var: 0.9729171395301819\n",
      "        vf_loss: 2155.03662109375\n",
      "    load_time_ms: 2.556\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 958464\n",
      "    sample_time_ms: 27635.638\n",
      "    update_time_ms: 2.965\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.22195121951219\n",
      "    ram_util_percent: 24.17317073170732\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06588734802042726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.515022757760426\n",
      "    mean_inference_ms: 0.48337301229200386\n",
      "    mean_raw_obs_processing_ms: 3.7143031813929235\n",
      "  time_since_restore: 1724.3730759620667\n",
      "  time_this_iter_s: 31.74064302444458\n",
      "  time_total_s: 1724.3730759620667\n",
      "  timers:\n",
      "    learn_throughput: 6697.003\n",
      "    learn_time_ms: 2239.808\n",
      "    load_throughput: 9360196.385\n",
      "    load_time_ms: 1.603\n",
      "    sample_throughput: 610.486\n",
      "    sample_time_ms: 24570.585\n",
      "    update_time_ms: 1.601\n",
      "  timestamp: 1665246915\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 64\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     64 |          1724.37 | 960000 | -1951.69 |              2314.45 |              -7932.1 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 975000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-35-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1954.6830499868797\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 325\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2703048586845398\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.4364289045333862\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02098269574344158\n",
      "          model: {}\n",
      "          policy_loss: 0.00747524993494153\n",
      "          total_loss: 2990.74169921875\n",
      "          vf_explained_var: -1.884933276130596e-08\n",
      "          vf_loss: 2990.72802734375\n",
      "    num_agent_steps_sampled: 975000\n",
      "    num_agent_steps_trained: 975000\n",
      "    num_steps_sampled: 975000\n",
      "    num_steps_trained: 975000\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.666666666666668\n",
      "    ram_util_percent: 30.158333333333342\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.64947870790002\n",
      "    mean_inference_ms: 0.4116547448117834\n",
      "    mean_processing_ms: 4.123912570589144\n",
      "  time_since_restore: 1891.3591330051422\n",
      "  time_this_iter_s: 28.790822505950928\n",
      "  time_total_s: 1891.3591330051422\n",
      "  timestamp: 1665273067\n",
      "  timesteps_since_restore: 960000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 64\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     64 |          1891.36 |      960000 |  -1485.4 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-51-37\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1396.0062109226883\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 325\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.924\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3322689533233643\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.036324601620435715\n",
      "        policy_loss: 0.0033697618637233973\n",
      "        total_loss: 2038.3165283203125\n",
      "        vf_explained_var: 0.9757378697395325\n",
      "        vf_loss: 2038.3072509765625\n",
      "    load_time_ms: 2.552\n",
      "    num_steps_sampled: 975000\n",
      "    num_steps_trained: 973440\n",
      "    sample_time_ms: 27655.695\n",
      "    update_time_ms: 2.952\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.92142857142857\n",
      "    ram_util_percent: 24.17142857142857\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06587622774283562\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5134441841711697\n",
      "    mean_inference_ms: 0.48332718412146164\n",
      "    mean_raw_obs_processing_ms: 3.7115032448575045\n",
      "  time_since_restore: 1749.4466454982758\n",
      "  time_this_iter_s: 25.073569536209106\n",
      "  time_total_s: 1749.4466454982758\n",
      "  timers:\n",
      "    learn_throughput: 6890.444\n",
      "    learn_time_ms: 2176.928\n",
      "    load_throughput: 9080545.573\n",
      "    load_time_ms: 1.652\n",
      "    sample_throughput: 609.062\n",
      "    sample_time_ms: 24628.049\n",
      "    update_time_ms: 1.385\n",
      "  timestamp: 1665246940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 975000\n",
      "  training_iteration: 65\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     65 |          1749.45 | 975000 | -1954.68 |              2314.45 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 990000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-36-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -1985.9314252171293\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 330\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2703048586845398\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.32407546043396\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03701285272836685\n",
      "          model: {}\n",
      "          policy_loss: 0.014432821422815323\n",
      "          total_loss: 2911.4169921875\n",
      "          vf_explained_var: -1.3245476715439963e-08\n",
      "          vf_loss: 2911.392578125\n",
      "    num_agent_steps_sampled: 990000\n",
      "    num_agent_steps_trained: 990000\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 990000\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.459615384615386\n",
      "    ram_util_percent: 30.04615384615385\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.647828926206447\n",
      "    mean_inference_ms: 0.41172937312919616\n",
      "    mean_processing_ms: 4.123286897053825\n",
      "  time_since_restore: 1920.7764110565186\n",
      "  time_this_iter_s: 29.417278051376343\n",
      "  time_total_s: 1920.7764110565186\n",
      "  timestamp: 1665273097\n",
      "  timesteps_since_restore: 975000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 975000\n",
      "  training_iteration: 65\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     65 |          1920.78 |      975000 | -1396.01 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-52-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1379.3434598279068\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 330\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.077\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16018065810203552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8931322693824768\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.07058688253164291\n",
      "        policy_loss: 0.015435976907610893\n",
      "        total_loss: 2980.332763671875\n",
      "        vf_explained_var: 0.9777279496192932\n",
      "        vf_loss: 2980.30615234375\n",
      "    load_time_ms: 2.518\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 988416\n",
      "    sample_time_ms: 27656.018\n",
      "    update_time_ms: 2.97\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.15714285714286\n",
      "    ram_util_percent: 24.18809523809524\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06586481714286849\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.511831681734114\n",
      "    mean_inference_ms: 0.48328080946570295\n",
      "    mean_raw_obs_processing_ms: 3.711965271183764\n",
      "  time_since_restore: 1785.7313122749329\n",
      "  time_this_iter_s: 36.284666776657104\n",
      "  time_total_s: 1785.7313122749329\n",
      "  timers:\n",
      "    learn_throughput: 6715.919\n",
      "    learn_time_ms: 2233.499\n",
      "    load_throughput: 9343098.993\n",
      "    load_time_ms: 1.605\n",
      "    sample_throughput: 583.217\n",
      "    sample_time_ms: 25719.406\n",
      "    update_time_ms: 1.523\n",
      "  timestamp: 1665246977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 66\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     66 |          1785.73 | 990000 | -1985.93 |              2314.45 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1005000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-36-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -2043.8400416283737\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 335\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2703048586845398\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0395911931991577\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01844828948378563\n",
      "          model: {}\n",
      "          policy_loss: 0.002526217373088002\n",
      "          total_loss: 2723.46826171875\n",
      "          vf_explained_var: -7.1321797356915795e-09\n",
      "          vf_loss: 2723.460693359375\n",
      "    num_agent_steps_sampled: 1005000\n",
      "    num_agent_steps_trained: 1005000\n",
      "    num_steps_sampled: 1005000\n",
      "    num_steps_trained: 1005000\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.417142857142856\n",
      "    ram_util_percent: 30.15714285714286\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.646261063980285\n",
      "    mean_inference_ms: 0.41179936748079476\n",
      "    mean_processing_ms: 4.122653741685557\n",
      "  time_since_restore: 1950.0176723003387\n",
      "  time_this_iter_s: 29.24126124382019\n",
      "  time_total_s: 1950.0176723003387\n",
      "  timestamp: 1665273126\n",
      "  timesteps_since_restore: 990000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 66\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     66 |          1950.02 |      990000 | -1379.34 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-52-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1443.3046977791091\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 335\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.815\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.24027100205421448\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9352211356163025\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008084884844720364\n",
      "        policy_loss: -0.0007713447557762265\n",
      "        total_loss: 4086.717529296875\n",
      "        vf_explained_var: 0.9664185643196106\n",
      "        vf_loss: 4086.716064453125\n",
      "    load_time_ms: 2.5\n",
      "    num_steps_sampled: 1005000\n",
      "    num_steps_trained: 1003392\n",
      "    sample_time_ms: 27655.23\n",
      "    update_time_ms: 2.972\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.78048780487805\n",
      "    ram_util_percent: 24.168292682926833\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06585471326944331\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5103220897629925\n",
      "    mean_inference_ms: 0.48324135078969915\n",
      "    mean_raw_obs_processing_ms: 3.7125105447280395\n",
      "  time_since_restore: 1810.3288288116455\n",
      "  time_this_iter_s: 24.597516536712646\n",
      "  time_total_s: 1810.3288288116455\n",
      "  timers:\n",
      "    learn_throughput: 6637.004\n",
      "    learn_time_ms: 2260.056\n",
      "    load_throughput: 9210153.711\n",
      "    load_time_ms: 1.629\n",
      "    sample_throughput: 583.304\n",
      "    sample_time_ms: 25715.581\n",
      "    update_time_ms: 1.633\n",
      "  timestamp: 1665247001\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1005000\n",
      "  training_iteration: 67\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:36:41,736\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 204.0x the scale of `vf_clip_param`. This means that it will take more than 204.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     67 |          1810.33 | 1005000 | -2043.84 |              2314.45 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1020000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-37-07\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -2246.4703637211614\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 340\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2703048586845398\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.7605440616607666\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030259544029831886\n",
      "          model: {}\n",
      "          policy_loss: 0.01683422178030014\n",
      "          total_loss: 2974.739013671875\n",
      "          vf_explained_var: -4.0755314678619925e-09\n",
      "          vf_loss: 2974.71337890625\n",
      "    num_agent_steps_sampled: 1020000\n",
      "    num_agent_steps_trained: 1020000\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.024324324324326\n",
      "    ram_util_percent: 30.16216216216217\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.644702932491251\n",
      "    mean_inference_ms: 0.4118644929322724\n",
      "    mean_processing_ms: 4.122086680489302\n",
      "  time_since_restore: 1979.071202993393\n",
      "  time_this_iter_s: 29.0535306930542\n",
      "  time_total_s: 1979.071202993393\n",
      "  timestamp: 1665273155\n",
      "  timesteps_since_restore: 1005000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1005000\n",
      "  training_iteration: 67\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     67 |          1979.07 |     1005000 |  -1443.3 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-53-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1543.699431703233\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 340\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.173\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.323654055595398\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014535913243889809\n",
      "        policy_loss: 0.00452587241306901\n",
      "        total_loss: 6282.7119140625\n",
      "        vf_explained_var: 0.9518312215805054\n",
      "        vf_loss: 6282.70654296875\n",
      "    load_time_ms: 2.625\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1018368\n",
      "    sample_time_ms: 27665.03\n",
      "    update_time_ms: 2.871\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.31666666666668\n",
      "    ram_util_percent: 24.199999999999996\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06584495943414184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5087977324323623\n",
      "    mean_inference_ms: 0.4832026289635269\n",
      "    mean_raw_obs_processing_ms: 3.7134837205734077\n",
      "  time_since_restore: 1835.7030725479126\n",
      "  time_this_iter_s: 25.37424373626709\n",
      "  time_total_s: 1835.7030725479126\n",
      "  timers:\n",
      "    learn_throughput: 6615.518\n",
      "    learn_time_ms: 2267.396\n",
      "    load_throughput: 9290670.132\n",
      "    load_time_ms: 1.615\n",
      "    sample_throughput: 582.392\n",
      "    sample_time_ms: 25755.83\n",
      "    update_time_ms: 1.687\n",
      "  timestamp: 1665247027\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 68\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:37:07,178\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 225.0x the scale of `vf_clip_param`. This means that it will take more than 225.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     68 |           1835.7 | 1020000 | -2246.47 |              2314.45 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n"
=======
      "    mean_env_wait_ms: 4.6432205958090265\n",
      "    mean_inference_ms: 0.41193652167656664\n",
      "    mean_processing_ms: 4.121626882430888\n",
      "  time_since_restore: 2008.2087144851685\n",
      "  time_this_iter_s: 29.137511491775513\n",
      "  time_total_s: 2008.2087144851685\n",
      "  timestamp: 1665273184\n",
      "  timesteps_since_restore: 1020000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 68\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     68 |          2008.21 |     1020000 |  -1543.7 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1035000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-37-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -2363.300444502345\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 345\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2703048586845398\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.9251625537872314\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029114270582795143\n",
      "          model: {}\n",
      "          policy_loss: 0.014757885597646236\n",
      "          total_loss: 3115.55810546875\n",
      "          vf_explained_var: -4.58497284583359e-09\n",
      "          vf_loss: 3115.5361328125\n",
      "    num_agent_steps_sampled: 1035000\n",
      "    num_agent_steps_trained: 1035000\n",
      "    num_steps_sampled: 1035000\n",
      "    num_steps_trained: 1035000\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.89772727272727\n",
      "    ram_util_percent: 30.09545454545455\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-53-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2430.268397138448\n",
      "  episode_reward_mean: -1598.5367797497427\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 345\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.461\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.06891930103302002\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.034609146416187286\n",
      "        policy_loss: 0.009135644882917404\n",
      "        total_loss: 3792.73046875\n",
      "        vf_explained_var: 0.9718257784843445\n",
      "        vf_loss: 3792.71630859375\n",
      "    load_time_ms: 2.538\n",
      "    num_steps_sampled: 1035000\n",
      "    num_steps_trained: 1033344\n",
      "    sample_time_ms: 27792.357\n",
      "    update_time_ms: 2.754\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.0452380952381\n",
      "    ram_util_percent: 24.214285714285715\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06583594610060706\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.507317289742281\n",
      "    mean_inference_ms: 0.48316676193485486\n",
      "    mean_raw_obs_processing_ms: 3.7158206105327944\n",
      "  time_since_restore: 1866.9861783981323\n",
      "  time_this_iter_s: 31.283105850219727\n",
      "  time_total_s: 1866.9861783981323\n",
      "  timers:\n",
      "    learn_throughput: 6745.24\n",
      "    learn_time_ms: 2223.79\n",
      "    load_throughput: 9241404.838\n",
      "    load_time_ms: 1.623\n",
      "    sample_throughput: 579.96\n",
      "    sample_time_ms: 25863.852\n",
      "    update_time_ms: 1.666\n",
      "  timestamp: 1665247058\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1035000\n",
      "  training_iteration: 69\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:37:38,534\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 236.0x the scale of `vf_clip_param`. This means that it will take more than 236.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     69 |          1866.99 | 1035000 |  -2363.3 |              2314.45 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1050000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-38-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -2432.6892792683684\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 350\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2703048586845398\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2251412868499756\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.06674806028604507\n",
      "          model: {}\n",
      "          policy_loss: 0.029865840449929237\n",
      "          total_loss: 3126.378662109375\n",
      "          vf_explained_var: 3.056648489874192e-09\n",
      "          vf_loss: 3126.331298828125\n",
      "    num_agent_steps_sampled: 1050000\n",
      "    num_agent_steps_trained: 1050000\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1050000\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.717142857142857\n",
      "    ram_util_percent: 30.168571428571433\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.64170435433812\n",
      "    mean_inference_ms: 0.4120013243773851\n",
      "    mean_processing_ms: 4.121494754899889\n",
      "  time_since_restore: 2038.2466099262238\n",
      "  time_this_iter_s: 30.037895441055298\n",
      "  time_total_s: 2038.2466099262238\n",
      "  timestamp: 1665273214\n",
      "  timesteps_since_restore: 1035000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1035000\n",
      "  training_iteration: 69\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     69 |          2038.25 |     1035000 | -1598.54 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-54-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1627.5485976016726\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 350\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.963\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2026757299900055\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013194246217608452\n",
      "        policy_loss: 0.002526839729398489\n",
      "        total_loss: 3083.585205078125\n",
      "        vf_explained_var: 0.9770655632019043\n",
      "        vf_loss: 3083.581298828125\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1048320\n",
      "    sample_time_ms: 27726.399\n",
      "    update_time_ms: 2.846\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.06428571428572\n",
      "    ram_util_percent: 24.202380952380945\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0658269015895755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.505851046588201\n",
      "    mean_inference_ms: 0.48313087930826043\n",
      "    mean_raw_obs_processing_ms: 3.7181912664163574\n",
      "  time_since_restore: 1891.591097831726\n",
      "  time_this_iter_s: 24.60491943359375\n",
      "  time_total_s: 1891.591097831726\n",
      "  timers:\n",
      "    learn_throughput: 6738.681\n",
      "    learn_time_ms: 2225.955\n",
      "    load_throughput: 9031273.416\n",
      "    load_time_ms: 1.661\n",
      "    sample_throughput: 579.046\n",
      "    sample_time_ms: 25904.687\n",
      "    update_time_ms: 1.679\n",
      "  timestamp: 1665247083\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 70\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.640196673978032\n",
      "    mean_inference_ms: 0.4120589619950139\n",
      "    mean_processing_ms: 4.121157611385666\n",
      "  time_since_restore: 2067.2586171627045\n",
      "  time_this_iter_s: 29.012007236480713\n",
      "  time_total_s: 2067.2586171627045\n",
      "  timestamp: 1665273243\n",
      "  timesteps_since_restore: 1050000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 70\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     70 |          2067.26 |     1050000 | -1627.55 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     70 |          1891.59 | 1050000 | -2432.69 |              2314.45 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:38:03,197\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 243.0x the scale of `vf_clip_param`. This means that it will take more than 243.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1065000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-38-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -2506.019650224459\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 355\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4054573178291321\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.327120065689087\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011056452989578247\n",
      "          model: {}\n",
      "          policy_loss: 0.008409051224589348\n",
      "          total_loss: 2881.114501953125\n",
      "          vf_explained_var: -7.641621557752387e-09\n",
      "          vf_loss: 2881.1015625\n",
      "    num_agent_steps_sampled: 1065000\n",
      "    num_agent_steps_trained: 1065000\n",
      "    num_steps_sampled: 1065000\n",
      "    num_steps_trained: 1065000\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.170270270270265\n",
      "    ram_util_percent: 30.164864864864867\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-54-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1557.100542400353\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 355\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.268\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.848048210144043\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02766149304807186\n",
      "        policy_loss: 0.005472071003168821\n",
      "        total_loss: 2681.08203125\n",
      "        vf_explained_var: 0.9621966481208801\n",
      "        vf_loss: 2681.072998046875\n",
      "    load_time_ms: 2.647\n",
      "    num_steps_sampled: 1065000\n",
      "    num_steps_trained: 1063296\n",
      "    sample_time_ms: 27713.835\n",
      "    update_time_ms: 2.827\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.247619047619054\n",
      "    ram_util_percent: 24.18809523809524\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06581797019522663\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5044896492259245\n",
      "    mean_inference_ms: 0.4830961395027785\n",
      "    mean_raw_obs_processing_ms: 3.7188533739635066\n",
      "  time_since_restore: 1916.93190407753\n",
      "  time_this_iter_s: 25.340806245803833\n",
      "  time_total_s: 1916.93190407753\n",
      "  timers:\n",
      "    learn_throughput: 6559.755\n",
      "    learn_time_ms: 2286.671\n",
      "    load_throughput: 8870951.186\n",
      "    load_time_ms: 1.691\n",
      "    sample_throughput: 580.082\n",
      "    sample_time_ms: 25858.407\n",
      "    update_time_ms: 1.653\n",
      "  timestamp: 1665247108\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1065000\n",
      "  training_iteration: 71\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     71 |          1916.93 | 1065000 | -2506.02 |              2314.45 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:38:28,592\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 251.0x the scale of `vf_clip_param`. This means that it will take more than 251.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1080000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-38-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -2471.2310548615787\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 360\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4054573178291321\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.3965274393558502\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008040125481784344\n",
      "          model: {}\n",
      "          policy_loss: 0.0024205308873206377\n",
      "          total_loss: 2822.23193359375\n",
      "          vf_explained_var: 4.0755314678619925e-09\n",
      "          vf_loss: 2822.22607421875\n",
      "    num_agent_steps_sampled: 1080000\n",
      "    num_agent_steps_trained: 1080000\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.53684210526316\n",
      "    ram_util_percent: 30.173684210526318\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.638775797410336\n",
      "    mean_inference_ms: 0.4121152694859346\n",
      "    mean_processing_ms: 4.120821069964958\n",
      "  time_since_restore: 2096.4127728939056\n",
      "  time_this_iter_s: 29.154155731201172\n",
      "  time_total_s: 2096.4127728939056\n",
      "  timestamp: 1665273273\n",
      "  timesteps_since_restore: 1065000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1065000\n",
      "  training_iteration: 71\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     71 |          2096.41 |     1065000 |  -1557.1 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-55-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1504.751640110329\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 360\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.342\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.12013550102710724\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.08287081867456436\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.22376243770122528\n",
      "        policy_loss: 0.02846589870750904\n",
      "        total_loss: 4492.29736328125\n",
      "        vf_explained_var: 0.959092378616333\n",
      "        vf_loss: 4492.2421875\n",
      "    load_time_ms: 2.596\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1078272\n",
      "    sample_time_ms: 27641.456\n",
      "    update_time_ms: 2.865\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.5375\n",
      "    ram_util_percent: 24.244999999999997\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06580855380161683\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5032155970345946\n",
      "    mean_inference_ms: 0.48306275208759625\n",
      "    mean_raw_obs_processing_ms: 3.71978430601712\n",
      "  time_since_restore: 1943.4632453918457\n",
      "  time_this_iter_s: 26.531341314315796\n",
      "  time_total_s: 1943.4632453918457\n",
      "  timers:\n",
      "    learn_throughput: 6513.173\n",
      "    learn_time_ms: 2303.025\n",
      "    load_throughput: 8044208.615\n",
      "    load_time_ms: 1.865\n",
      "    sample_throughput: 579.523\n",
      "    sample_time_ms: 25883.351\n",
      "    update_time_ms: 1.628\n",
      "  timestamp: 1665247135\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 72\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     72 |          1943.46 | 1080000 | -2471.23 |              2314.45 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:38:55,181\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 247.0x the scale of `vf_clip_param`. This means that it will take more than 247.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1095000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-39-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2314.450685613813\n",
      "  episode_reward_mean: -2399.984304814212\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 365\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20272865891456604\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3360072374343872\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029448306187987328\n",
      "          model: {}\n",
      "          policy_loss: 0.004347336944192648\n",
      "          total_loss: 2930.564697265625\n",
      "          vf_explained_var: -2.547207111902594e-09\n",
      "          vf_loss: 2930.55419921875\n",
      "    num_agent_steps_sampled: 1095000\n",
      "    num_agent_steps_trained: 1095000\n",
      "    num_steps_sampled: 1095000\n",
      "    num_steps_trained: 1095000\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.574285714285715\n",
      "    ram_util_percent: 30.21714285714286\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.637346608044783\n",
      "    mean_inference_ms: 0.412169219739403\n",
      "    mean_processing_ms: 4.120528762084245\n",
      "  time_since_restore: 2124.8368389606476\n",
      "  time_this_iter_s: 28.424066066741943\n",
      "  time_total_s: 2124.8368389606476\n",
      "  timestamp: 1665273301\n",
      "  timesteps_since_restore: 1080000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 72\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     72 |          2124.84 |     1080000 | -1504.75 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-55-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1535.3853648337235\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 365\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.424\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.18020324409008026\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1623600572347641\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007445329334586859\n",
      "        policy_loss: 1.0585747077129781e-05\n",
      "        total_loss: 2328.591552734375\n",
      "        vf_explained_var: 0.9848737716674805\n",
      "        vf_loss: 2328.590087890625\n",
      "    load_time_ms: 2.556\n",
      "    num_steps_sampled: 1095000\n",
      "    num_steps_trained: 1093248\n",
      "    sample_time_ms: 27622.159\n",
      "    update_time_ms: 2.744\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.44634146341463\n",
      "    ram_util_percent: 24.19268292682927\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06579922768252632\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5019452505134363\n",
      "    mean_inference_ms: 0.483026625974484\n",
      "    mean_raw_obs_processing_ms: 3.7205888357433965\n",
      "  time_since_restore: 1967.9825539588928\n",
      "  time_this_iter_s: 24.51930856704712\n",
      "  time_total_s: 1967.9825539588928\n",
      "  timers:\n",
      "    learn_throughput: 6576.58\n",
      "    learn_time_ms: 2280.821\n",
      "    load_throughput: 9001425.015\n",
      "    load_time_ms: 1.666\n",
      "    sample_throughput: 594.222\n",
      "    sample_time_ms: 25243.108\n",
      "    update_time_ms: 1.798\n",
      "  timestamp: 1665247159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1095000\n",
      "  training_iteration: 73\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:39:19,749\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 240.0x the scale of `vf_clip_param`. This means that it will take more than 240.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     73 |          1967.98 | 1095000 | -2399.98 |              2314.45 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
=======
      "    mean_env_wait_ms: 4.635964229989829\n",
      "    mean_inference_ms: 0.41221627779817394\n",
      "    mean_processing_ms: 4.120168409084132\n",
      "  time_since_restore: 2153.7427775859833\n",
      "  time_this_iter_s: 28.905938625335693\n",
      "  time_total_s: 2153.7427775859833\n",
      "  timestamp: 1665273330\n",
      "  timesteps_since_restore: 1095000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1095000\n",
      "  training_iteration: 73\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     73 |          2153.74 |     1095000 | -1535.39 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1110000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-39-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.2421550047243\n",
      "  episode_reward_mean: -2410.3017858791227\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 370\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20272865891456604\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2846462726593018\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04428035393357277\n",
      "          model: {}\n",
      "          policy_loss: 0.02262950874865055\n",
      "          total_loss: 3260.82958984375\n",
      "          vf_explained_var: -6.113296979748384e-09\n",
      "          vf_loss: 3260.798095703125\n",
      "    num_agent_steps_sampled: 1110000\n",
      "    num_agent_steps_trained: 1110000\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1110000\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.569767441860467\n",
      "    ram_util_percent: 30.211627906976748\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-55-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1346.9378549661\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 370\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.438\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09010162204504013\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.424919605255127\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017055783420801163\n",
      "        policy_loss: 0.0020091894548386335\n",
      "        total_loss: 3906.638671875\n",
      "        vf_explained_var: 0.9603806138038635\n",
      "        vf_loss: 3906.63525390625\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1108224\n",
      "    sample_time_ms: 27656.205\n",
      "    update_time_ms: 2.707\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.53571428571429\n",
      "    ram_util_percent: 24.240476190476187\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.065789676583257\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.5006527387399853\n",
      "    mean_inference_ms: 0.4829897073548011\n",
      "    mean_raw_obs_processing_ms: 3.722474251698604\n",
      "  time_since_restore: 1998.018642425537\n",
      "  time_this_iter_s: 30.036088466644287\n",
      "  time_total_s: 1998.018642425537\n",
      "  timers:\n",
      "    learn_throughput: 6660.452\n",
      "    learn_time_ms: 2252.099\n",
      "    load_throughput: 9096694.717\n",
      "    load_time_ms: 1.649\n",
      "    sample_throughput: 597.568\n",
      "    sample_time_ms: 25101.766\n",
      "    update_time_ms: 1.744\n",
      "  timestamp: 1665247189\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 74\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     74 |          1998.02 | 1110000 |  -2410.3 |              1780.24 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:39:49,857\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 241.0x the scale of `vf_clip_param`. This means that it will take more than 241.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1125000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-40-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1731.8509332843425\n",
      "  episode_reward_mean: -2475.7758186987207\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 375\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30409297347068787\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9577838182449341\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009824109263718128\n",
      "          model: {}\n",
      "          policy_loss: 0.005330823827534914\n",
      "          total_loss: 2733.501953125\n",
      "          vf_explained_var: -1.171715258152517e-08\n",
      "          vf_loss: 2733.493896484375\n",
      "    num_agent_steps_sampled: 1125000\n",
      "    num_agent_steps_trained: 1125000\n",
      "    num_steps_sampled: 1125000\n",
      "    num_steps_trained: 1125000\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.808695652173913\n",
      "    ram_util_percent: 30.300000000000015\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.634652302975045\n",
      "    mean_inference_ms: 0.41225765444959833\n",
      "    mean_processing_ms: 4.119837657769072\n",
      "  time_since_restore: 2182.863212585449\n",
      "  time_this_iter_s: 29.120434999465942\n",
      "  time_total_s: 2182.863212585449\n",
      "  timestamp: 1665273359\n",
      "  timesteps_since_restore: 1110000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 74\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     74 |          2182.86 |     1110000 | -1346.94 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1325.5982324864922\n",
      "  episode_reward_min: -7213.801330926539\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 375\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.68\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09010162204504013\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3788661062717438\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0099959596991539\n",
      "        policy_loss: -0.0003471083182375878\n",
      "        total_loss: 3430.6884765625\n",
      "        vf_explained_var: 0.9789103269577026\n",
      "        vf_loss: 3430.687744140625\n",
      "    load_time_ms: 2.404\n",
      "    num_steps_sampled: 1125000\n",
      "    num_steps_trained: 1123200\n",
      "    sample_time_ms: 27658.698\n",
      "    update_time_ms: 2.668\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.21666666666667\n",
      "    ram_util_percent: 24.202380952380956\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06578004042679575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.499341335621475\n",
      "    mean_inference_ms: 0.48295339759519385\n",
      "    mean_raw_obs_processing_ms: 3.7260187768372277\n",
      "  time_since_restore: 2030.6181509494781\n",
      "  time_this_iter_s: 32.59950852394104\n",
      "  time_total_s: 2030.6181509494781\n",
      "  timers:\n",
      "    learn_throughput: 6542.695\n",
      "    learn_time_ms: 2292.633\n",
      "    load_throughput: 9096431.67\n",
      "    load_time_ms: 1.649\n",
      "    sample_throughput: 581.093\n",
      "    sample_time_ms: 25813.432\n",
      "    update_time_ms: 1.893\n",
      "  timestamp: 1665247222\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1125000\n",
      "  training_iteration: 75\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     75 |          2030.62 | 1125000 | -2475.78 |              1731.85 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:40:22,537\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 248.0x the scale of `vf_clip_param`. This means that it will take more than 248.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1140000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-40-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1967.6986690688911\n",
      "  episode_reward_mean: -2423.065064659257\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 380\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.15204648673534393\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.6506679058074951\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05402948334813118\n",
      "          model: {}\n",
      "          policy_loss: 0.013153285719454288\n",
      "          total_loss: 2863.762451171875\n",
      "          vf_explained_var: -6.622738357719982e-09\n",
      "          vf_loss: 2863.740966796875\n",
      "    num_agent_steps_sampled: 1140000\n",
      "    num_agent_steps_trained: 1140000\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.581081081081074\n",
      "    ram_util_percent: 30.267567567567564\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.633487369221881\n",
      "    mean_inference_ms: 0.41230371052620124\n",
      "    mean_processing_ms: 4.119520662370051\n",
      "  time_since_restore: 2212.3059737682343\n",
      "  time_this_iter_s: 29.442761182785034\n",
      "  time_total_s: 2212.3059737682343\n",
      "  timestamp: 1665273389\n",
      "  timesteps_since_restore: 1125000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1125000\n",
      "  training_iteration: 75\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     75 |          2212.31 |     1125000 |  -1325.6 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-56-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1505.2163364523617\n",
      "  episode_reward_mean: -1215.7969022734956\n",
      "  episode_reward_min: -6797.021123619138\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 380\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.746\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0349434614181519\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011094636283814907\n",
      "        policy_loss: 0.0025965706445276737\n",
      "        total_loss: 2098.9150390625\n",
      "        vf_explained_var: 0.9856294393539429\n",
      "        vf_loss: 2098.912109375\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1138176\n",
      "    sample_time_ms: 27627.776\n",
      "    update_time_ms: 2.685\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.082926829268295\n",
      "    ram_util_percent: 24.236585365853657\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06577131057480311\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.498146351137304\n",
      "    mean_inference_ms: 0.48292298234833\n",
      "    mean_raw_obs_processing_ms: 3.7295346650268733\n",
      "  time_since_restore: 2056.003403186798\n",
      "  time_this_iter_s: 25.385252237319946\n",
      "  time_total_s: 2056.003403186798\n",
      "  timers:\n",
      "    learn_throughput: 6587.805\n",
      "    learn_time_ms: 2276.934\n",
      "    load_throughput: 8978559.196\n",
      "    load_time_ms: 1.671\n",
      "    sample_throughput: 606.311\n",
      "    sample_time_ms: 24739.791\n",
      "    update_time_ms: 1.749\n",
      "  timestamp: 1665247247\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 76\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:40:47,994\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 242.0x the scale of `vf_clip_param`. This means that it will take more than 242.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     76 |             2056 | 1140000 | -2423.07 |               1967.7 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1155000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-41-13\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1967.6986690688911\n",
      "  episode_reward_mean: -2317.1942442550016\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 385\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2280697375535965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.8173703551292419\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03773948922753334\n",
      "          model: {}\n",
      "          policy_loss: 0.013218413107097149\n",
      "          total_loss: 2862.716064453125\n",
      "          vf_explained_var: -8.660504313695583e-09\n",
      "          vf_loss: 2862.693603515625\n",
      "    num_agent_steps_sampled: 1155000\n",
      "    num_agent_steps_trained: 1155000\n",
      "    num_steps_sampled: 1155000\n",
      "    num_steps_trained: 1155000\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.294444444444444\n",
      "    ram_util_percent: 30.263888888888882\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.632361228522145\n",
      "    mean_inference_ms: 0.41234417606944446\n",
      "    mean_processing_ms: 4.11917593005291\n",
      "  time_since_restore: 2241.229974746704\n",
      "  time_this_iter_s: 28.92400097846985\n",
      "  time_total_s: 2241.229974746704\n",
      "  timestamp: 1665273417\n",
      "  timesteps_since_restore: 1140000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 76\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     76 |          2241.23 |     1140000 |  -1215.8 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-57-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1350.2941063699932\n",
      "  episode_reward_mean: -1299.9205328159087\n",
      "  episode_reward_min: -6797.021123619138\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 385\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.074\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.997388243675232\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013290481641888618\n",
      "        policy_loss: 0.0025325173046439886\n",
      "        total_loss: 4463.45263671875\n",
      "        vf_explained_var: 0.9755052924156189\n",
      "        vf_loss: 4463.44921875\n",
      "    load_time_ms: 2.471\n",
      "    num_steps_sampled: 1155000\n",
      "    num_steps_trained: 1153152\n",
      "    sample_time_ms: 27612.578\n",
      "    update_time_ms: 2.703\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.99285714285714\n",
      "    ram_util_percent: 24.219047619047622\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06576224468827643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4970394203738113\n",
      "    mean_inference_ms: 0.48289183591263357\n",
      "    mean_raw_obs_processing_ms: 3.7333272446685326\n",
      "  time_since_restore: 2081.7675971984863\n",
      "  time_this_iter_s: 25.764194011688232\n",
      "  time_total_s: 2081.7675971984863\n",
      "  timers:\n",
      "    learn_throughput: 6613.339\n",
      "    learn_time_ms: 2268.143\n",
      "    load_throughput: 8657093.321\n",
      "    load_time_ms: 1.733\n",
      "    sample_throughput: 603.246\n",
      "    sample_time_ms: 24865.479\n",
      "    update_time_ms: 1.572\n",
      "  timestamp: 1665247273\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1155000\n",
      "  training_iteration: 77\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:41:13,807\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 232.0x the scale of `vf_clip_param`. This means that it will take more than 232.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     77 |          2081.77 | 1155000 | -2317.19 |               1967.7 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1170000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-41-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1967.6986690688911\n",
      "  episode_reward_mean: -2511.7634551305323\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 390\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2280697375535965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.7719063758850098\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01670040935277939\n",
      "          model: {}\n",
      "          policy_loss: 0.010970847681164742\n",
      "          total_loss: 3326.358642578125\n",
      "          vf_explained_var: -5.094414223805188e-09\n",
      "          vf_loss: 3326.343505859375\n",
      "    num_agent_steps_sampled: 1170000\n",
      "    num_agent_steps_trained: 1170000\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1170000\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.751351351351357\n",
      "    ram_util_percent: 30.264864864864858\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.631222066355051\n",
      "    mean_inference_ms: 0.4123871431758259\n",
      "    mean_processing_ms: 4.118856707548836\n",
      "  time_since_restore: 2270.1248359680176\n",
      "  time_this_iter_s: 28.894861221313477\n",
      "  time_total_s: 2270.1248359680176\n",
      "  timestamp: 1665273446\n",
      "  timesteps_since_restore: 1155000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1155000\n",
      "  training_iteration: 77\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     77 |          2270.12 |     1155000 | -1299.92 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-57-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1350.2941063699932\n",
      "  episode_reward_mean: -1216.3572017872561\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 390\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.574\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5149365067481995\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.039941683411598206\n",
      "        policy_loss: -0.0030962007585912943\n",
      "        total_loss: 3147.349365234375\n",
      "        vf_explained_var: 0.9782958030700684\n",
      "        vf_loss: 3147.3505859375\n",
      "    load_time_ms: 2.509\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1168128\n",
      "    sample_time_ms: 27592.216\n",
      "    update_time_ms: 2.825\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.01951219512195\n",
      "    ram_util_percent: 24.226829268292683\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06575387224046851\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4959370857854712\n",
      "    mean_inference_ms: 0.482862449879409\n",
      "    mean_raw_obs_processing_ms: 3.737361993600772\n",
      "  time_since_restore: 2107.0613543987274\n",
      "  time_this_iter_s: 25.29375720024109\n",
      "  time_total_s: 2107.0613543987274\n",
      "  timers:\n",
      "    learn_throughput: 6592.616\n",
      "    learn_time_ms: 2275.273\n",
      "    load_throughput: 8481337.288\n",
      "    load_time_ms: 1.769\n",
      "    sample_throughput: 603.612\n",
      "    sample_time_ms: 24850.392\n",
      "    update_time_ms: 1.472\n",
      "  timestamp: 1665247299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 78\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:41:39,150\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 251.0x the scale of `vf_clip_param`. This means that it will take more than 251.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
=======
      "    mean_env_wait_ms: 4.630116006330648\n",
      "    mean_inference_ms: 0.4124292672199397\n",
      "    mean_processing_ms: 4.11856699269013\n",
      "  time_since_restore: 2299.066123008728\n",
      "  time_this_iter_s: 28.94128704071045\n",
      "  time_total_s: 2299.066123008728\n",
      "  timestamp: 1665273475\n",
      "  timesteps_since_restore: 1170000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 78\n",
      "  trial_id: a95f16f0\n",
      "  \n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
<<<<<<< HEAD
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     78 |          2107.06 | 1170000 | -2511.76 |               1967.7 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1185000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-42-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1967.6986690688911\n",
      "  episode_reward_mean: -2479.5144850316397\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 395\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2280697375535965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9770799279212952\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021527936682105064\n",
      "          model: {}\n",
      "          policy_loss: 0.007460635155439377\n",
      "          total_loss: 3162.7783203125\n",
      "          vf_explained_var: -6.622738357719982e-09\n",
      "          vf_loss: 3162.765869140625\n",
      "    num_agent_steps_sampled: 1185000\n",
      "    num_agent_steps_trained: 1185000\n",
      "    num_steps_sampled: 1185000\n",
      "    num_steps_trained: 1185000\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.3\n",
      "    ram_util_percent: 30.21627906976744\n",
      "  pid: 307\n",
=======
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     78 |          2299.07 |     1170000 | -1216.36 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-58-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1350.2941063699932\n",
      "  episode_reward_mean: -1181.6650592703515\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 395\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.048\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5619403123855591\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018223034217953682\n",
      "        policy_loss: 0.0015551141696050763\n",
      "        total_loss: 2936.881103515625\n",
      "        vf_explained_var: 0.9762338399887085\n",
      "        vf_loss: 2936.87890625\n",
      "    load_time_ms: 2.636\n",
      "    num_steps_sampled: 1185000\n",
      "    num_steps_trained: 1183104\n",
      "    sample_time_ms: 27558.854\n",
      "    update_time_ms: 2.8\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.50714285714285\n",
      "    ram_util_percent: 24.338095238095235\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06574554256097033\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4948883630316434\n",
      "    mean_inference_ms: 0.48283141152656256\n",
      "    mean_raw_obs_processing_ms: 3.7410646708130573\n",
      "  time_since_restore: 2137.1019451618195\n",
      "  time_this_iter_s: 30.04059076309204\n",
      "  time_total_s: 2137.1019451618195\n",
      "  timers:\n",
      "    learn_throughput: 6611.024\n",
      "    learn_time_ms: 2268.938\n",
      "    load_throughput: 8474368.61\n",
      "    load_time_ms: 1.77\n",
      "    sample_throughput: 606.491\n",
      "    sample_time_ms: 24732.455\n",
      "    update_time_ms: 1.485\n",
      "  timestamp: 1665247329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1185000\n",
      "  training_iteration: 79\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:42:09,260\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 248.0x the scale of `vf_clip_param`. This means that it will take more than 248.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.4/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     79 |           2137.1 | 1185000 | -2479.51 |               1967.7 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1200000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-42-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1967.6986690688911\n",
      "  episode_reward_mean: -2601.9825600974414\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 400\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2280697375535965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.1478912830352783\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014247545972466469\n",
      "          model: {}\n",
      "          policy_loss: 0.007178671192377806\n",
      "          total_loss: 3322.775146484375\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 3322.764404296875\n",
      "    num_agent_steps_sampled: 1200000\n",
      "    num_agent_steps_trained: 1200000\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1200000\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.89090909090909\n",
      "    ram_util_percent: 30.211363636363636\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.62920109567249\n",
      "    mean_inference_ms: 0.41248151031541497\n",
      "    mean_processing_ms: 4.118302959255484\n",
      "  time_since_restore: 2328.7762808799744\n",
      "  time_this_iter_s: 29.710157871246338\n",
      "  time_total_s: 2328.7762808799744\n",
      "  timestamp: 1665273505\n",
      "  timesteps_since_restore: 1185000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1185000\n",
      "  training_iteration: 79\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     79 |          2328.78 |     1185000 | -1181.67 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-58-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2263.235322337614\n",
      "  episode_reward_mean: -1131.1405425671294\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 400\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.356\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.812896192073822\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0166899673640728\n",
      "        policy_loss: -0.0001831790868891403\n",
      "        total_loss: 2929.33837890625\n",
      "        vf_explained_var: 0.9759217500686646\n",
      "        vf_loss: 2929.337890625\n",
      "    load_time_ms: 2.626\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1198080\n",
      "    sample_time_ms: 27677.271\n",
      "    update_time_ms: 2.659\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.06511627906977\n",
      "    ram_util_percent: 24.265116279069765\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06573815231909215\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.493887863577421\n",
      "    mean_inference_ms: 0.4828056405193579\n",
      "    mean_raw_obs_processing_ms: 3.746342637890828\n",
      "  time_since_restore: 2168.4670996665955\n",
      "  time_this_iter_s: 31.365154504776\n",
      "  time_total_s: 2168.4670996665955\n",
      "  timers:\n",
      "    learn_throughput: 6479.708\n",
      "    learn_time_ms: 2314.919\n",
      "    load_throughput: 8489233.717\n",
      "    load_time_ms: 1.767\n",
      "    sample_throughput: 591.425\n",
      "    sample_time_ms: 25362.484\n",
      "    update_time_ms: 1.469\n",
      "  timestamp: 1665247360\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 80\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:42:40,702\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 260.0x the scale of `vf_clip_param`. This means that it will take more than 260.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     80 |          2168.47 | 1200000 | -2601.98 |               1967.7 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n"
=======
      "    mean_env_wait_ms: 4.628283609913923\n",
      "    mean_inference_ms: 0.4125292786339454\n",
      "    mean_processing_ms: 4.118211449411464\n",
      "  time_since_restore: 2358.9538543224335\n",
      "  time_this_iter_s: 30.177573442459106\n",
      "  time_total_s: 2358.9538543224335\n",
      "  timestamp: 1665273535\n",
      "  timesteps_since_restore: 1200000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 80\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     80 |          2358.95 |     1200000 | -1131.14 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1215000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-43-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1967.6986690688911\n",
      "  episode_reward_mean: -2621.9404069696916\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 405\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2280697375535965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.001972187776118517\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0867113247513771\n",
      "          model: {}\n",
      "          policy_loss: 0.031148793175816536\n",
      "          total_loss: 3067.628662109375\n",
      "          vf_explained_var: -1.1207711203553572e-08\n",
      "          vf_loss: 3067.5771484375\n",
      "    num_agent_steps_sampled: 1215000\n",
      "    num_agent_steps_trained: 1215000\n",
      "    num_steps_sampled: 1215000\n",
      "    num_steps_trained: 1215000\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.324999999999996\n",
      "    ram_util_percent: 30.218181818181815\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-59-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2263.235322337614\n",
      "  episode_reward_mean: -1014.8624565898383\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 405\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.593\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8254194259643555\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024917250499129295\n",
      "        policy_loss: 0.00222373497672379\n",
      "        total_loss: 2083.748779296875\n",
      "        vf_explained_var: 0.9825114011764526\n",
      "        vf_loss: 2083.74560546875\n",
      "    load_time_ms: 2.554\n",
      "    num_steps_sampled: 1215000\n",
      "    num_steps_trained: 1213056\n",
      "    sample_time_ms: 27689.456\n",
      "    update_time_ms: 2.624\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.945238095238096\n",
      "    ram_util_percent: 24.266666666666666\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0657306777345706\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4929150998274\n",
      "    mean_inference_ms: 0.48277811880010646\n",
      "    mean_raw_obs_processing_ms: 3.752710332355862\n",
      "  time_since_restore: 2198.716404438019\n",
      "  time_this_iter_s: 30.24930477142334\n",
      "  time_total_s: 2198.716404438019\n",
      "  timers:\n",
      "    learn_throughput: 6687.439\n",
      "    learn_time_ms: 2243.011\n",
      "    load_throughput: 8790878.605\n",
      "    load_time_ms: 1.706\n",
      "    sample_throughput: 578.588\n",
      "    sample_time_ms: 25925.199\n",
      "    update_time_ms: 1.517\n",
      "  timestamp: 1665247391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1215000\n",
      "  training_iteration: 81\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     81 |          2198.72 | 1215000 | -2621.94 |               1967.7 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:43:11,004\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 262.0x the scale of `vf_clip_param`. This means that it will take more than 262.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1230000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-43-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1967.6986690688911\n",
      "  episode_reward_mean: -2483.809652641133\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 410\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.34210461378097534\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.6593831777572632\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012420108541846275\n",
      "          model: {}\n",
      "          policy_loss: 0.005444633774459362\n",
      "          total_loss: 2169.603271484375\n",
      "          vf_explained_var: -2.0377657339309962e-09\n",
      "          vf_loss: 2169.59375\n",
      "    num_agent_steps_sampled: 1230000\n",
      "    num_agent_steps_trained: 1230000\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1230000\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.408888888888892\n",
      "    ram_util_percent: 30.26222222222223\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.62739736370733\n",
      "    mean_inference_ms: 0.4125748431959476\n",
      "    mean_processing_ms: 4.11810281663075\n",
      "  time_since_restore: 2388.2311573028564\n",
      "  time_this_iter_s: 29.277302980422974\n",
      "  time_total_s: 2388.2311573028564\n",
      "  timestamp: 1665273565\n",
      "  timesteps_since_restore: 1215000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1215000\n",
      "  training_iteration: 81\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     81 |          2388.23 |     1215000 | -1014.86 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_18-59-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2263.235322337614\n",
      "  episode_reward_mean: -1069.6952347046788\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 410\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.398\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.045050811022520065\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.808097779750824\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.3199496865272522\n",
      "        policy_loss: 0.038910288363695145\n",
      "        total_loss: 5179.810546875\n",
      "        vf_explained_var: 0.9700908064842224\n",
      "        vf_loss: 5179.7568359375\n",
      "    load_time_ms: 2.423\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1228032\n",
      "    sample_time_ms: 27757.205\n",
      "    update_time_ms: 2.581\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.57619047619047\n",
      "    ram_util_percent: 24.266666666666662\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06572317386821167\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4919365062905894\n",
      "    mean_inference_ms: 0.48275119689669893\n",
      "    mean_raw_obs_processing_ms: 3.7601322900254583\n",
      "  time_since_restore: 2230.5799584388733\n",
      "  time_this_iter_s: 31.863554000854492\n",
      "  time_total_s: 2230.5799584388733\n",
      "  timers:\n",
      "    learn_throughput: 6734.128\n",
      "    learn_time_ms: 2227.46\n",
      "    load_throughput: 8675237.859\n",
      "    load_time_ms: 1.729\n",
      "    sample_throughput: 566.597\n",
      "    sample_time_ms: 26473.824\n",
      "    update_time_ms: 1.516\n",
      "  timestamp: 1665247422\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 82\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.626478831989462\n",
      "    mean_inference_ms: 0.41261750850277035\n",
      "    mean_processing_ms: 4.1179999343943505\n",
      "  time_since_restore: 2417.3286724090576\n",
      "  time_this_iter_s: 29.097515106201172\n",
      "  time_total_s: 2417.3286724090576\n",
      "  timestamp: 1665273594\n",
      "  timesteps_since_restore: 1230000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 82\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     82 |          2417.33 |     1230000 |  -1069.7 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:43:42,937\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 248.0x the scale of `vf_clip_param`. This means that it will take more than 248.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     82 |          2230.58 | 1230000 | -2483.81 |               1967.7 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1245000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-44-07\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1967.6986690688911\n",
      "  episode_reward_mean: -2514.495551162443\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 415\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.34210461378097534\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7665794491767883\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.07770765572786331\n",
      "          model: {}\n",
      "          policy_loss: 0.007711911108344793\n",
      "          total_loss: 2831.888916015625\n",
      "          vf_explained_var: -2.547207111902594e-09\n",
      "          vf_loss: 2831.8544921875\n",
      "    num_agent_steps_sampled: 1245000\n",
      "    num_agent_steps_trained: 1245000\n",
      "    num_steps_sampled: 1245000\n",
      "    num_steps_trained: 1245000\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.202777777777776\n",
      "    ram_util_percent: 30.327777777777783\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-00-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1072.8873881331706\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 415\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1480.121\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06757621467113495\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4440262019634247\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018486035987734795\n",
      "        policy_loss: 0.0022734208032488823\n",
      "        total_loss: 2788.25732421875\n",
      "        vf_explained_var: 0.9804291129112244\n",
      "        vf_loss: 2788.25390625\n",
      "    load_time_ms: 2.386\n",
      "    num_steps_sampled: 1245000\n",
      "    num_steps_trained: 1243008\n",
      "    sample_time_ms: 27890.968\n",
      "    update_time_ms: 2.697\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.16046511627906\n",
      "    ram_util_percent: 24.279069767441854\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06571598365549654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4909396480223216\n",
      "    mean_inference_ms: 0.4827243334958311\n",
      "    mean_raw_obs_processing_ms: 3.766039670125433\n",
      "  time_since_restore: 2255.595456123352\n",
      "  time_this_iter_s: 25.01549768447876\n",
      "  time_total_s: 2255.595456123352\n",
      "  timers:\n",
      "    learn_throughput: 6633.986\n",
      "    learn_time_ms: 2261.084\n",
      "    load_throughput: 7866975.104\n",
      "    load_time_ms: 1.907\n",
      "    sample_throughput: 566.255\n",
      "    sample_time_ms: 26489.811\n",
      "    update_time_ms: 1.393\n",
      "  timestamp: 1665247447\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1245000\n",
      "  training_iteration: 83\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     83 |           2255.6 | 1245000 |  -2514.5 |               1967.7 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:44:07,999\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 251.0x the scale of `vf_clip_param`. This means that it will take more than 251.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1260000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-44-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1967.6986690688911\n",
      "  episode_reward_mean: -2479.859996851745\n",
      "  episode_reward_min: -8214.95284352449\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 420\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5131568908691406\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0757734775543213\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020667489618062973\n",
      "          model: {}\n",
      "          policy_loss: 0.010034331120550632\n",
      "          total_loss: 3146.4638671875\n",
      "          vf_explained_var: -1.5792684493476372e-08\n",
      "          vf_loss: 3146.443115234375\n",
      "    num_agent_steps_sampled: 1260000\n",
      "    num_agent_steps_trained: 1260000\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1260000\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.255555555555553\n",
      "    ram_util_percent: 30.350000000000005\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.625627231812884\n",
      "    mean_inference_ms: 0.4126605268403466\n",
      "    mean_processing_ms: 4.118036913146782\n",
      "  time_since_restore: 2447.560133934021\n",
      "  time_this_iter_s: 30.23146152496338\n",
      "  time_total_s: 2447.560133934021\n",
      "  timestamp: 1665273624\n",
      "  timesteps_since_restore: 1245000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1245000\n",
      "  training_iteration: 83\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     83 |          2447.56 |     1245000 | -1072.89 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-00-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1162.7323584375397\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 420\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.811\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06757621467113495\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.3736580610275269\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010879043489694595\n",
      "        policy_loss: 0.0018454903038218617\n",
      "        total_loss: 3875.99365234375\n",
      "        vf_explained_var: 0.9795897603034973\n",
      "        vf_loss: 3875.991455078125\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1257984\n",
      "    sample_time_ms: 27952.719\n",
      "    update_time_ms: 2.754\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.895348837209305\n",
      "    ram_util_percent: 24.267441860465112\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06570924073022871\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.489949613782416\n",
      "    mean_inference_ms: 0.4826972707475341\n",
      "    mean_raw_obs_processing_ms: 3.77029489722402\n",
      "  time_since_restore: 2280.7554171085358\n",
      "  time_this_iter_s: 25.159960985183716\n",
      "  time_total_s: 2280.7554171085358\n",
      "  timers:\n",
      "    learn_throughput: 6594.472\n",
      "    learn_time_ms: 2274.632\n",
      "    load_throughput: 7663815.429\n",
      "    load_time_ms: 1.957\n",
      "    sample_throughput: 577.18\n",
      "    sample_time_ms: 25988.436\n",
      "    update_time_ms: 1.459\n",
      "  timestamp: 1665247473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 84\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     84 |          2280.76 | 1260000 | -2479.86 |               1967.7 |             -8214.95 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:44:33,229\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 248.0x the scale of `vf_clip_param`. This means that it will take more than 248.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1275000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-45-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2437.929157962197\n",
      "  episode_reward_min: -8063.785226228408\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 425\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5131568908691406\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.627829909324646\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014728059992194176\n",
      "          model: {}\n",
      "          policy_loss: 0.0050888583064079285\n",
      "          total_loss: 2987.627197265625\n",
      "          vf_explained_var: 9.679387069638778e-09\n",
      "          vf_loss: 2987.614501953125\n",
      "    num_agent_steps_sampled: 1275000\n",
      "    num_agent_steps_trained: 1275000\n",
      "    num_steps_sampled: 1275000\n",
      "    num_steps_trained: 1275000\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.922222222222224\n",
      "    ram_util_percent: 30.33111111111111\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.624764202128018\n",
      "    mean_inference_ms: 0.4126962837501578\n",
      "    mean_processing_ms: 4.1182108699248205\n",
      "  time_since_restore: 2477.2963902950287\n",
      "  time_this_iter_s: 29.73625636100769\n",
      "  time_total_s: 2477.2963902950287\n",
      "  timestamp: 1665273654\n",
      "  timesteps_since_restore: 1260000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 84\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     84 |           2477.3 |     1260000 | -1162.73 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-01-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1240.4845996441977\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 425\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1479.354\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06757621467113495\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19314377009868622\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009139331988990307\n",
      "        policy_loss: -0.0003545279905665666\n",
      "        total_loss: 6355.0546875\n",
      "        vf_explained_var: 0.9592911005020142\n",
      "        vf_loss: 6355.05517578125\n",
      "    load_time_ms: 2.568\n",
      "    num_steps_sampled: 1275000\n",
      "    num_steps_trained: 1272960\n",
      "    sample_time_ms: 27873.397\n",
      "    update_time_ms: 2.846\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.25853658536586\n",
      "    ram_util_percent: 24.26829268292683\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06570281953254768\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.488988390119801\n",
      "    mean_inference_ms: 0.48267091738424384\n",
      "    mean_raw_obs_processing_ms: 3.7758055544002973\n",
      "  time_since_restore: 2312.21204161644\n",
      "  time_this_iter_s: 31.456624507904053\n",
      "  time_total_s: 2312.21204161644\n",
      "  timers:\n",
      "    learn_throughput: 6619.433\n",
      "    learn_time_ms: 2266.055\n",
      "    load_throughput: 7907117.272\n",
      "    load_time_ms: 1.897\n",
      "    sample_throughput: 579.528\n",
      "    sample_time_ms: 25883.114\n",
      "    update_time_ms: 1.315\n",
      "  timestamp: 1665247504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1275000\n",
      "  training_iteration: 85\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:45:04,740\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 244.0x the scale of `vf_clip_param`. This means that it will take more than 244.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
=======
      "    mean_env_wait_ms: 4.623830316594058\n",
      "    mean_inference_ms: 0.41272566607209316\n",
      "    mean_processing_ms: 4.11832603612715\n",
      "  time_since_restore: 2505.9441890716553\n",
      "  time_this_iter_s: 28.647798776626587\n",
      "  time_total_s: 2505.9441890716553\n",
      "  timestamp: 1665273683\n",
      "  timesteps_since_restore: 1275000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1275000\n",
      "  training_iteration: 85\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     85 |          2505.94 |     1275000 | -1240.48 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     85 |          2312.21 | 1275000 | -2437.93 |               2299.5 |             -8063.79 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1290000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-45-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2367.0494469490404\n",
      "  episode_reward_min: -8063.785226228408\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 430\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5131568908691406\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.4438342750072479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007171756122261286\n",
      "          model: {}\n",
      "          policy_loss: 0.0015316794160753489\n",
      "          total_loss: 2919.3125\n",
      "          vf_explained_var: -5.094414223805188e-09\n",
      "          vf_loss: 2919.307373046875\n",
      "    num_agent_steps_sampled: 1290000\n",
      "    num_agent_steps_trained: 1290000\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1290000\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.924324324324324\n",
      "    ram_util_percent: 30.42432432432433\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-01-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1264.4583999048148\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 430\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.033\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.033788107335567474\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.4460644721984863\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0098287183791399\n",
      "        policy_loss: 0.002172253793105483\n",
      "        total_loss: 5743.85986328125\n",
      "        vf_explained_var: 0.9693247675895691\n",
      "        vf_loss: 5743.857421875\n",
      "    load_time_ms: 2.522\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1287936\n",
      "    sample_time_ms: 27900.705\n",
      "    update_time_ms: 2.863\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00731707317074\n",
      "    ram_util_percent: 24.287804878048778\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06569743701157513\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.488100844256115\n",
      "    mean_inference_ms: 0.4826490902920248\n",
      "    mean_raw_obs_processing_ms: 3.778562398289397\n",
      "  time_since_restore: 2337.9710919857025\n",
      "  time_this_iter_s: 25.759050369262695\n",
      "  time_total_s: 2337.9710919857025\n",
      "  timers:\n",
      "    learn_throughput: 6602.032\n",
      "    learn_time_ms: 2272.028\n",
      "    load_throughput: 7913781.132\n",
      "    load_time_ms: 1.895\n",
      "    sample_throughput: 578.844\n",
      "    sample_time_ms: 25913.724\n",
      "    update_time_ms: 1.579\n",
      "  timestamp: 1665247530\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 86\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     86 |          2337.97 | 1290000 | -2367.05 |               2299.5 |             -8063.79 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:45:30,573\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 237.0x the scale of `vf_clip_param`. This means that it will take more than 237.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1305000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-45-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2259.318091501576\n",
      "  episode_reward_min: -8063.785226228408\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 435\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2565784454345703\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.1427640914916992\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.048304516822099686\n",
      "          model: {}\n",
      "          policy_loss: 0.019814984872937202\n",
      "          total_loss: 2578.951904296875\n",
      "          vf_explained_var: -5.603855601776786e-09\n",
      "          vf_loss: 2578.919677734375\n",
      "    num_agent_steps_sampled: 1305000\n",
      "    num_agent_steps_trained: 1305000\n",
      "    num_steps_sampled: 1305000\n",
      "    num_steps_trained: 1305000\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.29189189189189\n",
      "    ram_util_percent: 30.367567567567576\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.622879477121413\n",
      "    mean_inference_ms: 0.41275208407975045\n",
      "    mean_processing_ms: 4.1184102999157775\n",
      "  time_since_restore: 2535.157905817032\n",
      "  time_this_iter_s: 29.213716745376587\n",
      "  time_total_s: 2535.157905817032\n",
      "  timestamp: 1665273712\n",
      "  timesteps_since_restore: 1290000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 86\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     86 |          2535.16 |     1290000 | -1264.46 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-02-21\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1137.0350168708862\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 435\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.524\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.016894053667783737\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.166917324066162\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023554105311632156\n",
      "        policy_loss: 0.0023250493686646223\n",
      "        total_loss: 2347.670654296875\n",
      "        vf_explained_var: 0.9792936444282532\n",
      "        vf_loss: 2347.66796875\n",
      "    load_time_ms: 2.397\n",
      "    num_steps_sampled: 1305000\n",
      "    num_steps_trained: 1302912\n",
      "    sample_time_ms: 27937.159\n",
      "    update_time_ms: 2.82\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.38095238095238\n",
      "    ram_util_percent: 24.29523809523809\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06569268447838318\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4872575746390417\n",
      "    mean_inference_ms: 0.4826315301890072\n",
      "    mean_raw_obs_processing_ms: 3.7814583794902306\n",
      "  time_since_restore: 2363.8330397605896\n",
      "  time_this_iter_s: 25.861947774887085\n",
      "  time_total_s: 2363.8330397605896\n",
      "  timers:\n",
      "    learn_throughput: 6447.902\n",
      "    learn_time_ms: 2326.338\n",
      "    load_throughput: 8138169.4\n",
      "    load_time_ms: 1.843\n",
      "    sample_throughput: 579.841\n",
      "    sample_time_ms: 25869.179\n",
      "    update_time_ms: 1.565\n",
      "  timestamp: 1665247556\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1305000\n",
      "  training_iteration: 87\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.622045861554236\n",
      "    mean_inference_ms: 0.41277879178279114\n",
      "    mean_processing_ms: 4.118502520123163\n",
      "  time_since_restore: 2564.440548658371\n",
      "  time_this_iter_s: 29.28264284133911\n",
      "  time_total_s: 2564.440548658371\n",
      "  timestamp: 1665273741\n",
      "  timesteps_since_restore: 1305000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1305000\n",
      "  training_iteration: 87\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     87 |          2564.44 |     1305000 | -1137.04 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     87 |          2363.83 | 1305000 | -2259.32 |               2299.5 |             -8063.79 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:45:56,507\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 226.0x the scale of `vf_clip_param`. This means that it will take more than 226.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1320000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-46-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2229.8106458750144\n",
      "  episode_reward_min: -8063.785226228408\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 440\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.38486766815185547\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.6431587934494019\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016317183151841164\n",
      "          model: {}\n",
      "          policy_loss: 0.005996534135192633\n",
      "          total_loss: 3131.74365234375\n",
      "          vf_explained_var: -1.4773800849354757e-08\n",
      "          vf_loss: 3131.73193359375\n",
      "    num_agent_steps_sampled: 1320000\n",
      "    num_agent_steps_trained: 1320000\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1320000\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.249999999999996\n",
      "    ram_util_percent: 30.35555555555556\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-02-50\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1072.5851958114433\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 440\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.789\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.016894053667783737\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4312853217124939\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01877225935459137\n",
      "        policy_loss: 0.000625555869191885\n",
      "        total_loss: 4533.39306640625\n",
      "        vf_explained_var: 0.9743164777755737\n",
      "        vf_loss: 4533.392578125\n",
      "    load_time_ms: 2.233\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1317888\n",
      "    sample_time_ms: 27959.998\n",
      "    update_time_ms: 2.828\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.93571428571428\n",
      "    ram_util_percent: 24.30952380952381\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06568851712690255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4864765146273005\n",
      "    mean_inference_ms: 0.48261877612365367\n",
      "    mean_raw_obs_processing_ms: 3.784424109667607\n",
      "  time_since_restore: 2389.385491847992\n",
      "  time_this_iter_s: 25.552452087402344\n",
      "  time_total_s: 2389.385491847992\n",
      "  timers:\n",
      "    learn_throughput: 6444.152\n",
      "    learn_time_ms: 2327.692\n",
      "    load_throughput: 7658404.645\n",
      "    load_time_ms: 1.959\n",
      "    sample_throughput: 579.295\n",
      "    sample_time_ms: 25893.547\n",
      "    update_time_ms: 1.593\n",
      "  timestamp: 1665247582\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 88\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     88 |          2389.39 | 1320000 | -2229.81 |               2299.5 |             -8063.79 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:46:22,121\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 223.0x the scale of `vf_clip_param`. This means that it will take more than 223.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1335000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-46-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2165.0194655815103\n",
      "  episode_reward_min: -8063.785226228408\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 445\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.38486766815185547\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.08754120022058487\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018369169905781746\n",
      "          model: {}\n",
      "          policy_loss: 0.0066942693665623665\n",
      "          total_loss: 3004.977783203125\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 3004.9638671875\n",
      "    num_agent_steps_sampled: 1335000\n",
      "    num_agent_steps_trained: 1335000\n",
      "    num_steps_sampled: 1335000\n",
      "    num_steps_trained: 1335000\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.36216216216216\n",
      "    ram_util_percent: 30.35945945945947\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.621219524822948\n",
      "    mean_inference_ms: 0.4127961959813982\n",
      "    mean_processing_ms: 4.118555760192853\n",
      "  time_since_restore: 2593.6007521152496\n",
      "  time_this_iter_s: 29.160203456878662\n",
      "  time_total_s: 2593.6007521152496\n",
      "  timestamp: 1665273770\n",
      "  timesteps_since_restore: 1320000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 88\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     88 |           2593.6 |     1320000 | -1072.59 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-03-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -994.0837233174545\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 445\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.548\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.016894053667783737\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1237246990203857\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.07027580589056015\n",
      "        policy_loss: 0.0005361157818697393\n",
      "        total_loss: 3330.48388671875\n",
      "        vf_explained_var: 0.9840324521064758\n",
      "        vf_loss: 3330.482177734375\n",
      "    load_time_ms: 2.202\n",
      "    num_steps_sampled: 1335000\n",
      "    num_steps_trained: 1332864\n",
      "    sample_time_ms: 27896.071\n",
      "    update_time_ms: 2.81\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.119512195121956\n",
      "    ram_util_percent: 24.399999999999995\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656846790817084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.485716701433806\n",
      "    mean_inference_ms: 0.48260880582458365\n",
      "    mean_raw_obs_processing_ms: 3.786006303560461\n",
      "  time_since_restore: 2415.2462215423584\n",
      "  time_this_iter_s: 25.860729694366455\n",
      "  time_total_s: 2415.2462215423584\n",
      "  timers:\n",
      "    learn_throughput: 6375.911\n",
      "    learn_time_ms: 2352.605\n",
      "    load_throughput: 7698795.888\n",
      "    load_time_ms: 1.948\n",
      "    sample_throughput: 589.373\n",
      "    sample_time_ms: 25450.757\n",
      "    update_time_ms: 1.588\n",
      "  timestamp: 1665247608\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1335000\n",
      "  training_iteration: 89\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:46:48,046\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 217.0x the scale of `vf_clip_param`. This means that it will take more than 217.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     89 |          2415.25 | 1335000 | -2165.02 |               2299.5 |             -8063.79 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1350000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-47-13\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2290.421226881044\n",
      "  episode_reward_min: -8063.785226228408\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 450\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.38486766815185547\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.307645797729492\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.09815486520528793\n",
      "          model: {}\n",
      "          policy_loss: 0.01916634477674961\n",
      "          total_loss: 3219.3349609375\n",
      "          vf_explained_var: -1.6811567249419568e-08\n",
      "          vf_loss: 3219.27783203125\n",
      "    num_agent_steps_sampled: 1350000\n",
      "    num_agent_steps_trained: 1350000\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1350000\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.319444444444443\n",
      "    ram_util_percent: 30.39166666666667\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.620453602580143\n",
      "    mean_inference_ms: 0.4128161820084811\n",
      "    mean_processing_ms: 4.118350489021236\n",
      "  time_since_restore: 2622.6685638427734\n",
      "  time_this_iter_s: 29.067811727523804\n",
      "  time_total_s: 2622.6685638427734\n",
      "  timestamp: 1665273799\n",
      "  timesteps_since_restore: 1335000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1335000\n",
      "  training_iteration: 89\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     89 |          2622.67 |     1335000 | -994.084 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-03-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -959.6790556692515\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 450\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.953\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.28530678153038025\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016675032675266266\n",
      "        policy_loss: 0.0012183149810880423\n",
      "        total_loss: 5623.73974609375\n",
      "        vf_explained_var: 0.969857931137085\n",
      "        vf_loss: 5623.7373046875\n",
      "    load_time_ms: 2.208\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1347840\n",
      "    sample_time_ms: 27793.801\n",
      "    update_time_ms: 2.821\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.80714285714286\n",
      "    ram_util_percent: 24.31904761904762\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06568080255809378\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4849366106895316\n",
      "    mean_inference_ms: 0.48259737070511494\n",
      "    mean_raw_obs_processing_ms: 3.787624457569184\n",
      "  time_since_restore: 2440.3177206516266\n",
      "  time_this_iter_s: 25.07149910926819\n",
      "  time_total_s: 2440.3177206516266\n",
      "  timers:\n",
      "    learn_throughput: 6322.686\n",
      "    learn_time_ms: 2372.409\n",
      "    load_throughput: 7077640.283\n",
      "    load_time_ms: 2.119\n",
      "    sample_throughput: 604.805\n",
      "    sample_time_ms: 24801.376\n",
      "    update_time_ms: 1.597\n",
      "  timestamp: 1665247633\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 90\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:47:13,208\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 229.0x the scale of `vf_clip_param`. This means that it will take more than 229.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     90 |          2440.32 | 1350000 | -2290.42 |               2299.5 |             -8063.79 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 4.619705383496139\n",
      "    mean_inference_ms: 0.4128338873086125\n",
      "    mean_processing_ms: 4.118130406385417\n",
      "  time_since_restore: 2651.8176307678223\n",
      "  time_this_iter_s: 29.149066925048828\n",
      "  time_total_s: 2651.8176307678223\n",
      "  timestamp: 1665273829\n",
      "  timesteps_since_restore: 1350000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 90\n",
      "  trial_id: a95f16f0\n",
      "  \n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1365000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-47-50\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2212.594740917076\n",
      "  episode_reward_min: -8063.785226228408\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 455\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5773015022277832\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.14121504127979279\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006207666825503111\n",
      "          model: {}\n",
      "          policy_loss: 0.0018437012331560254\n",
      "          total_loss: 2730.298828125\n",
      "          vf_explained_var: 6.622738357719982e-09\n",
      "          vf_loss: 2730.292724609375\n",
      "    num_agent_steps_sampled: 1365000\n",
      "    num_agent_steps_trained: 1365000\n",
      "    num_steps_sampled: 1365000\n",
      "    num_steps_trained: 1365000\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.61132075471698\n",
      "    ram_util_percent: 30.286792452830195\n",
      "  pid: 307\n",
=======
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     90 |          2651.82 |     1350000 | -959.679 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-04-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1066.957102715363\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 455\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.19\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6355162858963013\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01650075986981392\n",
      "        policy_loss: 0.0014366336399689317\n",
      "        total_loss: 4339.79736328125\n",
      "        vf_explained_var: 0.977160632610321\n",
      "        vf_loss: 4339.79541015625\n",
      "    load_time_ms: 2.269\n",
      "    num_steps_sampled: 1365000\n",
      "    num_steps_trained: 1362816\n",
      "    sample_time_ms: 27788.215\n",
      "    update_time_ms: 2.904\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.15714285714285\n",
      "    ram_util_percent: 24.369047619047613\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06567722058282527\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4841903099071097\n",
      "    mean_inference_ms: 0.4825867245690937\n",
      "    mean_raw_obs_processing_ms: 3.791393584388991\n",
      "  time_since_restore: 2477.1437635421753\n",
      "  time_this_iter_s: 36.826042890548706\n",
      "  time_total_s: 2477.1437635421753\n",
      "  timers:\n",
      "    learn_throughput: 6123.701\n",
      "    learn_time_ms: 2449.499\n",
      "    load_throughput: 6909132.44\n",
      "    load_time_ms: 2.171\n",
      "    sample_throughput: 590.971\n",
      "    sample_time_ms: 25381.941\n",
      "    update_time_ms: 1.556\n",
      "  timestamp: 1665247670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1365000\n",
      "  training_iteration: 91\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     91 |          2477.14 | 1365000 | -2212.59 |               2299.5 |             -8063.79 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:47:50,100\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 221.0x the scale of `vf_clip_param`. This means that it will take more than 221.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1380000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-48-14\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2252.0437007000787\n",
      "  episode_reward_min: -8063.785226228408\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 460\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.5200713872909546\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01039374340325594\n",
      "          model: {}\n",
      "          policy_loss: 0.002303231041878462\n",
      "          total_loss: 3156.128662109375\n",
      "          vf_explained_var: -6.622738357719982e-09\n",
      "          vf_loss: 3156.123779296875\n",
      "    num_agent_steps_sampled: 1380000\n",
      "    num_agent_steps_trained: 1380000\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1380000\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.591428571428565\n",
      "    ram_util_percent: 30.45142857142857\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.618939753996901\n",
      "    mean_inference_ms: 0.41285260425875747\n",
      "    mean_processing_ms: 4.117950541398691\n",
      "  time_since_restore: 2681.0428171157837\n",
      "  time_this_iter_s: 29.225186347961426\n",
      "  time_total_s: 2681.0428171157837\n",
      "  timestamp: 1665273858\n",
      "  timesteps_since_restore: 1365000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1365000\n",
      "  training_iteration: 91\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     91 |          2681.04 |     1365000 | -1066.96 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-04-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -978.7637187619772\n",
      "  episode_reward_min: -6715.881975260267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 460\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.884\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8607137799263\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.039683688431978226\n",
      "        policy_loss: 0.004265520256012678\n",
      "        total_loss: 5037.36767578125\n",
      "        vf_explained_var: 0.9618366360664368\n",
      "        vf_loss: 5037.36181640625\n",
      "    load_time_ms: 2.392\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1377792\n",
      "    sample_time_ms: 27824.312\n",
      "    update_time_ms: 2.894\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.780952380952385\n",
      "    ram_util_percent: 24.333333333333332\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06567392920604627\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.483470515700866\n",
      "    mean_inference_ms: 0.4825753582660793\n",
      "    mean_raw_obs_processing_ms: 3.794897675350361\n",
      "  time_since_restore: 2501.676574230194\n",
      "  time_this_iter_s: 24.5328106880188\n",
      "  time_total_s: 2501.676574230194\n",
      "  timers:\n",
      "    learn_throughput: 6150.226\n",
      "    learn_time_ms: 2438.935\n",
      "    load_throughput: 7589668.858\n",
      "    load_time_ms: 1.976\n",
      "    sample_throughput: 608.275\n",
      "    sample_time_ms: 24659.909\n",
      "    update_time_ms: 1.545\n",
      "  timestamp: 1665247694\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 92\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:48:14,688\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 225.0x the scale of `vf_clip_param`. This means that it will take more than 225.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     92 |          2501.68 | 1380000 | -2252.04 |               2299.5 |             -8063.79 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1395000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-48-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2299.357529373259\n",
      "  episode_reward_min: -8063.785226228408\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 465\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.9399662017822266\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027416901662945747\n",
      "          model: {}\n",
      "          policy_loss: 0.017113078385591507\n",
      "          total_loss: 3456.958984375\n",
      "          vf_explained_var: -4.58497284583359e-09\n",
      "          vf_loss: 3456.93359375\n",
      "    num_agent_steps_sampled: 1395000\n",
      "    num_agent_steps_trained: 1395000\n",
      "    num_steps_sampled: 1395000\n",
      "    num_steps_trained: 1395000\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.322222222222223\n",
      "    ram_util_percent: 30.438888888888894\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.618338055923379\n",
      "    mean_inference_ms: 0.41287272278647463\n",
      "    mean_processing_ms: 4.117790367046256\n",
      "  time_since_restore: 2710.4996354579926\n",
      "  time_this_iter_s: 29.456818342208862\n",
      "  time_total_s: 2710.4996354579926\n",
      "  timestamp: 1665273887\n",
      "  timesteps_since_restore: 1380000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 92\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     92 |           2710.5 |     1380000 | -978.764 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-05-16\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1055.3252169441719\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 465\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.171\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.1694693565368652\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01278998889029026\n",
      "        policy_loss: 0.0036625086795538664\n",
      "        total_loss: 7786.6787109375\n",
      "        vf_explained_var: 0.960544764995575\n",
      "        vf_loss: 7786.67529296875\n",
      "    load_time_ms: 2.481\n",
      "    num_steps_sampled: 1395000\n",
      "    num_steps_trained: 1392768\n",
      "    sample_time_ms: 27695.559\n",
      "    update_time_ms: 2.862\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.75853658536585\n",
      "    ram_util_percent: 24.37073170731707\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06567077027791565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.482787384104623\n",
      "    mean_inference_ms: 0.4825657150452687\n",
      "    mean_raw_obs_processing_ms: 3.7984486049705173\n",
      "  time_since_restore: 2527.0701332092285\n",
      "  time_this_iter_s: 25.393558979034424\n",
      "  time_total_s: 2527.0701332092285\n",
      "  timers:\n",
      "    learn_throughput: 6019.604\n",
      "    learn_time_ms: 2491.858\n",
      "    load_throughput: 7399362.555\n",
      "    load_time_ms: 2.027\n",
      "    sample_throughput: 608.65\n",
      "    sample_time_ms: 24644.705\n",
      "    update_time_ms: 1.558\n",
      "  timestamp: 1665247720\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1395000\n",
      "  training_iteration: 93\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     93 |          2527.07 | 1395000 | -2299.36 |               2299.5 |             -8063.79 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:48:40,140\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 230.0x the scale of `vf_clip_param`. This means that it will take more than 230.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1410000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-49-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2292.401332484245\n",
      "  episode_reward_min: -8059.548538429305\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 470\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.5357040166854858\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.038006577640771866\n",
      "          model: {}\n",
      "          policy_loss: 0.02134809084236622\n",
      "          total_loss: 3351.501220703125\n",
      "          vf_explained_var: -1.0188828447610376e-08\n",
      "          vf_loss: 3351.468994140625\n",
      "    num_agent_steps_sampled: 1410000\n",
      "    num_agent_steps_trained: 1410000\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1410000\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.36666666666666\n",
      "    ram_util_percent: 30.44166666666667\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.617772997778211\n",
      "    mean_inference_ms: 0.4128977506061277\n",
      "    mean_processing_ms: 4.117620266924131\n",
      "  time_since_restore: 2739.4671897888184\n",
      "  time_this_iter_s: 28.967554330825806\n",
      "  time_total_s: 2739.4671897888184\n",
      "  timestamp: 1665273916\n",
      "  timesteps_since_restore: 1395000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1395000\n",
      "  training_iteration: 93\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     93 |          2739.47 |     1395000 | -1055.33 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-05-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1099.7615214984298\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 470\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.887\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4456946551799774\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01528334990143776\n",
      "        policy_loss: 0.0012774090282619\n",
      "        total_loss: 5059.5634765625\n",
      "        vf_explained_var: 0.9692041277885437\n",
      "        vf_loss: 5059.56103515625\n",
      "    load_time_ms: 2.484\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1407744\n",
      "    sample_time_ms: 27648.878\n",
      "    update_time_ms: 2.843\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.30476190476191\n",
      "    ram_util_percent: 24.364285714285714\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656679495976928\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.482125714364372\n",
      "    mean_inference_ms: 0.48255756026517643\n",
      "    mean_raw_obs_processing_ms: 3.8008804152809246\n",
      "  time_since_restore: 2551.811856985092\n",
      "  time_this_iter_s: 24.741723775863647\n",
      "  time_total_s: 2551.811856985092\n",
      "  timers:\n",
      "    learn_throughput: 6071.102\n",
      "    learn_time_ms: 2470.721\n",
      "    load_throughput: 8244710.323\n",
      "    load_time_ms: 1.819\n",
      "    sample_throughput: 609.151\n",
      "    sample_time_ms: 24624.455\n",
      "    update_time_ms: 1.465\n",
      "  timestamp: 1665247744\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 94\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     94 |          2551.81 | 1410000 |  -2292.4 |               2299.5 |             -8059.55 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:49:04,948\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 229.0x the scale of `vf_clip_param`. This means that it will take more than 229.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1425000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-49-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2284.749127440857\n",
      "  episode_reward_min: -8059.548538429305\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 475\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1247962713241577\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.033538393676280975\n",
      "          model: {}\n",
      "          policy_loss: 0.0132094481959939\n",
      "          total_loss: 3493.22119140625\n",
      "          vf_explained_var: -1.2226593959496768e-08\n",
      "          vf_loss: 3493.197998046875\n",
      "    num_agent_steps_sampled: 1425000\n",
      "    num_agent_steps_trained: 1425000\n",
      "    num_steps_sampled: 1425000\n",
      "    num_steps_trained: 1425000\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.632558139534886\n",
      "    ram_util_percent: 30.393023255813954\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.617235603031214\n",
      "    mean_inference_ms: 0.4129275729249891\n",
      "    mean_processing_ms: 4.117420011938783\n",
      "  time_since_restore: 2768.74352312088\n",
      "  time_this_iter_s: 29.276333332061768\n",
      "  time_total_s: 2768.74352312088\n",
      "  timestamp: 1665273946\n",
      "  timesteps_since_restore: 1410000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 94\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     94 |          2768.74 |     1410000 | -1099.76 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-06-15\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1106.0601510916756\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 475\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.64\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5146192908287048\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026105094701051712\n",
      "        policy_loss: 0.0005025003920309246\n",
      "        total_loss: 4274.2919921875\n",
      "        vf_explained_var: 0.9779508709907532\n",
      "        vf_loss: 4274.291015625\n",
      "    load_time_ms: 2.455\n",
      "    num_steps_sampled: 1425000\n",
      "    num_steps_trained: 1422720\n",
      "    sample_time_ms: 27682.054\n",
      "    update_time_ms: 2.838\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.6219512195122\n",
      "    ram_util_percent: 24.39512195121951\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06566524895175077\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4814853606959195\n",
      "    mean_inference_ms: 0.482547603530054\n",
      "    mean_raw_obs_processing_ms: 3.802836045942125\n",
      "  time_since_restore: 2581.912500143051\n",
      "  time_this_iter_s: 30.100643157958984\n",
      "  time_total_s: 2581.912500143051\n",
      "  timers:\n",
      "    learn_throughput: 6085.19\n",
      "    learn_time_ms: 2465.001\n",
      "    load_throughput: 8242873.988\n",
      "    load_time_ms: 1.82\n",
      "    sample_throughput: 612.39\n",
      "    sample_time_ms: 24494.212\n",
      "    update_time_ms: 1.702\n",
      "  timestamp: 1665247775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1425000\n",
      "  training_iteration: 95\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:49:35,126\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 228.0x the scale of `vf_clip_param`. This means that it will take more than 228.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     95 |          2581.91 | 1425000 | -2284.75 |               2299.5 |             -8059.55 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1440000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-50-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2334.0966712847353\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 480\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.845853328704834\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022962773218750954\n",
      "          model: {}\n",
      "          policy_loss: 0.011777202598750591\n",
      "          total_loss: 3591.561767578125\n",
      "          vf_explained_var: -8.151062935723985e-09\n",
      "          vf_loss: 3591.543212890625\n",
      "    num_agent_steps_sampled: 1440000\n",
      "    num_agent_steps_trained: 1440000\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1440000\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.555263157894736\n",
      "    ram_util_percent: 30.52894736842106\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.616620585871333\n",
      "    mean_inference_ms: 0.41295588171825814\n",
      "    mean_processing_ms: 4.117196417199374\n",
      "  time_since_restore: 2797.7398715019226\n",
      "  time_this_iter_s: 28.99634838104248\n",
      "  time_total_s: 2797.7398715019226\n",
      "  timestamp: 1665273975\n",
      "  timesteps_since_restore: 1425000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1425000\n",
      "  training_iteration: 95\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     95 |          2797.74 |     1425000 | -1106.06 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-06-44\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1116.84102316599\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 480\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.439\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8432796597480774\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013970511965453625\n",
      "        policy_loss: 0.0013001176994293928\n",
      "        total_loss: 4018.2099609375\n",
      "        vf_explained_var: 0.9740858674049377\n",
      "        vf_loss: 4018.208984375\n",
      "    load_time_ms: 2.448\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1437696\n",
      "    sample_time_ms: 27678.052\n",
      "    update_time_ms: 2.719\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34047619047618\n",
      "    ram_util_percent: 24.388095238095236\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06566257154826763\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.480871469076808\n",
      "    mean_inference_ms: 0.4825368744658779\n",
      "    mean_raw_obs_processing_ms: 3.805002183452022\n",
      "  time_since_restore: 2608.379366159439\n",
      "  time_this_iter_s: 26.46686601638794\n",
      "  time_total_s: 2608.379366159439\n",
      "  timers:\n",
      "    learn_throughput: 6116.951\n",
      "    learn_time_ms: 2452.202\n",
      "    load_throughput: 8244602.28\n",
      "    load_time_ms: 1.819\n",
      "    sample_throughput: 610.302\n",
      "    sample_time_ms: 24577.984\n",
      "    update_time_ms: 1.537\n",
      "  timestamp: 1665247801\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 96\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:50:01,681\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 233.0x the scale of `vf_clip_param`. This means that it will take more than 233.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     96 |          2608.38 | 1440000 |  -2334.1 |               2299.5 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1455000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-50-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2406.5079024794672\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 485\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9013785719871521\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013860725797712803\n",
      "          model: {}\n",
      "          policy_loss: 0.0021538890432566404\n",
      "          total_loss: 3315.369873046875\n",
      "          vf_explained_var: 4.0755314678619925e-09\n",
      "          vf_loss: 3315.36328125\n",
      "    num_agent_steps_sampled: 1455000\n",
      "    num_agent_steps_trained: 1455000\n",
      "    num_steps_sampled: 1455000\n",
      "    num_steps_trained: 1455000\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.637837837837836\n",
      "    ram_util_percent: 30.564864864864866\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.616006356778933\n",
      "    mean_inference_ms: 0.4129869700141948\n",
      "    mean_processing_ms: 4.1169811176130455\n",
      "  time_since_restore: 2826.890300512314\n",
      "  time_this_iter_s: 29.150429010391235\n",
      "  time_total_s: 2826.890300512314\n",
      "  timestamp: 1665274004\n",
      "  timesteps_since_restore: 1440000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 96\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     96 |          2826.89 |     1440000 | -1116.84 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-07-13\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1107.065118037445\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 485\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.358\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.376842498779297\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01408358197659254\n",
      "        policy_loss: 0.004214771091938019\n",
      "        total_loss: 5271.771484375\n",
      "        vf_explained_var: 0.9773116111755371\n",
      "        vf_loss: 5271.7666015625\n",
      "    load_time_ms: 2.575\n",
      "    num_steps_sampled: 1455000\n",
      "    num_steps_trained: 1452672\n",
      "    sample_time_ms: 27647.256\n",
      "    update_time_ms: 2.78\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.75121951219512\n",
      "    ram_util_percent: 24.397560975609757\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06566033692053631\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4802190358875866\n",
      "    mean_inference_ms: 0.48252803981498227\n",
      "    mean_raw_obs_processing_ms: 3.8073081518010974\n",
      "  time_since_restore: 2634.3775947093964\n",
      "  time_this_iter_s: 25.998228549957275\n",
      "  time_total_s: 2634.3775947093964\n",
      "  timers:\n",
      "    learn_throughput: 6315.118\n",
      "    learn_time_ms: 2375.253\n",
      "    load_throughput: 8296133.762\n",
      "    load_time_ms: 1.808\n",
      "    sample_throughput: 608.06\n",
      "    sample_time_ms: 24668.633\n",
      "    update_time_ms: 1.539\n",
      "  timestamp: 1665247827\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1455000\n",
      "  training_iteration: 97\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:50:27,789\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 241.0x the scale of `vf_clip_param`. This means that it will take more than 241.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     97 |          2634.38 | 1455000 | -2406.51 |               2299.5 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1470000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-50-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2206.156435469608\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 490\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.0879443883895874\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027066823095083237\n",
      "          model: {}\n",
      "          policy_loss: 0.010124475695192814\n",
      "          total_loss: 2753.283203125\n",
      "          vf_explained_var: -9.16994569166718e-09\n",
      "          vf_loss: 2753.265380859375\n",
      "    num_agent_steps_sampled: 1470000\n",
      "    num_agent_steps_trained: 1470000\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1470000\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.623255813953488\n",
      "    ram_util_percent: 30.416279069767445\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.615436395434574\n",
      "    mean_inference_ms: 0.4130147908395112\n",
      "    mean_processing_ms: 4.11680357957954\n",
      "  time_since_restore: 2855.846254348755\n",
      "  time_this_iter_s: 28.95595383644104\n",
      "  time_total_s: 2855.846254348755\n",
      "  timestamp: 1665274033\n",
      "  timesteps_since_restore: 1455000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1455000\n",
      "  training_iteration: 97\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     97 |          2855.85 |     1455000 | -1107.07 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-07-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1135.0522104188042\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 490\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.716\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.457065224647522\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016824068501591682\n",
      "        policy_loss: -0.00010781015589600429\n",
      "        total_loss: 6190.90478515625\n",
      "        vf_explained_var: 0.9712573289871216\n",
      "        vf_loss: 6190.904296875\n",
      "    load_time_ms: 2.579\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1467648\n",
      "    sample_time_ms: 27653.829\n",
      "    update_time_ms: 2.774\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.59285714285714\n",
      "    ram_util_percent: 24.38095238095238\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06565888071345855\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.479626704059647\n",
      "    mean_inference_ms: 0.4825249068662537\n",
      "    mean_raw_obs_processing_ms: 3.810469247958963\n",
      "  time_since_restore: 2664.7474615573883\n",
      "  time_this_iter_s: 30.369866847991943\n",
      "  time_total_s: 2664.7474615573883\n",
      "  timers:\n",
      "    learn_throughput: 6381.748\n",
      "    learn_time_ms: 2350.453\n",
      "    load_throughput: 8844015.857\n",
      "    load_time_ms: 1.696\n",
      "    sample_throughput: 595.821\n",
      "    sample_time_ms: 25175.357\n",
      "    update_time_ms: 1.501\n",
      "  timestamp: 1665247858\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 98\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:50:58,234\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 221.0x the scale of `vf_clip_param`. This means that it will take more than 221.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     98 |          2664.75 | 1470000 | -2206.16 |               2299.5 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1485000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-51-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2119.642309816424\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 495\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.077091932296753\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018547195941209793\n",
      "          model: {}\n",
      "          policy_loss: 0.007992634549736977\n",
      "          total_loss: 2715.85009765625\n",
      "          vf_explained_var: -3.056648489874192e-09\n",
      "          vf_loss: 2715.83642578125\n",
      "    num_agent_steps_sampled: 1485000\n",
      "    num_agent_steps_trained: 1485000\n",
      "    num_steps_sampled: 1485000\n",
      "    num_steps_trained: 1485000\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.078378378378382\n",
      "    ram_util_percent: 30.45945945945946\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.614928832718096\n",
      "    mean_inference_ms: 0.413041593528869\n",
      "    mean_processing_ms: 4.116582579432514\n",
      "  time_since_restore: 2885.0860941410065\n",
      "  time_this_iter_s: 29.239839792251587\n",
      "  time_total_s: 2885.0860941410065\n",
      "  timestamp: 1665274062\n",
      "  timesteps_since_restore: 1470000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 98\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     98 |          2885.09 |     1470000 | -1135.05 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-08-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1145.8055458351268\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 495\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.586\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.025341082364320755\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5346613526344299\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.047078538686037064\n",
      "        policy_loss: -0.0001362111943308264\n",
      "        total_loss: 4071.994873046875\n",
      "        vf_explained_var: 0.9742745161056519\n",
      "        vf_loss: 4071.993896484375\n",
      "    load_time_ms: 2.641\n",
      "    num_steps_sampled: 1485000\n",
      "    num_steps_trained: 1482624\n",
      "    sample_time_ms: 27688.379\n",
      "    update_time_ms: 2.901\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.55\n",
      "    ram_util_percent: 24.511904761904763\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06565774367679876\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4790900384650865\n",
      "    mean_inference_ms: 0.48252555754684023\n",
      "    mean_raw_obs_processing_ms: 3.8125952791562456\n",
      "  time_since_restore: 2690.10622048378\n",
      "  time_this_iter_s: 25.3587589263916\n",
      "  time_total_s: 2690.10622048378\n",
      "  timers:\n",
      "    learn_throughput: 6431.473\n",
      "    learn_time_ms: 2332.28\n",
      "    load_throughput: 8685897.312\n",
      "    load_time_ms: 1.727\n",
      "    sample_throughput: 596.574\n",
      "    sample_time_ms: 25143.582\n",
      "    update_time_ms: 1.495\n",
      "  timestamp: 1665247883\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1485000\n",
      "  training_iteration: 99\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:51:23,681\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 212.0x the scale of `vf_clip_param`. This means that it will take more than 212.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |     99 |          2690.11 | 1485000 | -2119.64 |               2299.5 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n"
=======
      "    mean_env_wait_ms: 4.6143297682504265\n",
      "    mean_inference_ms: 0.41306229453780574\n",
      "    mean_processing_ms: 4.116454317768105\n",
      "  time_since_restore: 2914.490220785141\n",
      "  time_this_iter_s: 29.40412664413452\n",
      "  time_total_s: 2914.490220785141\n",
      "  timestamp: 1665274091\n",
      "  timesteps_since_restore: 1485000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1485000\n",
      "  training_iteration: 99\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |     99 |          2914.49 |     1485000 | -1145.81 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1500000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-51-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2044.122912103021\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 500\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.8770887851715088\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029206251725554466\n",
      "          model: {}\n",
      "          policy_loss: 0.012474428862333298\n",
      "          total_loss: 3423.184326171875\n",
      "          vf_explained_var: 5.094414334827491e-10\n",
      "          vf_loss: 3423.163818359375\n",
      "    num_agent_steps_sampled: 1500000\n",
      "    num_agent_steps_trained: 1500000\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1500000\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.71111111111111\n",
      "    ram_util_percent: 30.46111111111111\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1083.5306336457922\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 500\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.541\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03801162168383598\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.692762017250061\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03342410549521446\n",
      "        policy_loss: 0.004095843061804771\n",
      "        total_loss: 2646.354248046875\n",
      "        vf_explained_var: 0.9727556705474854\n",
      "        vf_loss: 2646.34912109375\n",
      "    load_time_ms: 2.611\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1497600\n",
      "    sample_time_ms: 27762.694\n",
      "    update_time_ms: 2.872\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.127906976744185\n",
      "    ram_util_percent: 24.444186046511632\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06565611549251157\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4785530702501757\n",
      "    mean_inference_ms: 0.4825262727548622\n",
      "    mean_raw_obs_processing_ms: 3.8134919346309575\n",
      "  time_since_restore: 2715.4189195632935\n",
      "  time_this_iter_s: 25.31269907951355\n",
      "  time_total_s: 2715.4189195632935\n",
      "  timers:\n",
      "    learn_throughput: 6474.951\n",
      "    learn_time_ms: 2316.62\n",
      "    load_throughput: 8740682.699\n",
      "    load_time_ms: 1.716\n",
      "    sample_throughput: 595.625\n",
      "    sample_time_ms: 25183.648\n",
      "    update_time_ms: 1.516\n",
      "  timestamp: 1665247909\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 100\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:51:49,068\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 204.0x the scale of `vf_clip_param`. This means that it will take more than 204.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    100 |          2715.42 | 1500000 | -2044.12 |               2299.5 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1515000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-52-14\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2299.497932707432\n",
      "  episode_reward_mean: -2135.6271557639757\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 505\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2886507511138916\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.4691519737243652\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007646686397492886\n",
      "          model: {}\n",
      "          policy_loss: 0.001995906000956893\n",
      "          total_loss: 3043.877685546875\n",
      "          vf_explained_var: 1.0188828669654981e-09\n",
      "          vf_loss: 3043.873291015625\n",
      "    num_agent_steps_sampled: 1515000\n",
      "    num_agent_steps_trained: 1515000\n",
      "    num_steps_sampled: 1515000\n",
      "    num_steps_trained: 1515000\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.237837837837837\n",
      "    ram_util_percent: 30.470270270270273\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.613803361673012\n",
      "    mean_inference_ms: 0.41309183873977173\n",
      "    mean_processing_ms: 4.116190039670774\n",
      "  time_since_restore: 2944.381718635559\n",
      "  time_this_iter_s: 29.89149785041809\n",
      "  time_total_s: 2944.381718635559\n",
      "  timestamp: 1665274121\n",
      "  timesteps_since_restore: 1500000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 100\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    100 |          2944.38 |     1500000 | -1083.53 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-09-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1068.1257062109723\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 505\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.152\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03801162168383598\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3296489715576172\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013097870163619518\n",
      "        policy_loss: 0.001454950892366469\n",
      "        total_loss: 2499.485595703125\n",
      "        vf_explained_var: 0.9798266291618347\n",
      "        vf_loss: 2499.4833984375\n",
      "    load_time_ms: 2.564\n",
      "    num_steps_sampled: 1515000\n",
      "    num_steps_trained: 1512576\n",
      "    sample_time_ms: 27731.759\n",
      "    update_time_ms: 2.889\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.0390243902439\n",
      "    ram_util_percent: 24.38780487804878\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06565450254834843\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4779997702079597\n",
      "    mean_inference_ms: 0.4825273254905191\n",
      "    mean_raw_obs_processing_ms: 3.8133176090358365\n",
      "  time_since_restore: 2741.224457502365\n",
      "  time_this_iter_s: 25.805537939071655\n",
      "  time_total_s: 2741.224457502365\n",
      "  timers:\n",
      "    learn_throughput: 6449.839\n",
      "    learn_time_ms: 2325.64\n",
      "    load_throughput: 8958487.235\n",
      "    load_time_ms: 1.674\n",
      "    sample_throughput: 623.111\n",
      "    sample_time_ms: 24072.742\n",
      "    update_time_ms: 1.53\n",
      "  timestamp: 1665247934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1515000\n",
      "  training_iteration: 101\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:52:14,983\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 214.0x the scale of `vf_clip_param`. This means that it will take more than 214.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    101 |          2741.22 | 1515000 | -2135.63 |               2299.5 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 4.6132359090590915\n",
      "    mean_inference_ms: 0.4131198780951124\n",
      "    mean_processing_ms: 4.115918059297952\n",
      "  time_since_restore: 2973.303131580353\n",
      "  time_this_iter_s: 28.9214129447937\n",
      "  time_total_s: 2973.303131580353\n",
      "  timestamp: 1665274150\n",
      "  timesteps_since_restore: 1515000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1515000\n",
      "  training_iteration: 101\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    101 |           2973.3 |     1515000 | -1068.13 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1530000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-52-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2196.3880287761594\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 510\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.1443253755569458\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.05382072925567627\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02295498736202717\n",
      "          model: {}\n",
      "          policy_loss: 0.007689173799008131\n",
      "          total_loss: 3172.052734375\n",
      "          vf_explained_var: -1.5792684493476372e-08\n",
      "          vf_loss: 3172.041748046875\n",
      "    num_agent_steps_sampled: 1530000\n",
      "    num_agent_steps_trained: 1530000\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1530000\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.597222222222218\n",
      "    ram_util_percent: 30.55833333333333\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-09-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2304.9932155065926\n",
      "  episode_reward_mean: -1026.0753300720828\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 510\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.383\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03801162168383598\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.20896804332733154\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01642485521733761\n",
      "        policy_loss: 0.001751026837155223\n",
      "        total_loss: 3862.204345703125\n",
      "        vf_explained_var: 0.9791273474693298\n",
      "        vf_loss: 3862.201904296875\n",
      "    load_time_ms: 2.563\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1527552\n",
      "    sample_time_ms: 27700.117\n",
      "    update_time_ms: 2.985\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.919047619047625\n",
      "    ram_util_percent: 24.37142857142857\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06565370346549167\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4775203242458197\n",
      "    mean_inference_ms: 0.4825329231109293\n",
      "    mean_raw_obs_processing_ms: 3.8119453117267854\n",
      "  time_since_restore: 2766.8327326774597\n",
      "  time_this_iter_s: 25.608275175094604\n",
      "  time_total_s: 2766.8327326774597\n",
      "  timers:\n",
      "    learn_throughput: 6428.218\n",
      "    learn_time_ms: 2333.462\n",
      "    load_throughput: 8945749.264\n",
      "    load_time_ms: 1.677\n",
      "    sample_throughput: 620.552\n",
      "    sample_time_ms: 24172.023\n",
      "    update_time_ms: 1.574\n",
      "  timestamp: 1665247960\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 102\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:52:40,687\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 220.0x the scale of `vf_clip_param`. This means that it will take more than 220.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    102 |          2766.83 | 1530000 | -2196.39 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1545000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-53-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2099.1870619867077\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 515\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.1443253755569458\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.6053440570831299\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02700924500823021\n",
      "          model: {}\n",
      "          policy_loss: 0.0033592230174690485\n",
      "          total_loss: 2437.7412109375\n",
      "          vf_explained_var: -3.5660898678457897e-09\n",
      "          vf_loss: 2437.734130859375\n",
      "    num_agent_steps_sampled: 1545000\n",
      "    num_agent_steps_trained: 1545000\n",
      "    num_steps_sampled: 1545000\n",
      "    num_steps_trained: 1545000\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.28108108108108\n",
      "    ram_util_percent: 30.54864864864864\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.612721741776707\n",
      "    mean_inference_ms: 0.41314864070523205\n",
      "    mean_processing_ms: 4.115606900402228\n",
      "  time_since_restore: 3002.446583032608\n",
      "  time_this_iter_s: 29.14345145225525\n",
      "  time_total_s: 3002.446583032608\n",
      "  timestamp: 1665274180\n",
      "  timesteps_since_restore: 1530000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 102\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    102 |          3002.45 |     1530000 | -1026.08 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-10-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -973.1172966662795\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 515\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.114\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03801162168383598\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.550955891609192\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04918600618839264\n",
      "        policy_loss: 0.006843113340437412\n",
      "        total_loss: 3389.434814453125\n",
      "        vf_explained_var: 0.9743605852127075\n",
      "        vf_loss: 3389.42626953125\n",
      "    load_time_ms: 2.528\n",
      "    num_steps_sampled: 1545000\n",
      "    num_steps_trained: 1542528\n",
      "    sample_time_ms: 27804.665\n",
      "    update_time_ms: 3.003\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.78372093023256\n",
      "    ram_util_percent: 24.406976744186046\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06565288456557458\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.477101337700536\n",
      "    mean_inference_ms: 0.48254013369823295\n",
      "    mean_raw_obs_processing_ms: 3.8106595837296204\n",
      "  time_since_restore: 2792.320882797241\n",
      "  time_this_iter_s: 25.488150119781494\n",
      "  time_total_s: 2792.320882797241\n",
      "  timers:\n",
      "    learn_throughput: 6572.14\n",
      "    learn_time_ms: 2282.362\n",
      "    load_throughput: 9805273.985\n",
      "    load_time_ms: 1.53\n",
      "    sample_throughput: 619.0\n",
      "    sample_time_ms: 24232.629\n",
      "    update_time_ms: 1.637\n",
      "  timestamp: 1665247986\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1545000\n",
      "  training_iteration: 103\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:53:06,252\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 210.0x the scale of `vf_clip_param`. This means that it will take more than 210.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    103 |          2792.32 | 1545000 | -2099.19 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1560000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-53-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2104.0479402351784\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 520\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.1443253755569458\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0331465005874634\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.11125216633081436\n",
      "          model: {}\n",
      "          policy_loss: 0.017396410927176476\n",
      "          total_loss: 3077.451904296875\n",
      "          vf_explained_var: -9.679387069638778e-09\n",
      "          vf_loss: 3077.418212890625\n",
      "    num_agent_steps_sampled: 1560000\n",
      "    num_agent_steps_trained: 1560000\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1560000\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.65\n",
      "    ram_util_percent: 30.55555555555555\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.612220755990965\n",
      "    mean_inference_ms: 0.41317654056976716\n",
      "    mean_processing_ms: 4.115254173786068\n",
      "  time_since_restore: 3032.4468619823456\n",
      "  time_this_iter_s: 30.00027894973755\n",
      "  time_total_s: 3032.4468619823456\n",
      "  timestamp: 1665274210\n",
      "  timesteps_since_restore: 1545000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1545000\n",
      "  training_iteration: 103\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    103 |          3032.45 |     1545000 | -973.117 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-10-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -890.56837859654\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 520\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.063\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0315355062484741\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015799839049577713\n",
      "        policy_loss: 0.0024094178806990385\n",
      "        total_loss: 4196.25732421875\n",
      "        vf_explained_var: 0.9807722568511963\n",
      "        vf_loss: 4196.25390625\n",
      "    load_time_ms: 2.433\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1557504\n",
      "    sample_time_ms: 27763.307\n",
      "    update_time_ms: 3.001\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.12682926829268\n",
      "    ram_util_percent: 24.37073170731707\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06565215276124221\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.476690863942105\n",
      "    mean_inference_ms: 0.4825499252832584\n",
      "    mean_raw_obs_processing_ms: 3.809479745217505\n",
      "  time_since_restore: 2817.394424676895\n",
      "  time_this_iter_s: 25.07354187965393\n",
      "  time_total_s: 2817.394424676895\n",
      "  timers:\n",
      "    learn_throughput: 6522.802\n",
      "    learn_time_ms: 2299.625\n",
      "    load_throughput: 9860443.539\n",
      "    load_time_ms: 1.521\n",
      "    sample_throughput: 618.615\n",
      "    sample_time_ms: 24247.725\n",
      "    update_time_ms: 1.642\n",
      "  timestamp: 1665248011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 104\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:53:31,417\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 210.0x the scale of `vf_clip_param`. This means that it will take more than 210.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    104 |          2817.39 | 1560000 | -2104.05 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1575000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-53-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2094.962983886084\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 525\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2164880633354187\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.5232368111610413\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05643728747963905\n",
      "          model: {}\n",
      "          policy_loss: 0.0191804189234972\n",
      "          total_loss: 3374.81005859375\n",
      "          vf_explained_var: -9.16994569166718e-09\n",
      "          vf_loss: 3374.77880859375\n",
      "    num_agent_steps_sampled: 1575000\n",
      "    num_agent_steps_trained: 1575000\n",
      "    num_steps_sampled: 1575000\n",
      "    num_steps_trained: 1575000\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.783333333333335\n",
      "    ram_util_percent: 30.561111111111106\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.611725380295792\n",
      "    mean_inference_ms: 0.41320727988344935\n",
      "    mean_processing_ms: 4.114794529471978\n",
      "  time_since_restore: 3061.3078916072845\n",
      "  time_this_iter_s: 28.861029624938965\n",
      "  time_total_s: 3061.3078916072845\n",
      "  timestamp: 1665274238\n",
      "  timesteps_since_restore: 1560000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 104\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    104 |          3061.31 |     1560000 | -890.568 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-11-08\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -906.2964870946442\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 525\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.443\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0246442556381226\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02368396706879139\n",
      "        policy_loss: 0.0009363742428831756\n",
      "        total_loss: 6184.32763671875\n",
      "        vf_explained_var: 0.9737696647644043\n",
      "        vf_loss: 6184.3251953125\n",
      "    load_time_ms: 2.502\n",
      "    num_steps_sampled: 1575000\n",
      "    num_steps_trained: 1572480\n",
      "    sample_time_ms: 27767.183\n",
      "    update_time_ms: 2.983\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.64390243902439\n",
      "    ram_util_percent: 24.382926829268293\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06565130588926937\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.476298817144916\n",
      "    mean_inference_ms: 0.4825602755505225\n",
      "    mean_raw_obs_processing_ms: 3.8070631476464722\n",
      "  time_since_restore: 2842.6551656723022\n",
      "  time_this_iter_s: 25.260740995407104\n",
      "  time_total_s: 2842.6551656723022\n",
      "  timers:\n",
      "    learn_throughput: 6528.25\n",
      "    learn_time_ms: 2297.706\n",
      "    load_throughput: 8739711.337\n",
      "    load_time_ms: 1.716\n",
      "    sample_throughput: 631.158\n",
      "    sample_time_ms: 23765.829\n",
      "    update_time_ms: 1.385\n",
      "  timestamp: 1665248036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1575000\n",
      "  training_iteration: 105\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:53:56,772\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 209.0x the scale of `vf_clip_param`. This means that it will take more than 209.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    105 |          2842.66 | 1575000 | -2094.96 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1590000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-54-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2011.146422206972\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 530\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.32473209500312805\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -2.2890515327453613\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03751737251877785\n",
      "          model: {}\n",
      "          policy_loss: 0.011115022003650665\n",
      "          total_loss: 2573.27294921875\n",
      "          vf_explained_var: -5.603855601776786e-09\n",
      "          vf_loss: 2573.249755859375\n",
      "    num_agent_steps_sampled: 1590000\n",
      "    num_agent_steps_trained: 1590000\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1590000\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.857894736842105\n",
      "    ram_util_percent: 30.560526315789467\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.611327785876933\n",
      "    mean_inference_ms: 0.4132401730880676\n",
      "    mean_processing_ms: 4.114352870988591\n",
      "  time_since_restore: 3090.336881160736\n",
      "  time_this_iter_s: 29.028989553451538\n",
      "  time_total_s: 3090.336881160736\n",
      "  timestamp: 1665274268\n",
      "  timesteps_since_restore: 1575000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1575000\n",
      "  training_iteration: 105\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    105 |          3090.34 |     1575000 | -906.296 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-11-36\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -775.117329257706\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 530\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.377\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.6787952184677124\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020935634151101112\n",
      "        policy_loss: 0.0017429315485060215\n",
      "        total_loss: 4265.12451171875\n",
      "        vf_explained_var: 0.964768648147583\n",
      "        vf_loss: 4265.12158203125\n",
      "    load_time_ms: 2.579\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1587456\n",
      "    sample_time_ms: 27742.86\n",
      "    update_time_ms: 3.074\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.647619047619045\n",
      "    ram_util_percent: 24.36904761904762\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06565048303544087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.475945707015561\n",
      "    mean_inference_ms: 0.48257377884311414\n",
      "    mean_raw_obs_processing_ms: 3.8046531888210926\n",
      "  time_since_restore: 2869.0049340724945\n",
      "  time_this_iter_s: 26.34976840019226\n",
      "  time_total_s: 2869.0049340724945\n",
      "  timers:\n",
      "    learn_throughput: 6376.818\n",
      "    learn_time_ms: 2352.27\n",
      "    load_throughput: 8595237.51\n",
      "    load_time_ms: 1.745\n",
      "    sample_throughput: 632.909\n",
      "    sample_time_ms: 23700.106\n",
      "    update_time_ms: 1.287\n",
      "  timestamp: 1665248063\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 106\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:54:23,222\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 201.0x the scale of `vf_clip_param`. This means that it will take more than 201.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    106 |             2869 | 1590000 | -2011.15 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n"
=======
      "    mean_env_wait_ms: 4.610924656745879\n",
      "    mean_inference_ms: 0.4132712657656342\n",
      "    mean_processing_ms: 4.113916889287072\n",
      "  time_since_restore: 3119.255133628845\n",
      "  time_this_iter_s: 28.91825246810913\n",
      "  time_total_s: 3119.255133628845\n",
      "  timestamp: 1665274296\n",
      "  timesteps_since_restore: 1590000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 106\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    106 |          3119.26 |     1590000 | -775.117 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1605000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-54-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2071.666265168457\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 535\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.32473209500312805\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.07838207483291626\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04487745091319084\n",
      "          model: {}\n",
      "          policy_loss: 0.01949945092201233\n",
      "          total_loss: 3120.62451171875\n",
      "          vf_explained_var: -3.5660898678457897e-09\n",
      "          vf_loss: 3120.590576171875\n",
      "    num_agent_steps_sampled: 1605000\n",
      "    num_agent_steps_trained: 1605000\n",
      "    num_steps_sampled: 1605000\n",
      "    num_steps_trained: 1605000\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.96818181818182\n",
      "    ram_util_percent: 30.518181818181816\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-12-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -774.3465833524283\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 535\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.309\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3559075593948364\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02046525664627552\n",
      "        policy_loss: 0.00021659984486177564\n",
      "        total_loss: 4622.64111328125\n",
      "        vf_explained_var: 0.9776289463043213\n",
      "        vf_loss: 4622.638671875\n",
      "    load_time_ms: 2.581\n",
      "    num_steps_sampled: 1605000\n",
      "    num_steps_trained: 1602432\n",
      "    sample_time_ms: 27756.017\n",
      "    update_time_ms: 3.047\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.50487804878049\n",
      "    ram_util_percent: 24.4390243902439\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656495840833671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4755819703088093\n",
      "    mean_inference_ms: 0.4825886514976839\n",
      "    mean_raw_obs_processing_ms: 3.803196435065915\n",
      "  time_since_restore: 2899.834666967392\n",
      "  time_this_iter_s: 30.82973289489746\n",
      "  time_total_s: 2899.834666967392\n",
      "  timers:\n",
      "    learn_throughput: 6319.985\n",
      "    learn_time_ms: 2373.424\n",
      "    load_throughput: 8746880.214\n",
      "    load_time_ms: 1.715\n",
      "    sample_throughput: 620.814\n",
      "    sample_time_ms: 24161.823\n",
      "    update_time_ms: 1.39\n",
      "  timestamp: 1665248094\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1605000\n",
      "  training_iteration: 107\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:54:54,172\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 207.0x the scale of `vf_clip_param`. This means that it will take more than 207.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    107 |          2899.83 | 1605000 | -2071.67 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1620000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-55-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2039.7851041178264\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 540\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.48709815740585327\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3563929796218872\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.031696874648332596\n",
      "          model: {}\n",
      "          policy_loss: 0.020659007132053375\n",
      "          total_loss: 3436.533447265625\n",
      "          vf_explained_var: 1.528324244937096e-09\n",
      "          vf_loss: 3436.497314453125\n",
      "    num_agent_steps_sampled: 1620000\n",
      "    num_agent_steps_trained: 1620000\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1620000\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.011111111111113\n",
      "    ram_util_percent: 30.850000000000005\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.610486107921224\n",
      "    mean_inference_ms: 0.4133019768702538\n",
      "    mean_processing_ms: 4.113518356882286\n",
      "  time_since_restore: 3148.3614687919617\n",
      "  time_this_iter_s: 29.106335163116455\n",
      "  time_total_s: 3148.3614687919617\n",
      "  timestamp: 1665274326\n",
      "  timesteps_since_restore: 1605000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1605000\n",
      "  training_iteration: 107\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    107 |          3148.36 |     1605000 | -774.347 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-12-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -732.1406269215627\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 540\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.795\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.19983336329460144\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024851800873875618\n",
      "        policy_loss: 0.00487114954739809\n",
      "        total_loss: 4279.40234375\n",
      "        vf_explained_var: 0.9780691266059875\n",
      "        vf_loss: 4279.396484375\n",
      "    load_time_ms: 2.753\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1617408\n",
      "    sample_time_ms: 27761.399\n",
      "    update_time_ms: 3.039\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.99285714285715\n",
      "    ram_util_percent: 24.38095238095238\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564888263317673\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4752226383745053\n",
      "    mean_inference_ms: 0.4826072931999751\n",
      "    mean_raw_obs_processing_ms: 3.801810505214403\n",
      "  time_since_restore: 2925.0452041625977\n",
      "  time_this_iter_s: 25.21053719520569\n",
      "  time_total_s: 2925.0452041625977\n",
      "  timers:\n",
      "    learn_throughput: 6334.874\n",
      "    learn_time_ms: 2367.845\n",
      "    load_throughput: 8917473.636\n",
      "    load_time_ms: 1.682\n",
      "    sample_throughput: 634.2\n",
      "    sample_time_ms: 23651.837\n",
      "    update_time_ms: 1.38\n",
      "  timestamp: 1665248119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 108\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    108 |          2925.05 | 1620000 | -2039.79 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 4.610103842661124\n",
      "    mean_inference_ms: 0.4133355652252865\n",
      "    mean_processing_ms: 4.113089423403107\n",
      "  time_since_restore: 3177.6512031555176\n",
      "  time_this_iter_s: 29.289734363555908\n",
      "  time_total_s: 3177.6512031555176\n",
      "  timestamp: 1665274355\n",
      "  timesteps_since_restore: 1620000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 108\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    108 |          3177.65 |     1620000 | -732.141 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:55:19,465\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 204.0x the scale of `vf_clip_param`. This means that it will take more than 204.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1635000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-55-50\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2012.761816447191\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 545\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.48709815740585327\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.43078866600990295\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00366612384095788\n",
      "          model: {}\n",
      "          policy_loss: 0.00017028441652655602\n",
      "          total_loss: 2851.950439453125\n",
      "          vf_explained_var: -5.094414223805188e-09\n",
      "          vf_loss: 2851.948486328125\n",
      "    num_agent_steps_sampled: 1635000\n",
      "    num_agent_steps_trained: 1635000\n",
      "    num_steps_sampled: 1635000\n",
      "    num_steps_trained: 1635000\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.236363636363635\n",
      "    ram_util_percent: 30.62499999999999\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-13-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -738.2907670319129\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 545\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.777\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1907923221588135\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01335362158715725\n",
      "        policy_loss: 0.0007291707443073392\n",
      "        total_loss: 6226.07373046875\n",
      "        vf_explained_var: 0.9580186009407043\n",
      "        vf_loss: 6226.07275390625\n",
      "    load_time_ms: 2.797\n",
      "    num_steps_sampled: 1635000\n",
      "    num_steps_trained: 1632384\n",
      "    sample_time_ms: 27729.307\n",
      "    update_time_ms: 3.048\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.863414634146345\n",
      "    ram_util_percent: 24.470731707317075\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564785035879607\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.474852880678495\n",
      "    mean_inference_ms: 0.48262452929826827\n",
      "    mean_raw_obs_processing_ms: 3.801291524621564\n",
      "  time_since_restore: 2955.675479888916\n",
      "  time_this_iter_s: 30.63027572631836\n",
      "  time_total_s: 2955.675479888916\n",
      "  timers:\n",
      "    learn_throughput: 6344.627\n",
      "    learn_time_ms: 2364.205\n",
      "    load_throughput: 9054017.96\n",
      "    load_time_ms: 1.657\n",
      "    sample_throughput: 620.286\n",
      "    sample_time_ms: 24182.406\n",
      "    update_time_ms: 1.393\n",
      "  timestamp: 1665248150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1635000\n",
      "  training_iteration: 109\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 11:55:50,157\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 201.0x the scale of `vf_clip_param`. This means that it will take more than 201.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    109 |          2955.68 | 1635000 | -2012.76 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1650000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-56-20\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -1869.5066966532725\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 550\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.24354907870292664\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.434446096420288\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.032167598605155945\n",
      "          model: {}\n",
      "          policy_loss: 0.010984468273818493\n",
      "          total_loss: 3173.3115234375\n",
      "          vf_explained_var: -9.16994569166718e-09\n",
      "          vf_loss: 3173.292724609375\n",
      "    num_agent_steps_sampled: 1650000\n",
      "    num_agent_steps_trained: 1650000\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1650000\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.2046511627907\n",
      "    ram_util_percent: 30.520930232558133\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.609745593438416\n",
      "    mean_inference_ms: 0.41337108909180764\n",
      "    mean_processing_ms: 4.112675436873548\n",
      "  time_since_restore: 3206.7446949481964\n",
      "  time_this_iter_s: 29.093491792678833\n",
      "  time_total_s: 3206.7446949481964\n",
      "  timestamp: 1665274384\n",
      "  timesteps_since_restore: 1635000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1635000\n",
      "  training_iteration: 109\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    109 |          3206.74 |     1635000 | -738.291 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-13-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -706.9916580433859\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 550\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.277\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.091225028038025\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02456888183951378\n",
      "        policy_loss: 0.0034188162535429\n",
      "        total_loss: 3945.32666015625\n",
      "        vf_explained_var: 0.9742348790168762\n",
      "        vf_loss: 3945.321533203125\n",
      "    load_time_ms: 2.813\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1647360\n",
      "    sample_time_ms: 27656.415\n",
      "    update_time_ms: 3.095\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.84523809523809\n",
      "    ram_util_percent: 24.469047619047622\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564691569350291\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4745114834413533\n",
      "    mean_inference_ms: 0.4826445148881577\n",
      "    mean_raw_obs_processing_ms: 3.801754342167966\n",
      "  time_since_restore: 2985.8812232017517\n",
      "  time_this_iter_s: 30.205743312835693\n",
      "  time_total_s: 2985.8812232017517\n",
      "  timers:\n",
      "    learn_throughput: 6453.446\n",
      "    learn_time_ms: 2324.34\n",
      "    load_throughput: 10009475.778\n",
      "    load_time_ms: 1.499\n",
      "    sample_throughput: 606.998\n",
      "    sample_time_ms: 24711.762\n",
      "    update_time_ms: 1.437\n",
      "  timestamp: 1665248180\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 110\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    110 |          2985.88 | 1650000 | -1869.51 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1665000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-56-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -1868.6668392121585\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 555\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.24354907870292664\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.21718455851078033\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03925231471657753\n",
      "          model: {}\n",
      "          policy_loss: 0.016694650053977966\n",
      "          total_loss: 3034.69482421875\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 3034.668212890625\n",
      "    num_agent_steps_sampled: 1665000\n",
      "    num_agent_steps_trained: 1665000\n",
      "    num_steps_sampled: 1665000\n",
      "    num_steps_trained: 1665000\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.813513513513513\n",
      "    ram_util_percent: 30.559459459459454\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.609390750824523\n",
      "    mean_inference_ms: 0.4134064535551198\n",
      "    mean_processing_ms: 4.112338673093251\n",
      "  time_since_restore: 3235.9027197360992\n",
      "  time_this_iter_s: 29.158024787902832\n",
      "  time_total_s: 3235.9027197360992\n",
      "  timestamp: 1665274413\n",
      "  timesteps_since_restore: 1650000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 110\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    110 |           3235.9 |     1650000 | -706.992 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -658.7625136028649\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 555\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.211\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.722289502620697\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012634229846298695\n",
      "        policy_loss: -0.0009680307703092694\n",
      "        total_loss: 5830.93994140625\n",
      "        vf_explained_var: 0.9719670414924622\n",
      "        vf_loss: 5830.94140625\n",
      "    load_time_ms: 2.721\n",
      "    num_steps_sampled: 1665000\n",
      "    num_steps_trained: 1662336\n",
      "    sample_time_ms: 27741.422\n",
      "    update_time_ms: 3.059\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.33953488372093\n",
      "    ram_util_percent: 24.444186046511632\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564566199194609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4741528425314523\n",
      "    mean_inference_ms: 0.4826671540736233\n",
      "    mean_raw_obs_processing_ms: 3.8003688263489273\n",
      "  time_since_restore: 3012.065018415451\n",
      "  time_this_iter_s: 26.18379521369934\n",
      "  time_total_s: 3012.065018415451\n",
      "  timers:\n",
      "    learn_throughput: 6585.23\n",
      "    learn_time_ms: 2277.825\n",
      "    load_throughput: 8819221.172\n",
      "    load_time_ms: 1.701\n",
      "    sample_throughput: 604.946\n",
      "    sample_time_ms: 24795.61\n",
      "    update_time_ms: 1.502\n",
      "  timestamp: 1665248206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1665000\n",
      "  training_iteration: 111\n",
      "  trial_id: 26f87_00000\n",
=======
      "    mean_env_wait_ms: 4.608976947903485\n",
      "    mean_inference_ms: 0.41343649853305264\n",
      "    mean_processing_ms: 4.1121156685435265\n",
      "  time_since_restore: 3265.6723737716675\n",
      "  time_this_iter_s: 29.769654035568237\n",
      "  time_total_s: 3265.6723737716675\n",
      "  timestamp: 1665274443\n",
      "  timesteps_since_restore: 1665000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1665000\n",
      "  training_iteration: 111\n",
      "  trial_id: a95f16f0\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
<<<<<<< HEAD
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    111 |          3012.07 | 1665000 | -1868.67 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1680000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-57-16\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -1823.5522686712343\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 560\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.24354907870292664\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.13041596114635468\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027217721566557884\n",
      "          model: {}\n",
      "          policy_loss: 0.010697387158870697\n",
      "          total_loss: 3112.44287109375\n",
      "          vf_explained_var: -4.0755314678619925e-09\n",
      "          vf_loss: 3112.42529296875\n",
      "    num_agent_steps_sampled: 1680000\n",
      "    num_agent_steps_trained: 1680000\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1680000\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.168181818181814\n",
      "    ram_util_percent: 30.5340909090909\n",
      "  pid: 307\n",
=======
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    111 |          3265.67 |     1665000 | -658.763 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-14-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -682.8020698440298\n",
      "  episode_reward_min: -7276.30485339901\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 560\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.184\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.057017434388399124\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8114820122718811\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.040801290422677994\n",
      "        policy_loss: 0.004419150296598673\n",
      "        total_loss: 5460.3984375\n",
      "        vf_explained_var: 0.9734519720077515\n",
      "        vf_loss: 5460.3916015625\n",
      "    load_time_ms: 2.667\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1677312\n",
      "    sample_time_ms: 27729.79\n",
      "    update_time_ms: 2.997\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.81707317073171\n",
      "    ram_util_percent: 24.39268292682927\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564462505067153\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.473829152989406\n",
      "    mean_inference_ms: 0.4826915603905253\n",
      "    mean_raw_obs_processing_ms: 3.799902682372753\n",
      "  time_since_restore: 3042.233295440674\n",
      "  time_this_iter_s: 30.16827702522278\n",
      "  time_total_s: 3042.233295440674\n",
      "  timers:\n",
      "    learn_throughput: 6636.772\n",
      "    learn_time_ms: 2260.135\n",
      "    load_throughput: 8802193.743\n",
      "    load_time_ms: 1.704\n",
      "    sample_throughput: 593.607\n",
      "    sample_time_ms: 25269.223\n",
      "    update_time_ms: 1.615\n",
      "  timestamp: 1665248236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 112\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.5/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    112 |          3042.23 | 1680000 | -1823.55 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1695000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-57-43\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -1839.8849024818928\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 565\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.24354907870292664\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.7621235847473145\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013078893534839153\n",
      "          model: {}\n",
      "          policy_loss: 0.006986022926867008\n",
      "          total_loss: 3448.93701171875\n",
      "          vf_explained_var: -5.603855601776786e-09\n",
      "          vf_loss: 3448.926513671875\n",
      "    num_agent_steps_sampled: 1695000\n",
      "    num_agent_steps_trained: 1695000\n",
      "    num_steps_sampled: 1695000\n",
      "    num_steps_trained: 1695000\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.349999999999998\n",
      "    ram_util_percent: 30.59210526315789\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.6085706876889345\n",
      "    mean_inference_ms: 0.4134681975584168\n",
      "    mean_processing_ms: 4.111861871979146\n",
      "  time_since_restore: 3294.6982595920563\n",
      "  time_this_iter_s: 29.025885820388794\n",
      "  time_total_s: 3294.6982595920563\n",
      "  timestamp: 1665274472\n",
      "  timesteps_since_restore: 1680000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 112\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    112 |           3294.7 |     1680000 | -682.802 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-15-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -532.2382736600273\n",
      "  episode_reward_min: -7216.611501805993\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 565\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.4083263874053955\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024414852261543274\n",
      "        policy_loss: 0.002980123506858945\n",
      "        total_loss: 4854.11181640625\n",
      "        vf_explained_var: 0.9762009978294373\n",
      "        vf_loss: 4854.10693359375\n",
      "    load_time_ms: 2.699\n",
      "    num_steps_sampled: 1695000\n",
      "    num_steps_trained: 1692288\n",
      "    sample_time_ms: 27705.504\n",
      "    update_time_ms: 3.024\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.604651162790695\n",
      "    ram_util_percent: 24.434883720930234\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564401957137084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4735122869026145\n",
      "    mean_inference_ms: 0.48271938727609914\n",
      "    mean_raw_obs_processing_ms: 3.799718783486916\n",
      "  time_since_restore: 3068.787879228592\n",
      "  time_this_iter_s: 26.55458378791809\n",
      "  time_total_s: 3068.787879228592\n",
      "  timers:\n",
      "    learn_throughput: 6518.748\n",
      "    learn_time_ms: 2301.055\n",
      "    load_throughput: 9360753.448\n",
      "    load_time_ms: 1.602\n",
      "    sample_throughput: 592.065\n",
      "    sample_time_ms: 25335.059\n",
      "    update_time_ms: 1.622\n",
      "  timestamp: 1665248263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1695000\n",
      "  training_iteration: 113\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    113 |          3068.79 | 1695000 | -1839.88 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1710000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-58-08\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -1870.270818581281\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 570\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.24354907870292664\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.2542319297790527\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019097229465842247\n",
      "          model: {}\n",
      "          policy_loss: 0.009684158489108086\n",
      "          total_loss: 3234.145751953125\n",
      "          vf_explained_var: -8.660504313695583e-09\n",
      "          vf_loss: 3234.13134765625\n",
      "    num_agent_steps_sampled: 1710000\n",
      "    num_agent_steps_trained: 1710000\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1710000\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.81142857142857\n",
      "    ram_util_percent: 30.660000000000004\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.608161590812867\n",
      "    mean_inference_ms: 0.41349584845710263\n",
      "    mean_processing_ms: 4.111761617340572\n",
      "  time_since_restore: 3324.4720265865326\n",
      "  time_this_iter_s: 29.77376699447632\n",
      "  time_total_s: 3324.4720265865326\n",
      "  timestamp: 1665274502\n",
      "  timesteps_since_restore: 1695000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1695000\n",
      "  training_iteration: 113\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    113 |          3324.47 |     1695000 | -532.238 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-15-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1939.0363842365593\n",
      "  episode_reward_mean: -572.6309161026587\n",
      "  episode_reward_min: -7216.611501805993\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 570\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.249\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.014012090861797333\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.023895220831036568\n",
      "        policy_loss: 0.002019602572545409\n",
      "        total_loss: 6279.8505859375\n",
      "        vf_explained_var: 0.9663018584251404\n",
      "        vf_loss: 6279.8466796875\n",
      "    load_time_ms: 2.819\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1707264\n",
      "    sample_time_ms: 27691.182\n",
      "    update_time_ms: 3.014\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.099999999999994\n",
      "    ram_util_percent: 24.397560975609753\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656436212690026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.473208161608868\n",
      "    mean_inference_ms: 0.482749495579016\n",
      "    mean_raw_obs_processing_ms: 3.799473750498541\n",
      "  time_since_restore: 3093.135819911957\n",
      "  time_this_iter_s: 24.347940683364868\n",
      "  time_total_s: 3093.135819911957\n",
      "  timers:\n",
      "    learn_throughput: 6511.704\n",
      "    learn_time_ms: 2303.545\n",
      "    load_throughput: 9288475.507\n",
      "    load_time_ms: 1.615\n",
      "    sample_throughput: 593.821\n",
      "    sample_time_ms: 25260.129\n",
      "    update_time_ms: 1.903\n",
      "  timestamp: 1665248288\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 114\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    114 |          3093.14 | 1710000 | -1870.27 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1725000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-58-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -1816.7485750005917\n",
      "  episode_reward_min: -8098.169144697511\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 575\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.24354907870292664\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.32837238907814026\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0631071925163269\n",
      "          model: {}\n",
      "          policy_loss: 0.022640632465481758\n",
      "          total_loss: 3244.010498046875\n",
      "          vf_explained_var: -1.171715258152517e-08\n",
      "          vf_loss: 3243.972412109375\n",
      "    num_agent_steps_sampled: 1725000\n",
      "    num_agent_steps_trained: 1725000\n",
      "    num_steps_sampled: 1725000\n",
      "    num_steps_trained: 1725000\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.574285714285715\n",
      "    ram_util_percent: 30.64857142857143\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.607689734870681\n",
      "    mean_inference_ms: 0.4135200446196779\n",
      "    mean_processing_ms: 4.1116849671463545\n",
      "  time_since_restore: 3353.186223745346\n",
      "  time_this_iter_s: 28.714197158813477\n",
      "  time_total_s: 3353.186223745346\n",
      "  timestamp: 1665274531\n",
      "  timesteps_since_restore: 1710000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 114\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    114 |          3353.19 |     1710000 | -572.631 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-16-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -466.8823175016477\n",
      "  episode_reward_min: -7216.611501805993\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 575\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.307\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.642006754875183\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030634930357336998\n",
      "        policy_loss: 0.004697473719716072\n",
      "        total_loss: 3694.657958984375\n",
      "        vf_explained_var: 0.977961003780365\n",
      "        vf_loss: 3694.650634765625\n",
      "    load_time_ms: 2.754\n",
      "    num_steps_sampled: 1725000\n",
      "    num_steps_trained: 1722240\n",
      "    sample_time_ms: 27777.12\n",
      "    update_time_ms: 3.046\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.7952380952381\n",
      "    ram_util_percent: 24.430952380952384\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564334348756472\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4729278706046607\n",
      "    mean_inference_ms: 0.4827829422598686\n",
      "    mean_raw_obs_processing_ms: 3.7984307606334333\n",
      "  time_since_restore: 3118.076587200165\n",
      "  time_this_iter_s: 24.940767288208008\n",
      "  time_total_s: 3118.076587200165\n",
      "  timers:\n",
      "    learn_throughput: 6519.316\n",
      "    learn_time_ms: 2300.855\n",
      "    load_throughput: 10428749.503\n",
      "    load_time_ms: 1.438\n",
      "    sample_throughput: 594.505\n",
      "    sample_time_ms: 25231.064\n",
      "    update_time_ms: 1.937\n",
      "  timestamp: 1665248313\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1725000\n",
      "  training_iteration: 115\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    115 |          3118.08 | 1725000 | -1816.75 |              2776.09 |             -8098.17 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1740000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-58-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -1776.1379852159441\n",
      "  episode_reward_min: -7708.287380663002\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 580\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8276717066764832\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02616354450583458\n",
      "          model: {}\n",
      "          policy_loss: 0.00838781800121069\n",
      "          total_loss: 3359.880859375\n",
      "          vf_explained_var: -1.630212587144797e-08\n",
      "          vf_loss: 3359.863037109375\n",
      "    num_agent_steps_sampled: 1740000\n",
      "    num_agent_steps_trained: 1740000\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1740000\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.433333333333337\n",
      "    ram_util_percent: 30.646153846153855\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.607266935375819\n",
      "    mean_inference_ms: 0.4135414378829111\n",
      "    mean_processing_ms: 4.111694972137034\n",
      "  time_since_restore: 3383.0750257968903\n",
      "  time_this_iter_s: 29.88880205154419\n",
      "  time_total_s: 3383.0750257968903\n",
      "  timestamp: 1665274561\n",
      "  timesteps_since_restore: 1725000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1725000\n",
      "  training_iteration: 115\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    115 |          3383.08 |     1725000 | -466.882 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-16-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -441.50114755512527\n",
      "  episode_reward_min: -7216.611501805993\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 580\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.037\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3438079357147217\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017958056181669235\n",
      "        policy_loss: 0.00404729600995779\n",
      "        total_loss: 4874.68212890625\n",
      "        vf_explained_var: 0.9610697031021118\n",
      "        vf_loss: 4874.6767578125\n",
      "    load_time_ms: 2.556\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1737216\n",
      "    sample_time_ms: 28367.652\n",
      "    update_time_ms: 3.045\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.934\n",
      "    ram_util_percent: 24.392000000000003\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564299838061359\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.472630356227853\n",
      "    mean_inference_ms: 0.48281844843019023\n",
      "    mean_raw_obs_processing_ms: 3.7974904717951232\n",
      "  time_since_restore: 3144.8682055473328\n",
      "  time_this_iter_s: 26.79161834716797\n",
      "  time_total_s: 3144.8682055473328\n",
      "  timers:\n",
      "    learn_throughput: 6595.89\n",
      "    learn_time_ms: 2274.143\n",
      "    load_throughput: 10157995.35\n",
      "    load_time_ms: 1.477\n",
      "    sample_throughput: 592.855\n",
      "    sample_time_ms: 25301.288\n",
      "    update_time_ms: 2.131\n",
      "  timestamp: 1665248339\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 116\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    116 |          3144.87 | 1740000 | -1776.14 |              2776.09 |             -7708.29 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1755000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-59-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -1816.034743991307\n",
      "  episode_reward_min: -7708.287380663002\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 585\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.7755322456359863\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02525383234024048\n",
      "          model: {}\n",
      "          policy_loss: 0.011666839942336082\n",
      "          total_loss: 3380.44482421875\n",
      "          vf_explained_var: 7.1321797356915795e-09\n",
      "          vf_loss: 3380.423583984375\n",
      "    num_agent_steps_sampled: 1755000\n",
      "    num_agent_steps_trained: 1755000\n",
      "    num_steps_sampled: 1755000\n",
      "    num_steps_trained: 1755000\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.544186046511626\n",
      "    ram_util_percent: 30.588372093023256\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.606907962149798\n",
      "    mean_inference_ms: 0.41356563601017776\n",
      "    mean_processing_ms: 4.1124295466365615\n",
      "  time_since_restore: 3417.8935997486115\n",
      "  time_this_iter_s: 34.81857395172119\n",
      "  time_total_s: 3417.8935997486115\n",
      "  timestamp: 1665274595\n",
      "  timesteps_since_restore: 1740000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 116\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    116 |          3417.89 |     1740000 | -441.501 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-17-05\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -326.92364108050225\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 585\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.497\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8024796843528748\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02799306996166706\n",
      "        policy_loss: 0.0028724470175802708\n",
      "        total_loss: 7330.7373046875\n",
      "        vf_explained_var: 0.9478491544723511\n",
      "        vf_loss: 7330.732421875\n",
      "    load_time_ms: 2.548\n",
      "    num_steps_sampled: 1755000\n",
      "    num_steps_trained: 1752192\n",
      "    sample_time_ms: 28368.845\n",
      "    update_time_ms: 3.072\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00714285714285\n",
      "    ram_util_percent: 24.509523809523813\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564286430625456\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4723410055666477\n",
      "    mean_inference_ms: 0.48285535708952837\n",
      "    mean_raw_obs_processing_ms: 3.7972562627974487\n",
      "  time_since_restore: 3174.914978981018\n",
      "  time_this_iter_s: 30.046773433685303\n",
      "  time_total_s: 3174.914978981018\n",
      "  timers:\n",
      "    learn_throughput: 6637.218\n",
      "    learn_time_ms: 2259.983\n",
      "    load_throughput: 10054103.81\n",
      "    load_time_ms: 1.492\n",
      "    sample_throughput: 594.358\n",
      "    sample_time_ms: 25237.317\n",
      "    update_time_ms: 2.09\n",
      "  timestamp: 1665248370\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1755000\n",
      "  training_iteration: 117\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    117 |          3174.91 | 1755000 | -1816.03 |              2776.09 |             -7708.29 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n"
=======
      "    mean_env_wait_ms: 4.606505478591894\n",
      "    mean_inference_ms: 0.4135880717224043\n",
      "    mean_processing_ms: 4.113210108178541\n",
      "  time_since_restore: 3446.996555328369\n",
      "  time_this_iter_s: 29.10295557975769\n",
      "  time_total_s: 3446.996555328369\n",
      "  timestamp: 1665274625\n",
      "  timesteps_since_restore: 1755000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1755000\n",
      "  training_iteration: 117\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    117 |             3447 |     1755000 | -326.924 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1770000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_11-59-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -1898.8765548316305\n",
      "  episode_reward_min: -7708.287380663002\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 590\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7046069502830505\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021365268155932426\n",
      "          model: {}\n",
      "          policy_loss: 0.00842498429119587\n",
      "          total_loss: 3559.097412109375\n",
      "          vf_explained_var: -1.3754918093411561e-08\n",
      "          vf_loss: 3559.081298828125\n",
      "    num_agent_steps_sampled: 1770000\n",
      "    num_agent_steps_trained: 1770000\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1770000\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.34358974358974\n",
      "    ram_util_percent: 30.70000000000001\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-17-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -250.33394932087242\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 590\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.607\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.0807507038116455\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019083630293607712\n",
      "        policy_loss: 0.0037646328564733267\n",
      "        total_loss: 4081.593017578125\n",
      "        vf_explained_var: 0.9708542227745056\n",
      "        vf_loss: 4081.587646484375\n",
      "    load_time_ms: 2.517\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1767168\n",
      "    sample_time_ms: 28389.776\n",
      "    update_time_ms: 3.058\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.878571428571426\n",
      "    ram_util_percent: 24.48333333333333\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564275328332138\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.472056331302611\n",
      "    mean_inference_ms: 0.4828921959699825\n",
      "    mean_raw_obs_processing_ms: 3.796381539325375\n",
      "  time_since_restore: 3202.18635058403\n",
      "  time_this_iter_s: 27.271371603012085\n",
      "  time_total_s: 3202.18635058403\n",
      "  timers:\n",
      "    learn_throughput: 6496.689\n",
      "    learn_time_ms: 2308.868\n",
      "    load_throughput: 9893315.302\n",
      "    load_time_ms: 1.516\n",
      "    sample_throughput: 590.689\n",
      "    sample_time_ms: 25394.058\n",
      "    update_time_ms: 2.153\n",
      "  timestamp: 1665248397\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 118\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    118 |          3202.19 | 1770000 | -1898.88 |              2776.09 |             -7708.29 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1785000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-00-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2048.5193167199877\n",
      "  episode_reward_min: -7708.287380663002\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 595\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.782514810562134\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027392076328396797\n",
      "          model: {}\n",
      "          policy_loss: 0.01534468587487936\n",
      "          total_loss: 3688.652587890625\n",
      "          vf_explained_var: 3.5660898678457897e-09\n",
      "          vf_loss: 3688.627197265625\n",
      "    num_agent_steps_sampled: 1785000\n",
      "    num_agent_steps_trained: 1785000\n",
      "    num_steps_sampled: 1785000\n",
      "    num_steps_trained: 1785000\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.824324324324323\n",
      "    ram_util_percent: 30.8054054054054\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.606136048919354\n",
      "    mean_inference_ms: 0.4136101476116002\n",
      "    mean_processing_ms: 4.114014198085135\n",
      "  time_since_restore: 3476.49649643898\n",
      "  time_this_iter_s: 29.499941110610962\n",
      "  time_total_s: 3476.49649643898\n",
      "  timestamp: 1665274654\n",
      "  timesteps_since_restore: 1770000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 118\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    118 |           3476.5 |     1770000 | -250.334 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-18-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -214.3125481062305\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 595\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.46\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.08552615344524384\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.4621456861495972\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009518875740468502\n",
      "        policy_loss: 0.002183140954002738\n",
      "        total_loss: 4240.62109375\n",
      "        vf_explained_var: 0.9627314805984497\n",
      "        vf_loss: 4240.61767578125\n",
      "    load_time_ms: 2.437\n",
      "    num_steps_sampled: 1785000\n",
      "    num_steps_trained: 1782144\n",
      "    sample_time_ms: 28401.408\n",
      "    update_time_ms: 3.053\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.29047619047619\n",
      "    ram_util_percent: 24.547619047619047\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564227238296413\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4717444430146833\n",
      "    mean_inference_ms: 0.48292822128488555\n",
      "    mean_raw_obs_processing_ms: 3.7954696603172358\n",
      "  time_since_restore: 3227.94052362442\n",
      "  time_this_iter_s: 25.754173040390015\n",
      "  time_total_s: 3227.94052362442\n",
      "  timers:\n",
      "    learn_throughput: 6415.73\n",
      "    learn_time_ms: 2338.003\n",
      "    load_throughput: 9886940.944\n",
      "    load_time_ms: 1.517\n",
      "    sample_throughput: 602.967\n",
      "    sample_time_ms: 24877.003\n",
      "    update_time_ms: 2.251\n",
      "  timestamp: 1665248423\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1785000\n",
      "  training_iteration: 119\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:00:23,287\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 205.0x the scale of `vf_clip_param`. This means that it will take more than 205.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    119 |          3227.94 | 1785000 | -2048.52 |              2776.09 |             -7708.29 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 4.6057786606336535\n",
      "    mean_inference_ms: 0.41363048647979084\n",
      "    mean_processing_ms: 4.114775363848158\n",
      "  time_since_restore: 3505.7239265441895\n",
      "  time_this_iter_s: 29.22743010520935\n",
      "  time_total_s: 3505.7239265441895\n",
      "  timestamp: 1665274683\n",
      "  timesteps_since_restore: 1785000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1785000\n",
      "  training_iteration: 119\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    119 |          3505.72 |     1785000 | -214.313 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1800000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-00-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2035.3816199045643\n",
      "  episode_reward_min: -7708.287380663002\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 600\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3797941207885742\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019345572218298912\n",
      "          model: {}\n",
      "          policy_loss: 0.009479121305048466\n",
      "          total_loss: 3479.766845703125\n",
      "          vf_explained_var: 5.094414334827491e-10\n",
      "          vf_loss: 3479.750244140625\n",
      "    num_agent_steps_sampled: 1800000\n",
      "    num_agent_steps_trained: 1800000\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1800000\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.641666666666666\n",
      "    ram_util_percent: 30.702777777777783\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-18-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -248.34365217397152\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 600\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.766\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.127180814743042\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025934217497706413\n",
      "        policy_loss: 0.004408563021570444\n",
      "        total_loss: 4658.91845703125\n",
      "        vf_explained_var: 0.967108964920044\n",
      "        vf_loss: 4658.91357421875\n",
      "    load_time_ms: 2.498\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1797120\n",
      "    sample_time_ms: 28424.851\n",
      "    update_time_ms: 3.081\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.13809523809524\n",
      "    ram_util_percent: 24.56904761904762\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564219864507247\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.471457478980845\n",
      "    mean_inference_ms: 0.4829658097205026\n",
      "    mean_raw_obs_processing_ms: 3.794532841674327\n",
      "  time_since_restore: 3253.4798550605774\n",
      "  time_this_iter_s: 25.539331436157227\n",
      "  time_total_s: 3253.4798550605774\n",
      "  timers:\n",
      "    learn_throughput: 6225.726\n",
      "    learn_time_ms: 2409.358\n",
      "    load_throughput: 8755766.474\n",
      "    load_time_ms: 1.713\n",
      "    sample_throughput: 616.298\n",
      "    sample_time_ms: 24338.856\n",
      "    update_time_ms: 2.182\n",
      "  timestamp: 1665248448\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 120\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:00:48,902\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 204.0x the scale of `vf_clip_param`. This means that it will take more than 204.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    120 |          3253.48 | 1800000 | -2035.38 |              2776.09 |             -7708.29 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1815000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-01-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2776.093748767079\n",
      "  episode_reward_mean: -2004.7456995159664\n",
      "  episode_reward_min: -7708.287380663002\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 605\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.777878999710083\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028095412999391556\n",
      "          model: {}\n",
      "          policy_loss: 0.015297963283956051\n",
      "          total_loss: 3340.347412109375\n",
      "          vf_explained_var: 6.622738357719982e-09\n",
      "          vf_loss: 3340.322265625\n",
      "    num_agent_steps_sampled: 1815000\n",
      "    num_agent_steps_trained: 1815000\n",
      "    num_steps_sampled: 1815000\n",
      "    num_steps_trained: 1815000\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.52093023255814\n",
      "    ram_util_percent: 30.66046511627907\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.60541344198285\n",
      "    mean_inference_ms: 0.4136462847737591\n",
      "    mean_processing_ms: 4.115514716642043\n",
      "  time_since_restore: 3535.120398044586\n",
      "  time_this_iter_s: 29.39647150039673\n",
      "  time_total_s: 3535.120398044586\n",
      "  timestamp: 1665274713\n",
      "  timesteps_since_restore: 1800000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 120\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    120 |          3535.12 |     1800000 | -248.344 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-19-05\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -233.69260696647547\n",
      "  episode_reward_min: -5865.125727549055\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 605\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.737\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.3914910554885864\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018928954377770424\n",
      "        policy_loss: 0.0016813043039292097\n",
      "        total_loss: 5782.2138671875\n",
      "        vf_explained_var: 0.9582907557487488\n",
      "        vf_loss: 5782.2109375\n",
      "    load_time_ms: 2.592\n",
      "    num_steps_sampled: 1815000\n",
      "    num_steps_trained: 1812096\n",
      "    sample_time_ms: 28632.404\n",
      "    update_time_ms: 3.088\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.177777777777784\n",
      "    ram_util_percent: 24.488888888888887\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564199213110884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4711568793093135\n",
      "    mean_inference_ms: 0.4830037627203477\n",
      "    mean_raw_obs_processing_ms: 3.794395335612403\n",
      "  time_since_restore: 3283.3817999362946\n",
      "  time_this_iter_s: 29.901944875717163\n",
      "  time_total_s: 3283.3817999362946\n",
      "  timers:\n",
      "    learn_throughput: 6319.713\n",
      "    learn_time_ms: 2373.526\n",
      "    load_throughput: 9890982.266\n",
      "    load_time_ms: 1.517\n",
      "    sample_throughput: 606.135\n",
      "    sample_time_ms: 24746.945\n",
      "    update_time_ms: 2.154\n",
      "  timestamp: 1665248478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1815000\n",
      "  training_iteration: 121\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    121 |          3283.38 | 1815000 | -2004.75 |              2776.09 |             -7708.29 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1830000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-01-45\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2089.512062248086\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 610\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.2633605003356934\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016834568232297897\n",
      "          model: {}\n",
      "          policy_loss: 0.007674333173781633\n",
      "          total_loss: 3581.0615234375\n",
      "          vf_explained_var: 6.622738357719982e-09\n",
      "          vf_loss: 3581.047607421875\n",
      "    num_agent_steps_sampled: 1830000\n",
      "    num_agent_steps_trained: 1830000\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1830000\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.636842105263153\n",
      "    ram_util_percent: 30.744736842105254\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.605115267661921\n",
      "    mean_inference_ms: 0.4136695532553567\n",
      "    mean_processing_ms: 4.11655447643646\n",
      "  time_since_restore: 3566.956563949585\n",
      "  time_this_iter_s: 31.83616590499878\n",
      "  time_total_s: 3566.956563949585\n",
      "  timestamp: 1665274745\n",
      "  timesteps_since_restore: 1815000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1815000\n",
      "  training_iteration: 121\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    121 |          3566.96 |     1815000 | -233.693 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-19-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 1990.9570440594177\n",
      "  episode_reward_mean: -272.89578988422437\n",
      "  episode_reward_min: -5230.271423256226\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 610\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.694\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5194271206855774\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010956435464322567\n",
      "        policy_loss: -0.0009797611273825169\n",
      "        total_loss: 6418.654296875\n",
      "        vf_explained_var: 0.9618275761604309\n",
      "        vf_loss: 6418.654296875\n",
      "    load_time_ms: 2.617\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1827072\n",
      "    sample_time_ms: 28625.617\n",
      "    update_time_ms: 3.0\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.5390243902439\n",
      "    ram_util_percent: 24.636585365853655\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564155893611029\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4708353144701714\n",
      "    mean_inference_ms: 0.48303993873330264\n",
      "    mean_raw_obs_processing_ms: 3.7945106945888303\n",
      "  time_since_restore: 3310.0030312538147\n",
      "  time_this_iter_s: 26.62123131752014\n",
      "  time_total_s: 3310.0030312538147\n",
      "  timers:\n",
      "    learn_throughput: 6207.941\n",
      "    learn_time_ms: 2416.26\n",
      "    load_throughput: 9023501.571\n",
      "    load_time_ms: 1.662\n",
      "    sample_throughput: 616.032\n",
      "    sample_time_ms: 24349.37\n",
      "    update_time_ms: 2.065\n",
      "  timestamp: 1665248505\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 122\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    122 |             3310 | 1830000 | -2089.51 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:01:45,608\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 209.0x the scale of `vf_clip_param`. This means that it will take more than 209.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1845000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-02-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2197.1478527683644\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 615\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2267611026763916\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029813475906848907\n",
      "          model: {}\n",
      "          policy_loss: 0.007937752641737461\n",
      "          total_loss: 3503.96826171875\n",
      "          vf_explained_var: -5.603855601776786e-09\n",
      "          vf_loss: 3503.94970703125\n",
      "    num_agent_steps_sampled: 1845000\n",
      "    num_agent_steps_trained: 1845000\n",
      "    num_steps_sampled: 1845000\n",
      "    num_steps_trained: 1845000\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.18333333333333\n",
      "    ram_util_percent: 30.74722222222222\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.604798031331761\n",
      "    mean_inference_ms: 0.41369379739908374\n",
      "    mean_processing_ms: 4.117602159654835\n",
      "  time_since_restore: 3595.9035654067993\n",
      "  time_this_iter_s: 28.947001457214355\n",
      "  time_total_s: 3595.9035654067993\n",
      "  timestamp: 1665274774\n",
      "  timesteps_since_restore: 1830000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 122\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    122 |           3595.9 |     1830000 | -272.896 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-20-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -309.1162525806457\n",
      "  episode_reward_min: -5230.271423256226\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 615\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.822\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.1301732063293457\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0188137199729681\n",
      "        policy_loss: 0.002994529902935028\n",
      "        total_loss: 4141.87744140625\n",
      "        vf_explained_var: 0.9795982241630554\n",
      "        vf_loss: 4141.873046875\n",
      "    load_time_ms: 2.57\n",
      "    num_steps_sampled: 1845000\n",
      "    num_steps_trained: 1842048\n",
      "    sample_time_ms: 28615.243\n",
      "    update_time_ms: 2.947\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.32093023255814\n",
      "    ram_util_percent: 24.548837209302324\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564115667044804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4705024723191196\n",
      "    mean_inference_ms: 0.4830761330344263\n",
      "    mean_raw_obs_processing_ms: 3.794626890844933\n",
      "  time_since_restore: 3335.100461244583\n",
      "  time_this_iter_s: 25.097429990768433\n",
      "  time_total_s: 3335.100461244583\n",
      "  timers:\n",
      "    learn_throughput: 6311.684\n",
      "    learn_time_ms: 2376.545\n",
      "    load_throughput: 9007739.996\n",
      "    load_time_ms: 1.665\n",
      "    sample_throughput: 618.719\n",
      "    sample_time_ms: 24243.633\n",
      "    update_time_ms: 1.946\n",
      "  timestamp: 1665248530\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1845000\n",
      "  training_iteration: 123\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    123 |           3335.1 | 1845000 | -2197.15 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:02:10,794\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 220.0x the scale of `vf_clip_param`. This means that it will take more than 220.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1860000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-02-37\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2235.1628482809315\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 620\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.012096881866455\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02009890228509903\n",
      "          model: {}\n",
      "          policy_loss: 0.010469278320670128\n",
      "          total_loss: 3748.61572265625\n",
      "          vf_explained_var: -6.622738357719982e-09\n",
      "          vf_loss: 3748.597412109375\n",
      "    num_agent_steps_sampled: 1860000\n",
      "    num_agent_steps_trained: 1860000\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1860000\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.908108108108106\n",
      "    ram_util_percent: 30.748648648648643\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.604414768633935\n",
      "    mean_inference_ms: 0.4137139191198095\n",
      "    mean_processing_ms: 4.118671837197956\n",
      "  time_since_restore: 3625.572982311249\n",
      "  time_this_iter_s: 29.669416904449463\n",
      "  time_total_s: 3625.572982311249\n",
      "  timestamp: 1665274803\n",
      "  timesteps_since_restore: 1845000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1845000\n",
      "  training_iteration: 123\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    123 |          3625.57 |     1845000 | -309.116 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-20-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -333.3973356658798\n",
      "  episode_reward_min: -5230.271423256226\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 620\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.896\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.09128948301076889\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01526044961065054\n",
      "        policy_loss: -0.0013523886445909739\n",
      "        total_loss: 4682.70654296875\n",
      "        vf_explained_var: 0.976188063621521\n",
      "        vf_loss: 4682.70703125\n",
      "    load_time_ms: 2.466\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1857024\n",
      "    sample_time_ms: 28718.831\n",
      "    update_time_ms: 2.962\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.64523809523809\n",
      "    ram_util_percent: 24.492857142857144\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06564050226810232\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4701732397084863\n",
      "    mean_inference_ms: 0.4831102831289644\n",
      "    mean_raw_obs_processing_ms: 3.7948916368600503\n",
      "  time_since_restore: 3361.3261687755585\n",
      "  time_this_iter_s: 26.225707530975342\n",
      "  time_total_s: 3361.3261687755585\n",
      "  timers:\n",
      "    learn_throughput: 6274.573\n",
      "    learn_time_ms: 2390.601\n",
      "    load_throughput: 9076877.353\n",
      "    load_time_ms: 1.653\n",
      "    sample_throughput: 614.316\n",
      "    sample_time_ms: 24417.404\n",
      "    update_time_ms: 1.835\n",
      "  timestamp: 1665248557\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 124\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:02:37,097\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 224.0x the scale of `vf_clip_param`. This means that it will take more than 224.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    124 |          3361.33 | 1860000 | -2235.16 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n"
=======
      "    mean_env_wait_ms: 4.604102081319154\n",
      "    mean_inference_ms: 0.41373632210339395\n",
      "    mean_processing_ms: 4.119754466893311\n",
      "  time_since_restore: 3655.3227796554565\n",
      "  time_this_iter_s: 29.749797344207764\n",
      "  time_total_s: 3655.3227796554565\n",
      "  timestamp: 1665274833\n",
      "  timesteps_since_restore: 1860000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 124\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    124 |          3655.32 |     1860000 | -333.397 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1875000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-03-08\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2302.531601752667\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 625\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.7011469602584839\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03084147535264492\n",
      "          model: {}\n",
      "          policy_loss: 0.008433015085756779\n",
      "          total_loss: 3510.522216796875\n",
      "          vf_explained_var: -1.0188828669654981e-09\n",
      "          vf_loss: 3510.502685546875\n",
      "    num_agent_steps_sampled: 1875000\n",
      "    num_agent_steps_trained: 1875000\n",
      "    num_steps_sampled: 1875000\n",
      "    num_steps_trained: 1875000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.57111111111111\n",
      "    ram_util_percent: 30.69111111111111\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-21-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -286.83314640107056\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 625\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.972\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.02393629215657711\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0201624296605587\n",
      "        policy_loss: 0.004428813699632883\n",
      "        total_loss: 7794.986328125\n",
      "        vf_explained_var: 0.9607923030853271\n",
      "        vf_loss: 7794.98046875\n",
      "    load_time_ms: 2.519\n",
      "    num_steps_sampled: 1875000\n",
      "    num_steps_trained: 1872000\n",
      "    sample_time_ms: 28733.911\n",
      "    update_time_ms: 2.951\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.94418604651163\n",
      "    ram_util_percent: 24.539534883720926\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563982066402753\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4697944943525947\n",
      "    mean_inference_ms: 0.4831439723384529\n",
      "    mean_raw_obs_processing_ms: 3.7960780240677496\n",
      "  time_since_restore: 3392.183000802994\n",
      "  time_this_iter_s: 30.856832027435303\n",
      "  time_total_s: 3392.183000802994\n",
      "  timers:\n",
      "    learn_throughput: 6279.014\n",
      "    learn_time_ms: 2388.91\n",
      "    load_throughput: 9188094.751\n",
      "    load_time_ms: 1.633\n",
      "    sample_throughput: 599.747\n",
      "    sample_time_ms: 25010.543\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1665248588\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1875000\n",
      "  training_iteration: 125\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:03:08,041\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 230.0x the scale of `vf_clip_param`. This means that it will take more than 230.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    125 |          3392.18 | 1875000 | -2302.53 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1890000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-03-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2381.8880892645375\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 630\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.3410995900630951\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019912701100111008\n",
      "          model: {}\n",
      "          policy_loss: 0.005852023139595985\n",
      "          total_loss: 3364.000244140625\n",
      "          vf_explained_var: -1.630212587144797e-08\n",
      "          vf_loss: 3363.987548828125\n",
      "    num_agent_steps_sampled: 1890000\n",
      "    num_agent_steps_trained: 1890000\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1890000\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.905555555555555\n",
      "    ram_util_percent: 30.75555555555555\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.603761953472316\n",
      "    mean_inference_ms: 0.4137585458939919\n",
      "    mean_processing_ms: 4.12097776333285\n",
      "  time_since_restore: 3685.3535900115967\n",
      "  time_this_iter_s: 30.030810356140137\n",
      "  time_total_s: 3685.3535900115967\n",
      "  timestamp: 1665274863\n",
      "  timesteps_since_restore: 1875000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1875000\n",
      "  training_iteration: 125\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    125 |          3685.35 |     1875000 | -286.833 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-21-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -274.69306888813605\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 630\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.636\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.8453298807144165\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029890988022089005\n",
      "        policy_loss: 0.0013420976465567946\n",
      "        total_loss: 2749.57861328125\n",
      "        vf_explained_var: 0.9818205833435059\n",
      "        vf_loss: 2749.57568359375\n",
      "    load_time_ms: 2.638\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1886976\n",
      "    sample_time_ms: 28141.049\n",
      "    update_time_ms: 2.944\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.331707317073175\n",
      "    ram_util_percent: 24.490243902439026\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563889855509941\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.469362997748787\n",
      "    mean_inference_ms: 0.48317518598502057\n",
      "    mean_raw_obs_processing_ms: 3.7973711887316988\n",
      "  time_since_restore: 3417.7201743125916\n",
      "  time_this_iter_s: 25.53717350959778\n",
      "  time_total_s: 3417.7201743125916\n",
      "  timers:\n",
      "    learn_throughput: 6409.326\n",
      "    learn_time_ms: 2340.34\n",
      "    load_throughput: 9493384.838\n",
      "    load_time_ms: 1.58\n",
      "    sample_throughput: 601.59\n",
      "    sample_time_ms: 24933.906\n",
      "    update_time_ms: 1.849\n",
      "  timestamp: 1665248613\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 126\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    126 |          3417.72 | 1890000 | -2381.89 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:03:33,667\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 238.0x the scale of `vf_clip_param`. This means that it will take more than 238.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1905000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-03-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2338.1988729448913\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 635\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.3177014589309692\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.036770183593034744\n",
      "          model: {}\n",
      "          policy_loss: 0.011453652754426003\n",
      "          total_loss: 3153.36328125\n",
      "          vf_explained_var: -1.1207711203553572e-08\n",
      "          vf_loss: 3153.338134765625\n",
      "    num_agent_steps_sampled: 1905000\n",
      "    num_agent_steps_trained: 1905000\n",
      "    num_steps_sampled: 1905000\n",
      "    num_steps_trained: 1905000\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.563888888888886\n",
      "    ram_util_percent: 30.774999999999995\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.603471636823789\n",
      "    mean_inference_ms: 0.41378233361148714\n",
      "    mean_processing_ms: 4.122176016263388\n",
      "  time_since_restore: 3714.251203775406\n",
      "  time_this_iter_s: 28.897613763809204\n",
      "  time_total_s: 3714.251203775406\n",
      "  timestamp: 1665274892\n",
      "  timesteps_since_restore: 1890000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 126\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    126 |          3714.25 |     1890000 | -274.693 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-22-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2231.4982670018558\n",
      "  episode_reward_mean: -315.75902365300135\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 635\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.247\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.04276307672262192\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7555730938911438\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007832398638129234\n",
      "        policy_loss: 0.001212835544720292\n",
      "        total_loss: 5810.8740234375\n",
      "        vf_explained_var: 0.9586175084114075\n",
      "        vf_loss: 5810.87255859375\n",
      "    load_time_ms: 2.642\n",
      "    num_steps_sampled: 1905000\n",
      "    num_steps_trained: 1901952\n",
      "    sample_time_ms: 28101.57\n",
      "    update_time_ms: 2.959\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.353658536585364\n",
      "    ram_util_percent: 24.507317073170732\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563743734803217\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4689344921510576\n",
      "    mean_inference_ms: 0.48320261213195903\n",
      "    mean_raw_obs_processing_ms: 3.7977836821815676\n",
      "  time_since_restore: 3442.443201303482\n",
      "  time_this_iter_s: 24.723026990890503\n",
      "  time_total_s: 3442.443201303482\n",
      "  timers:\n",
      "    learn_throughput: 6308.614\n",
      "    learn_time_ms: 2377.701\n",
      "    load_throughput: 9540025.475\n",
      "    load_time_ms: 1.572\n",
      "    sample_throughput: 615.651\n",
      "    sample_time_ms: 24364.449\n",
      "    update_time_ms: 1.825\n",
      "  timestamp: 1665248638\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1905000\n",
      "  training_iteration: 127\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:03:58,476\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 234.0x the scale of `vf_clip_param`. This means that it will take more than 234.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    127 |          3442.44 | 1905000 |  -2338.2 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n"
=======
      "    mean_env_wait_ms: 4.603129529901477\n",
      "    mean_inference_ms: 0.41380347564880354\n",
      "    mean_processing_ms: 4.12335273188731\n",
      "  time_since_restore: 3742.9559092521667\n",
      "  time_this_iter_s: 28.704705476760864\n",
      "  time_total_s: 3742.9559092521667\n",
      "  timestamp: 1665274921\n",
      "  timesteps_since_restore: 1905000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1905000\n",
      "  training_iteration: 127\n",
      "  trial_id: a95f16f0\n",
      "  \n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1920000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-04-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2298.4349646708088\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 640\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.047416675835847855\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023879675194621086\n",
      "          model: {}\n",
      "          policy_loss: 0.006433519534766674\n",
      "          total_loss: 3599.10986328125\n",
      "          vf_explained_var: -1.5792684493476372e-08\n",
      "          vf_loss: 3599.0947265625\n",
      "    num_agent_steps_sampled: 1920000\n",
      "    num_agent_steps_trained: 1920000\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1920000\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.784444444444443\n",
      "    ram_util_percent: 30.713333333333328\n",
      "  pid: 307\n",
=======
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    127 |          3742.96 |     1905000 | -315.759 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-22-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -315.3231404242886\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 640\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.652\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02138153836131096\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.41942593455314636\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013690865598618984\n",
      "        policy_loss: 0.0020902249962091446\n",
      "        total_loss: 4551.16064453125\n",
      "        vf_explained_var: 0.9781675934791565\n",
      "        vf_loss: 4551.15771484375\n",
      "    load_time_ms: 2.64\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1916928\n",
      "    sample_time_ms: 28089.729\n",
      "    update_time_ms: 2.985\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.00952380952381\n",
      "    ram_util_percent: 24.469047619047622\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563593328082284\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4685220057676327\n",
      "    mean_inference_ms: 0.4832288971501685\n",
      "    mean_raw_obs_processing_ms: 3.7990321441302144\n",
      "  time_since_restore: 3474.0501618385315\n",
      "  time_this_iter_s: 31.60696053504944\n",
      "  time_total_s: 3474.0501618385315\n",
      "  timers:\n",
      "    learn_throughput: 6392.896\n",
      "    learn_time_ms: 2346.355\n",
      "    load_throughput: 9653469.995\n",
      "    load_time_ms: 1.554\n",
      "    sample_throughput: 604.111\n",
      "    sample_time_ms: 24829.863\n",
      "    update_time_ms: 1.77\n",
      "  timestamp: 1665248670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 128\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    128 |          3474.05 | 1920000 | -2298.43 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:04:30,154\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 230.0x the scale of `vf_clip_param`. This means that it will take more than 230.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1935000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-04-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2276.5904799029904\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 645\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.8134556412696838\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027958540245890617\n",
      "          model: {}\n",
      "          policy_loss: 0.011756679974496365\n",
      "          total_loss: 3337.460205078125\n",
      "          vf_explained_var: -4.58497284583359e-09\n",
      "          vf_loss: 3337.438232421875\n",
      "    num_agent_steps_sampled: 1935000\n",
      "    num_agent_steps_trained: 1935000\n",
      "    num_steps_sampled: 1935000\n",
      "    num_steps_trained: 1935000\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.313513513513513\n",
      "    ram_util_percent: 30.7972972972973\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.602794854849637\n",
      "    mean_inference_ms: 0.413825286620731\n",
      "    mean_processing_ms: 4.124536436230338\n",
      "  time_since_restore: 3772.3318383693695\n",
      "  time_this_iter_s: 29.37592911720276\n",
      "  time_total_s: 3772.3318383693695\n",
      "  timestamp: 1665274950\n",
      "  timesteps_since_restore: 1920000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 128\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    128 |          3772.33 |     1920000 | -315.323 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-23-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -330.6076730161777\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 645\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.547\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02138153836131096\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.6612853407859802\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02198360115289688\n",
      "        policy_loss: -0.0010069701820611954\n",
      "        total_loss: 5714.85693359375\n",
      "        vf_explained_var: 0.9644346237182617\n",
      "        vf_loss: 5714.85693359375\n",
      "    load_time_ms: 2.668\n",
      "    num_steps_sampled: 1935000\n",
      "    num_steps_trained: 1931904\n",
      "    sample_time_ms: 28110.038\n",
      "    update_time_ms: 3.07\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.16428571428572\n",
      "    ram_util_percent: 24.473809523809525\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563463953568467\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4681437463532063\n",
      "    mean_inference_ms: 0.48325679397379395\n",
      "    mean_raw_obs_processing_ms: 3.7994749779945276\n",
      "  time_since_restore: 3500.0744671821594\n",
      "  time_this_iter_s: 26.02430534362793\n",
      "  time_total_s: 3500.0744671821594\n",
      "  timers:\n",
      "    learn_throughput: 6373.093\n",
      "    learn_time_ms: 2353.645\n",
      "    load_throughput: 9582308.056\n",
      "    load_time_ms: 1.565\n",
      "    sample_throughput: 603.629\n",
      "    sample_time_ms: 24849.691\n",
      "    update_time_ms: 1.689\n",
      "  timestamp: 1665248696\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1935000\n",
      "  training_iteration: 129\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:04:56,243\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 228.0x the scale of `vf_clip_param`. This means that it will take more than 228.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
=======
      "    mean_env_wait_ms: 4.602470688865662\n",
      "    mean_inference_ms: 0.41384672882160756\n",
      "    mean_processing_ms: 4.125726238479571\n",
      "  time_since_restore: 3801.7624838352203\n",
      "  time_this_iter_s: 29.43064546585083\n",
      "  time_total_s: 3801.7624838352203\n",
      "  timestamp: 1665274980\n",
      "  timesteps_since_restore: 1935000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1935000\n",
      "  training_iteration: 129\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    129 |          3801.76 |     1935000 | -330.608 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    129 |          3500.07 | 1935000 | -2276.59 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1950000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-05-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2157.2239502099883\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 650\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -2.2059757709503174\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03979285806417465\n",
      "          model: {}\n",
      "          policy_loss: 0.014092911034822464\n",
      "          total_loss: 2783.66455078125\n",
      "          vf_explained_var: 8.660504313695583e-09\n",
      "          vf_loss: 2783.63623046875\n",
      "    num_agent_steps_sampled: 1950000\n",
      "    num_agent_steps_trained: 1950000\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1950000\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.191891891891885\n",
      "    ram_util_percent: 30.93783783783784\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-23-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -314.10846412988246\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 650\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.387\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.02138153836131096\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.2480989694595337\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.1222262755036354\n",
      "        policy_loss: 0.00821064691990614\n",
      "        total_loss: 3343.060791015625\n",
      "        vf_explained_var: 0.9829971194267273\n",
      "        vf_loss: 3343.04931640625\n",
      "    load_time_ms: 2.612\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1946880\n",
      "    sample_time_ms: 28112.867\n",
      "    update_time_ms: 3.09\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.64418604651163\n",
      "    ram_util_percent: 24.64883720930233\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563382931383903\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.46784232545492\n",
      "    mean_inference_ms: 0.48328751426742067\n",
      "    mean_raw_obs_processing_ms: 3.799155223090541\n",
      "  time_since_restore: 3525.765612602234\n",
      "  time_this_iter_s: 25.691145420074463\n",
      "  time_total_s: 3525.765612602234\n",
      "  timers:\n",
      "    learn_throughput: 6470.062\n",
      "    learn_time_ms: 2318.37\n",
      "    load_throughput: 11231734.357\n",
      "    load_time_ms: 1.336\n",
      "    sample_throughput: 602.411\n",
      "    sample_time_ms: 24899.948\n",
      "    update_time_ms: 1.769\n",
      "  timestamp: 1665248722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 130\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:05:22,043\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 216.0x the scale of `vf_clip_param`. This means that it will take more than 216.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    130 |          3525.77 | 1950000 | -2157.22 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1965000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-05-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1981.8981791924514\n",
      "  episode_reward_mean: -2224.3023166423613\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 655\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9423407912254333\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022422729060053825\n",
      "          model: {}\n",
      "          policy_loss: 0.006087212357670069\n",
      "          total_loss: 3391.429443359375\n",
      "          vf_explained_var: -5.094414223805188e-09\n",
      "          vf_loss: 3391.415283203125\n",
      "    num_agent_steps_sampled: 1965000\n",
      "    num_agent_steps_trained: 1965000\n",
      "    num_steps_sampled: 1965000\n",
      "    num_steps_trained: 1965000\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.50810810810811\n",
      "    ram_util_percent: 30.827027027027036\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.602206092743847\n",
      "    mean_inference_ms: 0.4138695706579771\n",
      "    mean_processing_ms: 4.1268871870782835\n",
      "  time_since_restore: 3831.1851184368134\n",
      "  time_this_iter_s: 29.422634601593018\n",
      "  time_total_s: 3831.1851184368134\n",
      "  timestamp: 1665275009\n",
      "  timesteps_since_restore: 1950000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 130\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    130 |          3831.19 |     1950000 | -314.108 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-23-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -340.4421743929058\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 655\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.709\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.03370589390397072\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014017399400472641\n",
      "        policy_loss: 0.0013976864283904433\n",
      "        total_loss: 4129.19970703125\n",
      "        vf_explained_var: 0.9810900688171387\n",
      "        vf_loss: 4129.19775390625\n",
      "    load_time_ms: 2.617\n",
      "    num_steps_sampled: 1965000\n",
      "    num_steps_trained: 1961856\n",
      "    sample_time_ms: 27850.946\n",
      "    update_time_ms: 3.12\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.60487804878049\n",
      "    ram_util_percent: 24.62682926829269\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563345473072309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4675321784574997\n",
      "    mean_inference_ms: 0.48331894947136556\n",
      "    mean_raw_obs_processing_ms: 3.7987429487298856\n",
      "  time_since_restore: 3551.4109122753143\n",
      "  time_this_iter_s: 25.645299673080444\n",
      "  time_total_s: 3551.4109122753143\n",
      "  timers:\n",
      "    learn_throughput: 6315.494\n",
      "    learn_time_ms: 2375.111\n",
      "    load_throughput: 11268346.677\n",
      "    load_time_ms: 1.331\n",
      "    sample_throughput: 614.318\n",
      "    sample_time_ms: 24417.341\n",
      "    update_time_ms: 1.773\n",
      "  timestamp: 1665248747\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1965000\n",
      "  training_iteration: 131\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.601987726852476\n",
      "    mean_inference_ms: 0.41389312658875643\n",
      "    mean_processing_ms: 4.127953855407854\n",
      "  time_since_restore: 3860.405657052994\n",
      "  time_this_iter_s: 29.22053861618042\n",
      "  time_total_s: 3860.405657052994\n",
      "  timestamp: 1665275039\n",
      "  timesteps_since_restore: 1965000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1965000\n",
      "  training_iteration: 131\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    131 |          3860.41 |     1965000 | -340.442 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    131 |          3551.41 | 1965000 |  -2224.3 |               1981.9 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:05:47,779\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 222.0x the scale of `vf_clip_param`. This means that it will take more than 222.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1980000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-06-12\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1593.5773241870947\n",
      "  episode_reward_mean: -2324.5161924932227\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 660\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.8843846321105957\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020232394337654114\n",
      "          model: {}\n",
      "          policy_loss: 0.010090135037899017\n",
      "          total_loss: 3719.917236328125\n",
      "          vf_explained_var: 3.5660898678457897e-09\n",
      "          vf_loss: 3719.899658203125\n",
      "    num_agent_steps_sampled: 1980000\n",
      "    num_agent_steps_trained: 1980000\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1980000\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.482857142857146\n",
      "    ram_util_percent: 30.857142857142858\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -365.79721099470095\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 660\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.49\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.13655047118663788\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020603565499186516\n",
      "        policy_loss: 0.0018962122267112136\n",
      "        total_loss: 4042.813232421875\n",
      "        vf_explained_var: 0.9818778038024902\n",
      "        vf_loss: 4042.810546875\n",
      "    load_time_ms: 2.69\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1976832\n",
      "    sample_time_ms: 27942.894\n",
      "    update_time_ms: 3.219\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.75581395348837\n",
      "    ram_util_percent: 24.493023255813956\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563296326065945\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4672175525379587\n",
      "    mean_inference_ms: 0.4833511110304559\n",
      "    mean_raw_obs_processing_ms: 3.797565639356922\n",
      "  time_since_restore: 3576.3832845687866\n",
      "  time_this_iter_s: 24.97237229347229\n",
      "  time_total_s: 3576.3832845687866\n",
      "  timers:\n",
      "    learn_throughput: 6353.22\n",
      "    learn_time_ms: 2361.008\n",
      "    load_throughput: 12612677.92\n",
      "    load_time_ms: 1.189\n",
      "    sample_throughput: 618.127\n",
      "    sample_time_ms: 24266.846\n",
      "    update_time_ms: 1.706\n",
      "  timestamp: 1665248772\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 132\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:06:12,850\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 232.0x the scale of `vf_clip_param`. This means that it will take more than 232.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    132 |          3576.38 | 1980000 | -2324.52 |              1593.58 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 1995000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-06-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -2165.8613460293914\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 665\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.36532360315322876\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.861614465713501\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04482780769467354\n",
      "          model: {}\n",
      "          policy_loss: 0.014618431217968464\n",
      "          total_loss: 3251.460693359375\n",
      "          vf_explained_var: 5.094414334827491e-10\n",
      "          vf_loss: 3251.429443359375\n",
      "    num_agent_steps_sampled: 1995000\n",
      "    num_agent_steps_trained: 1995000\n",
      "    num_steps_sampled: 1995000\n",
      "    num_steps_trained: 1995000\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.810810810810807\n",
      "    ram_util_percent: 30.856756756756763\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.601792042073988\n",
      "    mean_inference_ms: 0.41391734413514647\n",
      "    mean_processing_ms: 4.129134891989152\n",
      "  time_since_restore: 3890.271917104721\n",
      "  time_this_iter_s: 29.866260051727295\n",
      "  time_total_s: 3890.271917104721\n",
      "  timestamp: 1665275068\n",
      "  timesteps_since_restore: 1980000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 132\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    132 |          3890.27 |     1980000 | -365.797 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-24-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -406.44315767286406\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 665\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1481.786\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4127935767173767\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022565145045518875\n",
      "        policy_loss: 0.00254058837890625\n",
      "        total_loss: 8158.41357421875\n",
      "        vf_explained_var: 0.9559457898139954\n",
      "        vf_loss: 8158.41015625\n",
      "    load_time_ms: 2.668\n",
      "    num_steps_sampled: 1995000\n",
      "    num_steps_trained: 1991808\n",
      "    sample_time_ms: 27920.055\n",
      "    update_time_ms: 3.231\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.85476190476191\n",
      "    ram_util_percent: 24.5\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563251512988305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.466979023258208\n",
      "    mean_inference_ms: 0.48338363707463494\n",
      "    mean_raw_obs_processing_ms: 3.7963171594456133\n",
      "  time_since_restore: 3602.144923686981\n",
      "  time_this_iter_s: 25.76163911819458\n",
      "  time_total_s: 3602.144923686981\n",
      "  timers:\n",
      "    learn_throughput: 6375.466\n",
      "    learn_time_ms: 2352.769\n",
      "    load_throughput: 12538025.867\n",
      "    load_time_ms: 1.196\n",
      "    sample_throughput: 616.233\n",
      "    sample_time_ms: 24341.435\n",
      "    update_time_ms: 1.711\n",
      "  timestamp: 1665248798\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1995000\n",
      "  training_iteration: 133\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:06:38,684\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 217.0x the scale of `vf_clip_param`. This means that it will take more than 217.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    133 |          3602.14 | 1995000 | -2165.86 |              2558.79 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2010000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-07-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -2092.950768093964\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 670\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5479854345321655\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.325933039188385\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018613601103425026\n",
      "          model: {}\n",
      "          policy_loss: 0.006000249180942774\n",
      "          total_loss: 3488.930908203125\n",
      "          vf_explained_var: -5.094414334827491e-10\n",
      "          vf_loss: 3488.9150390625\n",
      "    num_agent_steps_sampled: 2010000\n",
      "    num_agent_steps_trained: 2010000\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2010000\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.17222222222222\n",
      "    ram_util_percent: 30.866666666666674\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.601587850072211\n",
      "    mean_inference_ms: 0.4139414640199077\n",
      "    mean_processing_ms: 4.130220652291611\n",
      "  time_since_restore: 3919.706416606903\n",
      "  time_this_iter_s: 29.434499502182007\n",
      "  time_total_s: 3919.706416606903\n",
      "  timestamp: 1665275098\n",
      "  timesteps_since_restore: 1995000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 1995000\n",
      "  training_iteration: 133\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    133 |          3919.71 |     1995000 | -406.443 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-25-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -362.36126510107766\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 670\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.196\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.939169704914093\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01781870424747467\n",
      "        policy_loss: 0.0015701611991971731\n",
      "        total_loss: 6468.8408203125\n",
      "        vf_explained_var: 0.9580222964286804\n",
      "        vf_loss: 6468.8388671875\n",
      "    load_time_ms: 2.786\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2006784\n",
      "    sample_time_ms: 27843.826\n",
      "    update_time_ms: 3.226\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.77317073170732\n",
      "    ram_util_percent: 24.52926829268293\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656319507487163\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.466755239275908\n",
      "    mean_inference_ms: 0.48341454138816364\n",
      "    mean_raw_obs_processing_ms: 3.7952561458648626\n",
      "  time_since_restore: 3627.1344974040985\n",
      "  time_this_iter_s: 24.98957371711731\n",
      "  time_total_s: 3627.1344974040985\n",
      "  timers:\n",
      "    learn_throughput: 6482.779\n",
      "    learn_time_ms: 2313.823\n",
      "    load_throughput: 12463017.769\n",
      "    load_time_ms: 1.204\n",
      "    sample_throughput: 618.366\n",
      "    sample_time_ms: 24257.483\n",
      "    update_time_ms: 1.538\n",
      "  timestamp: 1665248823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 134\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:07:03,772\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 209.0x the scale of `vf_clip_param`. This means that it will take more than 209.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    134 |          3627.13 | 2010000 | -2092.95 |              2558.79 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 4.6013993041540875\n",
      "    mean_inference_ms: 0.4139660602102761\n",
      "    mean_processing_ms: 4.131309069285754\n",
      "  time_since_restore: 3948.7092945575714\n",
      "  time_this_iter_s: 29.002877950668335\n",
      "  time_total_s: 3948.7092945575714\n",
      "  timestamp: 1665275127\n",
      "  timesteps_since_restore: 2010000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 134\n",
      "  trial_id: a95f16f0\n",
      "  \n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2025000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-07-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -2041.7399992705905\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 675\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5479854345321655\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.8008862733840942\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01735592447221279\n",
      "          model: {}\n",
      "          policy_loss: 0.006200156174600124\n",
      "          total_loss: 2792.32373046875\n",
      "          vf_explained_var: -1.171715258152517e-08\n",
      "          vf_loss: 2792.3076171875\n",
      "    num_agent_steps_sampled: 2025000\n",
      "    num_agent_steps_trained: 2025000\n",
      "    num_steps_sampled: 2025000\n",
      "    num_steps_trained: 2025000\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.472972972972972\n",
      "    ram_util_percent: 30.854054054054064\n",
      "  pid: 307\n",
=======
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    134 |          3948.71 |     2010000 | -362.361 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-25-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -364.9206270928317\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 675\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.075\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03207230567932129\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.8007339239120483\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.041017599403858185\n",
      "        policy_loss: 0.009157867170870304\n",
      "        total_loss: 4110.2666015625\n",
      "        vf_explained_var: 0.9717850685119629\n",
      "        vf_loss: 4110.25634765625\n",
      "    load_time_ms: 2.757\n",
      "    num_steps_sampled: 2025000\n",
      "    num_steps_trained: 2021760\n",
      "    sample_time_ms: 27934.544\n",
      "    update_time_ms: 3.21\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.291111111111114\n",
      "    ram_util_percent: 24.55555555555555\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563155415975296\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.466547006848931\n",
      "    mean_inference_ms: 0.4834443781347315\n",
      "    mean_raw_obs_processing_ms: 3.7943425721209976\n",
      "  time_since_restore: 3653.0455615520477\n",
      "  time_this_iter_s: 25.91106414794922\n",
      "  time_total_s: 3653.0455615520477\n",
      "  timers:\n",
      "    learn_throughput: 6531.22\n",
      "    learn_time_ms: 2296.661\n",
      "    load_throughput: 12104773.449\n",
      "    load_time_ms: 1.239\n",
      "    sample_throughput: 630.781\n",
      "    sample_time_ms: 23780.061\n",
      "    update_time_ms: 1.499\n",
      "  timestamp: 1665248849\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2025000\n",
      "  training_iteration: 135\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:07:29,767\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 204.0x the scale of `vf_clip_param`. This means that it will take more than 204.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    135 |          3653.05 | 2025000 | -2041.74 |              2558.79 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2040000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-07-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1996.2261869749677\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 680\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5479854345321655\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.5798534154891968\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.07008674740791321\n",
      "          model: {}\n",
      "          policy_loss: 0.032076362520456314\n",
      "          total_loss: 3224.959716796875\n",
      "          vf_explained_var: -3.5660898678457897e-09\n",
      "          vf_loss: 3224.888916015625\n",
      "    num_agent_steps_sampled: 2040000\n",
      "    num_agent_steps_trained: 2040000\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2040000\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.91351351351351\n",
      "    ram_util_percent: 30.851351351351358\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.60119374563582\n",
      "    mean_inference_ms: 0.4139883996797817\n",
      "    mean_processing_ms: 4.132495892168871\n",
      "  time_since_restore: 3979.6456735134125\n",
      "  time_this_iter_s: 30.936378955841064\n",
      "  time_total_s: 3979.6456735134125\n",
      "  timestamp: 1665275158\n",
      "  timesteps_since_restore: 2025000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2025000\n",
      "  training_iteration: 135\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    135 |          3979.65 |     2025000 | -364.921 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-26-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -463.6783490399857\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 680\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1482.549\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.048108458518981934\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.137397289276123\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011613890528678894\n",
      "        policy_loss: 0.0006970480317249894\n",
      "        total_loss: 8842.4384765625\n",
      "        vf_explained_var: 0.9620862603187561\n",
      "        vf_loss: 8842.435546875\n",
      "    load_time_ms: 2.642\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2036736\n",
      "    sample_time_ms: 28000.426\n",
      "    update_time_ms: 3.22\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.37380952380953\n",
      "    ram_util_percent: 24.55714285714286\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563160732072157\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4663760510833628\n",
      "    mean_inference_ms: 0.4834760572809551\n",
      "    mean_raw_obs_processing_ms: 3.793392144766825\n",
      "  time_since_restore: 3679.1147122383118\n",
      "  time_this_iter_s: 26.069150686264038\n",
      "  time_total_s: 3679.1147122383118\n",
      "  timers:\n",
      "    learn_throughput: 6572.644\n",
      "    learn_time_ms: 2282.187\n",
      "    load_throughput: 10579921.3\n",
      "    load_time_ms: 1.418\n",
      "    sample_throughput: 628.988\n",
      "    sample_time_ms: 23847.814\n",
      "    update_time_ms: 1.451\n",
      "  timestamp: 1665248875\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 136\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.601001482599136\n",
      "    mean_inference_ms: 0.41401068029746235\n",
      "    mean_processing_ms: 4.132942987047096\n",
      "  time_since_restore: 4009.196026802063\n",
      "  time_this_iter_s: 29.550353288650513\n",
      "  time_total_s: 4009.196026802063\n",
      "  timestamp: 1665275187\n",
      "  timesteps_since_restore: 2040000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 136\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    136 |           4009.2 |     2040000 | -463.678 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    136 |          3679.11 | 2040000 | -1996.23 |              2558.79 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2055000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-08-21\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1913.7641584578555\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 685\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8219781517982483\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.5591027736663818\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02272135019302368\n",
      "          model: {}\n",
      "          policy_loss: 0.009189416654407978\n",
      "          total_loss: 3107.54638671875\n",
      "          vf_explained_var: 4.58497284583359e-09\n",
      "          vf_loss: 3107.51806640625\n",
      "    num_agent_steps_sampled: 2055000\n",
      "    num_agent_steps_trained: 2055000\n",
      "    num_steps_sampled: 2055000\n",
      "    num_steps_trained: 2055000\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.28918918918919\n",
      "    ram_util_percent: 30.85945945945947\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-26-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -425.75658810240105\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 685\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.494\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.048108458518981934\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -1.2202695608139038\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.032547395676374435\n",
      "        policy_loss: 0.0038417335599660873\n",
      "        total_loss: 4574.52099609375\n",
      "        vf_explained_var: 0.9622170329093933\n",
      "        vf_loss: 4574.515625\n",
      "    load_time_ms: 2.653\n",
      "    num_steps_sampled: 2055000\n",
      "    num_steps_trained: 2051712\n",
      "    sample_time_ms: 28091.656\n",
      "    update_time_ms: 3.229\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.530952380952385\n",
      "    ram_util_percent: 24.523809523809526\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563190714498118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4662201586017387\n",
      "    mean_inference_ms: 0.4835092118043901\n",
      "    mean_raw_obs_processing_ms: 3.7917505967537726\n",
      "  time_since_restore: 3704.4089245796204\n",
      "  time_this_iter_s: 25.294212341308594\n",
      "  time_total_s: 3704.4089245796204\n",
      "  timers:\n",
      "    learn_throughput: 6626.584\n",
      "    learn_time_ms: 2263.61\n",
      "    load_throughput: 10596136.421\n",
      "    load_time_ms: 1.416\n",
      "    sample_throughput: 627.007\n",
      "    sample_time_ms: 23923.159\n",
      "    update_time_ms: 1.447\n",
      "  timestamp: 1665248901\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2055000\n",
      "  training_iteration: 137\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    137 |          3704.41 | 2055000 | -1913.76 |              2558.79 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2070000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-08-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1919.9415641749358\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 690\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8219781517982483\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9356129169464111\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011943849734961987\n",
      "          model: {}\n",
      "          policy_loss: 0.006612853612750769\n",
      "          total_loss: 3401.631103515625\n",
      "          vf_explained_var: -8.660504313695583e-09\n",
      "          vf_loss: 3401.61474609375\n",
      "    num_agent_steps_sampled: 2070000\n",
      "    num_agent_steps_trained: 2070000\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2070000\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.625\n",
      "    ram_util_percent: 30.866666666666674\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.60084956197632\n",
      "    mean_inference_ms: 0.41403135312977285\n",
      "    mean_processing_ms: 4.133378830337071\n",
      "  time_since_restore: 4038.8226342201233\n",
      "  time_this_iter_s: 29.626607418060303\n",
      "  time_total_s: 4038.8226342201233\n",
      "  timestamp: 1665275217\n",
      "  timesteps_since_restore: 2055000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2055000\n",
      "  training_iteration: 137\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    137 |          4038.82 |     2055000 | -425.757 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-27-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -443.2208777393199\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 690\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.748\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.048108458518981934\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33957600593566895\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 1.2059952020645142\n",
      "        policy_loss: 0.1090601310133934\n",
      "        total_loss: 5531.68310546875\n",
      "        vf_explained_var: 0.9669268727302551\n",
      "        vf_loss: 5531.515625\n",
      "    load_time_ms: 2.635\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2066688\n",
      "    sample_time_ms: 28070.534\n",
      "    update_time_ms: 3.161\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.41428571428571\n",
      "    ram_util_percent: 24.564285714285717\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563177932317997\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4660429928367353\n",
      "    mean_inference_ms: 0.48354039999063714\n",
      "    mean_raw_obs_processing_ms: 3.7899933120291944\n",
      "  time_since_restore: 3729.6622366905212\n",
      "  time_this_iter_s: 25.25331211090088\n",
      "  time_total_s: 3729.6622366905212\n",
      "  timers:\n",
      "    learn_throughput: 6748.611\n",
      "    learn_time_ms: 2222.68\n",
      "    load_throughput: 10306090.489\n",
      "    load_time_ms: 1.455\n",
      "    sample_throughput: 642.994\n",
      "    sample_time_ms: 23328.375\n",
      "    update_time_ms: 1.426\n",
      "  timestamp: 1665248926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 138\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.600696688736571\n",
      "    mean_inference_ms: 0.4140522493745782\n",
      "    mean_processing_ms: 4.133812772866338\n",
      "  time_since_restore: 4067.9983863830566\n",
      "  time_this_iter_s: 29.17575216293335\n",
      "  time_total_s: 4067.9983863830566\n",
      "  timestamp: 1665275246\n",
      "  timesteps_since_restore: 2070000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 138\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    138 |             4068 |     2070000 | -443.221 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    138 |          3729.66 | 2070000 | -1919.94 |              2558.79 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2085000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-09-12\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1797.4761057185285\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 695\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8219781517982483\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.6952086687088013\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022748198360204697\n",
      "          model: {}\n",
      "          policy_loss: 0.008871698752045631\n",
      "          total_loss: 3174.779052734375\n",
      "          vf_explained_var: 5.603855601776786e-09\n",
      "          vf_loss: 3174.751708984375\n",
      "    num_agent_steps_sampled: 2085000\n",
      "    num_agent_steps_trained: 2085000\n",
      "    num_steps_sampled: 2085000\n",
      "    num_steps_trained: 2085000\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.57222222222222\n",
      "    ram_util_percent: 30.89166666666667\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-27-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -545.0487220704886\n",
      "  episode_reward_min: -5015.691682822105\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 695\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.252\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.0721626877784729\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.9841999411582947\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001832595095038414\n",
      "        policy_loss: -0.001014543347992003\n",
      "        total_loss: 12828.6064453125\n",
      "        vf_explained_var: 0.9147266745567322\n",
      "        vf_loss: 12828.6064453125\n",
      "    load_time_ms: 2.579\n",
      "    num_steps_sampled: 2085000\n",
      "    num_steps_trained: 2081664\n",
      "    sample_time_ms: 28042.586\n",
      "    update_time_ms: 3.051\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.75365853658536\n",
      "    ram_util_percent: 24.573170731707318\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563178396942791\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4659000582891992\n",
      "    mean_inference_ms: 0.48357095436429554\n",
      "    mean_raw_obs_processing_ms: 3.7883392660556057\n",
      "  time_since_restore: 3755.3040313720703\n",
      "  time_this_iter_s: 25.641794681549072\n",
      "  time_total_s: 3755.3040313720703\n",
      "  timers:\n",
      "    learn_throughput: 6835.11\n",
      "    learn_time_ms: 2194.551\n",
      "    load_throughput: 10332324.974\n",
      "    load_time_ms: 1.452\n",
      "    sample_throughput: 643.271\n",
      "    sample_time_ms: 23318.311\n",
      "    update_time_ms: 1.406\n",
      "  timestamp: 1665248952\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2085000\n",
      "  training_iteration: 139\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    139 |           3755.3 | 2085000 | -1797.48 |              2558.79 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2100000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-09-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1764.234294185556\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 700\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8219781517982483\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.5420166850090027\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014317546039819717\n",
      "          model: {}\n",
      "          policy_loss: 0.007382854353636503\n",
      "          total_loss: 3444.591064453125\n",
      "          vf_explained_var: -8.151062935723985e-09\n",
      "          vf_loss: 3444.57177734375\n",
      "    num_agent_steps_sampled: 2100000\n",
      "    num_agent_steps_trained: 2100000\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2100000\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.673684210526318\n",
      "    ram_util_percent: 30.85526315789475\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600549311915443\n",
      "    mean_inference_ms: 0.41407279578218814\n",
      "    mean_processing_ms: 4.134217752410624\n",
      "  time_since_restore: 4097.133095979691\n",
      "  time_this_iter_s: 29.13470959663391\n",
      "  time_total_s: 4097.133095979691\n",
      "  timestamp: 1665275276\n",
      "  timesteps_since_restore: 2085000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2085000\n",
      "  training_iteration: 139\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    139 |          4097.13 |     2085000 | -545.049 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-28-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -667.5094238768147\n",
      "  episode_reward_min: -5663.576779273668\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 700\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.3\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.03608134388923645\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.9201149940490723\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002317895647138357\n",
      "        policy_loss: 0.0003936747962143272\n",
      "        total_loss: 8298.9052734375\n",
      "        vf_explained_var: 0.9592844247817993\n",
      "        vf_loss: 8298.904296875\n",
      "    load_time_ms: 2.581\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2096640\n",
      "    sample_time_ms: 28053.463\n",
      "    update_time_ms: 3.008\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.87906976744186\n",
      "    ram_util_percent: 24.625581395348835\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563162837099362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.465783005415567\n",
      "    mean_inference_ms: 0.4835996836298928\n",
      "    mean_raw_obs_processing_ms: 3.7868928681226457\n",
      "  time_since_restore: 3781.834286212921\n",
      "  time_this_iter_s: 26.53025484085083\n",
      "  time_total_s: 3781.834286212921\n",
      "  timers:\n",
      "    learn_throughput: 6792.058\n",
      "    learn_time_ms: 2208.462\n",
      "    load_throughput: 10235668.5\n",
      "    load_time_ms: 1.465\n",
      "    sample_throughput: 641.359\n",
      "    sample_time_ms: 23387.835\n",
      "    update_time_ms: 1.34\n",
      "  timestamp: 1665248978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 140\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    140 |          3781.83 | 2100000 | -1764.23 |              2558.79 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2115000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-10-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1686.3865801510783\n",
      "  episode_reward_min: -8261.374423863153\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 705\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8219781517982483\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.47885826230049133\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008604928851127625\n",
      "          model: {}\n",
      "          policy_loss: 0.004090027417987585\n",
      "          total_loss: 3122.058837890625\n",
      "          vf_explained_var: -1.0698269825581974e-08\n",
      "          vf_loss: 3122.047607421875\n",
      "    num_agent_steps_sampled: 2115000\n",
      "    num_agent_steps_trained: 2115000\n",
      "    num_steps_sampled: 2115000\n",
      "    num_steps_trained: 2115000\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.37837837837838\n",
      "    ram_util_percent: 31.010810810810806\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.60041081459956\n",
      "    mean_inference_ms: 0.4140923289330711\n",
      "    mean_processing_ms: 4.134628285420682\n",
      "  time_since_restore: 4126.664918661118\n",
      "  time_this_iter_s: 29.531822681427002\n",
      "  time_total_s: 4126.664918661118\n",
      "  timestamp: 1665275305\n",
      "  timesteps_since_restore: 2100000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 140\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    140 |          4126.66 |     2100000 | -667.509 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-28-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -788.4322924356742\n",
      "  episode_reward_min: -5663.576779273668\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 705\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.575\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.018040671944618225\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0700119733810425\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007846910506486893\n",
      "        policy_loss: -0.0015746726421639323\n",
      "        total_loss: 11183.2763671875\n",
      "        vf_explained_var: 0.9275637269020081\n",
      "        vf_loss: 11183.2763671875\n",
      "    load_time_ms: 2.631\n",
      "    num_steps_sampled: 2115000\n",
      "    num_steps_trained: 2111616\n",
      "    sample_time_ms: 28066.459\n",
      "    update_time_ms: 3.017\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.730952380952374\n",
      "    ram_util_percent: 24.571428571428573\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563158592688495\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.465696971772244\n",
      "    mean_inference_ms: 0.4836279780846786\n",
      "    mean_raw_obs_processing_ms: 3.7847383648682165\n",
      "  time_since_restore: 3807.3529708385468\n",
      "  time_this_iter_s: 25.51868462562561\n",
      "  time_total_s: 3807.3529708385468\n",
      "  timers:\n",
      "    learn_throughput: 6773.275\n",
      "    learn_time_ms: 2214.586\n",
      "    load_throughput: 9983427.22\n",
      "    load_time_ms: 1.502\n",
      "    sample_throughput: 641.877\n",
      "    sample_time_ms: 23368.957\n",
      "    update_time_ms: 1.458\n",
      "  timestamp: 1665249004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2115000\n",
      "  training_iteration: 141\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    141 |          3807.35 | 2115000 | -1686.39 |              2558.79 |             -8261.37 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2130000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-10-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1663.7035325490715\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 710\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.41098907589912415\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.6356151103973389\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04006316512823105\n",
      "          model: {}\n",
      "          policy_loss: 0.02279338799417019\n",
      "          total_loss: 3547.844482421875\n",
      "          vf_explained_var: -1.3754918093411561e-08\n",
      "          vf_loss: 3547.8046875\n",
      "    num_agent_steps_sampled: 2130000\n",
      "    num_agent_steps_trained: 2130000\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2130000\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.505263157894735\n",
      "    ram_util_percent: 30.989473684210537\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600225052670536\n",
      "    mean_inference_ms: 0.41410465743761415\n",
      "    mean_processing_ms: 4.134791727991211\n",
      "  time_since_restore: 4156.028628349304\n",
      "  time_this_iter_s: 29.363709688186646\n",
      "  time_total_s: 4156.028628349304\n",
      "  timestamp: 1665275334\n",
      "  timesteps_since_restore: 2115000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2115000\n",
      "  training_iteration: 141\n",
      "  trial_id: a95f16f0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    141 |          4156.03 |     2115000 | -788.432 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-29-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -791.6770136289699\n",
      "  episode_reward_min: -5663.576779273668\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 710\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.291\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.009020335972309113\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.163979172706604\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010056531056761742\n",
      "        policy_loss: -0.001747257192619145\n",
      "        total_loss: 12356.345703125\n",
      "        vf_explained_var: 0.912399411201477\n",
      "        vf_loss: 12356.345703125\n",
      "    load_time_ms: 2.665\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2126592\n",
      "    sample_time_ms: 27964.792\n",
      "    update_time_ms: 3.004\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.25121951219512\n",
      "    ram_util_percent: 24.573170731707318\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563142660153583\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.465605818166307\n",
      "    mean_inference_ms: 0.48365656036422505\n",
      "    mean_raw_obs_processing_ms: 3.7825574800321937\n",
      "  time_since_restore: 3833.905244588852\n",
      "  time_this_iter_s: 26.552273750305176\n",
      "  time_total_s: 3833.905244588852\n",
      "  timers:\n",
      "    learn_throughput: 6747.916\n",
      "    learn_time_ms: 2222.909\n",
      "    load_throughput: 9886164.145\n",
      "    load_time_ms: 1.517\n",
      "    sample_throughput: 637.794\n",
      "    sample_time_ms: 23518.579\n",
      "    update_time_ms: 1.472\n",
      "  timestamp: 1665249031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 142\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.6/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    142 |          3833.91 | 2130000 |  -1663.7 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2145000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-10-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1590.7573211423164\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 715\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.6202075481414795\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013806946575641632\n",
      "          model: {}\n",
      "          policy_loss: 0.004147643223404884\n",
      "          total_loss: 3250.4423828125\n",
      "          vf_explained_var: -5.094414223805188e-09\n",
      "          vf_loss: 3250.429931640625\n",
      "    num_agent_steps_sampled: 2145000\n",
      "    num_agent_steps_trained: 2145000\n",
      "    num_steps_sampled: 2145000\n",
      "    num_steps_trained: 2145000\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.84722222222222\n",
      "    ram_util_percent: 30.96388888888889\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.6000562427301155\n",
      "    mean_inference_ms: 0.4141133967610675\n",
      "    mean_processing_ms: 4.134961237152949\n",
      "  time_since_restore: 4184.885762214661\n",
      "  time_this_iter_s: 28.857133865356445\n",
      "  time_total_s: 4184.885762214661\n",
      "  timestamp: 1665275363\n",
      "  timesteps_since_restore: 2130000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 142\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    142 |          4184.89 |     2130000 | -791.677 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-29-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -929.0647965125041\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 715\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.314\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.009020335972309113\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.8851028680801392\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010745520703494549\n",
      "        policy_loss: -0.0005985460011288524\n",
      "        total_loss: 12801.076171875\n",
      "        vf_explained_var: 0.9255713224411011\n",
      "        vf_loss: 12801.0771484375\n",
      "    load_time_ms: 2.558\n",
      "    num_steps_sampled: 2145000\n",
      "    num_steps_trained: 2141568\n",
      "    sample_time_ms: 27933.484\n",
      "    update_time_ms: 3.027\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.16341463414634\n",
      "    ram_util_percent: 24.573170731707318\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563164140336454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4655498739127695\n",
      "    mean_inference_ms: 0.4836876567276785\n",
      "    mean_raw_obs_processing_ms: 3.780339417915318\n",
      "  time_since_restore: 3858.9912855625153\n",
      "  time_this_iter_s: 25.08604097366333\n",
      "  time_total_s: 3858.9912855625153\n",
      "  timers:\n",
      "    learn_throughput: 6728.841\n",
      "    learn_time_ms: 2229.21\n",
      "    load_throughput: 9981526.55\n",
      "    load_time_ms: 1.503\n",
      "    sample_throughput: 639.802\n",
      "    sample_time_ms: 23444.747\n",
      "    update_time_ms: 1.467\n",
      "  timestamp: 1665249056\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2145000\n",
      "  training_iteration: 143\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    143 |          3858.99 | 2145000 | -1590.76 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2160000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-11-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1532.9702001293167\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 720\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.08717840164899826\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016705622896552086\n",
      "          model: {}\n",
      "          policy_loss: 0.008063146844506264\n",
      "          total_loss: 3215.640869140625\n",
      "          vf_explained_var: 1.528324244937096e-09\n",
      "          vf_loss: 3215.6220703125\n",
      "    num_agent_steps_sampled: 2160000\n",
      "    num_agent_steps_trained: 2160000\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2160000\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.94324324324324\n",
      "    ram_util_percent: 30.93783783783784\n",
      "  pid: 307\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06563159885865762\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.465488364629444\n",
      "    mean_inference_ms: 0.4837178760179245\n",
      "    mean_raw_obs_processing_ms: 3.7781701063628943\n",
      "  time_since_restore: 3885.152812242508\n",
      "  time_this_iter_s: 26.161526679992676\n",
      "  time_total_s: 3885.152812242508\n",
      "  timers:\n",
      "    learn_throughput: 6571.6\n",
      "    learn_time_ms: 2282.549\n",
      "    load_throughput: 9062364.6\n",
      "    load_time_ms: 1.655\n",
      "    sample_throughput: 638.072\n",
      "    sample_time_ms: 23508.321\n",
      "    update_time_ms: 1.474\n",
      "  timestamp: 1665249082\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 144\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    144 |          3885.15 | 2160000 | -1532.97 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2175000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-11-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1487.5969035306753\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 725\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9088347554206848\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015675466507673264\n",
      "          model: {}\n",
      "          policy_loss: 0.008759738877415657\n",
      "          total_loss: 3387.67529296875\n",
      "          vf_explained_var: -1.528324244937096e-09\n",
      "          vf_loss: 3387.6572265625\n",
      "    num_agent_steps_sampled: 2175000\n",
      "    num_agent_steps_trained: 2175000\n",
      "    num_steps_sampled: 2175000\n",
      "    num_steps_trained: 2175000\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.23513513513514\n",
      "    ram_util_percent: 30.95945945945946\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599899843852498\n",
      "    mean_inference_ms: 0.41412408754640984\n",
      "    mean_processing_ms: 4.135066624216551\n",
      "  time_since_restore: 4214.006501913071\n",
      "  time_this_iter_s: 29.120739698410034\n",
      "  time_total_s: 4214.006501913071\n",
      "  timestamp: 1665275393\n",
      "  timesteps_since_restore: 2145000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2145000\n",
      "  training_iteration: 143\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    143 |          4214.01 |     2145000 | -929.065 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-30-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -1085.6496126884713\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 720\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.869\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.009020335972309113\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 3.1751787662506104\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005936908069998026\n",
      "        policy_loss: 0.00011150513455504552\n",
      "        total_loss: 14388.396484375\n",
      "        vf_explained_var: 0.9164915084838867\n",
      "        vf_loss: 14388.3984375\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2156544\n",
      "    sample_time_ms: 27968.294\n",
      "    update_time_ms: 3.021\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.98809523809524\n",
      "    ram_util_percent: 24.609523809523807\n",
      "  pid: 25636\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.599715033751196\n",
      "    mean_inference_ms: 0.41413529177540304\n",
      "    mean_processing_ms: 4.1351721281430205\n",
      "  time_since_restore: 4243.361526012421\n",
      "  time_this_iter_s: 29.355024099349976\n",
      "  time_total_s: 4243.361526012421\n",
      "  timestamp: 1665275422\n",
      "  timesteps_since_restore: 2160000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 144\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    144 |          4243.36 |     2160000 | -1085.65 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-30-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -1126.8758901141944\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 725\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.493\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.004510167986154556\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.932579755783081\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006915210280567408\n",
      "        policy_loss: -0.0005713237915188074\n",
      "        total_loss: 11446.794921875\n",
      "        vf_explained_var: 0.8895868062973022\n",
      "        vf_loss: 11446.7978515625\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 2175000\n",
      "    num_steps_trained: 2171520\n",
      "    sample_time_ms: 27816.439\n",
      "    update_time_ms: 3.022\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.80714285714286\n",
      "    ram_util_percent: 24.60238095238096\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563180206640759\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4654731000688286\n",
      "    mean_inference_ms: 0.4837502385520148\n",
      "    mean_raw_obs_processing_ms: 3.7752655317829427\n",
      "  time_since_restore: 3910.843968153\n",
      "  time_this_iter_s: 25.691155910491943\n",
      "  time_total_s: 3910.843968153\n",
      "  timers:\n",
      "    learn_throughput: 6474.077\n",
      "    learn_time_ms: 2316.933\n",
      "    load_throughput: 9271365.626\n",
      "    load_time_ms: 1.618\n",
      "    sample_throughput: 639.6\n",
      "    sample_time_ms: 23452.155\n",
      "    update_time_ms: 1.317\n",
      "  timestamp: 1665249108\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2175000\n",
      "  training_iteration: 145\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    145 |          3910.84 | 2175000 |  -1487.6 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2190000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-12-13\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1570.1820832268847\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 730\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.4574085474014282\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015185565687716007\n",
      "          model: {}\n",
      "          policy_loss: 0.007776038721203804\n",
      "          total_loss: 3431.861572265625\n",
      "          vf_explained_var: 1.528324244937096e-09\n",
      "          vf_loss: 3431.843994140625\n",
      "    num_agent_steps_sampled: 2190000\n",
      "    num_agent_steps_trained: 2190000\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2190000\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.035135135135135\n",
      "    ram_util_percent: 30.96216216216216\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599565768318886\n",
      "    mean_inference_ms: 0.41414431203022145\n",
      "    mean_processing_ms: 4.135168744433745\n",
      "  time_since_restore: 4272.8041779994965\n",
      "  time_this_iter_s: 29.442651987075806\n",
      "  time_total_s: 4272.8041779994965\n",
      "  timestamp: 1665275451\n",
      "  timesteps_since_restore: 2175000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2175000\n",
      "  training_iteration: 145\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    145 |           4272.8 |     2175000 | -1126.88 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-31-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -1318.8937809751476\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 730\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.206\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.002255083993077278\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.045476198196411\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01267511211335659\n",
      "        policy_loss: 0.00044150077155791223\n",
      "        total_loss: 14996.4609375\n",
      "        vf_explained_var: 0.8774191737174988\n",
      "        vf_loss: 14996.4609375\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2186496\n",
      "    sample_time_ms: 28390.457\n",
      "    update_time_ms: 3.025\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.119607843137256\n",
      "    ram_util_percent: 24.572549019607834\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563237053974959\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.465465692495611\n",
      "    mean_inference_ms: 0.48378336555626517\n",
      "    mean_raw_obs_processing_ms: 3.772376825997985\n",
      "  time_since_restore: 3936.2679097652435\n",
      "  time_this_iter_s: 25.423941612243652\n",
      "  time_total_s: 3936.2679097652435\n",
      "  timers:\n",
      "    learn_throughput: 6356.489\n",
      "    learn_time_ms: 2359.793\n",
      "    load_throughput: 10337757.768\n",
      "    load_time_ms: 1.451\n",
      "    sample_throughput: 642.542\n",
      "    sample_time_ms: 23344.77\n",
      "    update_time_ms: 1.35\n",
      "  timestamp: 1665249133\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 146\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    146 |          3936.27 | 2190000 | -1570.18 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2205000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-12-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1600.3342705959353\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 735\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.17516162991523743\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03203602880239487\n",
      "          model: {}\n",
      "          policy_loss: 0.01404493860900402\n",
      "          total_loss: 3328.692138671875\n",
      "          vf_explained_var: 3.5660898678457897e-09\n",
      "          vf_loss: 3328.65869140625\n",
      "    num_agent_steps_sampled: 2205000\n",
      "    num_agent_steps_trained: 2205000\n",
      "    num_steps_sampled: 2205000\n",
      "    num_steps_trained: 2205000\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.50277777777778\n",
      "    ram_util_percent: 30.97222222222222\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599395042909751\n",
      "    mean_inference_ms: 0.41415407703301615\n",
      "    mean_processing_ms: 4.135875896244492\n",
      "  time_since_restore: 4308.091898679733\n",
      "  time_this_iter_s: 35.287720680236816\n",
      "  time_total_s: 4308.091898679733\n",
      "  timestamp: 1665275487\n",
      "  timesteps_since_restore: 2190000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 146\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    146 |          4308.09 |     2190000 | -1318.89 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-31-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2297.5409344279897\n",
      "  episode_reward_mean: -1407.6420335298117\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 735\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.774\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.002255083993077278\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.0557630062103271\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011994288302958012\n",
      "        policy_loss: -0.0023702376056462526\n",
      "        total_loss: 13250.8369140625\n",
      "        vf_explained_var: 0.8713727593421936\n",
      "        vf_loss: 13250.8388671875\n",
      "    load_time_ms: 2.304\n",
      "    num_steps_sampled: 2205000\n",
      "    num_steps_trained: 2201472\n",
      "    sample_time_ms: 28323.638\n",
      "    update_time_ms: 2.893\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.81219512195122\n",
      "    ram_util_percent: 24.62926829268293\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563309216043625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4654710242756965\n",
      "    mean_inference_ms: 0.4838168219540267\n",
      "    mean_raw_obs_processing_ms: 3.769628599098311\n",
      "  time_since_restore: 3961.543600797653\n",
      "  time_this_iter_s: 25.275691032409668\n",
      "  time_total_s: 3961.543600797653\n",
      "  timers:\n",
      "    learn_throughput: 6407.337\n",
      "    learn_time_ms: 2341.066\n",
      "    load_throughput: 10382968.611\n",
      "    load_time_ms: 1.445\n",
      "    sample_throughput: 642.076\n",
      "    sample_time_ms: 23361.738\n",
      "    update_time_ms: 1.369\n",
      "  timestamp: 1665249159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2205000\n",
      "  training_iteration: 147\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    147 |          3961.54 | 2205000 | -1600.33 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2220000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-13-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1651.2138542166194\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 740\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3996723890304565\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01591774821281433\n",
      "          model: {}\n",
      "          policy_loss: 0.007999471388757229\n",
      "          total_loss: 3527.135498046875\n",
      "          vf_explained_var: 1.528324244937096e-09\n",
      "          vf_loss: 3527.118408203125\n",
      "    num_agent_steps_sampled: 2220000\n",
      "    num_agent_steps_trained: 2220000\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2220000\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.48857142857143\n",
      "    ram_util_percent: 30.962857142857143\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599262288310877\n",
      "    mean_inference_ms: 0.41416514321813686\n",
      "    mean_processing_ms: 4.136587314091486\n",
      "  time_since_restore: 4337.054119586945\n",
      "  time_this_iter_s: 28.962220907211304\n",
      "  time_total_s: 4337.054119586945\n",
      "  timestamp: 1665275516\n",
      "  timesteps_since_restore: 2205000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2205000\n",
      "  training_iteration: 147\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    147 |          4337.05 |     2205000 | -1407.64 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-32-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1451.2730002371982\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 740\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.055\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.002255083993077278\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.34298476576805115\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026841143146157265\n",
      "        policy_loss: 0.0005412781029008329\n",
      "        total_loss: 15626.0205078125\n",
      "        vf_explained_var: 0.7796371579170227\n",
      "        vf_loss: 15626.0185546875\n",
      "    load_time_ms: 2.349\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2216448\n",
      "    sample_time_ms: 28400.851\n",
      "    update_time_ms: 2.955\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.54883720930233\n",
      "    ram_util_percent: 24.618604651162787\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563333454394774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4654478977925254\n",
      "    mean_inference_ms: 0.4838461584853792\n",
      "    mean_raw_obs_processing_ms: 3.7660612165485627\n",
      "  time_since_restore: 3986.3679428100586\n",
      "  time_this_iter_s: 24.824342012405396\n",
      "  time_total_s: 3986.3679428100586\n",
      "  timers:\n",
      "    learn_throughput: 6358.962\n",
      "    learn_time_ms: 2358.876\n",
      "    load_throughput: 10536687.322\n",
      "    load_time_ms: 1.424\n",
      "    sample_throughput: 643.744\n",
      "    sample_time_ms: 23301.197\n",
      "    update_time_ms: 1.395\n",
      "  timestamp: 1665249184\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 148\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    148 |          3986.37 | 2220000 | -1651.21 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2235000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-13-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1796.3791237713888\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 745\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.609640121459961\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01615944504737854\n",
      "          model: {}\n",
      "          policy_loss: 0.007716448977589607\n",
      "          total_loss: 3508.667236328125\n",
      "          vf_explained_var: -4.58497284583359e-09\n",
      "          vf_loss: 3508.649658203125\n",
      "    num_agent_steps_sampled: 2235000\n",
      "    num_agent_steps_trained: 2235000\n",
      "    num_steps_sampled: 2235000\n",
      "    num_steps_trained: 2235000\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.865909090909092\n",
      "    ram_util_percent: 30.940909090909088\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599158234579604\n",
      "    mean_inference_ms: 0.41417689909084243\n",
      "    mean_processing_ms: 4.13732445918991\n",
      "  time_since_restore: 4366.996723413467\n",
      "  time_this_iter_s: 29.942603826522827\n",
      "  time_total_s: 4366.996723413467\n",
      "  timestamp: 1665275546\n",
      "  timesteps_since_restore: 2220000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 148\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    148 |             4367 |     2220000 | -1451.27 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-32-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1496.5372983094871\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 745\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.66\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.002255083993077278\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.22729328274726868\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05730970948934555\n",
      "        policy_loss: -0.007348787039518356\n",
      "        total_loss: 19164.1640625\n",
      "        vf_explained_var: 0.6334642171859741\n",
      "        vf_loss: 19164.16796875\n",
      "    load_time_ms: 2.424\n",
      "    num_steps_sampled: 2235000\n",
      "    num_steps_trained: 2231424\n",
      "    sample_time_ms: 28443.1\n",
      "    update_time_ms: 2.989\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.94285714285714\n",
      "    ram_util_percent: 24.62619047619048\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563348966753972\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.465395532776595\n",
      "    mean_inference_ms: 0.48387480379708636\n",
      "    mean_raw_obs_processing_ms: 3.763076904591836\n",
      "  time_since_restore: 4017.153605699539\n",
      "  time_this_iter_s: 30.78566288948059\n",
      "  time_total_s: 4017.153605699539\n",
      "  timers:\n",
      "    learn_throughput: 6373.142\n",
      "    learn_time_ms: 2353.627\n",
      "    load_throughput: 10404432.023\n",
      "    load_time_ms: 1.442\n",
      "    sample_throughput: 629.699\n",
      "    sample_time_ms: 23820.893\n",
      "    update_time_ms: 1.377\n",
      "  timestamp: 1665249215\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2235000\n",
      "  training_iteration: 149\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    149 |          4017.15 | 2235000 | -1796.38 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2250000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-14-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1831.6126700438015\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 750\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.4097710847854614\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01809283345937729\n",
      "          model: {}\n",
      "          policy_loss: 0.0048157162964344025\n",
      "          total_loss: 3037.162353515625\n",
      "          vf_explained_var: -6.113296979748384e-09\n",
      "          vf_loss: 3037.14599609375\n",
      "    num_agent_steps_sampled: 2250000\n",
      "    num_agent_steps_trained: 2250000\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2250000\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.330555555555556\n",
      "    ram_util_percent: 30.99166666666666\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.59904346089881\n",
      "    mean_inference_ms: 0.41418966520939465\n",
      "    mean_processing_ms: 4.13806755779374\n",
      "  time_since_restore: 4396.560938119888\n",
      "  time_this_iter_s: 29.5642147064209\n",
      "  time_total_s: 4396.560938119888\n",
      "  timestamp: 1665275575\n",
      "  timesteps_since_restore: 2235000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2235000\n",
      "  training_iteration: 149\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    149 |          4396.56 |     2235000 | -1496.54 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-33-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1579.941426140573\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 750\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.156\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.003382625989615917\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.10784763097763062\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.06456905603408813\n",
      "        policy_loss: -0.005394523963332176\n",
      "        total_loss: 18940.5625\n",
      "        vf_explained_var: 0.5870441794395447\n",
      "        vf_loss: 18940.56640625\n",
      "    load_time_ms: 2.481\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2246400\n",
      "    sample_time_ms: 28404.099\n",
      "    update_time_ms: 2.923\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34285714285714\n",
      "    ram_util_percent: 24.685714285714283\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563321509052242\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.465291354783728\n",
      "    mean_inference_ms: 0.48390004625056654\n",
      "    mean_raw_obs_processing_ms: 3.7600831842221782\n",
      "  time_since_restore: 4041.9907281398773\n",
      "  time_this_iter_s: 24.837122440338135\n",
      "  time_total_s: 4041.9907281398773\n",
      "  timers:\n",
      "    learn_throughput: 6486.36\n",
      "    learn_time_ms: 2312.545\n",
      "    load_throughput: 9366327.731\n",
      "    load_time_ms: 1.601\n",
      "    sample_throughput: 633.097\n",
      "    sample_time_ms: 23693.044\n",
      "    update_time_ms: 1.358\n",
      "  timestamp: 1665249240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 150\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    150 |          4041.99 | 2250000 | -1831.61 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2265000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-14-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1743.9328759637078\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 755\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.1259795427322388\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020439255982637405\n",
      "          model: {}\n",
      "          policy_loss: 0.006509965751320124\n",
      "          total_loss: 3081.5029296875\n",
      "          vf_explained_var: 9.16994569166718e-09\n",
      "          vf_loss: 3081.4833984375\n",
      "    num_agent_steps_sampled: 2265000\n",
      "    num_agent_steps_trained: 2265000\n",
      "    num_steps_sampled: 2265000\n",
      "    num_steps_trained: 2265000\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.00277777777778\n",
      "    ram_util_percent: 31.05555555555555\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.5989022105501105\n",
      "    mean_inference_ms: 0.4142029327847766\n",
      "    mean_processing_ms: 4.1387924873462145\n",
      "  time_since_restore: 4425.697472572327\n",
      "  time_this_iter_s: 29.136534452438354\n",
      "  time_total_s: 4425.697472572327\n",
      "  timestamp: 1665275605\n",
      "  timesteps_since_restore: 2250000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 150\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    150 |           4425.7 |     2250000 | -1579.94 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-33-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1610.202028506972\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 755\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.13\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.005073938984423876\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.1529041826725006\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05043758079409599\n",
      "        policy_loss: -0.003804660402238369\n",
      "        total_loss: 17540.533203125\n",
      "        vf_explained_var: 0.5616912245750427\n",
      "        vf_loss: 17540.537109375\n",
      "    load_time_ms: 2.435\n",
      "    num_steps_sampled: 2265000\n",
      "    num_steps_trained: 2261376\n",
      "    sample_time_ms: 28391.622\n",
      "    update_time_ms: 2.865\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.34285714285714\n",
      "    ram_util_percent: 24.62619047619048\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563269853227462\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4652074246952607\n",
      "    mean_inference_ms: 0.48392306781500694\n",
      "    mean_raw_obs_processing_ms: 3.757121829524201\n",
      "  time_since_restore: 4067.4778587818146\n",
      "  time_this_iter_s: 25.487130641937256\n",
      "  time_total_s: 4067.4778587818146\n",
      "  timers:\n",
      "    learn_throughput: 6513.253\n",
      "    learn_time_ms: 2302.997\n",
      "    load_throughput: 8941807.845\n",
      "    load_time_ms: 1.678\n",
      "    sample_throughput: 632.915\n",
      "    sample_time_ms: 23699.865\n",
      "    update_time_ms: 1.198\n",
      "  timestamp: 1665249265\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2265000\n",
      "  training_iteration: 151\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    151 |          4067.48 | 2265000 | -1743.93 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2280000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-14-50\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2558.7908574319563\n",
      "  episode_reward_mean: -1756.819973401973\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 760\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6164836287498474\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.7895357608795166\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.003263790626078844\n",
      "          model: {}\n",
      "          policy_loss: 0.0022211300674825907\n",
      "          total_loss: 3397.693115234375\n",
      "          vf_explained_var: -3.5660898678457897e-09\n",
      "          vf_loss: 3397.688720703125\n",
      "    num_agent_steps_sampled: 2280000\n",
      "    num_agent_steps_trained: 2280000\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2280000\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.58333333333333\n",
      "    ram_util_percent: 31.03055555555555\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598780666573027\n",
      "    mean_inference_ms: 0.414217807015232\n",
      "    mean_processing_ms: 4.139505126893971\n",
      "  time_since_restore: 4454.915128469467\n",
      "  time_this_iter_s: 29.217655897140503\n",
      "  time_total_s: 4454.915128469467\n",
      "  timestamp: 1665275634\n",
      "  timesteps_since_restore: 2265000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2265000\n",
      "  training_iteration: 151\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    151 |          4454.92 |     2265000 |  -1610.2 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-34-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1664.473935500487\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 760\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.32\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.007610908709466457\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.1259537935256958\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02458787150681019\n",
      "        policy_loss: -0.002807941287755966\n",
      "        total_loss: 17133.642578125\n",
      "        vf_explained_var: 0.5334187746047974\n",
      "        vf_loss: 17133.646484375\n",
      "    load_time_ms: 2.337\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2276352\n",
      "    sample_time_ms: 28466.499\n",
      "    update_time_ms: 2.789\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.28095238095238\n",
      "    ram_util_percent: 24.635714285714286\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563267160880465\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4650957216956977\n",
      "    mean_inference_ms: 0.483947718869285\n",
      "    mean_raw_obs_processing_ms: 3.75426723094583\n",
      "  time_since_restore: 4092.1414709091187\n",
      "  time_this_iter_s: 24.663612127304077\n",
      "  time_total_s: 4092.1414709091187\n",
      "  timers:\n",
      "    learn_throughput: 6603.114\n",
      "    learn_time_ms: 2271.656\n",
      "    load_throughput: 8180921.669\n",
      "    load_time_ms: 1.834\n",
      "    sample_throughput: 637.145\n",
      "    sample_time_ms: 23542.506\n",
      "    update_time_ms: 1.178\n",
      "  timestamp: 1665249290\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 152\n",
      "  trial_id: 26f87_00000\n",
=======
      "    mean_env_wait_ms: 4.598679679754497\n",
      "    mean_inference_ms: 0.41423185489683917\n",
      "    mean_processing_ms: 4.140112971842593\n",
      "  time_since_restore: 4484.530905485153\n",
      "  time_this_iter_s: 29.615777015686035\n",
      "  time_total_s: 4484.530905485153\n",
      "  timestamp: 1665275663\n",
      "  timesteps_since_restore: 2280000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 152\n",
      "  trial_id: a95f16f0\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
<<<<<<< HEAD
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    152 |          4092.14 | 2280000 | -1756.82 |              2558.79 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2295000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-15-15\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1938.9329557600133\n",
      "  episode_reward_mean: -1822.407689347823\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 765\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3082418143749237\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.850398600101471\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04133685678243637\n",
      "          model: {}\n",
      "          policy_loss: 0.018528549000620842\n",
      "          total_loss: 3432.212890625\n",
      "          vf_explained_var: -7.641621557752387e-09\n",
      "          vf_loss: 3432.181884765625\n",
      "    num_agent_steps_sampled: 2295000\n",
      "    num_agent_steps_trained: 2295000\n",
      "    num_steps_sampled: 2295000\n",
      "    num_steps_trained: 2295000\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.00857142857143\n",
      "    ram_util_percent: 31.168571428571433\n",
      "  pid: 307\n",
=======
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    152 |          4484.53 |     2280000 | -1664.47 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-34-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1725.9490217705104\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 765\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.297\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.007610908709466457\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.2456514537334442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05699871852993965\n",
      "        policy_loss: -0.0033833638299256563\n",
      "        total_loss: 15692.4326171875\n",
      "        vf_explained_var: 0.5481157898902893\n",
      "        vf_loss: 15692.4345703125\n",
      "    load_time_ms: 2.475\n",
      "    num_steps_sampled: 2295000\n",
      "    num_steps_trained: 2291328\n",
      "    sample_time_ms: 28506.513\n",
      "    update_time_ms: 2.813\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.66428571428571\n",
      "    ram_util_percent: 24.67142857142857\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563253696484744\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.464945891854125\n",
      "    mean_inference_ms: 0.4839714169087241\n",
      "    mean_raw_obs_processing_ms: 3.751352447357958\n",
      "  time_since_restore: 4116.977411270142\n",
      "  time_this_iter_s: 24.83594036102295\n",
      "  time_total_s: 4116.977411270142\n",
      "  timers:\n",
      "    learn_throughput: 6625.981\n",
      "    learn_time_ms: 2263.816\n",
      "    load_throughput: 7346827.816\n",
      "    load_time_ms: 2.042\n",
      "    sample_throughput: 637.617\n",
      "    sample_time_ms: 23525.089\n",
      "    update_time_ms: 1.199\n",
      "  timestamp: 1665249315\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2295000\n",
      "  training_iteration: 153\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    153 |          4116.98 | 2295000 | -1822.41 |              1938.93 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2310000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-15-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1938.9329557600133\n",
      "  episode_reward_mean: -1859.9138676134964\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 770\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.46236270666122437\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.492295265197754\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030039526522159576\n",
      "          model: {}\n",
      "          policy_loss: 0.014369728043675423\n",
      "          total_loss: 3596.3544921875\n",
      "          vf_explained_var: -2.547207111902594e-09\n",
      "          vf_loss: 3596.325927734375\n",
      "    num_agent_steps_sampled: 2310000\n",
      "    num_agent_steps_trained: 2310000\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2310000\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.62702702702703\n",
      "    ram_util_percent: 31.078378378378364\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598590828524638\n",
      "    mean_inference_ms: 0.4142472823315876\n",
      "    mean_processing_ms: 4.1406918739750775\n",
      "  time_since_restore: 4514.063265323639\n",
      "  time_this_iter_s: 29.532359838485718\n",
      "  time_total_s: 4514.063265323639\n",
      "  timestamp: 1665275693\n",
      "  timesteps_since_restore: 2295000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2295000\n",
      "  training_iteration: 153\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    153 |          4514.06 |     2295000 | -1725.95 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-35-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 2228.994470378808\n",
      "  episode_reward_mean: -1807.2222500470168\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 770\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.01\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.011416362598538399\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.09796711802482605\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04054972529411316\n",
      "        policy_loss: -0.0020543753635138273\n",
      "        total_loss: 14467.3623046875\n",
      "        vf_explained_var: 0.5246385931968689\n",
      "        vf_loss: 14467.36328125\n",
      "    load_time_ms: 2.546\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2306304\n",
      "    sample_time_ms: 28491.652\n",
      "    update_time_ms: 2.804\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.292857142857144\n",
      "    ram_util_percent: 24.669047619047618\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563295296306103\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.464814618227444\n",
      "    mean_inference_ms: 0.4839988748528718\n",
      "    mean_raw_obs_processing_ms: 3.748464956974904\n",
      "  time_since_restore: 4142.792519330978\n",
      "  time_this_iter_s: 25.815108060836792\n",
      "  time_total_s: 4142.792519330978\n",
      "  timers:\n",
      "    learn_throughput: 6593.576\n",
      "    learn_time_ms: 2274.941\n",
      "    load_throughput: 7268653.819\n",
      "    load_time_ms: 2.064\n",
      "    sample_throughput: 638.868\n",
      "    sample_time_ms: 23479.019\n",
      "    update_time_ms: 1.207\n",
      "  timestamp: 1665249341\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 154\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.598546235055701\n",
      "    mean_inference_ms: 0.4142626217610924\n",
      "    mean_processing_ms: 4.14125376445213\n",
      "  time_since_restore: 4543.258025407791\n",
      "  time_this_iter_s: 29.19476008415222\n",
      "  time_total_s: 4543.258025407791\n",
      "  timestamp: 1665275722\n",
      "  timesteps_since_restore: 2310000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 154\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    154 |          4543.26 |     2310000 | -1807.22 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    154 |          4142.79 | 2310000 | -1859.91 |              1938.93 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2325000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-16-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1938.9329557600133\n",
      "  episode_reward_mean: -2013.0283047228947\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 775\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.46236270666122437\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.331838607788086\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.036527082324028015\n",
      "          model: {}\n",
      "          policy_loss: 0.022703664377331734\n",
      "          total_loss: 3521.374755859375\n",
      "          vf_explained_var: -3.056648489874192e-09\n",
      "          vf_loss: 3521.3349609375\n",
      "    num_agent_steps_sampled: 2325000\n",
      "    num_agent_steps_trained: 2325000\n",
      "    num_steps_sampled: 2325000\n",
      "    num_steps_trained: 2325000\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.889189189189196\n",
      "    ram_util_percent: 31.059459459459447\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-35-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 949.7323704405056\n",
      "  episode_reward_mean: -1940.9835344858034\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 775\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.047\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.017124544829130173\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.14931339025497437\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015556865371763706\n",
      "        policy_loss: 0.000505601754412055\n",
      "        total_loss: 13889.236328125\n",
      "        vf_explained_var: 0.5023787021636963\n",
      "        vf_loss: 13889.2353515625\n",
      "    load_time_ms: 2.725\n",
      "    num_steps_sampled: 2325000\n",
      "    num_steps_trained: 2321280\n",
      "    sample_time_ms: 28463.559\n",
      "    update_time_ms: 2.849\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.654761904761905\n",
      "    ram_util_percent: 24.676190476190477\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563349522330236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4646611055370475\n",
      "    mean_inference_ms: 0.4840267639154653\n",
      "    mean_raw_obs_processing_ms: 3.745556898132959\n",
      "  time_since_restore: 4168.070684194565\n",
      "  time_this_iter_s: 25.278164863586426\n",
      "  time_total_s: 4168.070684194565\n",
      "  timers:\n",
      "    learn_throughput: 6637.365\n",
      "    learn_time_ms: 2259.933\n",
      "    load_throughput: 6665454.661\n",
      "    load_time_ms: 2.25\n",
      "    sample_throughput: 639.593\n",
      "    sample_time_ms: 23452.42\n",
      "    update_time_ms: 1.243\n",
      "  timestamp: 1665249366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2325000\n",
      "  training_iteration: 155\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:16:06,700\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 201.0x the scale of `vf_clip_param`. This means that it will take more than 201.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    155 |          4168.07 | 2325000 | -2013.03 |              1938.93 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2340000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-16-37\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1938.9329557600133\n",
      "  episode_reward_mean: -2101.9631489178278\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 780\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.46236270666122437\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.926924228668213\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016672994941473007\n",
      "          model: {}\n",
      "          policy_loss: 0.008804179728031158\n",
      "          total_loss: 3565.983154296875\n",
      "          vf_explained_var: -6.113296979748384e-09\n",
      "          vf_loss: 3565.966552734375\n",
      "    num_agent_steps_sampled: 2340000\n",
      "    num_agent_steps_trained: 2340000\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2340000\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.42093023255814\n",
      "    ram_util_percent: 31.01627906976744\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598526013559214\n",
      "    mean_inference_ms: 0.41428003158423926\n",
      "    mean_processing_ms: 4.141627605572811\n",
      "  time_since_restore: 4572.42258810997\n",
      "  time_this_iter_s: 29.164562702178955\n",
      "  time_total_s: 4572.42258810997\n",
      "  timestamp: 1665275752\n",
      "  timesteps_since_restore: 2325000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2325000\n",
      "  training_iteration: 155\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    155 |          4572.42 |     2325000 | -1940.98 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-36-21\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 949.7323704405056\n",
      "  episode_reward_mean: -1968.641163497926\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 780\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.674\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.017124544829130173\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.06898795813322067\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0358881950378418\n",
      "        policy_loss: -0.003627411788329482\n",
      "        total_loss: 12602.833984375\n",
      "        vf_explained_var: 0.4964130222797394\n",
      "        vf_loss: 12602.8369140625\n",
      "    load_time_ms: 2.796\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2336256\n",
      "    sample_time_ms: 27914.746\n",
      "    update_time_ms: 2.862\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.25\n",
      "    ram_util_percent: 24.72142857142857\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563385767221804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.464481630668041\n",
      "    mean_inference_ms: 0.48405213513783935\n",
      "    mean_raw_obs_processing_ms: 3.7431653339942352\n",
      "  time_since_restore: 4198.542078256607\n",
      "  time_this_iter_s: 30.471394062042236\n",
      "  time_total_s: 4198.542078256607\n",
      "  timers:\n",
      "    learn_throughput: 6621.486\n",
      "    learn_time_ms: 2265.353\n",
      "    load_throughput: 6778490.546\n",
      "    load_time_ms: 2.213\n",
      "    sample_throughput: 626.257\n",
      "    sample_time_ms: 23951.835\n",
      "    update_time_ms: 1.21\n",
      "  timestamp: 1665249397\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 156\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:16:37,296\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 210.0x the scale of `vf_clip_param`. This means that it will take more than 210.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    156 |          4198.54 | 2340000 | -2101.96 |              1938.93 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2355000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-17-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1938.9329557600133\n",
      "  episode_reward_mean: -2038.8142670484626\n",
      "  episode_reward_min: -7913.932615843404\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 785\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.46236270666122437\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -2.2800981998443604\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.040900249034166336\n",
      "          model: {}\n",
      "          policy_loss: 0.015501949936151505\n",
      "          total_loss: 2848.3125\n",
      "          vf_explained_var: -1.3245476715439963e-08\n",
      "          vf_loss: 2848.278076171875\n",
      "    num_agent_steps_sampled: 2355000\n",
      "    num_agent_steps_trained: 2355000\n",
      "    num_steps_sampled: 2355000\n",
      "    num_steps_trained: 2355000\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.349999999999998\n",
      "    ram_util_percent: 31.052631578947356\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598508474091682\n",
      "    mean_inference_ms: 0.41429718079192596\n",
      "    mean_processing_ms: 4.14201118023251\n",
      "  time_since_restore: 4602.248920917511\n",
      "  time_this_iter_s: 29.826332807540894\n",
      "  time_total_s: 4602.248920917511\n",
      "  timestamp: 1665275781\n",
      "  timesteps_since_restore: 2340000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 156\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    156 |          4602.25 |     2340000 | -1968.64 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-36-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 949.7323704405056\n",
      "  episode_reward_mean: -2096.7324093039574\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 785\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1490.03\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.017124544829130173\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.26043593883514404\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008108356967568398\n",
      "        policy_loss: 0.0008498912793584168\n",
      "        total_loss: 11786.0703125\n",
      "        vf_explained_var: 0.4949008822441101\n",
      "        vf_loss: 11786.0703125\n",
      "    load_time_ms: 2.838\n",
      "    num_steps_sampled: 2355000\n",
      "    num_steps_trained: 2351232\n",
      "    sample_time_ms: 27941.923\n",
      "    update_time_ms: 2.917\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.07619047619048\n",
      "    ram_util_percent: 24.70952380952381\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656334058587038\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.46429428759035\n",
      "    mean_inference_ms: 0.4840725544267649\n",
      "    mean_raw_obs_processing_ms: 3.7409210703358866\n",
      "  time_since_restore: 4224.624491691589\n",
      "  time_this_iter_s: 26.0824134349823\n",
      "  time_total_s: 4224.624491691589\n",
      "  timers:\n",
      "    learn_throughput: 6602.625\n",
      "    learn_time_ms: 2271.824\n",
      "    load_throughput: 6266640.105\n",
      "    load_time_ms: 2.394\n",
      "    sample_throughput: 624.321\n",
      "    sample_time_ms: 24026.109\n",
      "    update_time_ms: 1.154\n",
      "  timestamp: 1665249423\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2355000\n",
      "  training_iteration: 157\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    157 |          4224.62 | 2355000 | -2038.81 |              1938.93 |             -7913.93 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:17:03,461\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 204.0x the scale of `vf_clip_param`. This means that it will take more than 204.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2370000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -1986.913536419589\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 790\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.4154224991798401\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.031047126278281212\n",
      "          model: {}\n",
      "          policy_loss: 0.013025345280766487\n",
      "          total_loss: 3372.687255859375\n",
      "          vf_explained_var: -1.2736035337468365e-08\n",
      "          vf_loss: 3372.653564453125\n",
      "    num_agent_steps_sampled: 2370000\n",
      "    num_agent_steps_trained: 2370000\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2370000\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.505405405405405\n",
      "    ram_util_percent: 31.059459459459447\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598501787828901\n",
      "    mean_inference_ms: 0.414316794745698\n",
      "    mean_processing_ms: 4.142347271141818\n",
      "  time_since_restore: 4631.487166404724\n",
      "  time_this_iter_s: 29.238245487213135\n",
      "  time_total_s: 4631.487166404724\n",
      "  timestamp: 1665275811\n",
      "  timesteps_since_restore: 2355000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2355000\n",
      "  training_iteration: 157\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:36:51,169\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 210.0x the scale of `vf_clip_param`. This means that it will take more than 210.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    157 |          4631.49 |     2355000 | -2096.73 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-37-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 331.67387782218276\n",
      "  episode_reward_mean: -2197.224686903223\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 790\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.828\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.008562272414565086\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.33438655734062195\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.037462808191776276\n",
      "        policy_loss: -0.0026380172930657864\n",
      "        total_loss: 10757.484375\n",
      "        vf_explained_var: 0.49246394634246826\n",
      "        vf_loss: 10757.4873046875\n",
      "    load_time_ms: 2.771\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2366208\n",
      "    sample_time_ms: 28440.462\n",
      "    update_time_ms: 2.945\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.784000000000002\n",
      "    ram_util_percent: 24.682000000000002\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563288122915724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.464118777190828\n",
      "    mean_inference_ms: 0.48409201240437383\n",
      "    mean_raw_obs_processing_ms: 3.738775796916838\n",
      "  time_since_restore: 4250.581258535385\n",
      "  time_this_iter_s: 25.956766843795776\n",
      "  time_total_s: 4250.581258535385\n",
      "  timers:\n",
      "    learn_throughput: 6542.76\n",
      "    learn_time_ms: 2292.611\n",
      "    load_throughput: 6333191.734\n",
      "    load_time_ms: 2.368\n",
      "    sample_throughput: 621.94\n",
      "    sample_time_ms: 24118.065\n",
      "    update_time_ms: 1.276\n",
      "  timestamp: 1665249449\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 158\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    158 |          4250.58 | 2370000 | -1986.91 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2385000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-17-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -1997.59133868329\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 795\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.352914422750473\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02687148004770279\n",
      "          model: {}\n",
      "          policy_loss: 0.013181189075112343\n",
      "          total_loss: 3172.70703125\n",
      "          vf_explained_var: -7.1321797356915795e-09\n",
      "          vf_loss: 3172.675537109375\n",
      "    num_agent_steps_sampled: 2385000\n",
      "    num_agent_steps_trained: 2385000\n",
      "    num_steps_sampled: 2385000\n",
      "    num_steps_trained: 2385000\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.918421052631576\n",
      "    ram_util_percent: 31.065789473684198\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598481427205419\n",
      "    mean_inference_ms: 0.4143376545012803\n",
      "    mean_processing_ms: 4.143285012278902\n",
      "  time_since_restore: 4666.412700176239\n",
      "  time_this_iter_s: 34.92553377151489\n",
      "  time_total_s: 4666.412700176239\n",
      "  timestamp: 1665275846\n",
      "  timesteps_since_restore: 2370000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 158\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:37:26,139\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 220.0x the scale of `vf_clip_param`. This means that it will take more than 220.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    158 |          4666.41 |     2370000 | -2197.22 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 331.67387782218276\n",
      "  episode_reward_mean: -2233.834935649191\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 795\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.027\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.008562272414565086\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.04618608579039574\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05279072746634483\n",
      "        policy_loss: -0.005566587671637535\n",
      "        total_loss: 9678.7841796875\n",
      "        vf_explained_var: 0.4616768956184387\n",
      "        vf_loss: 9678.7919921875\n",
      "    load_time_ms: 2.749\n",
      "    num_steps_sampled: 2385000\n",
      "    num_steps_trained: 2381184\n",
      "    sample_time_ms: 28418.806\n",
      "    update_time_ms: 2.941\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.27857142857143\n",
      "    ram_util_percent: 24.740476190476187\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563246691009557\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4639257285942056\n",
      "    mean_inference_ms: 0.4841112749880051\n",
      "    mean_raw_obs_processing_ms: 3.7367350805622306\n",
      "  time_since_restore: 4277.066271781921\n",
      "  time_this_iter_s: 26.485013246536255\n",
      "  time_total_s: 4277.066271781921\n",
      "  timers:\n",
      "    learn_throughput: 6533.996\n",
      "    learn_time_ms: 2295.685\n",
      "    load_throughput: 6343216.648\n",
      "    load_time_ms: 2.365\n",
      "    sample_throughput: 633.309\n",
      "    sample_time_ms: 23685.113\n",
      "    update_time_ms: 1.332\n",
      "  timestamp: 1665249476\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2385000\n",
      "  training_iteration: 159\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    159 |          4277.07 | 2385000 | -1997.59 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2400000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-18-21\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -2028.7145149096116\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 800\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.46306574344635\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026905464008450508\n",
      "          model: {}\n",
      "          policy_loss: 0.01543891616165638\n",
      "          total_loss: 3662.625244140625\n",
      "          vf_explained_var: 2.0377657339309962e-09\n",
      "          vf_loss: 3662.591796875\n",
      "    num_agent_steps_sampled: 2400000\n",
      "    num_agent_steps_trained: 2400000\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2400000\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.350000000000005\n",
      "    ram_util_percent: 31.055555555555543\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598470715582391\n",
      "    mean_inference_ms: 0.41435908720158154\n",
      "    mean_processing_ms: 4.144230264020688\n",
      "  time_since_restore: 4695.752468585968\n",
      "  time_this_iter_s: 29.339768409729004\n",
      "  time_total_s: 4695.752468585968\n",
      "  timestamp: 1665275875\n",
      "  timesteps_since_restore: 2385000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2385000\n",
      "  training_iteration: 159\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:37:55,522\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 223.0x the scale of `vf_clip_param`. This means that it will take more than 223.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    159 |          4695.75 |     2385000 | -2233.83 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-38-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: 331.67387782218276\n",
      "  episode_reward_mean: -2250.0042873356315\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 800\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.876\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01284340862184763\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.330886572599411\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021007783710956573\n",
      "        policy_loss: -0.0001833121059462428\n",
      "        total_loss: 9045.1630859375\n",
      "        vf_explained_var: 0.4418555498123169\n",
      "        vf_loss: 9045.162109375\n",
      "    load_time_ms: 2.735\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2396160\n",
      "    sample_time_ms: 28472.017\n",
      "    update_time_ms: 2.971\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.26428571428571\n",
      "    ram_util_percent: 24.835714285714282\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563188798806563\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4637187043012485\n",
      "    mean_inference_ms: 0.4841299090693105\n",
      "    mean_raw_obs_processing_ms: 3.7345838721055253\n",
      "  time_since_restore: 4302.135665178299\n",
      "  time_this_iter_s: 25.069393396377563\n",
      "  time_total_s: 4302.135665178299\n",
      "  timers:\n",
      "    learn_throughput: 6482.878\n",
      "    learn_time_ms: 2313.787\n",
      "    load_throughput: 6835492.878\n",
      "    load_time_ms: 2.194\n",
      "    sample_throughput: 633.169\n",
      "    sample_time_ms: 23690.343\n",
      "    update_time_ms: 1.368\n",
      "  timestamp: 1665249501\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 160\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:18:21,243\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 203.0x the scale of `vf_clip_param`. This means that it will take more than 203.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    160 |          4302.14 | 2400000 | -2028.71 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n"
=======
      "    mean_env_wait_ms: 4.598434227937273\n",
      "    mean_inference_ms: 0.4143825465783586\n",
      "    mean_processing_ms: 4.1451695863933296\n",
      "  time_since_restore: 4725.429888486862\n",
      "  time_this_iter_s: 29.677419900894165\n",
      "  time_total_s: 4725.429888486862\n",
      "  timestamp: 1665275905\n",
      "  timesteps_since_restore: 2400000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 160\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:38:25,240\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 225.0x the scale of `vf_clip_param`. This means that it will take more than 225.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    160 |          4725.43 |     2400000 |    -2250 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2415000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-18-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -2115.6057710106693\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 805\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.8968710899353027\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012361845001578331\n",
      "          model: {}\n",
      "          policy_loss: 0.0070338197983801365\n",
      "          total_loss: 3464.635498046875\n",
      "          vf_explained_var: -5.603855601776786e-09\n",
      "          vf_loss: 3464.619873046875\n",
      "    num_agent_steps_sampled: 2415000\n",
      "    num_agent_steps_trained: 2415000\n",
      "    num_steps_sampled: 2415000\n",
      "    num_steps_trained: 2415000\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.658139534883723\n",
      "    ram_util_percent: 31.018604651162786\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-38-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -168.72296340351065\n",
      "  episode_reward_mean: -2290.863914347413\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 805\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1491.005\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01284340862184763\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.0653565302491188\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026273924857378006\n",
      "        policy_loss: 0.002766192890703678\n",
      "        total_loss: 8216.9013671875\n",
      "        vf_explained_var: 0.41166889667510986\n",
      "        vf_loss: 8216.8994140625\n",
      "    load_time_ms: 2.79\n",
      "    num_steps_sampled: 2415000\n",
      "    num_steps_trained: 2411136\n",
      "    sample_time_ms: 28558.23\n",
      "    update_time_ms: 2.895\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.29302325581395\n",
      "    ram_util_percent: 24.765116279069765\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656313866621089\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.46348715887812\n",
      "    mean_inference_ms: 0.48414922139402555\n",
      "    mean_raw_obs_processing_ms: 3.7330425753809062\n",
      "  time_since_restore: 4332.173728227615\n",
      "  time_this_iter_s: 30.038063049316406\n",
      "  time_total_s: 4332.173728227615\n",
      "  timers:\n",
      "    learn_throughput: 6555.367\n",
      "    learn_time_ms: 2288.201\n",
      "    load_throughput: 7056603.52\n",
      "    load_time_ms: 2.126\n",
      "    sample_throughput: 620.584\n",
      "    sample_time_ms: 24170.797\n",
      "    update_time_ms: 1.354\n",
      "  timestamp: 1665249531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2415000\n",
      "  training_iteration: 161\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:18:51,397\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 212.0x the scale of `vf_clip_param`. This means that it will take more than 212.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    161 |          4332.17 | 2415000 | -2115.61 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2430000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-19-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -2091.9396244094214\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 810\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.6554456949234009\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013792913407087326\n",
      "          model: {}\n",
      "          policy_loss: 0.0076486472971737385\n",
      "          total_loss: 3589.325927734375\n",
      "          vf_explained_var: -9.16994569166718e-09\n",
      "          vf_loss: 3589.30908203125\n",
      "    num_agent_steps_sampled: 2430000\n",
      "    num_agent_steps_trained: 2430000\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2430000\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.572972972972973\n",
      "    ram_util_percent: 31.059459459459447\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598416180894682\n",
      "    mean_inference_ms: 0.41440654535225624\n",
      "    mean_processing_ms: 4.1461576695962385\n",
      "  time_since_restore: 4755.521234035492\n",
      "  time_this_iter_s: 30.09134554862976\n",
      "  time_total_s: 4755.521234035492\n",
      "  timestamp: 1665275935\n",
      "  timesteps_since_restore: 2415000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2415000\n",
      "  training_iteration: 161\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:38:55,379\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 229.0x the scale of `vf_clip_param`. This means that it will take more than 229.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    161 |          4755.52 |     2415000 | -2290.86 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-39-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -168.72296340351065\n",
      "  episode_reward_mean: -2319.2740197297026\n",
      "  episode_reward_min: -6096.905326237817\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 810\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1489.936\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01284340862184763\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.1910860240459442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04495931416749954\n",
      "        policy_loss: -0.003344633849337697\n",
      "        total_loss: 7738.68017578125\n",
      "        vf_explained_var: 0.3935202360153198\n",
      "        vf_loss: 7738.68212890625\n",
      "    load_time_ms: 2.81\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2426112\n",
      "    sample_time_ms: 28534.946\n",
      "    update_time_ms: 2.977\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.97857142857142\n",
      "    ram_util_percent: 24.766666666666662\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563094497864623\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4632445226024955\n",
      "    mean_inference_ms: 0.48416899791618007\n",
      "    mean_raw_obs_processing_ms: 3.7314933716120966\n",
      "  time_since_restore: 4358.116352558136\n",
      "  time_this_iter_s: 25.94262433052063\n",
      "  time_total_s: 4358.116352558136\n",
      "  timers:\n",
      "    learn_throughput: 6548.386\n",
      "    learn_time_ms: 2290.641\n",
      "    load_throughput: 7707378.505\n",
      "    load_time_ms: 1.946\n",
      "    sample_throughput: 617.383\n",
      "    sample_time_ms: 24296.12\n",
      "    update_time_ms: 1.36\n",
      "  timestamp: 1665249557\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 162\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.598408795985491\n",
      "    mean_inference_ms: 0.4144320737755476\n",
      "    mean_processing_ms: 4.147142108471573\n",
      "  time_since_restore: 4784.894551038742\n",
      "  time_this_iter_s: 29.373317003250122\n",
      "  time_total_s: 4784.894551038742\n",
      "  timestamp: 1665275964\n",
      "  timesteps_since_restore: 2430000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 162\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:39:24,791\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 232.0x the scale of `vf_clip_param`. This means that it will take more than 232.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    162 |          4784.89 |     2430000 | -2319.27 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:19:17,416\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 209.0x the scale of `vf_clip_param`. This means that it will take more than 209.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    162 |          4358.12 | 2430000 | -2091.94 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2445000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-19-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -2174.582129956924\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 815\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.5155187845230103\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02502870000898838\n",
      "          model: {}\n",
      "          policy_loss: 0.015298508107662201\n",
      "          total_loss: 3734.38330078125\n",
      "          vf_explained_var: -7.641621557752387e-09\n",
      "          vf_loss: 3734.35107421875\n",
      "    num_agent_steps_sampled: 2445000\n",
      "    num_agent_steps_trained: 2445000\n",
      "    num_steps_sampled: 2445000\n",
      "    num_steps_trained: 2445000\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.794444444444444\n",
      "    ram_util_percent: 31.15555555555556\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-39-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -168.72296340351065\n",
      "  episode_reward_mean: -2325.759047897289\n",
      "  episode_reward_min: -5344.3064949363625\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 815\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.903\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2154727727174759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022165970876812935\n",
      "        policy_loss: -0.0008467144216410816\n",
      "        total_loss: 7048.935546875\n",
      "        vf_explained_var: 0.3413122594356537\n",
      "        vf_loss: 7048.93603515625\n",
      "    load_time_ms: 2.674\n",
      "    num_steps_sampled: 2445000\n",
      "    num_steps_trained: 2441088\n",
      "    sample_time_ms: 28516.275\n",
      "    update_time_ms: 2.97\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.80714285714286\n",
      "    ram_util_percent: 24.76904761904762\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563051314902144\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4629862211179785\n",
      "    mean_inference_ms: 0.48418780951092427\n",
      "    mean_raw_obs_processing_ms: 3.73003217667704\n",
      "  time_since_restore: 4383.339113473892\n",
      "  time_this_iter_s: 25.222760915756226\n",
      "  time_total_s: 4383.339113473892\n",
      "  timers:\n",
      "    learn_throughput: 6487.624\n",
      "    learn_time_ms: 2312.094\n",
      "    load_throughput: 8486943.384\n",
      "    load_time_ms: 1.767\n",
      "    sample_throughput: 616.939\n",
      "    sample_time_ms: 24313.58\n",
      "    update_time_ms: 1.342\n",
      "  timestamp: 1665249582\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2445000\n",
      "  training_iteration: 163\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:19:42,735\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 217.0x the scale of `vf_clip_param`. This means that it will take more than 217.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    163 |          4383.34 | 2445000 | -2174.58 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2460000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-20-07\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -2202.6569691254244\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 820\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8456780314445496\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.035543739795684814\n",
      "          model: {}\n",
      "          policy_loss: 0.015179049223661423\n",
      "          total_loss: 3525.44970703125\n",
      "          vf_explained_var: -6.622738357719982e-09\n",
      "          vf_loss: 3525.409912109375\n",
      "    num_agent_steps_sampled: 2460000\n",
      "    num_agent_steps_trained: 2460000\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2460000\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.194444444444446\n",
      "    ram_util_percent: 31.23333333333333\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.59841167793677\n",
      "    mean_inference_ms: 0.414456916576874\n",
      "    mean_processing_ms: 4.148125222223958\n",
      "  time_since_restore: 4814.218566656113\n",
      "  time_this_iter_s: 29.324015617370605\n",
      "  time_total_s: 4814.218566656113\n",
      "  timestamp: 1665275994\n",
      "  timesteps_since_restore: 2445000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2445000\n",
      "  training_iteration: 163\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:39:54,160\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 233.0x the scale of `vf_clip_param`. This means that it will take more than 233.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    163 |          4814.22 |     2445000 | -2325.76 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-40-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -168.72296340351065\n",
      "  episode_reward_mean: -2270.3796074728943\n",
      "  episode_reward_min: -4723.489998307621\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 820\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.585\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.005081459414213896\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011867215856909752\n",
      "        policy_loss: 0.00045722670620307326\n",
      "        total_loss: 6378.578125\n",
      "        vf_explained_var: 0.3975961208343506\n",
      "        vf_loss: 6378.57763671875\n",
      "    load_time_ms: 2.651\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2456064\n",
      "    sample_time_ms: 29031.049\n",
      "    update_time_ms: 2.961\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.369387755102043\n",
      "    ram_util_percent: 24.751020408163264\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563052573774879\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4627370824959387\n",
      "    mean_inference_ms: 0.4842088013198109\n",
      "    mean_raw_obs_processing_ms: 3.728516893726086\n",
      "  time_since_restore: 4408.410985469818\n",
      "  time_this_iter_s: 25.071871995925903\n",
      "  time_total_s: 4408.410985469818\n",
      "  timers:\n",
      "    learn_throughput: 6670.979\n",
      "    learn_time_ms: 2248.545\n",
      "    load_throughput: 9436570.623\n",
      "    load_time_ms: 1.59\n",
      "    sample_throughput: 617.215\n",
      "    sample_time_ms: 24302.708\n",
      "    update_time_ms: 1.587\n",
      "  timestamp: 1665249607\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 164\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:20:07,927\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 220.0x the scale of `vf_clip_param`. This means that it will take more than 220.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    164 |          4408.41 | 2460000 | -2202.66 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2475000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-20-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -2168.199729869648\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 825\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.37549522519111633\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01430447306483984\n",
      "          model: {}\n",
      "          policy_loss: 0.0028491513803601265\n",
      "          total_loss: 3386.904296875\n",
      "          vf_explained_var: 3.056648489874192e-09\n",
      "          vf_loss: 3386.8916015625\n",
      "    num_agent_steps_sampled: 2475000\n",
      "    num_agent_steps_trained: 2475000\n",
      "    num_steps_sampled: 2475000\n",
      "    num_steps_trained: 2475000\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.31764705882353\n",
      "    ram_util_percent: 31.22352941176471\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598445315850919\n",
      "    mean_inference_ms: 0.4144815459188944\n",
      "    mean_processing_ms: 4.149553498724559\n",
      "  time_since_restore: 4848.557833909988\n",
      "  time_this_iter_s: 34.33926725387573\n",
      "  time_total_s: 4848.557833909988\n",
      "  timestamp: 1665276028\n",
      "  timesteps_since_restore: 2460000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 164\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:40:28,548\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 227.0x the scale of `vf_clip_param`. This means that it will take more than 227.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    164 |          4848.56 |     2460000 | -2270.38 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-40-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1004.0313367372298\n",
      "  episode_reward_mean: -2323.759033855797\n",
      "  episode_reward_min: -4723.489998307621\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 825\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.84\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.022156784310936928\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01921439915895462\n",
      "        policy_loss: 0.000602418149355799\n",
      "        total_loss: 5535.71923828125\n",
      "        vf_explained_var: 0.3999291658401489\n",
      "        vf_loss: 5535.7177734375\n",
      "    load_time_ms: 2.474\n",
      "    num_steps_sampled: 2475000\n",
      "    num_steps_trained: 2471040\n",
      "    sample_time_ms: 29093.333\n",
      "    update_time_ms: 2.923\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.60697674418604\n",
      "    ram_util_percent: 24.77209302325581\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656301261196399\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4624636170913847\n",
      "    mean_inference_ms: 0.48422677526067454\n",
      "    mean_raw_obs_processing_ms: 3.726955089159794\n",
      "  time_since_restore: 4432.063810825348\n",
      "  time_this_iter_s: 23.652825355529785\n",
      "  time_total_s: 4432.063810825348\n",
      "  timers:\n",
      "    learn_throughput: 6718.293\n",
      "    learn_time_ms: 2232.71\n",
      "    load_throughput: 9580411.147\n",
      "    load_time_ms: 1.566\n",
      "    sample_throughput: 620.967\n",
      "    sample_time_ms: 24155.863\n",
      "    update_time_ms: 1.744\n",
      "  timestamp: 1665249631\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2475000\n",
      "  training_iteration: 165\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:20:31,679\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 217.0x the scale of `vf_clip_param`. This means that it will take more than 217.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    165 |          4432.06 | 2475000 |  -2168.2 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2490000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -2049.225400587657\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 830\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.4733119010925293\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02589697577059269\n",
      "          model: {}\n",
      "          policy_loss: 0.009912772104144096\n",
      "          total_loss: 2959.21875\n",
      "          vf_explained_var: -6.622738357719982e-09\n",
      "          vf_loss: 2959.19091796875\n",
      "    num_agent_steps_sampled: 2490000\n",
      "    num_agent_steps_trained: 2490000\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2490000\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.71627906976744\n",
      "    ram_util_percent: 31.118604651162794\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.59849120122431\n",
      "    mean_inference_ms: 0.41450863354872064\n",
      "    mean_processing_ms: 4.1509768388290675\n",
      "  time_since_restore: 4878.325911283493\n",
      "  time_this_iter_s: 29.76807737350464\n",
      "  time_total_s: 4878.325911283493\n",
      "  timestamp: 1665276058\n",
      "  timesteps_since_restore: 2475000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2475000\n",
      "  training_iteration: 165\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:40:58,359\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 232.0x the scale of `vf_clip_param`. This means that it will take more than 232.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    165 |          4878.33 |     2475000 | -2323.76 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-41-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1004.0313367372298\n",
      "  episode_reward_mean: -2300.8919400975424\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 830\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.892\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19329829514026642\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030243339017033577\n",
      "        policy_loss: -0.0003315714711789042\n",
      "        total_loss: 4979.9287109375\n",
      "        vf_explained_var: 0.4366035759449005\n",
      "        vf_loss: 4979.9287109375\n",
      "    load_time_ms: 2.388\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2486016\n",
      "    sample_time_ms: 29020.503\n",
      "    update_time_ms: 2.864\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 35.07560975609756\n",
      "    ram_util_percent: 24.773170731707314\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06563001438709842\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.462221818320441\n",
      "    mean_inference_ms: 0.4842467624942045\n",
      "    mean_raw_obs_processing_ms: 3.7259326812449314\n",
      "  time_since_restore: 4462.392566204071\n",
      "  time_this_iter_s: 30.328755378723145\n",
      "  time_total_s: 4462.392566204071\n",
      "  timers:\n",
      "    learn_throughput: 6777.94\n",
      "    learn_time_ms: 2213.062\n",
      "    load_throughput: 8594885.246\n",
      "    load_time_ms: 1.745\n",
      "    sample_throughput: 620.835\n",
      "    sample_time_ms: 24161.016\n",
      "    update_time_ms: 1.764\n",
      "  timestamp: 1665249662\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 166\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:21:02,146\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 205.0x the scale of `vf_clip_param`. This means that it will take more than 205.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    166 |          4462.39 | 2490000 | -2049.23 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2505000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -2031.3723852316784\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 835\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.9904554486274719\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0186394564807415\n",
      "          model: {}\n",
      "          policy_loss: 0.006716258358210325\n",
      "          total_loss: 2817.170654296875\n",
      "          vf_explained_var: -1.0698269825581974e-08\n",
      "          vf_loss: 2817.15087890625\n",
      "    num_agent_steps_sampled: 2505000\n",
      "    num_agent_steps_trained: 2505000\n",
      "    num_steps_sampled: 2505000\n",
      "    num_steps_trained: 2505000\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.225\n",
      "    ram_util_percent: 31.16388888888889\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598590374527539\n",
      "    mean_inference_ms: 0.41453447133212834\n",
      "    mean_processing_ms: 4.151711865789816\n",
      "  time_since_restore: 4907.41340470314\n",
      "  time_this_iter_s: 29.087493419647217\n",
      "  time_total_s: 4907.41340470314\n",
      "  timestamp: 1665276087\n",
      "  timesteps_since_restore: 2490000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 166\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:41:27,491\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 230.0x the scale of `vf_clip_param`. This means that it will take more than 230.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    166 |          4907.41 |     2490000 | -2300.89 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-41-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1004.0313367372298\n",
      "  episode_reward_mean: -2332.650146312571\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 835\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.011\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.14328129589557648\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016347669064998627\n",
      "        policy_loss: 0.0016411039978265762\n",
      "        total_loss: 4548.50732421875\n",
      "        vf_explained_var: 0.4839540123939514\n",
      "        vf_loss: 4548.505859375\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 2505000\n",
      "    num_steps_trained: 2500992\n",
      "    sample_time_ms: 29007.15\n",
      "    update_time_ms: 2.968\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.2452380952381\n",
      "    ram_util_percent: 24.814285714285717\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562976889469019\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.461951843318887\n",
      "    mean_inference_ms: 0.4842660112258108\n",
      "    mean_raw_obs_processing_ms: 3.7249549027984723\n",
      "  time_since_restore: 4487.688298940659\n",
      "  time_this_iter_s: 25.295732736587524\n",
      "  time_total_s: 4487.688298940659\n",
      "  timers:\n",
      "    learn_throughput: 6727.397\n",
      "    learn_time_ms: 2229.688\n",
      "    load_throughput: 9562355.23\n",
      "    load_time_ms: 1.569\n",
      "    sample_throughput: 623.292\n",
      "    sample_time_ms: 24065.758\n",
      "    update_time_ms: 1.784\n",
      "  timestamp: 1665249687\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2505000\n",
      "  training_iteration: 167\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:21:27,538\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 203.0x the scale of `vf_clip_param`. This means that it will take more than 203.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    167 |          4487.69 | 2505000 | -2031.37 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2520000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-21-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -1973.0595458539653\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 840\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.004749405197799206\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021867722272872925\n",
      "          model: {}\n",
      "          policy_loss: 0.006595562677830458\n",
      "          total_loss: 3573.529541015625\n",
      "          vf_explained_var: 1.528324244937096e-09\n",
      "          vf_loss: 3573.5078125\n",
      "    num_agent_steps_sampled: 2520000\n",
      "    num_agent_steps_trained: 2520000\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2520000\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.464864864864865\n",
      "    ram_util_percent: 31.159459459459462\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598711567757855\n",
      "    mean_inference_ms: 0.4145607264572588\n",
      "    mean_processing_ms: 4.15243628876064\n",
      "  time_since_restore: 4936.500764846802\n",
      "  time_this_iter_s: 29.0873601436615\n",
      "  time_total_s: 4936.500764846802\n",
      "  timestamp: 1665276116\n",
      "  timesteps_since_restore: 2505000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2505000\n",
      "  training_iteration: 167\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:41:56,622\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 233.0x the scale of `vf_clip_param`. This means that it will take more than 233.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    167 |           4936.5 |     2505000 | -2332.65 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-42-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1103.140363387535\n",
      "  episode_reward_mean: -2402.6335178958516\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 840\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.252\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.26088207960128784\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02775290608406067\n",
      "        policy_loss: 0.005442923866212368\n",
      "        total_loss: 4408.01123046875\n",
      "        vf_explained_var: 0.3879912495613098\n",
      "        vf_loss: 4408.00537109375\n",
      "    load_time_ms: 2.378\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2515968\n",
      "    sample_time_ms: 28483.256\n",
      "    update_time_ms: 2.938\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.845238095238095\n",
      "    ram_util_percent: 24.809523809523803\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562965712058622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4617030833708338\n",
      "    mean_inference_ms: 0.48428646617669147\n",
      "    mean_raw_obs_processing_ms: 3.724052859672515\n",
      "  time_since_restore: 4513.242141723633\n",
      "  time_this_iter_s: 25.553842782974243\n",
      "  time_total_s: 4513.242141723633\n",
      "  timers:\n",
      "    learn_throughput: 6715.537\n",
      "    learn_time_ms: 2233.626\n",
      "    load_throughput: 8618787.073\n",
      "    load_time_ms: 1.74\n",
      "    sample_throughput: 624.435\n",
      "    sample_time_ms: 24021.726\n",
      "    update_time_ms: 1.633\n",
      "  timestamp: 1665249713\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 168\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    168 |          4513.24 | 2520000 | -1973.06 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2535000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-22-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -1818.3740460394608\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 845\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.2744505405426025\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029903963208198547\n",
      "          model: {}\n",
      "          policy_loss: 0.012738454155623913\n",
      "          total_loss: 3040.5390625\n",
      "          vf_explained_var: -8.151062935723985e-09\n",
      "          vf_loss: 3040.50537109375\n",
      "    num_agent_steps_sampled: 2535000\n",
      "    num_agent_steps_trained: 2535000\n",
      "    num_steps_sampled: 2535000\n",
      "    num_steps_trained: 2535000\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.331578947368417\n",
      "    ram_util_percent: 31.155263157894744\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.598796452531365\n",
      "    mean_inference_ms: 0.4145865939454888\n",
      "    mean_processing_ms: 4.15316145656306\n",
      "  time_since_restore: 4966.199636936188\n",
      "  time_this_iter_s: 29.698872089385986\n",
      "  time_total_s: 4966.199636936188\n",
      "  timestamp: 1665276146\n",
      "  timesteps_since_restore: 2520000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 168\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:42:26,362\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 240.0x the scale of `vf_clip_param`. This means that it will take more than 240.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    168 |           4966.2 |     2520000 | -2402.63 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1230.743773462393\n",
      "  episode_reward_mean: -2483.861428648229\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 845\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.378\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.16403000056743622\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02657071314752102\n",
      "        policy_loss: 0.005339247640222311\n",
      "        total_loss: 3721.5537109375\n",
      "        vf_explained_var: 0.5928465723991394\n",
      "        vf_loss: 3721.5478515625\n",
      "    load_time_ms: 2.379\n",
      "    num_steps_sampled: 2535000\n",
      "    num_steps_trained: 2530944\n",
      "    sample_time_ms: 28521.769\n",
      "    update_time_ms: 2.931\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.574418604651164\n",
      "    ram_util_percent: 24.813953488372093\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562962659017868\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4614900535902255\n",
      "    mean_inference_ms: 0.4843067795290945\n",
      "    mean_raw_obs_processing_ms: 3.7227337817429818\n",
      "  time_since_restore: 4539.892965555191\n",
      "  time_this_iter_s: 26.650823831558228\n",
      "  time_total_s: 4539.892965555191\n",
      "  timers:\n",
      "    learn_throughput: 6719.264\n",
      "    learn_time_ms: 2232.387\n",
      "    load_throughput: 8562250.439\n",
      "    load_time_ms: 1.752\n",
      "    sample_throughput: 623.97\n",
      "    sample_time_ms: 24039.625\n",
      "    update_time_ms: 1.584\n",
      "  timestamp: 1665249739\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2535000\n",
      "  training_iteration: 169\n",
      "  trial_id: 26f87_00000\n",
=======
      "    mean_env_wait_ms: 4.598895786957919\n",
      "    mean_inference_ms: 0.4146107145135195\n",
      "    mean_processing_ms: 4.1538911390490485\n",
      "  time_since_restore: 4995.925312280655\n",
      "  time_this_iter_s: 29.725675344467163\n",
      "  time_total_s: 4995.925312280655\n",
      "  timestamp: 1665276176\n",
      "  timesteps_since_restore: 2535000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2535000\n",
      "  training_iteration: 169\n",
      "  trial_id: a95f16f0\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    169 |          4539.89 | 2535000 | -1818.37 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2550000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-22-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1780.9896235052067\n",
      "  episode_reward_mean: -1941.1610534517752\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 850\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.998818039894104\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017860902473330498\n",
      "          model: {}\n",
      "          policy_loss: 0.010739183984696865\n",
      "          total_loss: 3476.550537109375\n",
      "          vf_explained_var: -1.2226593959496768e-08\n",
      "          vf_loss: 3476.52734375\n",
      "    num_agent_steps_sampled: 2550000\n",
      "    num_agent_steps_trained: 2550000\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2550000\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.560526315789474\n",
      "    ram_util_percent: 31.160526315789483\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:42:56,131\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 248.0x the scale of `vf_clip_param`. This means that it will take more than 248.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    169 |          4995.93 |     2535000 | -2483.86 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-43-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1514.2423555665912\n",
      "  episode_reward_mean: -2553.263482844099\n",
      "  episode_reward_min: -3367.858108050978\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 850\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.829\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.17122262716293335\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03199290111660957\n",
      "        policy_loss: 0.006445098202675581\n",
      "        total_loss: 3623.298828125\n",
      "        vf_explained_var: 0.5443859100341797\n",
      "        vf_loss: 3623.2919921875\n",
      "    load_time_ms: 2.269\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2545920\n",
      "    sample_time_ms: 28481.265\n",
      "    update_time_ms: 2.983\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.214285714285715\n",
      "    ram_util_percent: 24.883333333333333\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562940770909913\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.461257962382792\n",
      "    mean_inference_ms: 0.48432580533651226\n",
      "    mean_raw_obs_processing_ms: 3.721562943465948\n",
      "  time_since_restore: 4566.668307542801\n",
      "  time_this_iter_s: 26.775341987609863\n",
      "  time_total_s: 4566.668307542801\n",
      "  timers:\n",
      "    learn_throughput: 6582.1\n",
      "    learn_time_ms: 2278.908\n",
      "    load_throughput: 8534954.011\n",
      "    load_time_ms: 1.757\n",
      "    sample_throughput: 620.766\n",
      "    sample_time_ms: 24163.712\n",
      "    update_time_ms: 1.58\n",
      "  timestamp: 1665249766\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 170\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    170 |          4566.67 | 2550000 | -1941.16 |              1780.99 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2565000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-23-13\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1455.326845455007\n",
      "  episode_reward_mean: -1956.065408770315\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 855\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.0062326192855835\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020253418013453484\n",
      "          model: {}\n",
      "          policy_loss: 0.009122570045292377\n",
      "          total_loss: 3175.099853515625\n",
      "          vf_explained_var: -3.056648489874192e-09\n",
      "          vf_loss: 3175.076416015625\n",
      "    num_agent_steps_sampled: 2565000\n",
      "    num_agent_steps_trained: 2565000\n",
      "    num_steps_sampled: 2565000\n",
      "    num_steps_trained: 2565000\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.76842105263158\n",
      "    ram_util_percent: 31.221052631578942\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.59900140511342\n",
      "    mean_inference_ms: 0.4146340350309604\n",
      "    mean_processing_ms: 4.154610921523528\n",
      "  time_since_restore: 5025.202634096146\n",
      "  time_this_iter_s: 29.277321815490723\n",
      "  time_total_s: 5025.202634096146\n",
      "  timestamp: 1665276205\n",
      "  timesteps_since_restore: 2550000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 170\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:43:25,448\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 255.0x the scale of `vf_clip_param`. This means that it will take more than 255.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    170 |           5025.2 |     2550000 | -2553.26 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-44-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1724.3917387173487\n",
      "  episode_reward_mean: -2613.7860583043152\n",
      "  episode_reward_min: -3440.0462255857474\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 855\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.312\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.33030346035957336\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025763558223843575\n",
      "        policy_loss: 0.006514173466712236\n",
      "        total_loss: 3541.632568359375\n",
      "        vf_explained_var: 0.4889925420284271\n",
      "        vf_loss: 3541.62548828125\n",
      "    load_time_ms: 2.283\n",
      "    num_steps_sampled: 2565000\n",
      "    num_steps_trained: 2560896\n",
      "    sample_time_ms: 29027.392\n",
      "    update_time_ms: 3.11\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.049999999999997\n",
      "    ram_util_percent: 24.721999999999998\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562922007131027\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4610231308222534\n",
      "    mean_inference_ms: 0.4843447802099518\n",
      "    mean_raw_obs_processing_ms: 3.720472687689126\n",
      "  time_since_restore: 4592.926911354065\n",
      "  time_this_iter_s: 26.258603811264038\n",
      "  time_total_s: 4592.926911354065\n",
      "  timers:\n",
      "    learn_throughput: 6465.56\n",
      "    learn_time_ms: 2319.985\n",
      "    load_throughput: 8731463.465\n",
      "    load_time_ms: 1.718\n",
      "    sample_throughput: 631.718\n",
      "    sample_time_ms: 23744.784\n",
      "    update_time_ms: 1.566\n",
      "  timestamp: 1665249793\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2565000\n",
      "  training_iteration: 171\n",
      "  trial_id: 26f87_00000\n",
=======
      "    mean_env_wait_ms: 4.599084031318937\n",
      "    mean_inference_ms: 0.41465579546192166\n",
      "    mean_processing_ms: 4.155944595950255\n",
      "  time_since_restore: 5060.751228570938\n",
      "  time_this_iter_s: 35.54859447479248\n",
      "  time_total_s: 5060.751228570938\n",
      "  timestamp: 1665276241\n",
      "  timesteps_since_restore: 2565000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2565000\n",
      "  training_iteration: 171\n",
      "  trial_id: a95f16f0\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    171 |          4592.93 | 2565000 | -1956.07 |              1455.33 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2580000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-23-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1455.326845455007\n",
      "  episode_reward_mean: -1873.9573684901595\n",
      "  episode_reward_min: -7891.230137621037\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 860\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6935440301895142\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9701129794120789\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008334948681294918\n",
      "          model: {}\n",
      "          policy_loss: 0.00492850923910737\n",
      "          total_loss: 3429.330810546875\n",
      "          vf_explained_var: -8.660504313695583e-09\n",
      "          vf_loss: 3429.320556640625\n",
      "    num_agent_steps_sampled: 2580000\n",
      "    num_agent_steps_trained: 2580000\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2580000\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.641666666666666\n",
      "    ram_util_percent: 31.258333333333333\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:44:01,127\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 261.0x the scale of `vf_clip_param`. This means that it will take more than 261.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    171 |          5060.75 |     2565000 | -2613.79 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-44-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1724.3917387173487\n",
      "  episode_reward_mean: -2659.347269146316\n",
      "  episode_reward_min: -3440.0462255857474\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 860\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.754\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.28467294573783875\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.027947647497057915\n",
      "        policy_loss: 0.0033167183864861727\n",
      "        total_loss: 3080.940673828125\n",
      "        vf_explained_var: 0.5869052410125732\n",
      "        vf_loss: 3080.9365234375\n",
      "    load_time_ms: 2.237\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2575872\n",
      "    sample_time_ms: 29116.921\n",
      "    update_time_ms: 3.116\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.89772727272727\n",
      "    ram_util_percent: 24.775\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562858285338082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.460810505253797\n",
      "    mean_inference_ms: 0.4843613584582673\n",
      "    mean_raw_obs_processing_ms: 3.7193301475640688\n",
      "  time_since_restore: 4617.679140806198\n",
      "  time_this_iter_s: 24.75222945213318\n",
      "  time_total_s: 4617.679140806198\n",
      "  timers:\n",
      "    learn_throughput: 6407.251\n",
      "    learn_time_ms: 2341.098\n",
      "    load_throughput: 8698867.611\n",
      "    load_time_ms: 1.724\n",
      "    sample_throughput: 635.471\n",
      "    sample_time_ms: 23604.544\n",
      "    update_time_ms: 1.585\n",
      "  timestamp: 1665249818\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 172\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.7/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    172 |          4617.68 | 2580000 | -1873.96 |              1455.33 |             -7891.23 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2595000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-24-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1455.326845455007\n",
      "  episode_reward_mean: -1916.0630460051962\n",
      "  episode_reward_min: -7600.051626574294\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 865\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3467720150947571\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.8206602334976196\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03836072236299515\n",
      "          model: {}\n",
      "          policy_loss: 0.01968165673315525\n",
      "          total_loss: 3559.212158203125\n",
      "          vf_explained_var: -3.5660898678457897e-09\n",
      "          vf_loss: 3559.178955078125\n",
      "    num_agent_steps_sampled: 2595000\n",
      "    num_agent_steps_trained: 2595000\n",
      "    num_steps_sampled: 2595000\n",
      "    num_steps_trained: 2595000\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.775000000000002\n",
      "    ram_util_percent: 31.238888888888887\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599132627444876\n",
      "    mean_inference_ms: 0.41467717775001356\n",
      "    mean_processing_ms: 4.157338064334209\n",
      "  time_since_restore: 5091.02382850647\n",
      "  time_this_iter_s: 30.272599935531616\n",
      "  time_total_s: 5091.02382850647\n",
      "  timestamp: 1665276271\n",
      "  timesteps_since_restore: 2580000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 172\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:44:31,446\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 266.0x the scale of `vf_clip_param`. This means that it will take more than 266.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    172 |          5091.02 |     2580000 | -2659.35 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-45-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1796.5016225818085\n",
      "  episode_reward_mean: -2716.5967835605184\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 865\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.405\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.20867598056793213\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03481322154402733\n",
      "        policy_loss: 0.001790590351447463\n",
      "        total_loss: 2932.638427734375\n",
      "        vf_explained_var: 0.61077880859375\n",
      "        vf_loss: 2932.635986328125\n",
      "    load_time_ms: 2.355\n",
      "    num_steps_sampled: 2595000\n",
      "    num_steps_trained: 2590848\n",
      "    sample_time_ms: 29127.172\n",
      "    update_time_ms: 3.08\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.916666666666664\n",
      "    ram_util_percent: 24.77857142857143\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562765362868075\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.460581415103789\n",
      "    mean_inference_ms: 0.48437637799831124\n",
      "    mean_raw_obs_processing_ms: 3.718357213730095\n",
      "  time_since_restore: 4643.442512273788\n",
      "  time_this_iter_s: 25.763371467590332\n",
      "  time_total_s: 4643.442512273788\n",
      "  timers:\n",
      "    learn_throughput: 6531.85\n",
      "    learn_time_ms: 2296.44\n",
      "    load_throughput: 8863202.975\n",
      "    load_time_ms: 1.692\n",
      "    sample_throughput: 632.831\n",
      "    sample_time_ms: 23703.023\n",
      "    update_time_ms: 1.76\n",
      "  timestamp: 1665249843\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2595000\n",
      "  training_iteration: 173\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.599174754874134\n",
      "    mean_inference_ms: 0.41469717929282224\n",
      "    mean_processing_ms: 4.158752309522901\n",
      "  time_since_restore: 5120.467552900314\n",
      "  time_this_iter_s: 29.443724393844604\n",
      "  time_total_s: 5120.467552900314\n",
      "  timestamp: 1665276300\n",
      "  timesteps_since_restore: 2595000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2595000\n",
      "  training_iteration: 173\n",
      "  trial_id: a95f16f0\n",
      "  \u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:45:00,931\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 272.0x the scale of `vf_clip_param`. This means that it will take more than 272.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
<<<<<<< HEAD
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    173 |          4643.44 | 2595000 | -1916.06 |              1455.33 |             -7600.05 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2610000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-24-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1455.326845455007\n",
      "  episode_reward_mean: -1960.277396197579\n",
      "  episode_reward_min: -7600.051626574294\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 870\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3467720150947571\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.454362392425537\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026213113218545914\n",
      "          model: {}\n",
      "          policy_loss: 0.01745900698006153\n",
      "          total_loss: 3796.18212890625\n",
      "          vf_explained_var: -4.58497284583359e-09\n",
      "          vf_loss: 3796.1552734375\n",
      "    num_agent_steps_sampled: 2610000\n",
      "    num_agent_steps_trained: 2610000\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2610000\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.2054054054054\n",
      "    ram_util_percent: 31.251351351351342\n",
      "  pid: 307\n",
=======
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    173 |          5120.47 |     2595000 |  -2716.6 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-45-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -2022.7375143059926\n",
      "  episode_reward_mean: -2762.6763548838867\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 870\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.231\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.13759182393550873\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016564728692173958\n",
      "        policy_loss: 0.0036327873822301626\n",
      "        total_loss: 2733.45556640625\n",
      "        vf_explained_var: 0.7621610164642334\n",
      "        vf_loss: 2733.4521484375\n",
      "    load_time_ms: 2.379\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2605824\n",
      "    sample_time_ms: 28629.022\n",
      "    update_time_ms: 3.111\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.47857142857142\n",
      "    ram_util_percent: 24.764285714285712\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562654568805544\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.460349276730891\n",
      "    mean_inference_ms: 0.4843896529298561\n",
      "    mean_raw_obs_processing_ms: 3.7174199292887504\n",
      "  time_since_restore: 4668.897571563721\n",
      "  time_this_iter_s: 25.45505928993225\n",
      "  time_total_s: 4668.897571563721\n",
      "  timers:\n",
      "    learn_throughput: 6444.115\n",
      "    learn_time_ms: 2327.705\n",
      "    load_throughput: 8881219.65\n",
      "    load_time_ms: 1.689\n",
      "    sample_throughput: 632.634\n",
      "    sample_time_ms: 23710.375\n",
      "    update_time_ms: 1.515\n",
      "  timestamp: 1665249869\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 174\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    174 |           4668.9 | 2610000 | -1960.28 |              1455.33 |             -7600.05 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2625000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-24-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1455.326845455007\n",
      "  episode_reward_mean: -1991.1727418899382\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 875\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3467720150947571\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.948429584503174\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0076310038566589355\n",
      "          model: {}\n",
      "          policy_loss: 0.0008453790796920657\n",
      "          total_loss: 3477.438232421875\n",
      "          vf_explained_var: -1.1207711203553572e-08\n",
      "          vf_loss: 3477.43505859375\n",
      "    num_agent_steps_sampled: 2625000\n",
      "    num_agent_steps_trained: 2625000\n",
      "    num_steps_sampled: 2625000\n",
      "    num_steps_trained: 2625000\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.370270270270268\n",
      "    ram_util_percent: 31.27567567567569\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599227408881489\n",
      "    mean_inference_ms: 0.4147170382494865\n",
      "    mean_processing_ms: 4.16016943404186\n",
      "  time_since_restore: 5149.823895215988\n",
      "  time_this_iter_s: 29.356342315673828\n",
      "  time_total_s: 5149.823895215988\n",
      "  timestamp: 1665276330\n",
      "  timesteps_since_restore: 2610000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 174\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:45:30,329\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 276.0x the scale of `vf_clip_param`. This means that it will take more than 276.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    174 |          5149.82 |     2610000 | -2762.68 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-46-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -2083.295757788571\n",
      "  episode_reward_mean: -2790.134524687485\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 875\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.686\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.4362913966178894\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.029987171292304993\n",
      "        policy_loss: 0.001499005127698183\n",
      "        total_loss: 2220.6787109375\n",
      "        vf_explained_var: 0.7162125706672668\n",
      "        vf_loss: 2220.6767578125\n",
      "    load_time_ms: 2.492\n",
      "    num_steps_sampled: 2625000\n",
      "    num_steps_trained: 2620800\n",
      "    sample_time_ms: 28636.156\n",
      "    update_time_ms: 3.105\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.114285714285714\n",
      "    ram_util_percent: 24.77857142857143\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562554756806635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4601085718559896\n",
      "    mean_inference_ms: 0.4844032913483818\n",
      "    mean_raw_obs_processing_ms: 3.716503160102348\n",
      "  time_since_restore: 4694.550641536713\n",
      "  time_this_iter_s: 25.653069972991943\n",
      "  time_total_s: 4694.550641536713\n",
      "  timers:\n",
      "    learn_throughput: 6254.962\n",
      "    learn_time_ms: 2398.096\n",
      "    load_throughput: 8785599.978\n",
      "    load_time_ms: 1.707\n",
      "    sample_throughput: 629.188\n",
      "    sample_time_ms: 23840.25\n",
      "    update_time_ms: 1.328\n",
      "  timestamp: 1665249895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2625000\n",
      "  training_iteration: 175\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.599262255111073\n",
      "    mean_inference_ms: 0.41473560806041493\n",
      "    mean_processing_ms: 4.1616304371091415\n",
      "  time_since_restore: 5179.658919811249\n",
      "  time_this_iter_s: 29.83502459526062\n",
      "  time_total_s: 5179.658919811249\n",
      "  timestamp: 1665276360\n",
      "  timesteps_since_restore: 2625000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2625000\n",
      "  training_iteration: 175\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:46:00,206\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 279.0x the scale of `vf_clip_param`. This means that it will take more than 279.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    175 |          5179.66 |     2625000 | -2790.13 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    175 |          4694.55 | 2625000 | -1991.17 |              1455.33 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2640000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-25-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1455.326845455007\n",
      "  episode_reward_mean: -1877.0421493861168\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 880\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.17338600754737854\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.1476936340332031\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.06141894310712814\n",
      "          model: {}\n",
      "          policy_loss: 0.020695975050330162\n",
      "          total_loss: 3222.7265625\n",
      "          vf_explained_var: 5.603855601776786e-09\n",
      "          vf_loss: 3222.6953125\n",
      "    num_agent_steps_sampled: 2640000\n",
      "    num_agent_steps_trained: 2640000\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2640000\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.374358974358973\n",
      "    ram_util_percent: 31.37435897435899\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-46-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -2083.295757788571\n",
      "  episode_reward_mean: -2827.4890381428118\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 880\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.571\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.03228828310966492\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012687338516116142\n",
      "        policy_loss: 0.003817146411165595\n",
      "        total_loss: 2339.45068359375\n",
      "        vf_explained_var: 0.7646926045417786\n",
      "        vf_loss: 2339.446533203125\n",
      "    load_time_ms: 2.628\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2635776\n",
      "    sample_time_ms: 28719.711\n",
      "    update_time_ms: 3.168\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.20697674418604\n",
      "    ram_util_percent: 24.799999999999997\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562423970089154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4598856342696367\n",
      "    mean_inference_ms: 0.48441600233593346\n",
      "    mean_raw_obs_processing_ms: 3.715097606625422\n",
      "  time_since_restore: 4721.642894983292\n",
      "  time_this_iter_s: 27.09225344657898\n",
      "  time_total_s: 4721.642894983292\n",
      "  timers:\n",
      "    learn_throughput: 6137.528\n",
      "    learn_time_ms: 2443.981\n",
      "    load_throughput: 9812461.594\n",
      "    load_time_ms: 1.529\n",
      "    sample_throughput: 639.089\n",
      "    sample_time_ms: 23470.917\n",
      "    update_time_ms: 1.336\n",
      "  timestamp: 1665249922\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 176\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    176 |          4721.64 | 2640000 | -1877.04 |              1455.33 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2655000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-25-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2388.124275547652\n",
      "  episode_reward_mean: -1979.07750389564\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 885\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.260079026222229\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9580589532852173\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05377630889415741\n",
      "          model: {}\n",
      "          policy_loss: 0.023845788091421127\n",
      "          total_loss: 3503.888916015625\n",
      "          vf_explained_var: -3.5660898678457897e-09\n",
      "          vf_loss: 3503.8505859375\n",
      "    num_agent_steps_sampled: 2655000\n",
      "    num_agent_steps_trained: 2655000\n",
      "    num_steps_sampled: 2655000\n",
      "    num_steps_trained: 2655000\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.111428571428572\n",
      "    ram_util_percent: 31.279999999999998\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599288814193304\n",
      "    mean_inference_ms: 0.4147527629445991\n",
      "    mean_processing_ms: 4.163090521638867\n",
      "  time_since_restore: 5209.573093891144\n",
      "  time_this_iter_s: 29.91417407989502\n",
      "  time_total_s: 5209.573093891144\n",
      "  timestamp: 1665276390\n",
      "  timesteps_since_restore: 2640000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 176\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:46:30,163\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 283.0x the scale of `vf_clip_param`. This means that it will take more than 283.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    176 |          5209.57 |     2640000 | -2827.49 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-46-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2839.3972432315577\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 885\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.013\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7416759133338928\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.031866151839494705\n",
      "        policy_loss: 0.004936711862683296\n",
      "        total_loss: 1701.363037109375\n",
      "        vf_explained_var: 0.7751567959785461\n",
      "        vf_loss: 1701.357421875\n",
      "    load_time_ms: 2.714\n",
      "    num_steps_sampled: 2655000\n",
      "    num_steps_trained: 2650752\n",
      "    sample_time_ms: 28729.601\n",
      "    update_time_ms: 3.104\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.02857142857143\n",
      "    ram_util_percent: 24.776190476190475\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562345414922426\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4596816444288017\n",
      "    mean_inference_ms: 0.484432362260023\n",
      "    mean_raw_obs_processing_ms: 3.713542814167372\n",
      "  time_since_restore: 4746.663213968277\n",
      "  time_this_iter_s: 25.02031898498535\n",
      "  time_total_s: 4746.663213968277\n",
      "  timers:\n",
      "    learn_throughput: 6265.302\n",
      "    learn_time_ms: 2394.138\n",
      "    load_throughput: 9855037.594\n",
      "    load_time_ms: 1.522\n",
      "    sample_throughput: 638.481\n",
      "    sample_time_ms: 23493.243\n",
      "    update_time_ms: 1.328\n",
      "  timestamp: 1665249947\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2655000\n",
      "  training_iteration: 177\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.59931116313977\n",
      "    mean_inference_ms: 0.41476901707228875\n",
      "    mean_processing_ms: 4.164558206459979\n",
      "  time_since_restore: 5238.763829946518\n",
      "  time_this_iter_s: 29.190736055374146\n",
      "  time_total_s: 5238.763829946518\n",
      "  timestamp: 1665276419\n",
      "  timesteps_since_restore: 2655000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2655000\n",
      "  training_iteration: 177\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:46:59,396\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 284.0x the scale of `vf_clip_param`. This means that it will take more than 284.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    177 |          5238.76 |     2655000 |  -2839.4 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    177 |          4746.66 | 2655000 | -1979.08 |              2388.12 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2670000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-26-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2388.124275547652\n",
      "  episode_reward_mean: -2039.9007584025703\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 890\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3901185393333435\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3540726900100708\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029823007062077522\n",
      "          model: {}\n",
      "          policy_loss: 0.01501560304313898\n",
      "          total_loss: 3692.36669921875\n",
      "          vf_explained_var: -9.679387069638778e-09\n",
      "          vf_loss: 3692.340087890625\n",
      "    num_agent_steps_sampled: 2670000\n",
      "    num_agent_steps_trained: 2670000\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2670000\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.47555555555555\n",
      "    ram_util_percent: 31.217777777777773\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-47-28\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2872.1740650907436\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 890\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1483.507\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.24108535051345825\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030683482065796852\n",
      "        policy_loss: 0.003615394700318575\n",
      "        total_loss: 1777.502685546875\n",
      "        vf_explained_var: 0.8177247047424316\n",
      "        vf_loss: 1777.49853515625\n",
      "    load_time_ms: 2.71\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2665728\n",
      "    sample_time_ms: 28696.81\n",
      "    update_time_ms: 3.137\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.602380952380955\n",
      "    ram_util_percent: 24.766666666666662\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656225830654028\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4594684489790275\n",
      "    mean_inference_ms: 0.4844480001358658\n",
      "    mean_raw_obs_processing_ms: 3.7124987816087\n",
      "  time_since_restore: 4777.808292627335\n",
      "  time_this_iter_s: 31.145078659057617\n",
      "  time_total_s: 4777.808292627335\n",
      "  timers:\n",
      "    learn_throughput: 6270.728\n",
      "    learn_time_ms: 2392.067\n",
      "    load_throughput: 11006553.419\n",
      "    load_time_ms: 1.363\n",
      "    sample_throughput: 623.582\n",
      "    sample_time_ms: 24054.563\n",
      "    update_time_ms: 1.336\n",
      "  timestamp: 1665249978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 178\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    178 |          4777.81 | 2670000 |  -2039.9 |              2388.12 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:26:18,916\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 204.0x the scale of `vf_clip_param`. This means that it will take more than 204.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2685000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-26-44\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -2091.147911642529\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 895\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3901185393333435\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9394162893295288\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05590121075510979\n",
      "          model: {}\n",
      "          policy_loss: 0.02748888172209263\n",
      "          total_loss: 3752.6845703125\n",
      "          vf_explained_var: 3.5660898678457897e-09\n",
      "          vf_loss: 3752.63525390625\n",
      "    num_agent_steps_sampled: 2685000\n",
      "    num_agent_steps_trained: 2685000\n",
      "    num_steps_sampled: 2685000\n",
      "    num_steps_trained: 2685000\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.39189189189189\n",
      "    ram_util_percent: 31.267567567567557\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599373164786772\n",
      "    mean_inference_ms: 0.4147849299647089\n",
      "    mean_processing_ms: 4.1654088921947015\n",
      "  time_since_restore: 5268.120190858841\n",
      "  time_this_iter_s: 29.356360912322998\n",
      "  time_total_s: 5268.120190858841\n",
      "  timestamp: 1665276448\n",
      "  timesteps_since_restore: 2670000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 178\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:47:28,798\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 287.0x the scale of `vf_clip_param`. This means that it will take more than 287.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    178 |          5268.12 |     2670000 | -2872.17 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-47-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2890.5013105987764\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 895\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.955\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.01926511339843273\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5663248896598816\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.046338245272636414\n",
      "        policy_loss: -0.0005553254741244018\n",
      "        total_loss: 1813.369140625\n",
      "        vf_explained_var: 0.7924387454986572\n",
      "        vf_loss: 1813.368896484375\n",
      "    load_time_ms: 2.653\n",
      "    num_steps_sampled: 2685000\n",
      "    num_steps_trained: 2680704\n",
      "    sample_time_ms: 28632.949\n",
      "    update_time_ms: 3.192\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.33414634146341\n",
      "    ram_util_percent: 24.809756097560978\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06562153625171507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4592669272550065\n",
      "    mean_inference_ms: 0.48446230471191115\n",
      "    mean_raw_obs_processing_ms: 3.7114222201397022\n",
      "  time_since_restore: 4803.660845518112\n",
      "  time_this_iter_s: 25.852552890777588\n",
      "  time_total_s: 4803.660845518112\n",
      "  timers:\n",
      "    learn_throughput: 6269.849\n",
      "    learn_time_ms: 2392.402\n",
      "    load_throughput: 10006769.309\n",
      "    load_time_ms: 1.499\n",
      "    sample_throughput: 625.68\n",
      "    sample_time_ms: 23973.904\n",
      "    update_time_ms: 1.337\n",
      "  timestamp: 1665250004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2685000\n",
      "  training_iteration: 179\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:26:44,848\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 209.0x the scale of `vf_clip_param`. This means that it will take more than 209.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    179 |          4803.66 | 2685000 | -2091.15 |              2870.27 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2700000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-27-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -2017.2200310942458\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 900\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.0063426494598389\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029561763629317284\n",
      "          model: {}\n",
      "          policy_loss: 0.010842215269804\n",
      "          total_loss: 3282.847412109375\n",
      "          vf_explained_var: 3.056648489874192e-09\n",
      "          vf_loss: 3282.8193359375\n",
      "    num_agent_steps_sampled: 2700000\n",
      "    num_agent_steps_trained: 2700000\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2700000\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.691666666666666\n",
      "    ram_util_percent: 31.313888888888883\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599417728115829\n",
      "    mean_inference_ms: 0.4148055389231287\n",
      "    mean_processing_ms: 4.166244491373986\n",
      "  time_since_restore: 5297.2217898368835\n",
      "  time_this_iter_s: 29.101598978042603\n",
      "  time_total_s: 5297.2217898368835\n",
      "  timestamp: 1665276477\n",
      "  timesteps_since_restore: 2685000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2685000\n",
      "  training_iteration: 179\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:47:57,944\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 289.0x the scale of `vf_clip_param`. This means that it will take more than 289.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    179 |          5297.22 |     2685000 |  -2890.5 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-48-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2902.446647953793\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 900\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.056\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.028897669166326523\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.1546245813369751\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02446637861430645\n",
      "        policy_loss: 0.0022756322287023067\n",
      "        total_loss: 1607.4617919921875\n",
      "        vf_explained_var: 0.8388937711715698\n",
      "        vf_loss: 1607.45849609375\n",
      "    load_time_ms: 2.601\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2695680\n",
      "    sample_time_ms: 28655.638\n",
      "    update_time_ms: 3.185\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.44418604651163\n",
      "    ram_util_percent: 24.862790697674416\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656204434860576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4590697048828747\n",
      "    mean_inference_ms: 0.4844755667512322\n",
      "    mean_raw_obs_processing_ms: 3.710386937974164\n",
      "  time_since_restore: 4828.442032337189\n",
      "  time_this_iter_s: 24.781186819076538\n",
      "  time_total_s: 4828.442032337189\n",
      "  timers:\n",
      "    learn_throughput: 6432.779\n",
      "    learn_time_ms: 2331.807\n",
      "    load_throughput: 10132800.773\n",
      "    load_time_ms: 1.48\n",
      "    sample_throughput: 629.329\n",
      "    sample_time_ms: 23834.924\n",
      "    update_time_ms: 1.461\n",
      "  timestamp: 1665250029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 180\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=307)\u001b[0m 2022-10-08 12:27:09,733\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 202.0x the scale of `vf_clip_param`. This means that it will take more than 202.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    180 |          4828.44 | 2700000 | -2017.22 |              2870.27 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2715000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-27-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1956.0391232053635\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 905\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.28332072496414185\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013734111562371254\n",
      "          model: {}\n",
      "          policy_loss: 0.004752952139824629\n",
      "          total_loss: 3388.447021484375\n",
      "          vf_explained_var: -1.1207711203553572e-08\n",
      "          vf_loss: 3388.434326171875\n",
      "    num_agent_steps_sampled: 2715000\n",
      "    num_agent_steps_trained: 2715000\n",
      "    num_steps_sampled: 2715000\n",
      "    num_steps_trained: 2715000\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.87727272727273\n",
      "    ram_util_percent: 31.27954545454546\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599499180149728\n",
      "    mean_inference_ms: 0.4148248138271719\n",
      "    mean_processing_ms: 4.167059080807658\n",
      "  time_since_restore: 5326.724836111069\n",
      "  time_this_iter_s: 29.50304627418518\n",
      "  time_total_s: 5326.724836111069\n",
      "  timestamp: 1665276507\n",
      "  timesteps_since_restore: 2700000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 180\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:48:27,489\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 290.0x the scale of `vf_clip_param`. This means that it will take more than 290.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    180 |          5326.72 |     2700000 | -2902.45 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-48-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2903.293528460168\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 905\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.42\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.028897669166326523\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8669230937957764\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0682063102722168\n",
      "        policy_loss: 0.004827696830034256\n",
      "        total_loss: 1379.620361328125\n",
      "        vf_explained_var: 0.8151764869689941\n",
      "        vf_loss: 1379.61376953125\n",
      "    load_time_ms: 2.431\n",
      "    num_steps_sampled: 2715000\n",
      "    num_steps_trained: 2710656\n",
      "    sample_time_ms: 28024.569\n",
      "    update_time_ms: 3.128\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.23170731707317\n",
      "    ram_util_percent: 24.824390243902442\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06561888005146504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4588749651381936\n",
      "    mean_inference_ms: 0.4844857717790469\n",
      "    mean_raw_obs_processing_ms: 3.709372065544261\n",
      "  time_since_restore: 4859.604816675186\n",
      "  time_this_iter_s: 31.162784337997437\n",
      "  time_total_s: 4859.604816675186\n",
      "  timers:\n",
      "    learn_throughput: 6527.933\n",
      "    learn_time_ms: 2297.818\n",
      "    load_throughput: 9860907.182\n",
      "    load_time_ms: 1.521\n",
      "    sample_throughput: 615.792\n",
      "    sample_time_ms: 24358.881\n",
      "    update_time_ms: 1.654\n",
      "  timestamp: 1665250061\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2715000\n",
      "  training_iteration: 181\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    181 |           4859.6 | 2715000 | -1956.04 |              2870.27 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2730000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-28-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1866.3750061705061\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 910\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.8675642013549805\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023239444941282272\n",
      "          model: {}\n",
      "          policy_loss: 0.0070831202901899815\n",
      "          total_loss: 2658.92919921875\n",
      "          vf_explained_var: -6.113296979748384e-09\n",
      "          vf_loss: 2658.908447265625\n",
      "    num_agent_steps_sampled: 2730000\n",
      "    num_agent_steps_trained: 2730000\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2730000\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.36388888888889\n",
      "    ram_util_percent: 31.35833333333334\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599562827809026\n",
      "    mean_inference_ms: 0.41484348134823135\n",
      "    mean_processing_ms: 4.167807442377699\n",
      "  time_since_restore: 5355.974029779434\n",
      "  time_this_iter_s: 29.24919366836548\n",
      "  time_total_s: 5355.974029779434\n",
      "  timestamp: 1665276536\n",
      "  timesteps_since_restore: 2715000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2715000\n",
      "  training_iteration: 181\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:48:56,788\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 290.0x the scale of `vf_clip_param`. This means that it will take more than 290.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    181 |          5355.97 |     2715000 | -2903.29 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-49-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2916.34222254144\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 910\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.345\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.043346501886844635\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.3626382052898407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.04892020672559738\n",
      "        policy_loss: -0.004429658874869347\n",
      "        total_loss: 1471.9439697265625\n",
      "        vf_explained_var: 0.8233503699302673\n",
      "        vf_loss: 1471.9464111328125\n",
      "    load_time_ms: 2.53\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2725632\n",
      "    sample_time_ms: 27899.715\n",
      "    update_time_ms: 3.141\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.349999999999994\n",
      "    ram_util_percent: 24.81428571428571\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06561718792011188\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4586808624587944\n",
      "    mean_inference_ms: 0.48449373162144477\n",
      "    mean_raw_obs_processing_ms: 3.708351471733587\n",
      "  time_since_restore: 4884.779177188873\n",
      "  time_this_iter_s: 25.174360513687134\n",
      "  time_total_s: 4884.779177188873\n",
      "  timers:\n",
      "    learn_throughput: 6529.527\n",
      "    learn_time_ms: 2297.257\n",
      "    load_throughput: 8840039.342\n",
      "    load_time_ms: 1.697\n",
      "    sample_throughput: 614.721\n",
      "    sample_time_ms: 24401.314\n",
      "    update_time_ms: 1.784\n",
      "  timestamp: 1665250086\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 182\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    182 |          4884.78 | 2730000 | -1866.38 |              2870.27 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2745000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-28-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1762.6015275008226\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 915\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.2679554224014282\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026875220239162445\n",
      "          model: {}\n",
      "          policy_loss: 0.009888596832752228\n",
      "          total_loss: 3157.632568359375\n",
      "          vf_explained_var: 8.151062935723985e-09\n",
      "          vf_loss: 3157.60693359375\n",
      "    num_agent_steps_sampled: 2745000\n",
      "    num_agent_steps_trained: 2745000\n",
      "    num_steps_sampled: 2745000\n",
      "    num_steps_trained: 2745000\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.223684210526315\n",
      "    ram_util_percent: 31.347368421052646\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599641436780945\n",
      "    mean_inference_ms: 0.41486211163768155\n",
      "    mean_processing_ms: 4.168552268845514\n",
      "  time_since_restore: 5384.998537540436\n",
      "  time_this_iter_s: 29.024507761001587\n",
      "  time_total_s: 5384.998537540436\n",
      "  timestamp: 1665276565\n",
      "  timesteps_since_restore: 2730000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 182\n",
      "  trial_id: a95f16f0\n",
      "  \u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:49:25,862\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 292.0x the scale of `vf_clip_param`. This means that it will take more than 292.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    182 |             5385 |     2730000 | -2916.34 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-49-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2903.7567243490253\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 915\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.791\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06501975655555725\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.5669554471969604\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.024949120357632637\n",
      "        policy_loss: 0.0037160352803766727\n",
      "        total_loss: 1405.1654052734375\n",
      "        vf_explained_var: 0.8521865010261536\n",
      "        vf_loss: 1405.16015625\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 2745000\n",
      "    num_steps_trained: 2740608\n",
      "    sample_time_ms: 27870.873\n",
      "    update_time_ms: 3.243\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.639024390243904\n",
      "    ram_util_percent: 24.819512195121952\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06561528215258777\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4585071220205426\n",
      "    mean_inference_ms: 0.4845006058604194\n",
      "    mean_raw_obs_processing_ms: 3.7074453845453736\n",
      "  time_since_restore: 4911.325086593628\n",
      "  time_this_iter_s: 26.54590940475464\n",
      "  time_total_s: 4911.325086593628\n",
      "  timers:\n",
      "    learn_throughput: 6424.685\n",
      "    learn_time_ms: 2334.745\n",
      "    load_throughput: 8641160.312\n",
      "    load_time_ms: 1.736\n",
      "    sample_throughput: 613.691\n",
      "    sample_time_ms: 24442.286\n",
      "    update_time_ms: 1.756\n",
      "  timestamp: 1665250112\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2745000\n",
      "  training_iteration: 183\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    183 |          4911.33 | 2745000 |  -1762.6 |              2870.27 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n"
=======
      "    mean_env_wait_ms: 4.599725182960738\n",
      "    mean_inference_ms: 0.41488220126655356\n",
      "    mean_processing_ms: 4.1692804189315815\n",
      "  time_since_restore: 5414.139310121536\n",
      "  time_this_iter_s: 29.140772581100464\n",
      "  time_total_s: 5414.139310121536\n",
      "  timestamp: 1665276595\n",
      "  timesteps_since_restore: 2745000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2745000\n",
      "  training_iteration: 183\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:49:55,051\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 290.0x the scale of `vf_clip_param`. This means that it will take more than 290.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    183 |          5414.14 |     2745000 | -2903.76 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2760000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-29-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1753.397442231074\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 920\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.6414239406585693\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012648344971239567\n",
      "          model: {}\n",
      "          policy_loss: 0.00411427766084671\n",
      "          total_loss: 3097.00244140625\n",
      "          vf_explained_var: -7.641621557752387e-09\n",
      "          vf_loss: 3096.99072265625\n",
      "    num_agent_steps_sampled: 2760000\n",
      "    num_agent_steps_trained: 2760000\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2760000\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.669767441860465\n",
      "    ram_util_percent: 31.318604651162797\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-50-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2888.7417283876757\n",
      "  episode_reward_min: -3475.79538412804\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 920\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.958\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.06501975655555725\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.21450923383235931\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05325677990913391\n",
      "        policy_loss: 0.0027410604525357485\n",
      "        total_loss: 1252.860595703125\n",
      "        vf_explained_var: 0.8712721467018127\n",
      "        vf_loss: 1252.8546142578125\n",
      "    load_time_ms: 2.517\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2755584\n",
      "    sample_time_ms: 27893.096\n",
      "    update_time_ms: 3.238\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.181395348837206\n",
      "    ram_util_percent: 24.858139534883723\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0656133837524372\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4583370476608737\n",
      "    mean_inference_ms: 0.4845075288850981\n",
      "    mean_raw_obs_processing_ms: 3.707010912513533\n",
      "  time_since_restore: 4941.392063856125\n",
      "  time_this_iter_s: 30.06697726249695\n",
      "  time_total_s: 4941.392063856125\n",
      "  timers:\n",
      "    learn_throughput: 6518.955\n",
      "    learn_time_ms: 2300.982\n",
      "    load_throughput: 8637008.36\n",
      "    load_time_ms: 1.737\n",
      "    sample_throughput: 601.508\n",
      "    sample_time_ms: 24937.336\n",
      "    update_time_ms: 1.737\n",
      "  timestamp: 1665250143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 184\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    184 |          4941.39 | 2760000 |  -1753.4 |              2870.27 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2775000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1804.871538870011\n",
      "  episode_reward_min: -8149.869935808996\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 925\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.453515648841858\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0160432867705822\n",
      "          model: {}\n",
      "          policy_loss: 0.008884639479219913\n",
      "          total_loss: 3458.85986328125\n",
      "          vf_explained_var: 4.58497284583359e-09\n",
      "          vf_loss: 3458.841796875\n",
      "    num_agent_steps_sampled: 2775000\n",
      "    num_agent_steps_trained: 2775000\n",
      "    num_steps_sampled: 2775000\n",
      "    num_steps_trained: 2775000\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.45263157894737\n",
      "    ram_util_percent: 31.363157894736858\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599833409820961\n",
      "    mean_inference_ms: 0.4149012969174473\n",
      "    mean_processing_ms: 4.169552177517096\n",
      "  time_since_restore: 5443.719420433044\n",
      "  time_this_iter_s: 29.58011031150818\n",
      "  time_total_s: 5443.719420433044\n",
      "  timestamp: 1665276624\n",
      "  timesteps_since_restore: 2760000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 184\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:50:24,681\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 289.0x the scale of `vf_clip_param`. This means that it will take more than 289.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    184 |          5443.72 |     2760000 | -2888.74 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-50-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2893.2488982327545\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 925\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.816\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.09752963483333588\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.0021572643890976906\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.12715552747249603\n",
      "        policy_loss: 0.012293278239667416\n",
      "        total_loss: 1865.1329345703125\n",
      "        vf_explained_var: 0.895842432975769\n",
      "        vf_loss: 1865.1080322265625\n",
      "    load_time_ms: 2.533\n",
      "    num_steps_sampled: 2775000\n",
      "    num_steps_trained: 2770560\n",
      "    sample_time_ms: 27840.442\n",
      "    update_time_ms: 3.232\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.56904761904762\n",
      "    ram_util_percent: 24.864285714285714\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06561167798278286\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4581813401527546\n",
      "    mean_inference_ms: 0.48451517679816164\n",
      "    mean_raw_obs_processing_ms: 3.706726790126085\n",
      "  time_since_restore: 4967.278487205505\n",
      "  time_this_iter_s: 25.886423349380493\n",
      "  time_total_s: 4967.278487205505\n",
      "  timers:\n",
      "    learn_throughput: 6587.834\n",
      "    learn_time_ms: 2276.924\n",
      "    load_throughput: 9430488.353\n",
      "    load_time_ms: 1.591\n",
      "    sample_throughput: 600.356\n",
      "    sample_time_ms: 24985.194\n",
      "    update_time_ms: 1.725\n",
      "  timestamp: 1665250169\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2775000\n",
      "  training_iteration: 185\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    185 |          4967.28 | 2775000 | -1804.87 |              2870.27 |             -8149.87 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2790000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-29-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1888.9386518220153\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 930\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8970360159873962\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025064490735530853\n",
      "          model: {}\n",
      "          policy_loss: 0.014358100481331348\n",
      "          total_loss: 3420.452392578125\n",
      "          vf_explained_var: 3.056648489874192e-09\n",
      "          vf_loss: 3420.424072265625\n",
      "    num_agent_steps_sampled: 2790000\n",
      "    num_agent_steps_trained: 2790000\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2790000\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.752777777777776\n",
      "    ram_util_percent: 31.383333333333326\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599906793615738\n",
      "    mean_inference_ms: 0.4149192718101704\n",
      "    mean_processing_ms: 4.169819924417821\n",
      "  time_since_restore: 5473.026577234268\n",
      "  time_this_iter_s: 29.307156801223755\n",
      "  time_total_s: 5473.026577234268\n",
      "  timestamp: 1665276654\n",
      "  timesteps_since_restore: 2775000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2775000\n",
      "  training_iteration: 185\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:50:54,032\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 289.0x the scale of `vf_clip_param`. This means that it will take more than 289.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    185 |          5473.03 |     2775000 | -2893.25 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-51-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2876.748519859343\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 930\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.16\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.178558811545372\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025109291076660156\n",
      "        policy_loss: 0.0014107426395639777\n",
      "        total_loss: 1283.2623291015625\n",
      "        vf_explained_var: 0.8595194816589355\n",
      "        vf_loss: 1283.2572021484375\n",
      "    load_time_ms: 2.489\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2785536\n",
      "    sample_time_ms: 27790.145\n",
      "    update_time_ms: 3.265\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.56190476190476\n",
      "    ram_util_percent: 24.838095238095235\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06560982918465064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4580099913035327\n",
      "    mean_inference_ms: 0.48452185720791824\n",
      "    mean_raw_obs_processing_ms: 3.705944259688442\n",
      "  time_since_restore: 4992.692663192749\n",
      "  time_this_iter_s: 25.414175987243652\n",
      "  time_total_s: 4992.692663192749\n",
      "  timers:\n",
      "    learn_throughput: 6636.134\n",
      "    learn_time_ms: 2260.352\n",
      "    load_throughput: 9205841.21\n",
      "    load_time_ms: 1.629\n",
      "    sample_throughput: 604.012\n",
      "    sample_time_ms: 24833.94\n",
      "    update_time_ms: 1.712\n",
      "  timestamp: 1665250194\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 186\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    186 |          4992.69 | 2790000 | -1888.94 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2805000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-30-20\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1933.332131679838\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 935\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.6179674863815308\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0330522321164608\n",
      "          model: {}\n",
      "          policy_loss: 0.020627852529287338\n",
      "          total_loss: 3476.1240234375\n",
      "          vf_explained_var: -5.094414223805188e-09\n",
      "          vf_loss: 3476.083984375\n",
      "    num_agent_steps_sampled: 2805000\n",
      "    num_agent_steps_trained: 2805000\n",
      "    num_steps_sampled: 2805000\n",
      "    num_steps_trained: 2805000\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.488888888888887\n",
      "    ram_util_percent: 31.46388888888889\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.599986808953189\n",
      "    mean_inference_ms: 0.4149374689446009\n",
      "    mean_processing_ms: 4.170094426887482\n",
      "  time_since_restore: 5502.441032648087\n",
      "  time_this_iter_s: 29.41445541381836\n",
      "  time_total_s: 5502.441032648087\n",
      "  timestamp: 1665276683\n",
      "  timesteps_since_restore: 2790000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 186\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:51:23,491\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 288.0x the scale of `vf_clip_param`. This means that it will take more than 288.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    186 |          5502.44 |     2790000 | -2876.75 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-51-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2882.053539137801\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 935\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1484.963\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.02109302394092083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016904085874557495\n",
      "        policy_loss: 0.0005983602604828775\n",
      "        total_loss: 1294.55517578125\n",
      "        vf_explained_var: 0.9042912125587463\n",
      "        vf_loss: 1294.5521240234375\n",
      "    load_time_ms: 2.433\n",
      "    num_steps_sampled: 2805000\n",
      "    num_steps_trained: 2800512\n",
      "    sample_time_ms: 27815.884\n",
      "    update_time_ms: 3.287\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.97142857142857\n",
      "    ram_util_percent: 24.873809523809523\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06560817491310306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.457869611684481\n",
      "    mean_inference_ms: 0.4845295888280938\n",
      "    mean_raw_obs_processing_ms: 3.7051503329714093\n",
      "  time_since_restore: 5018.08442902565\n",
      "  time_this_iter_s: 25.391765832901\n",
      "  time_total_s: 5018.08442902565\n",
      "  timers:\n",
      "    learn_throughput: 6403.555\n",
      "    learn_time_ms: 2342.449\n",
      "    load_throughput: 8407777.733\n",
      "    load_time_ms: 1.784\n",
      "    sample_throughput: 605.119\n",
      "    sample_time_ms: 24788.498\n",
      "    update_time_ms: 1.864\n",
      "  timestamp: 1665250220\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2805000\n",
      "  training_iteration: 187\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    187 |          5018.08 | 2805000 | -1933.33 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2820000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-30-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1911.1819218681983\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 940\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.7320817708969116\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02287897653877735\n",
      "          model: {}\n",
      "          policy_loss: 0.006671463139355183\n",
      "          total_loss: 3171.4296875\n",
      "          vf_explained_var: 1.528324244937096e-09\n",
      "          vf_loss: 3171.409423828125\n",
      "    num_agent_steps_sampled: 2820000\n",
      "    num_agent_steps_trained: 2820000\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2820000\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.71578947368421\n",
      "    ram_util_percent: 31.36842105263159\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600057682463838\n",
      "    mean_inference_ms: 0.4149554215730833\n",
      "    mean_processing_ms: 4.170370662122095\n",
      "  time_since_restore: 5531.8867337703705\n",
      "  time_this_iter_s: 29.445701122283936\n",
      "  time_total_s: 5531.8867337703705\n",
      "  timestamp: 1665276712\n",
      "  timesteps_since_restore: 2805000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2805000\n",
      "  training_iteration: 187\n",
      "  trial_id: a95f16f0\n",
      "  \u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:51:52,979\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 288.0x the scale of `vf_clip_param`. This means that it will take more than 288.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    187 |          5531.89 |     2805000 | -2882.05 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-52-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2861.0674335480585\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 940\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.777\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7721999883651733\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011358455754816532\n",
      "        policy_loss: 0.0011059717508032918\n",
      "        total_loss: 1062.0225830078125\n",
      "        vf_explained_var: 0.8488186597824097\n",
      "        vf_loss: 1062.0196533203125\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2815488\n",
      "    sample_time_ms: 27836.191\n",
      "    update_time_ms: 3.257\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.07142857142858\n",
      "    ram_util_percent: 24.888095238095236\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06560654758484544\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4577190014240067\n",
      "    mean_inference_ms: 0.48453764328970483\n",
      "    mean_raw_obs_processing_ms: 3.704412000615615\n",
      "  time_since_restore: 5044.3103795051575\n",
      "  time_this_iter_s: 26.225950479507446\n",
      "  time_total_s: 5044.3103795051575\n",
      "  timers:\n",
      "    learn_throughput: 6436.829\n",
      "    learn_time_ms: 2330.34\n",
      "    load_throughput: 8446721.444\n",
      "    load_time_ms: 1.776\n",
      "    sample_throughput: 617.056\n",
      "    sample_time_ms: 24308.957\n",
      "    update_time_ms: 1.862\n",
      "  timestamp: 1665250246\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 188\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    188 |          5044.31 | 2820000 | -1911.18 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n"
=======
      "    mean_env_wait_ms: 4.600129567573859\n",
      "    mean_inference_ms: 0.41497353968363854\n",
      "    mean_processing_ms: 4.170620298961435\n",
      "  time_since_restore: 5561.464542388916\n",
      "  time_this_iter_s: 29.577808618545532\n",
      "  time_total_s: 5561.464542388916\n",
      "  timestamp: 1665276742\n",
      "  timesteps_since_restore: 2820000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 188\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:52:22,605\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 286.0x the scale of `vf_clip_param`. This means that it will take more than 286.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    188 |          5561.46 |     2820000 | -2861.07 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2835000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-31-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1964.5598509008175\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 945\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5851777791976929\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.24217724800109863\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04927981272339821\n",
      "          model: {}\n",
      "          policy_loss: 0.024936648085713387\n",
      "          total_loss: 3396.61083984375\n",
      "          vf_explained_var: -1.171715258152517e-08\n",
      "          vf_loss: 3396.556884765625\n",
      "    num_agent_steps_sampled: 2835000\n",
      "    num_agent_steps_trained: 2835000\n",
      "    num_steps_sampled: 2835000\n",
      "    num_steps_trained: 2835000\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.680769230769233\n",
      "    ram_util_percent: 31.290384615384617\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-52-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2845.689865415141\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 945\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.771\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7997622489929199\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010404490865767002\n",
      "        policy_loss: 0.002300113206729293\n",
      "        total_loss: 833.3055419921875\n",
      "        vf_explained_var: 0.8489974737167358\n",
      "        vf_loss: 833.3016967773438\n",
      "    load_time_ms: 2.578\n",
      "    num_steps_sampled: 2835000\n",
      "    num_steps_trained: 2830464\n",
      "    sample_time_ms: 27810.929\n",
      "    update_time_ms: 3.164\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.31219512195121\n",
      "    ram_util_percent: 24.914634146341463\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06560484546413256\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.457545311816655\n",
      "    mean_inference_ms: 0.48454538154122906\n",
      "    mean_raw_obs_processing_ms: 3.7045542912396887\n",
      "  time_since_restore: 5080.567144155502\n",
      "  time_this_iter_s: 36.25676465034485\n",
      "  time_total_s: 5080.567144155502\n",
      "  timers:\n",
      "    learn_throughput: 6452.189\n",
      "    learn_time_ms: 2324.792\n",
      "    load_throughput: 8482137.705\n",
      "    load_time_ms: 1.768\n",
      "    sample_throughput: 591.602\n",
      "    sample_time_ms: 25354.866\n",
      "    update_time_ms: 1.867\n",
      "  timestamp: 1665250282\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2835000\n",
      "  training_iteration: 189\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    189 |          5080.57 | 2835000 | -1964.56 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2850000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-31-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1885.8162586051578\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 950\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8777666687965393\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.17134054005146027\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020164895802736282\n",
      "          model: {}\n",
      "          policy_loss: 0.009802374057471752\n",
      "          total_loss: 3268.418212890625\n",
      "          vf_explained_var: -2.088709827319235e-08\n",
      "          vf_loss: 3268.39111328125\n",
      "    num_agent_steps_sampled: 2850000\n",
      "    num_agent_steps_trained: 2850000\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2850000\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.119444444444444\n",
      "    ram_util_percent: 31.35833333333334\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600172969586525\n",
      "    mean_inference_ms: 0.4149907430347175\n",
      "    mean_processing_ms: 4.170821998918188\n",
      "  time_since_restore: 5590.313106775284\n",
      "  time_this_iter_s: 28.848564386367798\n",
      "  time_total_s: 5590.313106775284\n",
      "  timestamp: 1665276771\n",
      "  timesteps_since_restore: 2835000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2835000\n",
      "  training_iteration: 189\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:52:51,497\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 285.0x the scale of `vf_clip_param`. This means that it will take more than 285.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    189 |          5590.31 |     2835000 | -2845.69 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m Could not connect to TraCI server at localhost:33431 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m Could not connect to TraCI server at localhost:57493 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m Could not connect to TraCI server at localhost:48261 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m Could not connect to TraCI server at localhost:48399 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m Could not connect to TraCI server at localhost:56939 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-53-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2832.012314896479\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 950\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.949\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7793335318565369\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03947479650378227\n",
      "        policy_loss: 0.01128850132226944\n",
      "        total_loss: 851.459228515625\n",
      "        vf_explained_var: 0.8720625638961792\n",
      "        vf_loss: 851.4420776367188\n",
      "    load_time_ms: 2.696\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2845440\n",
      "    sample_time_ms: 28389.141\n",
      "    update_time_ms: 3.12\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.298039215686277\n",
      "    ram_util_percent: 24.91568627450981\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06560332869166134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4573901186432288\n",
      "    mean_inference_ms: 0.4845542262145585\n",
      "    mean_raw_obs_processing_ms: 3.704685519137792\n",
      "  time_since_restore: 5106.110896348953\n",
      "  time_this_iter_s: 25.543752193450928\n",
      "  time_total_s: 5106.110896348953\n",
      "  timers:\n",
      "    learn_throughput: 6413.573\n",
      "    learn_time_ms: 2338.79\n",
      "    load_throughput: 8404408.288\n",
      "    load_time_ms: 1.785\n",
      "    sample_throughput: 590.145\n",
      "    sample_time_ms: 25417.466\n",
      "    update_time_ms: 1.716\n",
      "  timestamp: 1665250308\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 190\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    190 |          5106.11 | 2850000 | -1885.82 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
=======
      "    mean_env_wait_ms: 4.600186949823665\n",
      "    mean_inference_ms: 0.4150070495823472\n",
      "    mean_processing_ms: 4.171616792359069\n",
      "  time_since_restore: 5625.600764274597\n",
      "  time_this_iter_s: 35.287657499313354\n",
      "  time_total_s: 5625.600764274597\n",
      "  timestamp: 1665276806\n",
      "  timesteps_since_restore: 2850000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 190\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:53:26,834\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 283.0x the scale of `vf_clip_param`. This means that it will take more than 283.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2865000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-32-14\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1856.843771435448\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 955\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8777666687965393\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.5114880800247192\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01875985413789749\n",
      "          model: {}\n",
      "          policy_loss: 0.00759407551959157\n",
      "          total_loss: 2876.848388671875\n",
      "          vf_explained_var: -1.0188828669654981e-09\n",
      "          vf_loss: 2876.82421875\n",
      "    num_agent_steps_sampled: 2865000\n",
      "    num_agent_steps_trained: 2865000\n",
      "    num_steps_sampled: 2865000\n",
      "    num_steps_trained: 2865000\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.386842105263156\n",
      "    ram_util_percent: 31.35789473684212\n",
      "  pid: 307\n",
=======
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    190 |           5625.6 |     2850000 | -2832.01 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-53-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2831.9631363280046\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 955\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.108\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.14629444479942322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.05008396878838539\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0485977940261364\n",
      "        policy_loss: 0.003743192180991173\n",
      "        total_loss: 1313.6019287109375\n",
      "        vf_explained_var: 0.8735475540161133\n",
      "        vf_loss: 1313.5911865234375\n",
      "    load_time_ms: 2.817\n",
      "    num_steps_sampled: 2865000\n",
      "    num_steps_trained: 2860416\n",
      "    sample_time_ms: 28393.274\n",
      "    update_time_ms: 3.151\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.13095238095238\n",
      "    ram_util_percent: 24.923809523809524\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06560168211828907\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.457230232656556\n",
      "    mean_inference_ms: 0.48456160052710073\n",
      "    mean_raw_obs_processing_ms: 3.704846543923236\n",
      "  time_since_restore: 5132.070897817612\n",
      "  time_this_iter_s: 25.960001468658447\n",
      "  time_total_s: 5132.070897817612\n",
      "  timers:\n",
      "    learn_throughput: 6344.593\n",
      "    learn_time_ms: 2364.218\n",
      "    load_throughput: 8369525.482\n",
      "    load_time_ms: 1.792\n",
      "    sample_throughput: 603.085\n",
      "    sample_time_ms: 24872.112\n",
      "    update_time_ms: 1.527\n",
      "  timestamp: 1665250334\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2865000\n",
      "  training_iteration: 191\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    191 |          5132.07 | 2865000 | -1856.84 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2880000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-32-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1948.9398107969628\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 960\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8777666687965393\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.7393736839294434\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0066861435770988464\n",
      "          model: {}\n",
      "          policy_loss: 0.0023233278188854456\n",
      "          total_loss: 3524.853515625\n",
      "          vf_explained_var: -1.0188828447610376e-08\n",
      "          vf_loss: 3524.845703125\n",
      "    num_agent_steps_sampled: 2880000\n",
      "    num_agent_steps_trained: 2880000\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2880000\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.797222222222228\n",
      "    ram_util_percent: 31.38888888888889\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600212864007991\n",
      "    mean_inference_ms: 0.4150244171218253\n",
      "    mean_processing_ms: 4.17179163634971\n",
      "  time_since_restore: 5654.874876499176\n",
      "  time_this_iter_s: 29.274112224578857\n",
      "  time_total_s: 5654.874876499176\n",
      "  timestamp: 1665276836\n",
      "  timesteps_since_restore: 2865000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2865000\n",
      "  training_iteration: 191\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:53:56,243\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 283.0x the scale of `vf_clip_param`. This means that it will take more than 283.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    191 |          5654.87 |     2865000 | -2831.96 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-54-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1900.5212665345625\n",
      "  episode_reward_mean: -2800.951115698572\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 960\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1485.689\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.21944166719913483\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.48574793338775635\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012826258316636086\n",
      "        policy_loss: 0.0007155776838771999\n",
      "        total_loss: 807.7327880859375\n",
      "        vf_explained_var: 0.918988823890686\n",
      "        vf_loss: 807.7293090820312\n",
      "    load_time_ms: 2.763\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2875392\n",
      "    sample_time_ms: 28432.22\n",
      "    update_time_ms: 3.156\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.75476190476191\n",
      "    ram_util_percent: 24.91190476190476\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06560039932617447\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.457080505162213\n",
      "    mean_inference_ms: 0.48457037939883824\n",
      "    mean_raw_obs_processing_ms: 3.705116674161677\n",
      "  time_since_restore: 5157.19713640213\n",
      "  time_this_iter_s: 25.126238584518433\n",
      "  time_total_s: 5157.19713640213\n",
      "  timers:\n",
      "    learn_throughput: 6449.005\n",
      "    learn_time_ms: 2325.94\n",
      "    load_throughput: 9263584.428\n",
      "    load_time_ms: 1.619\n",
      "    sample_throughput: 602.265\n",
      "    sample_time_ms: 24905.996\n",
      "    update_time_ms: 1.387\n",
      "  timestamp: 1665250359\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 192\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    192 |           5157.2 | 2880000 | -1948.94 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
=======
      "    mean_env_wait_ms: 4.600262323604616\n",
      "    mean_inference_ms: 0.41504186142149524\n",
      "    mean_processing_ms: 4.171892755007912\n",
      "  time_since_restore: 5684.294137239456\n",
      "  time_this_iter_s: 29.41926074028015\n",
      "  time_total_s: 5684.294137239456\n",
      "  timestamp: 1665276865\n",
      "  timesteps_since_restore: 2880000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 192\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:54:25,702\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 280.0x the scale of `vf_clip_param`. This means that it will take more than 280.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    192 |          5684.29 |     2880000 | -2800.95 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2895000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-33-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1814.8413881462545\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 965\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.43888333439826965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -1.8730745315551758\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016286185011267662\n",
      "          model: {}\n",
      "          policy_loss: 0.004930523689836264\n",
      "          total_loss: 2486.76025390625\n",
      "          vf_explained_var: -8.660504313695583e-09\n",
      "          vf_loss: 2486.748291015625\n",
      "    num_agent_steps_sampled: 2895000\n",
      "    num_agent_steps_trained: 2895000\n",
      "    num_steps_sampled: 2895000\n",
      "    num_steps_trained: 2895000\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.900000000000002\n",
      "    ram_util_percent: 31.404545454545453\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-54-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2757.138908173802\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 965\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.969\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.21944166719913483\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.8928055763244629\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025531597435474396\n",
      "        policy_loss: 0.0036266231909394264\n",
      "        total_loss: 854.1825561523438\n",
      "        vf_explained_var: 0.9065285921096802\n",
      "        vf_loss: 854.1732788085938\n",
      "    load_time_ms: 2.703\n",
      "    num_steps_sampled: 2895000\n",
      "    num_steps_trained: 2890368\n",
      "    sample_time_ms: 28430.832\n",
      "    update_time_ms: 3.078\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.27804878048781\n",
      "    ram_util_percent: 24.921951219512195\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0655992605134187\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4569423855466717\n",
      "    mean_inference_ms: 0.4845792602220189\n",
      "    mean_raw_obs_processing_ms: 3.705826222412885\n",
      "  time_since_restore: 5187.949251413345\n",
      "  time_this_iter_s: 30.75211501121521\n",
      "  time_total_s: 5187.949251413345\n",
      "  timers:\n",
      "    learn_throughput: 6552.694\n",
      "    learn_time_ms: 2289.135\n",
      "    load_throughput: 9403847.361\n",
      "    load_time_ms: 1.595\n",
      "    sample_throughput: 591.401\n",
      "    sample_time_ms: 25363.509\n",
      "    update_time_ms: 1.232\n",
      "  timestamp: 1665250390\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2895000\n",
      "  training_iteration: 193\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    193 |          5187.95 | 2895000 | -1814.84 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2910000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-33-36\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1732.3143566442536\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 970\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.43888333439826965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.2837193012237549\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017918908968567848\n",
      "          model: {}\n",
      "          policy_loss: 0.0030560109298676252\n",
      "          total_loss: 3075.006591796875\n",
      "          vf_explained_var: 1.528324244937096e-09\n",
      "          vf_loss: 3074.99560546875\n",
      "    num_agent_steps_sampled: 2910000\n",
      "    num_agent_steps_trained: 2910000\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2910000\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.975\n",
      "    ram_util_percent: 31.44166666666667\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600312708208804\n",
      "    mean_inference_ms: 0.4150608790647731\n",
      "    mean_processing_ms: 4.171951755599631\n",
      "  time_since_restore: 5713.43232011795\n",
      "  time_this_iter_s: 29.138182878494263\n",
      "  time_total_s: 5713.43232011795\n",
      "  timestamp: 1665276894\n",
      "  timesteps_since_restore: 2895000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2895000\n",
      "  training_iteration: 193\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:54:54,884\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 276.0x the scale of `vf_clip_param`. This means that it will take more than 276.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    193 |          5713.43 |     2895000 | -2757.14 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-55-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2736.776014816758\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 970\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1486.512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.21944166719913483\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.20848050713539124\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.05804290249943733\n",
      "        policy_loss: 0.008949519135057926\n",
      "        total_loss: 1353.9375\n",
      "        vf_explained_var: 0.8919000029563904\n",
      "        vf_loss: 1353.915283203125\n",
      "    load_time_ms: 2.691\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2905344\n",
      "    sample_time_ms: 28352.17\n",
      "    update_time_ms: 3.06\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.52439024390244\n",
      "    ram_util_percent: 24.924390243902437\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06559782637199346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4567840835515913\n",
      "    mean_inference_ms: 0.4845865801797431\n",
      "    mean_raw_obs_processing_ms: 3.7065411352833575\n",
      "  time_since_restore: 5213.186140298843\n",
      "  time_this_iter_s: 25.236888885498047\n",
      "  time_total_s: 5213.186140298843\n",
      "  timers:\n",
      "    learn_throughput: 6589.017\n",
      "    learn_time_ms: 2276.516\n",
      "    load_throughput: 8608644.965\n",
      "    load_time_ms: 1.742\n",
      "    sample_throughput: 602.585\n",
      "    sample_time_ms: 24892.751\n",
      "    update_time_ms: 1.29\n",
      "  timestamp: 1665250416\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 194\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.6003350699794\n",
      "    mean_inference_ms: 0.4150792313824003\n",
      "    mean_processing_ms: 4.172010778018048\n",
      "  time_since_restore: 5742.220996856689\n",
      "  time_this_iter_s: 28.788676738739014\n",
      "  time_total_s: 5742.220996856689\n",
      "  timestamp: 1665276923\n",
      "  timesteps_since_restore: 2910000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 194\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:55:23,720\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 274.0x the scale of `vf_clip_param`. This means that it will take more than 274.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    194 |          5742.22 |     2910000 | -2736.78 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    194 |          5213.19 | 2910000 | -1732.31 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2925000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-34-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1621.6353388072464\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 975\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.43888333439826965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.03558128699660301\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03680453822016716\n",
      "          model: {}\n",
      "          policy_loss: 0.019581902772188187\n",
      "          total_loss: 3275.832275390625\n",
      "          vf_explained_var: -1.2226593959496768e-08\n",
      "          vf_loss: 3275.796630859375\n",
      "    num_agent_steps_sampled: 2925000\n",
      "    num_agent_steps_trained: 2925000\n",
      "    num_steps_sampled: 2925000\n",
      "    num_steps_trained: 2925000\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.317142857142855\n",
      "    ram_util_percent: 31.45142857142857\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-55-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2731.349799802271\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 975\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1487.459\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.32916250824928284\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.06891806423664093\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008932922035455704\n",
      "        policy_loss: 0.0015652332222089171\n",
      "        total_loss: 970.53369140625\n",
      "        vf_explained_var: 0.9288906455039978\n",
      "        vf_loss: 970.529296875\n",
      "    load_time_ms: 2.561\n",
      "    num_steps_sampled: 2925000\n",
      "    num_steps_trained: 2920320\n",
      "    sample_time_ms: 28352.857\n",
      "    update_time_ms: 3.101\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.82380952380952\n",
      "    ram_util_percent: 24.91428571428571\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06559614338062099\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4566342819747815\n",
      "    mean_inference_ms: 0.48459237436296104\n",
      "    mean_raw_obs_processing_ms: 3.7072603241075424\n",
      "  time_since_restore: 5237.970171689987\n",
      "  time_this_iter_s: 24.7840313911438\n",
      "  time_total_s: 5237.970171689987\n",
      "  timers:\n",
      "    learn_throughput: 6750.74\n",
      "    learn_time_ms: 2221.979\n",
      "    load_throughput: 8647930.613\n",
      "    load_time_ms: 1.735\n",
      "    sample_throughput: 603.943\n",
      "    sample_time_ms: 24836.787\n",
      "    update_time_ms: 1.296\n",
      "  timestamp: 1665250440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2925000\n",
      "  training_iteration: 195\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    195 |          5237.97 | 2925000 | -1621.64 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2940000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-34-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1700.4077542516886\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 980\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.43888333439826965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0274029970169067\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03388646990060806\n",
      "          model: {}\n",
      "          policy_loss: 0.017497099936008453\n",
      "          total_loss: 3246.73193359375\n",
      "          vf_explained_var: 9.16994569166718e-09\n",
      "          vf_loss: 3246.699951171875\n",
      "    num_agent_steps_sampled: 2940000\n",
      "    num_agent_steps_trained: 2940000\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2940000\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.1421052631579\n",
      "    ram_util_percent: 31.44736842105263\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600356484641459\n",
      "    mean_inference_ms: 0.4150975704730602\n",
      "    mean_processing_ms: 4.172028477721401\n",
      "  time_since_restore: 5771.54360127449\n",
      "  time_this_iter_s: 29.322604417800903\n",
      "  time_total_s: 5771.54360127449\n",
      "  timestamp: 1665276953\n",
      "  timesteps_since_restore: 2925000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2925000\n",
      "  training_iteration: 195\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:55:53,089\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 273.0x the scale of `vf_clip_param`. This means that it will take more than 273.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    195 |          5771.54 |     2925000 | -2731.35 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-56-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2698.8833979763544\n",
      "  episode_reward_min: -4474.5054057861435\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 980\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1488.025\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.16458125412464142\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.7241774797439575\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.07190393656492233\n",
      "        policy_loss: 0.022564150393009186\n",
      "        total_loss: 1188.767578125\n",
      "        vf_explained_var: 0.8365371823310852\n",
      "        vf_loss: 1188.7332763671875\n",
      "    load_time_ms: 2.589\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2935296\n",
      "    sample_time_ms: 28354.731\n",
      "    update_time_ms: 3.045\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.03333333333334\n",
      "    ram_util_percent: 24.973809523809525\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06559432302835248\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.456462434086763\n",
      "    mean_inference_ms: 0.48459672445110835\n",
      "    mean_raw_obs_processing_ms: 3.7079712081774647\n",
      "  time_since_restore: 5264.428423404694\n",
      "  time_this_iter_s: 26.45825171470642\n",
      "  time_total_s: 5264.428423404694\n",
      "  timers:\n",
      "    learn_throughput: 6626.013\n",
      "    learn_time_ms: 2263.805\n",
      "    load_throughput: 8698266.28\n",
      "    load_time_ms: 1.724\n",
      "    sample_throughput: 602.424\n",
      "    sample_time_ms: 24899.409\n",
      "    update_time_ms: 1.283\n",
      "  timestamp: 1665250467\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 196\n",
      "  trial_id: 26f87_00000\n",
      "  \n"
=======
      "    mean_env_wait_ms: 4.6003497208209225\n",
      "    mean_inference_ms: 0.41511560092936667\n",
      "    mean_processing_ms: 4.172044604467548\n",
      "  time_since_restore: 5800.982078552246\n",
      "  time_this_iter_s: 29.438477277755737\n",
      "  time_total_s: 5800.982078552246\n",
      "  timestamp: 1665276982\n",
      "  timesteps_since_restore: 2940000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 196\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:56:22,572\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 270.0x the scale of `vf_clip_param`. This means that it will take more than 270.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    196 |          5800.98 |     2940000 | -2698.88 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    196 |          5264.43 | 2940000 | -1700.41 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2955000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-34-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1701.733416155227\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 985\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.43888333439826965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.101831316947937\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026008564978837967\n",
      "          model: {}\n",
      "          policy_loss: 0.012180950492620468\n",
      "          total_loss: 3416.670166015625\n",
      "          vf_explained_var: -5.603855601776786e-09\n",
      "          vf_loss: 3416.646728515625\n",
      "    num_agent_steps_sampled: 2955000\n",
      "    num_agent_steps_trained: 2955000\n",
      "    num_steps_sampled: 2955000\n",
      "    num_steps_trained: 2955000\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.505128205128205\n",
      "    ram_util_percent: 31.45897435897435\n",
      "  pid: 307\n",
=======
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-56-52\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2723.524393307351\n",
      "  episode_reward_min: -4864.129066137782\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 985\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1490.005\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.24687188863754272\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.8173016309738159\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.028134247288107872\n",
      "        policy_loss: 0.0063261487521231174\n",
      "        total_loss: 1321.5992431640625\n",
      "        vf_explained_var: 0.9388377070426941\n",
      "        vf_loss: 1321.586181640625\n",
      "    load_time_ms: 2.56\n",
      "    num_steps_sampled: 2955000\n",
      "    num_steps_trained: 2950272\n",
      "    sample_time_ms: 28350.114\n",
      "    update_time_ms: 3.074\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.78333333333333\n",
      "    ram_util_percent: 24.91190476190476\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06559265360729748\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4562961545618047\n",
      "    mean_inference_ms: 0.4846015888635771\n",
      "    mean_raw_obs_processing_ms: 3.708876388414558\n",
      "  time_since_restore: 5291.765627622604\n",
      "  time_this_iter_s: 27.337204217910767\n",
      "  time_total_s: 5291.765627622604\n",
      "  timers:\n",
      "    learn_throughput: 6762.436\n",
      "    learn_time_ms: 2218.136\n",
      "    load_throughput: 9133672.077\n",
      "    load_time_ms: 1.642\n",
      "    sample_throughput: 596.66\n",
      "    sample_time_ms: 25139.944\n",
      "    update_time_ms: 1.133\n",
      "  timestamp: 1665250494\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2955000\n",
      "  training_iteration: 197\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.9/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    197 |          5291.77 | 2955000 | -1701.73 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2970000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-35-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2870.2741277451596\n",
      "  episode_reward_mean: -1656.8912028058328\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 990\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.43888333439826965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.08872649818658829\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019915636628866196\n",
      "          model: {}\n",
      "          policy_loss: 0.01001968327909708\n",
      "          total_loss: 3140.817626953125\n",
      "          vf_explained_var: -1.2226593959496768e-08\n",
      "          vf_loss: 3140.798583984375\n",
      "    num_agent_steps_sampled: 2970000\n",
      "    num_agent_steps_trained: 2970000\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2970000\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.586956521739133\n",
      "    ram_util_percent: 31.484782608695657\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600333274985896\n",
      "    mean_inference_ms: 0.4151329317550166\n",
      "    mean_processing_ms: 4.172083826839593\n",
      "  time_since_restore: 5830.401330947876\n",
      "  time_this_iter_s: 29.419252395629883\n",
      "  time_total_s: 5830.401330947876\n",
      "  timestamp: 1665277012\n",
      "  timesteps_since_restore: 2955000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2955000\n",
      "  training_iteration: 197\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:56:52,040\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 272.0x the scale of `vf_clip_param`. This means that it will take more than 272.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    197 |           5830.4 |     2955000 | -2723.52 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-57-21\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1204.8921368139615\n",
      "  episode_reward_mean: -2711.553457120202\n",
      "  episode_reward_min: -4864.129066137782\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 990\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1491.865\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.24687188863754272\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1674611121416092\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013069824315607548\n",
      "        policy_loss: 0.0024218023754656315\n",
      "        total_loss: 1397.3636474609375\n",
      "        vf_explained_var: 0.8998199701309204\n",
      "        vf_loss: 1397.358154296875\n",
      "    load_time_ms: 2.536\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2965248\n",
      "    sample_time_ms: 28342.85\n",
      "    update_time_ms: 3.104\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.65581395348838\n",
      "    ram_util_percent: 24.94651162790698\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06559106447970821\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.456130395070959\n",
      "    mean_inference_ms: 0.4846073145917336\n",
      "    mean_raw_obs_processing_ms: 3.7097476435982513\n",
      "  time_since_restore: 5323.297960281372\n",
      "  time_this_iter_s: 31.5323326587677\n",
      "  time_total_s: 5323.297960281372\n",
      "  timers:\n",
      "    learn_throughput: 6785.466\n",
      "    learn_time_ms: 2210.607\n",
      "    load_throughput: 8974076.768\n",
      "    load_time_ms: 1.671\n",
      "    sample_throughput: 584.161\n",
      "    sample_time_ms: 25677.837\n",
      "    update_time_ms: 1.148\n",
      "  timestamp: 1665250526\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 198\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    198 |           5323.3 | 2970000 | -1656.89 |              2870.27 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 2985000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-35-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2165.524982355543\n",
      "  episode_reward_mean: -1733.3122655874276\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 995\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.43888333439826965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.9048187732696533\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02826649695634842\n",
      "          model: {}\n",
      "          policy_loss: 0.019324542954564095\n",
      "          total_loss: 3916.050537109375\n",
      "          vf_explained_var: -5.603855601776786e-09\n",
      "          vf_loss: 3916.018798828125\n",
      "    num_agent_steps_sampled: 2985000\n",
      "    num_agent_steps_trained: 2985000\n",
      "    num_steps_sampled: 2985000\n",
      "    num_steps_trained: 2985000\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.726315789473684\n",
      "    ram_util_percent: 31.489473684210523\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600297466269579\n",
      "    mean_inference_ms: 0.41514842664056606\n",
      "    mean_processing_ms: 4.172136514037383\n",
      "  time_since_restore: 5859.925055980682\n",
      "  time_this_iter_s: 29.523725032806396\n",
      "  time_total_s: 5859.925055980682\n",
      "  timestamp: 1665277041\n",
      "  timesteps_since_restore: 2970000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 198\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:57:21,611\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 271.0x the scale of `vf_clip_param`. This means that it will take more than 271.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    198 |          5859.93 |     2970000 | -2711.55 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-57-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1086.908541912825\n",
      "  episode_reward_mean: -2677.1728743147796\n",
      "  episode_reward_min: -4864.129066137782\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 995\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1492.329\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.24687188863754272\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: -0.26606693863868713\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.1147492453455925\n",
      "        policy_loss: 0.012722477316856384\n",
      "        total_loss: 1280.7760009765625\n",
      "        vf_explained_var: 0.8874762058258057\n",
      "        vf_loss: 1280.73486328125\n",
      "    load_time_ms: 2.366\n",
      "    num_steps_sampled: 2985000\n",
      "    num_steps_trained: 2980224\n",
      "    sample_time_ms: 28414.594\n",
      "    update_time_ms: 3.196\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 33.70238095238095\n",
      "    ram_util_percent: 24.969047619047622\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.06558969050938518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4559582585053126\n",
      "    mean_inference_ms: 0.484615050244187\n",
      "    mean_raw_obs_processing_ms: 3.710704583811006\n",
      "  time_since_restore: 5349.910170078278\n",
      "  time_this_iter_s: 26.612209796905518\n",
      "  time_total_s: 5349.910170078278\n",
      "  timers:\n",
      "    learn_throughput: 6757.318\n",
      "    learn_time_ms: 2219.816\n",
      "    load_throughput: 8799854.535\n",
      "    load_time_ms: 1.705\n",
      "    sample_throughput: 607.188\n",
      "    sample_time_ms: 24704.047\n",
      "    update_time_ms: 1.221\n",
      "  timestamp: 1665250553\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2985000\n",
      "  training_iteration: 199\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    199 |          5349.91 | 2985000 | -1733.31 |              2165.52 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Could not connect to TraCI server at localhost:34795 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m Could not connect to TraCI server at localhost:34447 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m Could not connect to TraCI server at localhost:57509 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m Could not connect to TraCI server at localhost:54035 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=303)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Could not connect to TraCI server at localhost:36289 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=305)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=308)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_26f87_00000:\n",
      "  agent_timesteps_total: 3000000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_12-36-25\n",
      "  done: true\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2165.524982355543\n",
      "  episode_reward_mean: -1735.6408919515138\n",
      "  episode_reward_min: -8340.588520434227\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 1000\n",
      "  experiment_id: edcbe001b14143f4bf76a6a2914a7bd0\n",
      "  hostname: michael\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.43888333439826965\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: -0.3036324381828308\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025970499962568283\n",
      "          model: {}\n",
      "          policy_loss: 0.012625528499484062\n",
      "          total_loss: 3255.02099609375\n",
      "          vf_explained_var: -8.660504313695583e-09\n",
      "          vf_loss: 3254.997314453125\n",
      "    num_agent_steps_sampled: 3000000\n",
      "    num_agent_steps_trained: 3000000\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 3000000\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 141.225.10.229\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.546666666666663\n",
      "    ram_util_percent: 31.415555555555557\n",
      "  pid: 307\n",
=======
      "    mean_env_wait_ms: 4.600296382745667\n",
      "    mean_inference_ms: 0.4151586884383201\n",
      "    mean_processing_ms: 4.17219015677569\n",
      "  time_since_restore: 5889.494956254959\n",
      "  time_this_iter_s: 29.569900274276733\n",
      "  time_total_s: 5889.494956254959\n",
      "  timestamp: 1665277071\n",
      "  timesteps_since_restore: 2985000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 2985000\n",
      "  training_iteration: 199\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:57:51,233\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 268.0x the scale of `vf_clip_param`. This means that it will take more than 268.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status   | loc                |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+----------+--------------------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | RUNNING  | 192.168.1.65:25636 |    199 |          5889.49 |     2985000 | -2677.17 |\n",
      "+--------------------------------------+----------+--------------------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=25633)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=25634)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_a95f16f0:\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-08_19-58-20\n",
      "  done: true\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_reward_max: -1086.908541912825\n",
      "  episode_reward_mean: -2682.8721921558877\n",
      "  episode_reward_min: -4864.129066137782\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 1000\n",
      "  experiment_id: 715cdcf517784523a0486b0bfe573bc1\n",
      "  experiment_tag: '0'\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    grad_time_ms: 1490.493\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.3703078329563141\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.7362141609191895\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0041462150402367115\n",
      "        policy_loss: -0.0002459384559188038\n",
      "        total_loss: 1239.998046875\n",
      "        vf_explained_var: 0.9404228925704956\n",
      "        vf_loss: 1239.9969482421875\n",
      "    load_time_ms: 2.375\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 2995200\n",
      "    sample_time_ms: 27833.434\n",
      "    update_time_ms: 3.164\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.84285714285714\n",
      "    ram_util_percent: 25.059523809523803\n",
      "  pid: 25636\n",
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
<<<<<<< HEAD
      "    mean_action_processing_ms: 0.0655884929100469\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 3.4558032417542233\n",
      "    mean_inference_ms: 0.4846243018580486\n",
      "    mean_raw_obs_processing_ms: 3.7121980799596206\n",
      "  time_since_restore: 5381.739073514938\n",
      "  time_this_iter_s: 31.828903436660767\n",
      "  time_total_s: 5381.739073514938\n",
      "  timers:\n",
      "    learn_throughput: 6724.942\n",
      "    learn_time_ms: 2230.503\n",
      "    load_throughput: 8842524.245\n",
      "    load_time_ms: 1.696\n",
      "    sample_throughput: 592.368\n",
      "    sample_time_ms: 25322.112\n",
      "    update_time_ms: 1.228\n",
      "  timestamp: 1665250585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 200\n",
      "  trial_id: 26f87_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status   | loc                |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | RUNNING  | 141.225.10.229:307 |    200 |          5381.74 | 3000000 | -1735.64 |              2165.52 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+----------+--------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 9.8/31.2 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/7.23 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_0_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_1_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_3_25daa8673b2c24aecf80a7fc79df4e93, 0.0/6.0 CPU_group_25daa8673b2c24aecf80a7fc79df4e93, 0.0/1.0 CPU_group_4_25daa8673b2c24aecf80a7fc79df4e93)\n",
      "Result logdir: /home/michael-lab/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+-----------------------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_26f87_00000 | TERMINATED |       |    200 |          5381.74 | 3000000 | -1735.64 |              2165.52 |             -8340.59 |               3000 |\n",
      "+-----------------------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m 2022-10-08 12:36:26,117\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1027, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1103, in exit_actor\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 167, in format_exc\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 121, in format_exception\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m     type(value), value, tb, limit=limit).format(chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 508, in __init__\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m     capture_locals=capture_locals)\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 359, in extract\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m     linecache.checkcache(filename)\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/linecache.py\", line 74, in checkcache\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m     stat = os.stat(fullname)\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=301)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m 2022-10-08 12:36:26,118\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1027, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1103, in exit_actor\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 42, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/json/__init__.py\", line 183, in dumps\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m     def dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True,\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m   File \"/home/michael-lab/anaconda3/envs/flow/lib/python3.7/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=304)\u001b[0m SystemExit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-08 12:36:26,228\tINFO tune.py:550 -- Total run time: 5404.09 seconds (5403.26 seconds for the tuning loop).\n",
      "\u001b[0m"
=======
      "    mean_env_wait_ms: 4.600286435432724\n",
      "    mean_inference_ms: 0.41516980309590024\n",
      "    mean_processing_ms: 4.17224885766545\n",
      "  time_since_restore: 5918.953051567078\n",
      "  time_this_iter_s: 29.45809531211853\n",
      "  time_total_s: 5918.953051567078\n",
      "  timestamp: 1665277100\n",
      "  timesteps_since_restore: 3000000\n",
      "  timesteps_this_iter: 15000\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 200\n",
      "  trial_id: a95f16f0\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25636)\u001b[0m 2022-10-08 19:58:20,746\tWARNING ppo.py:144 -- The magnitude of your environment rewards are more than 268.0x the scale of `vf_clip_param`. This means that it will take more than 268.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 TERMINATED)\n",
      "+--------------------------------------+------------+-------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status     | loc   |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+------------+-------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | TERMINATED |       |    200 |          5918.95 |     3000000 | -2682.87 |\n",
      "+--------------------------------------+------------+-------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/3.47 GiB heap, 0.0/10.11 GiB objects\n",
      "Result logdir: /home/michael/ray_results/singleagent_onelane_ring\n",
      "Number of trials: 1 (1 TERMINATED)\n",
      "+--------------------------------------+------------+-------+--------+------------------+-------------+----------+\n",
      "| Trial name                           | status     | loc   |   iter |   total time (s) |   timesteps |   reward |\n",
      "|--------------------------------------+------------+-------+--------+------------------+-------------+----------|\n",
      "| PPO_WaveAttenuationPOEnv-v0_a95f16f0 | TERMINATED |       |    200 |          5918.95 |     3000000 | -2682.87 |\n",
      "+--------------------------------------+------------+-------+--------+------------------+-------------+----------+\n",
      "\n",
      "\n"
>>>>>>> 45ba339a35ad2740fb9ec6babd1e5d31fe54e2af
>>>>>>> 880e1f0d2279beb47f60394537ff7c97daa2a155
     ]
    }
   ],
   "source": [
    "!python examples/train.py singleagent_ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e948b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
