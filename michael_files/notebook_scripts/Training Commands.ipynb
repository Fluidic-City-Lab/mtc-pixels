{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c260093",
   "metadata": {},
   "source": [
    "## Training Single Agent Ring Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ee1510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_workers': 5, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'gamma': 0.999, 'lr': 5e-05, 'train_batch_size': 15000, 'model': {'_use_default_native_models': False, 'fcnet_hiddens': [32, 32], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'horizon': 3000, 'soft_horizon': False, 'no_done_at_end': False, 'env': None, 'observation_space': None, 'action_space': None, 'env_config': {}, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'simple_optimizer': -1, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.97, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.02, 'vf_share_layers': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 23:32:13,271\tINFO services.py:1247 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:32:15,388\tINFO trainer.py:720 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:32:18,103\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 15000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-33-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -3738.0171886967387\n",
      "  episode_reward_mean: -4725.603758890785\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 5\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3737782322754295\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0027361586594235317\n",
      "          policy_loss: -0.0024126092086435625\n",
      "          total_loss: 1971.826986332263\n",
      "          vf_explained_var: 0.008343493565917015\n",
      "          vf_loss: 1971.8288463527874\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 15000\n",
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 15000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.155737704918028\n",
      "    ram_util_percent: 19.31967213114755\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05379749591729514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 8.091445987679807\n",
      "    mean_inference_ms: 0.5027835665445095\n",
      "    mean_raw_obs_processing_ms: 4.096167820844997\n",
      "  time_since_restore: 42.12859654426575\n",
      "  time_this_iter_s: 42.12859654426575\n",
      "  time_total_s: 42.12859654426575\n",
      "  timers:\n",
      "    learn_throughput: 5886.333\n",
      "    learn_time_ms: 2548.276\n",
      "    sample_throughput: 379.03\n",
      "    sample_time_ms: 39574.745\n",
      "    update_time_ms: 1.37\n",
      "  timestamp: 1674279180\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 1\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         42.1286</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\"> -4725.6</td><td style=\"text-align: right;\">            -3738.02</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:33:00,232\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 473.0x the scale of `vf_clip_param`. This means that it will take more than 473.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-33-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -3738.0171886967387\n",
      "  episode_reward_mean: -4569.027290918233\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 10\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.296177717386666\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005201871571811761\n",
      "          policy_loss: -0.003392327988472909\n",
      "          total_loss: 1669.9544300144003\n",
      "          vf_explained_var: 0.004470540210604668\n",
      "          vf_loss: 1669.9572990805416\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.741860465116282\n",
      "    ram_util_percent: 19.367441860465114\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053897568213458626\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 7.150749238003575\n",
      "    mean_inference_ms: 0.5120038623249566\n",
      "    mean_raw_obs_processing_ms: 4.121075915029346\n",
      "  time_since_restore: 72.80967259407043\n",
      "  time_this_iter_s: 30.681076049804688\n",
      "  time_total_s: 72.80967259407043\n",
      "  timers:\n",
      "    learn_throughput: 5879.356\n",
      "    learn_time_ms: 2551.3\n",
      "    sample_throughput: 443.163\n",
      "    sample_time_ms: 33847.597\n",
      "    update_time_ms: 1.284\n",
      "  timestamp: 1674279210\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 2\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         72.8097</td><td style=\"text-align: right;\">30000</td><td style=\"text-align: right;\">-4569.03</td><td style=\"text-align: right;\">            -3738.02</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:33:30,950\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 457.0x the scale of `vf_clip_param`. This means that it will take more than 457.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 45000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-34-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -3738.0171886967387\n",
      "  episode_reward_mean: -4519.0942197868735\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 15\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2087461597838645\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008977885731242124\n",
      "          policy_loss: -0.0057410641490497575\n",
      "          total_loss: 1657.908419541181\n",
      "          vf_explained_var: 0.0019592661410570145\n",
      "          vf_loss: 1657.913712013374\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 45000\n",
      "    num_steps_sampled: 45000\n",
      "    num_steps_trained: 45000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.788636363636364\n",
      "    ram_util_percent: 19.36590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05394693536312699\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 6.618499190847695\n",
      "    mean_inference_ms: 0.5136059284321968\n",
      "    mean_raw_obs_processing_ms: 4.132741119926603\n",
      "  time_since_restore: 103.14651942253113\n",
      "  time_this_iter_s: 30.336846828460693\n",
      "  time_total_s: 103.14651942253113\n",
      "  timers:\n",
      "    learn_throughput: 5889.695\n",
      "    learn_time_ms: 2546.821\n",
      "    sample_throughput: 471.263\n",
      "    sample_time_ms: 31829.355\n",
      "    update_time_ms: 1.289\n",
      "  timestamp: 1674279241\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45000\n",
      "  training_iteration: 3\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:34:01,321\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 452.0x the scale of `vf_clip_param`. This means that it will take more than 452.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         103.147</td><td style=\"text-align: right;\">45000</td><td style=\"text-align: right;\">-4519.09</td><td style=\"text-align: right;\">            -3738.02</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-34-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2827.226827674596\n",
      "  episode_reward_mean: -4329.926150036985\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 20\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1412708385516022\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00752166588417521\n",
      "          policy_loss: -0.004228041105374883\n",
      "          total_loss: 1218.843259753211\n",
      "          vf_explained_var: 0.004099843092262745\n",
      "          vf_loss: 1218.8473007460773\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.302325581395348\n",
      "    ram_util_percent: 19.37209302325581\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0539373376732206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 6.269461835243154\n",
      "    mean_inference_ms: 0.5134961079794613\n",
      "    mean_raw_obs_processing_ms: 4.133506392230916\n",
      "  time_since_restore: 133.5378794670105\n",
      "  time_this_iter_s: 30.39136004447937\n",
      "  time_total_s: 133.5378794670105\n",
      "  timers:\n",
      "    learn_throughput: 5914.598\n",
      "    learn_time_ms: 2536.098\n",
      "    sample_throughput: 486.34\n",
      "    sample_time_ms: 30842.624\n",
      "    update_time_ms: 1.195\n",
      "  timestamp: 1674279271\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 4\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         133.538</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-4329.93</td><td style=\"text-align: right;\">            -2827.23</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:34:31,746\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 433.0x the scale of `vf_clip_param`. This means that it will take more than 433.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 75000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-35-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2827.226827674596\n",
      "  episode_reward_mean: -4207.12621258186\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 25\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.9496640791327267\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014688383409274811\n",
      "          policy_loss: -0.006583077420669971\n",
      "          total_loss: 1191.0557134595967\n",
      "          vf_explained_var: -0.0003191368014086038\n",
      "          vf_loss: 1191.0621153750662\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 75000\n",
      "    num_steps_sampled: 75000\n",
      "    num_steps_trained: 75000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.56279069767442\n",
      "    ram_util_percent: 19.37674418604651\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053921057322695844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 6.020814427343039\n",
      "    mean_inference_ms: 0.5130181237736919\n",
      "    mean_raw_obs_processing_ms: 4.126894366516802\n",
      "  time_since_restore: 163.20009922981262\n",
      "  time_this_iter_s: 29.662219762802124\n",
      "  time_total_s: 163.20009922981262\n",
      "  timers:\n",
      "    learn_throughput: 6007.123\n",
      "    learn_time_ms: 2497.036\n",
      "    sample_throughput: 497.719\n",
      "    sample_time_ms: 30137.475\n",
      "    update_time_ms: 1.114\n",
      "  timestamp: 1674279301\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 75000\n",
      "  training_iteration: 5\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:35:01,437\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 421.0x the scale of `vf_clip_param`. This means that it will take more than 421.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">           163.2</td><td style=\"text-align: right;\">75000</td><td style=\"text-align: right;\">-4207.13</td><td style=\"text-align: right;\">            -2827.23</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 90000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-35-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2827.226827674596\n",
      "  episode_reward_mean: -4098.42353300313\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 30\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.847256989751832\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018275870517164613\n",
      "          policy_loss: -0.007658488007846399\n",
      "          total_loss: 1064.6882085767843\n",
      "          vf_explained_var: -0.0010206830920651555\n",
      "          vf_loss: 1064.6956391932601\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.70714285714286\n",
      "    ram_util_percent: 19.373809523809523\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05392033178299779\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.832218429060555\n",
      "    mean_inference_ms: 0.5126518179750064\n",
      "    mean_raw_obs_processing_ms: 4.11925758819132\n",
      "  time_since_restore: 193.26353549957275\n",
      "  time_this_iter_s: 30.063436269760132\n",
      "  time_total_s: 193.26353549957275\n",
      "  timers:\n",
      "    learn_throughput: 5984.621\n",
      "    learn_time_ms: 2506.424\n",
      "    sample_throughput: 505.075\n",
      "    sample_time_ms: 29698.582\n",
      "    update_time_ms: 1.14\n",
      "  timestamp: 1674279331\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 6\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         193.264</td><td style=\"text-align: right;\">90000</td><td style=\"text-align: right;\">-4098.42</td><td style=\"text-align: right;\">            -2827.23</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:35:31,535\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 410.0x the scale of `vf_clip_param`. This means that it will take more than 410.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 105000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-36-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2827.226827674596\n",
      "  episode_reward_mean: -3970.394967806207\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 35\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.6614721160824016\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02890827503853266\n",
      "          policy_loss: -0.011315220672542514\n",
      "          total_loss: 853.1309696520789\n",
      "          vf_explained_var: -0.001004410325549543\n",
      "          vf_loss: 853.1419234970869\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 105000\n",
      "    num_steps_sampled: 105000\n",
      "    num_steps_trained: 105000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.14186046511627\n",
      "    ram_util_percent: 19.37906976744186\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05392300699246227\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.682670667326408\n",
      "    mean_inference_ms: 0.5123164270082636\n",
      "    mean_raw_obs_processing_ms: 4.11159400349909\n",
      "  time_since_restore: 222.96529173851013\n",
      "  time_this_iter_s: 29.701756238937378\n",
      "  time_total_s: 222.96529173851013\n",
      "  timers:\n",
      "    learn_throughput: 5981.547\n",
      "    learn_time_ms: 2507.713\n",
      "    sample_throughput: 511.265\n",
      "    sample_time_ms: 29338.99\n",
      "    update_time_ms: 1.102\n",
      "  timestamp: 1674279361\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 105000\n",
      "  training_iteration: 7\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:36:01,273\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 397.0x the scale of `vf_clip_param`. This means that it will take more than 397.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         222.965</td><td style=\"text-align: right;\">105000</td><td style=\"text-align: right;\">-3970.39</td><td style=\"text-align: right;\">            -2827.23</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 120000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-36-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2256.3357051423213\n",
      "  episode_reward_mean: -3813.0354799591937\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 40\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.5332000706407983\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01888525239653711\n",
      "          policy_loss: -0.007902120294096737\n",
      "          total_loss: 613.8586910700394\n",
      "          vf_explained_var: -0.000944085419178009\n",
      "          vf_loss: 613.8663571632515\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.670454545454547\n",
      "    ram_util_percent: 19.36590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053927756560088615\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.560993363402386\n",
      "    mean_inference_ms: 0.512035085003325\n",
      "    mean_raw_obs_processing_ms: 4.111214648803365\n",
      "  time_since_restore: 254.04330563545227\n",
      "  time_this_iter_s: 31.07801389694214\n",
      "  time_total_s: 254.04330563545227\n",
      "  timers:\n",
      "    learn_throughput: 5995.592\n",
      "    learn_time_ms: 2501.838\n",
      "    sample_throughput: 512.853\n",
      "    sample_time_ms: 29248.128\n",
      "    update_time_ms: 1.105\n",
      "  timestamp: 1674279392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 8\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         254.043</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-3813.04</td><td style=\"text-align: right;\">            -2256.34</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:36:32,386\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 381.0x the scale of `vf_clip_param`. This means that it will take more than 381.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 135000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-37-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1292.8405779453435\n",
      "  episode_reward_mean: -3584.507625150626\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 45\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.4529455253128278\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021716353399250377\n",
      "          policy_loss: -0.011210672037233993\n",
      "          total_loss: 277.3259386353574\n",
      "          vf_explained_var: -0.000732254353351891\n",
      "          vf_loss: 277.33687872159277\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 135000\n",
      "    num_steps_sampled: 135000\n",
      "    num_steps_trained: 135000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.936363636363637\n",
      "    ram_util_percent: 19.36590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053933732378171444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.461372101383348\n",
      "    mean_inference_ms: 0.5117837636784084\n",
      "    mean_raw_obs_processing_ms: 4.1102652180479655\n",
      "  time_since_restore: 284.4703860282898\n",
      "  time_this_iter_s: 30.427080392837524\n",
      "  time_total_s: 284.4703860282898\n",
      "  timers:\n",
      "    learn_throughput: 5986.097\n",
      "    learn_time_ms: 2505.806\n",
      "    sample_throughput: 515.525\n",
      "    sample_time_ms: 29096.57\n",
      "    update_time_ms: 1.153\n",
      "  timestamp: 1674279422\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 135000\n",
      "  training_iteration: 9\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">          284.47</td><td style=\"text-align: right;\">135000</td><td style=\"text-align: right;\">-3584.51</td><td style=\"text-align: right;\">            -1292.84</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:37:02,852\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 358.0x the scale of `vf_clip_param`. This means that it will take more than 358.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 150000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-37-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1160.5759752772901\n",
      "  episode_reward_mean: -3390.7006821952527\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 50\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.30799649771997484\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017778793557491703\n",
      "          policy_loss: -0.009159083465425991\n",
      "          total_loss: 232.64549220456917\n",
      "          vf_explained_var: -0.0004040604399051517\n",
      "          vf_loss: 232.6544300531937\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 150000\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.938636363636366\n",
      "    ram_util_percent: 19.36363636363636\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05394115513590567\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.377368773529249\n",
      "    mean_inference_ms: 0.5115615695860286\n",
      "    mean_raw_obs_processing_ms: 4.11095549275731\n",
      "  time_since_restore: 315.51004695892334\n",
      "  time_this_iter_s: 31.039660930633545\n",
      "  time_total_s: 315.51004695892334\n",
      "  timers:\n",
      "    learn_throughput: 5975.499\n",
      "    learn_time_ms: 2510.251\n",
      "    sample_throughput: 516.613\n",
      "    sample_time_ms: 29035.267\n",
      "    update_time_ms: 1.18\n",
      "  timestamp: 1674279453\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 10\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">          315.51</td><td style=\"text-align: right;\">150000</td><td style=\"text-align: right;\"> -3390.7</td><td style=\"text-align: right;\">            -1160.58</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:37:33,922\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 339.0x the scale of `vf_clip_param`. This means that it will take more than 339.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 165000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-38-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -407.72056742089086\n",
      "  episode_reward_mean: -3157.365108239535\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 55\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.13012132241816843\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030904726650346652\n",
      "          policy_loss: -0.013214643618833842\n",
      "          total_loss: 76.55091247558593\n",
      "          vf_explained_var: -0.0002353509044041857\n",
      "          vf_loss: 76.56374078201036\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 165000\n",
      "    num_steps_sampled: 165000\n",
      "    num_steps_trained: 165000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.776744186046507\n",
      "    ram_util_percent: 19.23720930232558\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05394540573031154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.30634153359794\n",
      "    mean_inference_ms: 0.5113510908576793\n",
      "    mean_raw_obs_processing_ms: 4.110922256105459\n",
      "  time_since_restore: 345.4650526046753\n",
      "  time_this_iter_s: 29.955005645751953\n",
      "  time_total_s: 345.4650526046753\n",
      "  timers:\n",
      "    learn_throughput: 6104.247\n",
      "    learn_time_ms: 2457.305\n",
      "    sample_throughput: 538.195\n",
      "    sample_time_ms: 27870.929\n",
      "    update_time_ms: 1.128\n",
      "  timestamp: 1674279483\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 165000\n",
      "  training_iteration: 11\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:38:03,909\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 316.0x the scale of `vf_clip_param`. This means that it will take more than 316.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         345.465</td><td style=\"text-align: right;\">165000</td><td style=\"text-align: right;\">-3157.37</td><td style=\"text-align: right;\">            -407.721</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-38-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -407.72056742089086\n",
      "  episode_reward_mean: -2973.041683908218\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 60\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.01590872664602426\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018917569460243467\n",
      "          policy_loss: -0.008581774108609089\n",
      "          total_loss: 74.15488620046843\n",
      "          vf_explained_var: 3.278629083069973e-05\n",
      "          vf_loss: 74.16323161690921\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.237209302325578\n",
      "    ram_util_percent: 18.818604651162786\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05394833379297185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.244416884567763\n",
      "    mean_inference_ms: 0.5112029188805984\n",
      "    mean_raw_obs_processing_ms: 4.11045308990347\n",
      "  time_since_restore: 375.56290197372437\n",
      "  time_this_iter_s: 30.097849369049072\n",
      "  time_total_s: 375.56290197372437\n",
      "  timers:\n",
      "    learn_throughput: 6110.136\n",
      "    learn_time_ms: 2454.937\n",
      "    sample_throughput: 539.275\n",
      "    sample_time_ms: 27815.136\n",
      "    update_time_ms: 1.095\n",
      "  timestamp: 1674279514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 12\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         375.563</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">-2973.04</td><td style=\"text-align: right;\">            -407.721</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:38:34,049\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 297.0x the scale of `vf_clip_param`. This means that it will take more than 297.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 195000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-39-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -407.72056742089086\n",
      "  episode_reward_mean: -2802.2494600341142\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 65\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.20204150080049443\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012691410320359364\n",
      "          policy_loss: -0.0058819515136331\n",
      "          total_loss: 54.70786951356015\n",
      "          vf_explained_var: -9.783738641999662e-05\n",
      "          vf_loss: 54.71359282671395\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 195000\n",
      "    num_steps_sampled: 195000\n",
      "    num_steps_trained: 195000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.77906976744186\n",
      "    ram_util_percent: 18.7953488372093\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05394915038983605\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.189913606050197\n",
      "    mean_inference_ms: 0.5112005039119125\n",
      "    mean_raw_obs_processing_ms: 4.111158559291128\n",
      "  time_since_restore: 406.04723167419434\n",
      "  time_this_iter_s: 30.48432970046997\n",
      "  time_total_s: 406.04723167419434\n",
      "  timers:\n",
      "    learn_throughput: 6120.457\n",
      "    learn_time_ms: 2450.797\n",
      "    sample_throughput: 538.907\n",
      "    sample_time_ms: 27834.131\n",
      "    update_time_ms: 1.051\n",
      "  timestamp: 1674279544\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 195000\n",
      "  training_iteration: 13\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         406.047</td><td style=\"text-align: right;\">195000</td><td style=\"text-align: right;\">-2802.25</td><td style=\"text-align: right;\">            -407.721</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:39:04,569\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 280.0x the scale of `vf_clip_param`. This means that it will take more than 280.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 210000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-39-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 627.1269889812006\n",
      "  episode_reward_mean: -2594.852382103886\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 70\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.17573015928205293\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015208790098193103\n",
      "          policy_loss: -0.006435967958729588\n",
      "          total_loss: 48.2788735082594\n",
      "          vf_explained_var: -2.112413858412765e-05\n",
      "          vf_loss: 48.28511936381712\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 210000\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.451923076923077\n",
      "    ram_util_percent: 18.832692307692305\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05394830570883322\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.142277971798919\n",
      "    mean_inference_ms: 0.5111590475972944\n",
      "    mean_raw_obs_processing_ms: 4.120844960793231\n",
      "  time_since_restore: 441.88808393478394\n",
      "  time_this_iter_s: 35.8408522605896\n",
      "  time_total_s: 441.88808393478394\n",
      "  timers:\n",
      "    learn_throughput: 6126.061\n",
      "    learn_time_ms: 2448.555\n",
      "    sample_throughput: 528.517\n",
      "    sample_time_ms: 28381.312\n",
      "    update_time_ms: 1.047\n",
      "  timestamp: 1674279580\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 14\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:39:40,445\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 259.0x the scale of `vf_clip_param`. This means that it will take more than 259.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         441.888</td><td style=\"text-align: right;\">210000</td><td style=\"text-align: right;\">-2594.85</td><td style=\"text-align: right;\">             627.127</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 225000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-40-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 627.1269889812006\n",
      "  episode_reward_mean: -2424.9660944246075\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 75\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.28467683967644886\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010400176757860998\n",
      "          policy_loss: -0.004290935983368337\n",
      "          total_loss: 42.4819844051943\n",
      "          vf_explained_var: 0.00013708937331102788\n",
      "          vf_loss: 42.48614541878135\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 225000\n",
      "    num_steps_sampled: 225000\n",
      "    num_steps_trained: 225000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.985714285714288\n",
      "    ram_util_percent: 18.876190476190477\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053945898397008835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.099678137601377\n",
      "    mean_inference_ms: 0.5110929275536694\n",
      "    mean_raw_obs_processing_ms: 4.127868542908528\n",
      "  time_since_restore: 471.5914714336395\n",
      "  time_this_iter_s: 29.70338749885559\n",
      "  time_total_s: 471.5914714336395\n",
      "  timers:\n",
      "    learn_throughput: 6074.816\n",
      "    learn_time_ms: 2469.21\n",
      "    sample_throughput: 528.825\n",
      "    sample_time_ms: 28364.761\n",
      "    update_time_ms: 1.067\n",
      "  timestamp: 1674279610\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 225000\n",
      "  training_iteration: 15\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:40:10,191\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 242.0x the scale of `vf_clip_param`. This means that it will take more than 242.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         471.591</td><td style=\"text-align: right;\">225000</td><td style=\"text-align: right;\">-2424.97</td><td style=\"text-align: right;\">             627.127</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 240000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-40-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 657.3880985800384\n",
      "  episode_reward_mean: -2258.3087870403783\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 80\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.3715194392002235\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009126997619742056\n",
      "          policy_loss: -0.00398613084186563\n",
      "          total_loss: 50.604453604100115\n",
      "          vf_explained_var: 0.02371157705783844\n",
      "          vf_loss: 50.60832583378937\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 240000\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.637209302325584\n",
      "    ram_util_percent: 18.87674418604651\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053944845297341434\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.061574439331386\n",
      "    mean_inference_ms: 0.5110263015725125\n",
      "    mean_raw_obs_processing_ms: 4.133146658220896\n",
      "  time_since_restore: 501.8394808769226\n",
      "  time_this_iter_s: 30.24800944328308\n",
      "  time_total_s: 501.8394808769226\n",
      "  timers:\n",
      "    learn_throughput: 6072.116\n",
      "    learn_time_ms: 2470.308\n",
      "    sample_throughput: 528.499\n",
      "    sample_time_ms: 28382.27\n",
      "    update_time_ms: 1.025\n",
      "  timestamp: 1674279640\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 16\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         501.839</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-2258.31</td><td style=\"text-align: right;\">             657.388</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:40:40,484\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 226.0x the scale of `vf_clip_param`. This means that it will take more than 226.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 255000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-41-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 657.3880985800384\n",
      "  episode_reward_mean: -2111.2195507694983\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 85\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0062499999999999995\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.49999651224431346\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010607753311026095\n",
      "          policy_loss: -0.004698996671664892\n",
      "          total_loss: 31.6206412121401\n",
      "          vf_explained_var: 0.28699469566345215\n",
      "          vf_loss: 31.625273866976723\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 255000\n",
      "    num_steps_sampled: 255000\n",
      "    num_steps_trained: 255000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.125\n",
      "    ram_util_percent: 18.94090909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0539452751677878\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 5.027291527014872\n",
      "    mean_inference_ms: 0.5109659004960551\n",
      "    mean_raw_obs_processing_ms: 4.137336001105141\n",
      "  time_since_restore: 532.2635457515717\n",
      "  time_this_iter_s: 30.424064874649048\n",
      "  time_total_s: 532.2635457515717\n",
      "  timers:\n",
      "    learn_throughput: 6069.19\n",
      "    learn_time_ms: 2471.5\n",
      "    sample_throughput: 527.18\n",
      "    sample_time_ms: 28453.282\n",
      "    update_time_ms: 1.084\n",
      "  timestamp: 1674279670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 255000\n",
      "  training_iteration: 17\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         532.264</td><td style=\"text-align: right;\">255000</td><td style=\"text-align: right;\">-2111.22</td><td style=\"text-align: right;\">             657.388</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14936)\u001b[0m 2023-01-20 23:41:10,948\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 211.0x the scale of `vf_clip_param`. This means that it will take more than 211.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 270000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-41-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 657.3880985800384\n",
      "  episode_reward_mean: -1982.2380829783215\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 90\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0062499999999999995\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.580048170180644\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007139382214998076\n",
      "          policy_loss: -0.0024207798278716914\n",
      "          total_loss: 40.78470347291332\n",
      "          vf_explained_var: 0.3256892263889313\n",
      "          vf_loss: 40.7870796381417\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 270000\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.362790697674424\n",
      "    ram_util_percent: 18.95581395348837\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05394743302018905\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.996153717562424\n",
      "    mean_inference_ms: 0.510920105490549\n",
      "    mean_raw_obs_processing_ms: 4.140593289798521\n",
      "  time_since_restore: 562.4907429218292\n",
      "  time_this_iter_s: 30.22719717025757\n",
      "  time_total_s: 562.4907429218292\n",
      "  timers:\n",
      "    learn_throughput: 6057.439\n",
      "    learn_time_ms: 2476.294\n",
      "    sample_throughput: 528.85\n",
      "    sample_time_ms: 28363.424\n",
      "    update_time_ms: 1.087\n",
      "  timestamp: 1674279701\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 18\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         562.491</td><td style=\"text-align: right;\">270000</td><td style=\"text-align: right;\">-1982.24</td><td style=\"text-align: right;\">             657.388</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 285000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-42-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 657.3880985800384\n",
      "  episode_reward_mean: -1853.2886467869068\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 95\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0031249999999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.6516369138733815\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005949577047624667\n",
      "          policy_loss: -0.0019987514104409998\n",
      "          total_loss: 42.68410828800525\n",
      "          vf_explained_var: 0.510018527507782\n",
      "          vf_loss: 42.686088553929736\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 285000\n",
      "    num_steps_sampled: 285000\n",
      "    num_steps_trained: 285000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.353488372093025\n",
      "    ram_util_percent: 18.96511627906977\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05395022391804683\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.967776256612914\n",
      "    mean_inference_ms: 0.5108792686143582\n",
      "    mean_raw_obs_processing_ms: 4.1430641994359805\n",
      "  time_since_restore: 592.7301802635193\n",
      "  time_this_iter_s: 30.239437341690063\n",
      "  time_total_s: 592.7301802635193\n",
      "  timers:\n",
      "    learn_throughput: 6092.902\n",
      "    learn_time_ms: 2461.881\n",
      "    sample_throughput: 528.93\n",
      "    sample_time_ms: 28359.136\n",
      "    update_time_ms: 1.01\n",
      "  timestamp: 1674279731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 285000\n",
      "  training_iteration: 19\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">          592.73</td><td style=\"text-align: right;\">285000</td><td style=\"text-align: right;\">-1853.29</td><td style=\"text-align: right;\">             657.388</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-42-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 657.3880985800384\n",
      "  episode_reward_mean: -1739.3006538177533\n",
      "  episode_reward_min: -5146.129810432308\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 100\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0015624999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.7375280078689931\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006391789832523958\n",
      "          policy_loss: -0.0022073420573625775\n",
      "          total_loss: 34.19782828799749\n",
      "          vf_explained_var: 0.6524127721786499\n",
      "          vf_loss: 34.20002565222271\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.352272727272727\n",
      "    ram_util_percent: 18.95681818181818\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05395304208150809\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.941842966533722\n",
      "    mean_inference_ms: 0.5108623327980986\n",
      "    mean_raw_obs_processing_ms: 4.145420500988294\n",
      "  time_since_restore: 623.1994135379791\n",
      "  time_this_iter_s: 30.46923327445984\n",
      "  time_total_s: 623.1994135379791\n",
      "  timers:\n",
      "    learn_throughput: 6091.709\n",
      "    learn_time_ms: 2462.363\n",
      "    sample_throughput: 530.004\n",
      "    sample_time_ms: 28301.698\n",
      "    update_time_ms: 0.952\n",
      "  timestamp: 1674279762\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 20\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         623.199</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> -1739.3</td><td style=\"text-align: right;\">             657.388</td><td style=\"text-align: right;\">            -5146.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 315000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-43-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 657.3880985800384\n",
      "  episode_reward_mean: -1512.4407000561039\n",
      "  episode_reward_min: -4772.635425437921\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 105\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0007812499999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.8684819272514117\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008289904102880129\n",
      "          policy_loss: -0.0027658294475937295\n",
      "          total_loss: 19.634531155279127\n",
      "          vf_explained_var: 0.6665889620780945\n",
      "          vf_loss: 19.637290468862503\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 315000\n",
      "    num_steps_sampled: 315000\n",
      "    num_steps_trained: 315000\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.04200000000001\n",
      "    ram_util_percent: 18.904\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053964683357675625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.759171016768539\n",
      "    mean_inference_ms: 0.5112520981376396\n",
      "    mean_raw_obs_processing_ms: 4.154198606243578\n",
      "  time_since_restore: 658.5927577018738\n",
      "  time_this_iter_s: 35.39334416389465\n",
      "  time_total_s: 658.5927577018738\n",
      "  timers:\n",
      "    learn_throughput: 5961.656\n",
      "    learn_time_ms: 2516.079\n",
      "    sample_throughput: 520.983\n",
      "    sample_time_ms: 28791.708\n",
      "    update_time_ms: 0.998\n",
      "  timestamp: 1674279797\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 315000\n",
      "  training_iteration: 21\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         658.593</td><td style=\"text-align: right;\">315000</td><td style=\"text-align: right;\">-1512.44</td><td style=\"text-align: right;\">             657.388</td><td style=\"text-align: right;\">            -4772.64</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 330000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-43-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 657.3880985800384\n",
      "  episode_reward_mean: -1293.0074236513797\n",
      "  episode_reward_min: -4622.728726414342\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 110\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.00039062499999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.9512163713826971\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006669513885828584\n",
      "          policy_loss: -0.001746741080088383\n",
      "          total_loss: 21.579711323269343\n",
      "          vf_explained_var: 0.7266287207603455\n",
      "          vf_loss: 21.581455444077314\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 330000\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.183720930232553\n",
      "    ram_util_percent: 18.96511627906977\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053966651116542176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.67007991762605\n",
      "    mean_inference_ms: 0.5107167264793327\n",
      "    mean_raw_obs_processing_ms: 4.1600520449011205\n",
      "  time_since_restore: 688.8441274166107\n",
      "  time_this_iter_s: 30.25136971473694\n",
      "  time_total_s: 688.8441274166107\n",
      "  timers:\n",
      "    learn_throughput: 5970.463\n",
      "    learn_time_ms: 2512.368\n",
      "    sample_throughput: 520.639\n",
      "    sample_time_ms: 28810.753\n",
      "    update_time_ms: 0.991\n",
      "  timestamp: 1674279827\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 22\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         688.844</td><td style=\"text-align: right;\">330000</td><td style=\"text-align: right;\">-1293.01</td><td style=\"text-align: right;\">             657.388</td><td style=\"text-align: right;\">            -4622.73</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 345000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-44-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 657.3880985800384\n",
      "  episode_reward_mean: -1086.8208773118936\n",
      "  episode_reward_min: -4244.354448795457\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 115\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.00019531249999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.0709412342410976\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006579597617380832\n",
      "          policy_loss: -0.0015068230392821765\n",
      "          total_loss: 13.653184425628792\n",
      "          vf_explained_var: 0.8280094265937805\n",
      "          vf_loss: 13.654689937526896\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 345000\n",
      "    num_steps_sampled: 345000\n",
      "    num_steps_trained: 345000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.66818181818182\n",
      "    ram_util_percent: 18.95909090909091\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053966621175251944\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.613344246979532\n",
      "    mean_inference_ms: 0.5103990985047967\n",
      "    mean_raw_obs_processing_ms: 4.165271929103334\n",
      "  time_since_restore: 719.0260303020477\n",
      "  time_this_iter_s: 30.18190288543701\n",
      "  time_total_s: 719.0260303020477\n",
      "  timers:\n",
      "    learn_throughput: 5955.573\n",
      "    learn_time_ms: 2518.649\n",
      "    sample_throughput: 521.3\n",
      "    sample_time_ms: 28774.237\n",
      "    update_time_ms: 0.992\n",
      "  timestamp: 1674279857\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 345000\n",
      "  training_iteration: 23\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         719.026</td><td style=\"text-align: right;\">345000</td><td style=\"text-align: right;\">-1086.82</td><td style=\"text-align: right;\">             657.388</td><td style=\"text-align: right;\">            -4244.35</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 360000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-44-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 967.5293038551488\n",
      "  episode_reward_mean: -896.1896665505445\n",
      "  episode_reward_min: -4244.354448795457\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 120\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 9.765624999999999e-05\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.0979394707639338\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.004218264577013452\n",
      "          policy_loss: -0.000719702462823588\n",
      "          total_loss: 25.220388802027298\n",
      "          vf_explained_var: 0.7615475058555603\n",
      "          vf_loss: 25.221108100373865\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 360000\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.486046511627904\n",
      "    ram_util_percent: 18.95813953488372\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05397395296529622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.572705436987834\n",
      "    mean_inference_ms: 0.5102587687491702\n",
      "    mean_raw_obs_processing_ms: 4.171539555437256\n",
      "  time_since_restore: 749.2595262527466\n",
      "  time_this_iter_s: 30.233495950698853\n",
      "  time_total_s: 749.2595262527466\n",
      "  timers:\n",
      "    learn_throughput: 5948.103\n",
      "    learn_time_ms: 2521.812\n",
      "    sample_throughput: 531.722\n",
      "    sample_time_ms: 28210.218\n",
      "    update_time_ms: 1.058\n",
      "  timestamp: 1674279888\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 24\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">          749.26</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -896.19</td><td style=\"text-align: right;\">             967.529</td><td style=\"text-align: right;\">            -4244.35</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 375000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-45-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 967.5293038551488\n",
      "  episode_reward_mean: -707.4743219897613\n",
      "  episode_reward_min: -3800.637704572344\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 125\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 4.8828124999999996e-05\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.1643831098483781\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00693549882767238\n",
      "          policy_loss: -0.0015312570040666702\n",
      "          total_loss: 26.00104642965026\n",
      "          vf_explained_var: 0.8203686475753784\n",
      "          vf_loss: 26.00257742849447\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 375000\n",
      "    num_steps_sampled: 375000\n",
      "    num_steps_trained: 375000\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.861904761904768\n",
      "    ram_util_percent: 18.964285714285715\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05398392294940274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.541476847596605\n",
      "    mean_inference_ms: 0.5102146581711355\n",
      "    mean_raw_obs_processing_ms: 4.1790327484752545\n",
      "  time_since_restore: 779.0494637489319\n",
      "  time_this_iter_s: 29.789937496185303\n",
      "  time_total_s: 779.0494637489319\n",
      "  timers:\n",
      "    learn_throughput: 5961.132\n",
      "    learn_time_ms: 2516.301\n",
      "    sample_throughput: 531.456\n",
      "    sample_time_ms: 28224.345\n",
      "    update_time_ms: 1.06\n",
      "  timestamp: 1674279918\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 375000\n",
      "  training_iteration: 25\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         779.049</td><td style=\"text-align: right;\">375000</td><td style=\"text-align: right;\">-707.474</td><td style=\"text-align: right;\">             967.529</td><td style=\"text-align: right;\">            -3800.64</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 390000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-45-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 967.5293038551488\n",
      "  episode_reward_mean: -516.7829764085147\n",
      "  episode_reward_min: -3396.040197690224\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 130\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.4414062499999998e-05\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.198193601733547\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.003808220443781532\n",
      "          policy_loss: -0.0005752265757202345\n",
      "          total_loss: 11.966404830399206\n",
      "          vf_explained_var: 0.9086801409721375\n",
      "          vf_loss: 11.966979926319446\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 390000\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.037209302325586\n",
      "    ram_util_percent: 18.967441860465115\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05399161948289013\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.516634005850612\n",
      "    mean_inference_ms: 0.5101909845671257\n",
      "    mean_raw_obs_processing_ms: 4.187069082115046\n",
      "  time_since_restore: 808.8612492084503\n",
      "  time_this_iter_s: 29.811785459518433\n",
      "  time_total_s: 808.8612492084503\n",
      "  timers:\n",
      "    learn_throughput: 5967.064\n",
      "    learn_time_ms: 2513.799\n",
      "    sample_throughput: 532.232\n",
      "    sample_time_ms: 28183.18\n",
      "    update_time_ms: 1.065\n",
      "  timestamp: 1674279947\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 26\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         808.861</td><td style=\"text-align: right;\">390000</td><td style=\"text-align: right;\">-516.783</td><td style=\"text-align: right;\">             967.529</td><td style=\"text-align: right;\">            -3396.04</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 405000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-46-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1507.2407076744678\n",
      "  episode_reward_mean: -335.9003495682227\n",
      "  episode_reward_min: -2958.200925996927\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 135\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.2207031249999999e-05\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.249216752133127\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0043803500443960865\n",
      "          policy_loss: -0.00087588418598713\n",
      "          total_loss: 28.006748077424906\n",
      "          vf_explained_var: 0.8918998837471008\n",
      "          vf_loss: 28.007623881808783\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 405000\n",
      "    num_steps_sampled: 405000\n",
      "    num_steps_trained: 405000\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.32790697674419\n",
      "    ram_util_percent: 18.969767441860466\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05399898660458329\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.496703079358726\n",
      "    mean_inference_ms: 0.5101989428307757\n",
      "    mean_raw_obs_processing_ms: 4.195567307300135\n",
      "  time_since_restore: 839.2051117420197\n",
      "  time_this_iter_s: 30.343862533569336\n",
      "  time_total_s: 839.2051117420197\n",
      "  timers:\n",
      "    learn_throughput: 5969.83\n",
      "    learn_time_ms: 2512.634\n",
      "    sample_throughput: 532.361\n",
      "    sample_time_ms: 28176.349\n",
      "    update_time_ms: 1.003\n",
      "  timestamp: 1674279978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 405000\n",
      "  training_iteration: 27\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         839.205</td><td style=\"text-align: right;\">405000</td><td style=\"text-align: right;\">  -335.9</td><td style=\"text-align: right;\">             1507.24</td><td style=\"text-align: right;\">             -2958.2</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 420000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-46-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1632.5418007372705\n",
      "  episode_reward_mean: -174.59330069069813\n",
      "  episode_reward_min: -2051.9060808221443\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 140\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.1035156249999995e-06\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.2575508562184996\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006739493633833324\n",
      "          policy_loss: -0.0016455356674900247\n",
      "          total_loss: 62.47703017380278\n",
      "          vf_explained_var: 0.8675454258918762\n",
      "          vf_loss: 62.478675606291176\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 420000\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.749999999999996\n",
      "    ram_util_percent: 18.974999999999998\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054005025252696744\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.480335860207324\n",
      "    mean_inference_ms: 0.510212219199541\n",
      "    mean_raw_obs_processing_ms: 4.201505159402117\n",
      "  time_since_restore: 869.4226529598236\n",
      "  time_this_iter_s: 30.217541217803955\n",
      "  time_total_s: 869.4226529598236\n",
      "  timers:\n",
      "    learn_throughput: 5961.991\n",
      "    learn_time_ms: 2515.938\n",
      "    sample_throughput: 532.442\n",
      "    sample_time_ms: 28172.074\n",
      "    update_time_ms: 0.97\n",
      "  timestamp: 1674280008\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 28\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         869.423</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">-174.593</td><td style=\"text-align: right;\">             1632.54</td><td style=\"text-align: right;\">            -2051.91</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 435000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-47-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1632.5418007372705\n",
      "  episode_reward_mean: -99.51473766894111\n",
      "  episode_reward_min: -1907.645326697455\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 145\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.0517578124999997e-06\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.2974481502831992\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01506542060265619\n",
      "          policy_loss: -0.0022390803995037106\n",
      "          total_loss: 40.495129792164946\n",
      "          vf_explained_var: 0.9404102563858032\n",
      "          vf_loss: 40.4973686614279\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 435000\n",
      "    num_steps_sampled: 435000\n",
      "    num_steps_trained: 435000\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.625581395348835\n",
      "    ram_util_percent: 18.969767441860466\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05401114085493437\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.465915900375125\n",
      "    mean_inference_ms: 0.5102423393727917\n",
      "    mean_raw_obs_processing_ms: 4.207813021526924\n",
      "  time_since_restore: 899.6245224475861\n",
      "  time_this_iter_s: 30.20186948776245\n",
      "  time_total_s: 899.6245224475861\n",
      "  timers:\n",
      "    learn_throughput: 5935.065\n",
      "    learn_time_ms: 2527.352\n",
      "    sample_throughput: 532.73\n",
      "    sample_time_ms: 28156.861\n",
      "    update_time_ms: 0.999\n",
      "  timestamp: 1674280038\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 435000\n",
      "  training_iteration: 29\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         899.625</td><td style=\"text-align: right;\">435000</td><td style=\"text-align: right;\">-99.5147</td><td style=\"text-align: right;\">             1632.54</td><td style=\"text-align: right;\">            -1907.65</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 450000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-47-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1632.5418007372705\n",
      "  episode_reward_mean: -33.4485155854354\n",
      "  episode_reward_min: -1193.4599873470122\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 150\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.0517578124999997e-06\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.359040661484508\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01289450495436894\n",
      "          policy_loss: -0.0025918323446017834\n",
      "          total_loss: 30.15647179393445\n",
      "          vf_explained_var: 0.9589183926582336\n",
      "          vf_loss: 30.15906361563731\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 450000\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.048\n",
      "    ram_util_percent: 18.928\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054016530439302685\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.453355952991003\n",
      "    mean_inference_ms: 0.5103378241467111\n",
      "    mean_raw_obs_processing_ms: 4.216162397902292\n",
      "  time_since_restore: 935.0575571060181\n",
      "  time_this_iter_s: 35.43303465843201\n",
      "  time_total_s: 935.0575571060181\n",
      "  timers:\n",
      "    learn_throughput: 5933.63\n",
      "    learn_time_ms: 2527.963\n",
      "    sample_throughput: 523.512\n",
      "    sample_time_ms: 28652.623\n",
      "    update_time_ms: 1.003\n",
      "  timestamp: 1674280074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 30\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 5.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         935.058</td><td style=\"text-align: right;\">450000</td><td style=\"text-align: right;\">-33.4485</td><td style=\"text-align: right;\">             1632.54</td><td style=\"text-align: right;\">            -1193.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 465000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-48-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1632.5418007372705\n",
      "  episode_reward_mean: 21.132295717301943\n",
      "  episode_reward_min: -1127.8712158247554\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 155\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.0517578124999997e-06\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.4483250318947485\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0047476193313917186\n",
      "          policy_loss: 0.0009933654816773863\n",
      "          total_loss: 35.1151509915368\n",
      "          vf_explained_var: 0.9206033945083618\n",
      "          vf_loss: 35.114157620931074\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 465000\n",
      "    num_steps_sampled: 465000\n",
      "    num_steps_trained: 465000\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.25333333333334\n",
      "    ram_util_percent: 18.964444444444442\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05402351640883677\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.441817275580842\n",
      "    mean_inference_ms: 0.5104481586072273\n",
      "    mean_raw_obs_processing_ms: 4.22505745423375\n",
      "  time_since_restore: 966.3743557929993\n",
      "  time_this_iter_s: 31.3167986869812\n",
      "  time_total_s: 966.3743557929993\n",
      "  timers:\n",
      "    learn_throughput: 5933.817\n",
      "    learn_time_ms: 2527.884\n",
      "    sample_throughput: 531.064\n",
      "    sample_time_ms: 28245.173\n",
      "    update_time_ms: 0.955\n",
      "  timestamp: 1674280105\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 465000\n",
      "  training_iteration: 31\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         966.374</td><td style=\"text-align: right;\">465000</td><td style=\"text-align: right;\"> 21.1323</td><td style=\"text-align: right;\">             1632.54</td><td style=\"text-align: right;\">            -1127.87</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 480000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-48-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 101.20223836922415\n",
      "  episode_reward_min: -1127.8712158247554\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 160\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.5258789062499999e-06\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.5016020800097514\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.004328223482359893\n",
      "          policy_loss: -4.393805481367192e-06\n",
      "          total_loss: 62.076573284601764\n",
      "          vf_explained_var: 0.8953312039375305\n",
      "          vf_loss: 62.0765777393923\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 480000\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.977272727272734\n",
      "    ram_util_percent: 18.970454545454547\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05403150969148151\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.431801272437763\n",
      "    mean_inference_ms: 0.510543323514367\n",
      "    mean_raw_obs_processing_ms: 4.233908033011147\n",
      "  time_since_restore: 996.8998532295227\n",
      "  time_this_iter_s: 30.525497436523438\n",
      "  time_total_s: 996.8998532295227\n",
      "  timers:\n",
      "    learn_throughput: 5944.673\n",
      "    learn_time_ms: 2523.267\n",
      "    sample_throughput: 530.463\n",
      "    sample_time_ms: 28277.17\n",
      "    update_time_ms: 0.961\n",
      "  timestamp: 1674280136\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 32\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">           996.9</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\"> 101.202</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -1127.87</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 495000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-49-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 148.58248410121695\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 165\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.629394531249999e-07\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.574337974443274\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007533366001659484\n",
      "          policy_loss: -5.0436371100782336e-05\n",
      "          total_loss: 44.69033989825491\n",
      "          vf_explained_var: 0.9081493020057678\n",
      "          vf_loss: 44.6903904308707\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 495000\n",
      "    num_steps_sampled: 495000\n",
      "    num_steps_trained: 495000\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.460465116279067\n",
      "    ram_util_percent: 18.967441860465115\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05404046798926477\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.422969816096492\n",
      "    mean_inference_ms: 0.5105528283313955\n",
      "    mean_raw_obs_processing_ms: 4.2418047234245675\n",
      "  time_since_restore: 1027.207046508789\n",
      "  time_this_iter_s: 30.307193279266357\n",
      "  time_total_s: 1027.207046508789\n",
      "  timers:\n",
      "    learn_throughput: 5939.767\n",
      "    learn_time_ms: 2525.352\n",
      "    sample_throughput: 530.269\n",
      "    sample_time_ms: 28287.523\n",
      "    update_time_ms: 1.021\n",
      "  timestamp: 1674280166\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 495000\n",
      "  training_iteration: 33\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         1027.21</td><td style=\"text-align: right;\">495000</td><td style=\"text-align: right;\"> 148.582</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 510000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-49-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 142.01377575222116\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 170\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.8146972656249997e-07\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.6117664672560612\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006894405494006569\n",
      "          policy_loss: -0.0006591942957484052\n",
      "          total_loss: 27.61490115432416\n",
      "          vf_explained_var: 0.9535518288612366\n",
      "          vf_loss: 27.615560366339604\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 510000\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.43255813953488\n",
      "    ram_util_percent: 18.96511627906977\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05405074748743227\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.414512911961385\n",
      "    mean_inference_ms: 0.5105870021468027\n",
      "    mean_raw_obs_processing_ms: 4.2433155439203825\n",
      "  time_since_restore: 1057.3532712459564\n",
      "  time_this_iter_s: 30.14622473716736\n",
      "  time_total_s: 1057.3532712459564\n",
      "  timers:\n",
      "    learn_throughput: 5948.928\n",
      "    learn_time_ms: 2521.463\n",
      "    sample_throughput: 530.358\n",
      "    sample_time_ms: 28282.794\n",
      "    update_time_ms: 0.984\n",
      "  timestamp: 1674280196\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 34\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         1057.35</td><td style=\"text-align: right;\">510000</td><td style=\"text-align: right;\"> 142.014</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 525000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-50-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 145.06959282462824\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 175\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.9073486328124998e-07\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.6586057521529116\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007309566728311821\n",
      "          policy_loss: 0.0002891320985805054\n",
      "          total_loss: 47.270070425130555\n",
      "          vf_explained_var: 0.9255102872848511\n",
      "          vf_loss: 47.26978124642776\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 525000\n",
      "    num_steps_sampled: 525000\n",
      "    num_steps_trained: 525000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.987999999999996\n",
      "    ram_util_percent: 18.93\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054062525392962704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.406848812973601\n",
      "    mean_inference_ms: 0.5106400582367978\n",
      "    mean_raw_obs_processing_ms: 4.248164144764281\n",
      "  time_since_restore: 1092.5438342094421\n",
      "  time_this_iter_s: 35.19056296348572\n",
      "  time_total_s: 1092.5438342094421\n",
      "  timers:\n",
      "    learn_throughput: 5947.97\n",
      "    learn_time_ms: 2521.869\n",
      "    sample_throughput: 520.428\n",
      "    sample_time_ms: 28822.456\n",
      "    update_time_ms: 0.965\n",
      "  timestamp: 1674280232\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 525000\n",
      "  training_iteration: 35\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         1092.54</td><td style=\"text-align: right;\">525000</td><td style=\"text-align: right;\">  145.07</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 540000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-51-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 172.7075687042035\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 180\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 9.536743164062499e-08\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.6927448075706677\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005613886161364047\n",
      "          policy_loss: -0.00045531037168861446\n",
      "          total_loss: 67.13505493422686\n",
      "          vf_explained_var: 0.8698174953460693\n",
      "          vf_loss: 67.13551016015522\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 540000\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.995238095238093\n",
      "    ram_util_percent: 18.976190476190474\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054073599115250184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.399707615812907\n",
      "    mean_inference_ms: 0.5106959353309988\n",
      "    mean_raw_obs_processing_ms: 4.253122996190151\n",
      "  time_since_restore: 1121.923705816269\n",
      "  time_this_iter_s: 29.379871606826782\n",
      "  time_total_s: 1121.923705816269\n",
      "  timers:\n",
      "    learn_throughput: 5951.892\n",
      "    learn_time_ms: 2520.207\n",
      "    sample_throughput: 521.18\n",
      "    sample_time_ms: 28780.825\n",
      "    update_time_ms: 1.021\n",
      "  timestamp: 1674280261\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 36\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         1121.92</td><td style=\"text-align: right;\">540000</td><td style=\"text-align: right;\"> 172.708</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 555000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-51-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 183.80341973666708\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 185\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 4.7683715820312496e-08\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7381610883494556\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00475341567932288\n",
      "          policy_loss: 0.0006904050849883233\n",
      "          total_loss: 32.3749336687185\n",
      "          vf_explained_var: 0.9187679886817932\n",
      "          vf_loss: 32.37424318103467\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 555000\n",
      "    num_steps_sampled: 555000\n",
      "    num_steps_trained: 555000\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.913636363636364\n",
      "    ram_util_percent: 18.993181818181817\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054084008109000166\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.392910220562275\n",
      "    mean_inference_ms: 0.5107527095687889\n",
      "    mean_raw_obs_processing_ms: 4.258440530719995\n",
      "  time_since_restore: 1152.240061044693\n",
      "  time_this_iter_s: 30.316355228424072\n",
      "  time_total_s: 1152.240061044693\n",
      "  timers:\n",
      "    learn_throughput: 5945.428\n",
      "    learn_time_ms: 2522.947\n",
      "    sample_throughput: 521.28\n",
      "    sample_time_ms: 28775.326\n",
      "    update_time_ms: 1.016\n",
      "  timestamp: 1674280291\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 555000\n",
      "  training_iteration: 37\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         1152.24</td><td style=\"text-align: right;\">555000</td><td style=\"text-align: right;\"> 183.803</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 570000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-52-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 217.32041112050277\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 190\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.3841857910156248e-08\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7855227229958874\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006877737741613919\n",
      "          policy_loss: -0.00046924812308812543\n",
      "          total_loss: 69.17644852783721\n",
      "          vf_explained_var: 0.9155533909797668\n",
      "          vf_loss: 69.17691799099163\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 570000\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.69302325581395\n",
      "    ram_util_percent: 19.020930232558143\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05409308555021289\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.386658437235095\n",
      "    mean_inference_ms: 0.5107997252593772\n",
      "    mean_raw_obs_processing_ms: 4.263785029758882\n",
      "  time_since_restore: 1182.4778950214386\n",
      "  time_this_iter_s: 30.237833976745605\n",
      "  time_total_s: 1182.4778950214386\n",
      "  timers:\n",
      "    learn_throughput: 5953.494\n",
      "    learn_time_ms: 2519.529\n",
      "    sample_throughput: 521.183\n",
      "    sample_time_ms: 28780.674\n",
      "    update_time_ms: 1.06\n",
      "  timestamp: 1674280322\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 38\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         1182.48</td><td style=\"text-align: right;\">570000</td><td style=\"text-align: right;\">  217.32</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 585000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-52-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 231.41226682777858\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 195\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.1920928955078124e-08\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7893026151899565\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005562779764428075\n",
      "          policy_loss: -0.0002197726442965963\n",
      "          total_loss: 65.42151785705049\n",
      "          vf_explained_var: 0.8994502425193787\n",
      "          vf_loss: 65.42173764341969\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 585000\n",
      "    num_steps_sampled: 585000\n",
      "    num_steps_trained: 585000\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.65116279069767\n",
      "    ram_util_percent: 18.972093023255812\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0541011988913212\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.380843124411294\n",
      "    mean_inference_ms: 0.5108545014661753\n",
      "    mean_raw_obs_processing_ms: 4.269261883205052\n",
      "  time_since_restore: 1212.866417169571\n",
      "  time_this_iter_s: 30.388522148132324\n",
      "  time_total_s: 1212.866417169571\n",
      "  timers:\n",
      "    learn_throughput: 5952.121\n",
      "    learn_time_ms: 2520.11\n",
      "    sample_throughput: 520.857\n",
      "    sample_time_ms: 28798.678\n",
      "    update_time_ms: 1.043\n",
      "  timestamp: 1674280352\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 585000\n",
      "  training_iteration: 39\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         1212.87</td><td style=\"text-align: right;\">585000</td><td style=\"text-align: right;\"> 231.412</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 600000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-53-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 223.47664219615547\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 200\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 5.960464477539062e-09\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7923972745062942\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005935496082282208\n",
      "          policy_loss: -0.00046209551855700754\n",
      "          total_loss: 59.061894875057675\n",
      "          vf_explained_var: 0.9193221926689148\n",
      "          vf_loss: 59.06235699491986\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 600000\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.897727272727266\n",
      "    ram_util_percent: 18.970454545454547\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0541091208508309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.375322225020953\n",
      "    mean_inference_ms: 0.5108866210649506\n",
      "    mean_raw_obs_processing_ms: 4.2745264094839435\n",
      "  time_since_restore: 1243.2234449386597\n",
      "  time_this_iter_s: 30.357027769088745\n",
      "  time_total_s: 1243.2234449386597\n",
      "  timers:\n",
      "    learn_throughput: 5962.459\n",
      "    learn_time_ms: 2515.741\n",
      "    sample_throughput: 530.123\n",
      "    sample_time_ms: 28295.331\n",
      "    update_time_ms: 1.095\n",
      "  timestamp: 1674280382\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 40\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         1243.22</td><td style=\"text-align: right;\">600000</td><td style=\"text-align: right;\"> 223.477</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 615000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-53-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 276.3605995643091\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 205\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.980232238769531e-09\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.8233010222346095\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007598985930426925\n",
      "          policy_loss: -0.0014074983016066885\n",
      "          total_loss: 75.50216916294421\n",
      "          vf_explained_var: 0.8692166805267334\n",
      "          vf_loss: 75.50357655670683\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 615000\n",
      "    num_steps_sampled: 615000\n",
      "    num_steps_trained: 615000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.381395348837213\n",
      "    ram_util_percent: 18.969767441860466\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05411602022132402\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.370261765295994\n",
      "    mean_inference_ms: 0.5109154552660637\n",
      "    mean_raw_obs_processing_ms: 4.275607940837492\n",
      "  time_since_restore: 1273.800673007965\n",
      "  time_this_iter_s: 30.57722806930542\n",
      "  time_total_s: 1273.800673007965\n",
      "  timers:\n",
      "    learn_throughput: 5971.605\n",
      "    learn_time_ms: 2511.888\n",
      "    sample_throughput: 531.44\n",
      "    sample_time_ms: 28225.183\n",
      "    update_time_ms: 1.092\n",
      "  timestamp: 1674280413\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 615000\n",
      "  training_iteration: 41\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">          1273.8</td><td style=\"text-align: right;\">615000</td><td style=\"text-align: right;\"> 276.361</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 630000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-54-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 305.8880972165227\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 210\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.4901161193847655e-09\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.861000961267342\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006239739353364083\n",
      "          policy_loss: -0.000611363041956546\n",
      "          total_loss: 41.31703253438917\n",
      "          vf_explained_var: 0.8710217475891113\n",
      "          vf_loss: 41.31764385255717\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 630000\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.866666666666667\n",
      "    ram_util_percent: 19.02619047619048\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054122072880260365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.365478521080195\n",
      "    mean_inference_ms: 0.5109380597518913\n",
      "    mean_raw_obs_processing_ms: 4.2766833581281425\n",
      "  time_since_restore: 1303.021579027176\n",
      "  time_this_iter_s: 29.220906019210815\n",
      "  time_total_s: 1303.021579027176\n",
      "  timers:\n",
      "    learn_throughput: 5956.474\n",
      "    learn_time_ms: 2518.268\n",
      "    sample_throughput: 534.031\n",
      "    sample_time_ms: 28088.235\n",
      "    update_time_ms: 1.145\n",
      "  timestamp: 1674280442\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 42\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         1303.02</td><td style=\"text-align: right;\">630000</td><td style=\"text-align: right;\"> 305.888</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 645000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-54-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 343.0937576404735\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 215\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.450580596923828e-10\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.93827812035205\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006628957492531889\n",
      "          policy_loss: 1.5340954700674292e-05\n",
      "          total_loss: 46.67495601945004\n",
      "          vf_explained_var: 0.9239841103553772\n",
      "          vf_loss: 46.67494062811642\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 645000\n",
      "    num_steps_sampled: 645000\n",
      "    num_steps_trained: 645000\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.972727272727273\n",
      "    ram_util_percent: 19.020454545454548\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05412806602932181\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.3610092924680846\n",
      "    mean_inference_ms: 0.5109614240430043\n",
      "    mean_raw_obs_processing_ms: 4.27785730143816\n",
      "  time_since_restore: 1333.3979244232178\n",
      "  time_this_iter_s: 30.37634539604187\n",
      "  time_total_s: 1333.3979244232178\n",
      "  timers:\n",
      "    learn_throughput: 5981.802\n",
      "    learn_time_ms: 2507.606\n",
      "    sample_throughput: 533.696\n",
      "    sample_time_ms: 28105.872\n",
      "    update_time_ms: 1.093\n",
      "  timestamp: 1674280473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 645000\n",
      "  training_iteration: 43\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">          1333.4</td><td style=\"text-align: right;\">645000</td><td style=\"text-align: right;\"> 343.094</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 660000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-55-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 365.70488865078516\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 220\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.725290298461914e-10\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.964174071206885\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0062326966666306\n",
      "          policy_loss: 0.0009384909510549347\n",
      "          total_loss: 53.85143659074428\n",
      "          vf_explained_var: 0.9299800395965576\n",
      "          vf_loss: 53.85049825603679\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 660000\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.567441860465124\n",
      "    ram_util_percent: 19.06046511627907\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05413338341300987\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.356941793316644\n",
      "    mean_inference_ms: 0.5109847950522622\n",
      "    mean_raw_obs_processing_ms: 4.278768827355119\n",
      "  time_since_restore: 1363.5345242023468\n",
      "  time_this_iter_s: 30.13659977912903\n",
      "  time_total_s: 1363.5345242023468\n",
      "  timers:\n",
      "    learn_throughput: 5965.074\n",
      "    learn_time_ms: 2514.638\n",
      "    sample_throughput: 533.848\n",
      "    sample_time_ms: 28097.877\n",
      "    update_time_ms: 1.079\n",
      "  timestamp: 1674280503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 44\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         1363.53</td><td style=\"text-align: right;\">660000</td><td style=\"text-align: right;\"> 365.705</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 675000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-55-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 388.3892108036351\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 225\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.862645149230957e-10\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.9878453755782823\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006234699137854267\n",
      "          policy_loss: -0.0003376612277954059\n",
      "          total_loss: 44.74893289582204\n",
      "          vf_explained_var: 0.9373444318771362\n",
      "          vf_loss: 44.74927059836307\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 675000\n",
      "    num_steps_sampled: 675000\n",
      "    num_steps_trained: 675000\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.028571428571436\n",
      "    ram_util_percent: 19.064285714285717\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05413856290167949\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.353155378213383\n",
      "    mean_inference_ms: 0.5110097528375115\n",
      "    mean_raw_obs_processing_ms: 4.279876737007688\n",
      "  time_since_restore: 1393.344379901886\n",
      "  time_this_iter_s: 29.809855699539185\n",
      "  time_total_s: 1393.344379901886\n",
      "  timers:\n",
      "    learn_throughput: 5963.734\n",
      "    learn_time_ms: 2515.203\n",
      "    sample_throughput: 544.281\n",
      "    sample_time_ms: 27559.286\n",
      "    update_time_ms: 1.078\n",
      "  timestamp: 1674280533\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 675000\n",
      "  training_iteration: 45\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         1393.34</td><td style=\"text-align: right;\">675000</td><td style=\"text-align: right;\"> 388.389</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 690000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-56-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 418.20794241402507\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 230\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 9.313225746154784e-11\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.9514164218458079\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.004886255333218166\n",
      "          policy_loss: 0.0006358057465719975\n",
      "          total_loss: 81.82077870773057\n",
      "          vf_explained_var: 0.8366135954856873\n",
      "          vf_loss: 81.82014299166404\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 690000\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.434883720930234\n",
      "    ram_util_percent: 19.06511627906977\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05414287111336736\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.349771153565181\n",
      "    mean_inference_ms: 0.5110239469388927\n",
      "    mean_raw_obs_processing_ms: 4.281049324970096\n",
      "  time_since_restore: 1423.476576089859\n",
      "  time_this_iter_s: 30.132196187973022\n",
      "  time_total_s: 1423.476576089859\n",
      "  timers:\n",
      "    learn_throughput: 5964.871\n",
      "    learn_time_ms: 2514.723\n",
      "    sample_throughput: 542.789\n",
      "    sample_time_ms: 27635.033\n",
      "    update_time_ms: 1.023\n",
      "  timestamp: 1674280563\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 46\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         1423.48</td><td style=\"text-align: right;\">690000</td><td style=\"text-align: right;\"> 418.208</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 705000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-56-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 436.0001428977798\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 235\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 4.656612873077392e-11\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.9844775963637789\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006150399484176124\n",
      "          policy_loss: 0.0004574111070862766\n",
      "          total_loss: 57.35532155117746\n",
      "          vf_explained_var: 0.8159553408622742\n",
      "          vf_loss: 57.354864232014805\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 705000\n",
      "    num_steps_sampled: 705000\n",
      "    num_steps_trained: 705000\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.686274509803923\n",
      "    ram_util_percent: 19.00980392156863\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054146369077699034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.3465232323139835\n",
      "    mean_inference_ms: 0.5110302215308056\n",
      "    mean_raw_obs_processing_ms: 4.284279818008509\n",
      "  time_since_restore: 1458.681589603424\n",
      "  time_this_iter_s: 35.20501351356506\n",
      "  time_total_s: 1458.681589603424\n",
      "  timers:\n",
      "    learn_throughput: 5962.094\n",
      "    learn_time_ms: 2515.895\n",
      "    sample_throughput: 533.377\n",
      "    sample_time_ms: 28122.724\n",
      "    update_time_ms: 1.038\n",
      "  timestamp: 1674280598\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 705000\n",
      "  training_iteration: 47\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         1458.68</td><td style=\"text-align: right;\">705000</td><td style=\"text-align: right;\">     436</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 720000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-57-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 464.86575890917317\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 240\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.328306436538696e-11\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.9853614331301996\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0056630651066325\n",
      "          policy_loss: -0.0011809576338283338\n",
      "          total_loss: 106.31839921595686\n",
      "          vf_explained_var: 0.8158418536186218\n",
      "          vf_loss: 106.31958036907649\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 720000\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.63023255813954\n",
      "    ram_util_percent: 19.06046511627907\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0541503520733888\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.343458738128325\n",
      "    mean_inference_ms: 0.511040752934016\n",
      "    mean_raw_obs_processing_ms: 4.287656706037302\n",
      "  time_since_restore: 1489.003035068512\n",
      "  time_this_iter_s: 30.32144546508789\n",
      "  time_total_s: 1489.003035068512\n",
      "  timers:\n",
      "    learn_throughput: 5947.677\n",
      "    learn_time_ms: 2521.993\n",
      "    sample_throughput: 533.335\n",
      "    sample_time_ms: 28124.936\n",
      "    update_time_ms: 1.045\n",
      "  timestamp: 1674280629\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 48\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">            1489</td><td style=\"text-align: right;\">720000</td><td style=\"text-align: right;\"> 464.866</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 735000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-57-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 533.1423657285733\n",
      "  episode_reward_min: -451.71546333354667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 245\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.164153218269348e-11\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.090970179792178\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008320340263845243\n",
      "          policy_loss: -0.0013680231544362792\n",
      "          total_loss: 125.97252537355584\n",
      "          vf_explained_var: 0.8741542100906372\n",
      "          vf_loss: 125.97389310416528\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 735000\n",
      "    num_steps_sampled: 735000\n",
      "    num_steps_trained: 735000\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.711904761904766\n",
      "    ram_util_percent: 19.076190476190476\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0541531922103861\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.340668671224674\n",
      "    mean_inference_ms: 0.5110444056630269\n",
      "    mean_raw_obs_processing_ms: 4.290668242622552\n",
      "  time_since_restore: 1518.7573869228363\n",
      "  time_this_iter_s: 29.75435185432434\n",
      "  time_total_s: 1518.7573869228363\n",
      "  timers:\n",
      "    learn_throughput: 5937.676\n",
      "    learn_time_ms: 2526.241\n",
      "    sample_throughput: 534.619\n",
      "    sample_time_ms: 28057.375\n",
      "    update_time_ms: 1.056\n",
      "  timestamp: 1674280658\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 735000\n",
      "  training_iteration: 49\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         1518.76</td><td style=\"text-align: right;\">735000</td><td style=\"text-align: right;\"> 533.142</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -451.715</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 750000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-58-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 586.4868222845541\n",
      "  episode_reward_min: -258.03508431552007\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 250\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 5.82076609134674e-12\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.1556018942493504\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00714997566163039\n",
      "          policy_loss: 0.00038171003856775115\n",
      "          total_loss: 98.45021954875881\n",
      "          vf_explained_var: 0.9177873134613037\n",
      "          vf_loss: 98.44983756501796\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 750000\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.07045454545454\n",
      "    ram_util_percent: 19.05454545454546\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415499020710172\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.338131169931212\n",
      "    mean_inference_ms: 0.5109872064478989\n",
      "    mean_raw_obs_processing_ms: 4.29087017382055\n",
      "  time_since_restore: 1549.22092461586\n",
      "  time_this_iter_s: 30.46353769302368\n",
      "  time_total_s: 1549.22092461586\n",
      "  timers:\n",
      "    learn_throughput: 5941.85\n",
      "    learn_time_ms: 2524.466\n",
      "    sample_throughput: 534.379\n",
      "    sample_time_ms: 28069.952\n",
      "    update_time_ms: 0.996\n",
      "  timestamp: 1674280689\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 50\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         1549.22</td><td style=\"text-align: right;\">750000</td><td style=\"text-align: right;\"> 586.487</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -258.035</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 765000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-58-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1819.9497102507196\n",
      "  episode_reward_mean: 618.2321406643863\n",
      "  episode_reward_min: -258.03508431552007\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 255\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.91038304567337e-12\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.155589959783069\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006450168643681832\n",
      "          policy_loss: -0.00016911287172460707\n",
      "          total_loss: 87.66942796222234\n",
      "          vf_explained_var: 0.8743788003921509\n",
      "          vf_loss: 87.66959708908857\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 765000\n",
      "    num_steps_sampled: 765000\n",
      "    num_steps_trained: 765000\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.248837209302327\n",
      "    ram_util_percent: 19.058139534883722\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0541556666749453\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.335737439179198\n",
      "    mean_inference_ms: 0.5109239330009556\n",
      "    mean_raw_obs_processing_ms: 4.290629997812185\n",
      "  time_since_restore: 1579.2613582611084\n",
      "  time_this_iter_s: 30.040433645248413\n",
      "  time_total_s: 1579.2613582611084\n",
      "  timers:\n",
      "    learn_throughput: 5948.622\n",
      "    learn_time_ms: 2521.592\n",
      "    sample_throughput: 535.348\n",
      "    sample_time_ms: 28019.17\n",
      "    update_time_ms: 1.0\n",
      "  timestamp: 1674280719\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 765000\n",
      "  training_iteration: 51\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         1579.26</td><td style=\"text-align: right;\">765000</td><td style=\"text-align: right;\"> 618.232</td><td style=\"text-align: right;\">             1819.95</td><td style=\"text-align: right;\">            -258.035</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 780000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-59-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1794.8856040758885\n",
      "  episode_reward_mean: 613.9343752988927\n",
      "  episode_reward_min: -258.03508431552007\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 260\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.455191522836685e-12\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.20519772000232\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007944694192806195\n",
      "          policy_loss: -9.564416388333853e-05\n",
      "          total_loss: 47.51459524025351\n",
      "          vf_explained_var: 0.9200977683067322\n",
      "          vf_loss: 47.514690775790456\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 780000\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.42325581395349\n",
      "    ram_util_percent: 19.053488372093025\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415553276218825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.333319811096353\n",
      "    mean_inference_ms: 0.5108558943820082\n",
      "    mean_raw_obs_processing_ms: 4.290672267166767\n",
      "  time_since_restore: 1609.4894168376923\n",
      "  time_this_iter_s: 30.228058576583862\n",
      "  time_total_s: 1609.4894168376923\n",
      "  timers:\n",
      "    learn_throughput: 5941.009\n",
      "    learn_time_ms: 2524.824\n",
      "    sample_throughput: 533.489\n",
      "    sample_time_ms: 28116.796\n",
      "    update_time_ms: 0.946\n",
      "  timestamp: 1674280749\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 52\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         1609.49</td><td style=\"text-align: right;\">780000</td><td style=\"text-align: right;\"> 613.934</td><td style=\"text-align: right;\">             1794.89</td><td style=\"text-align: right;\">            -258.035</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 795000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-20_23-59-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1794.8856040758885\n",
      "  episode_reward_mean: 652.2047241460094\n",
      "  episode_reward_min: -258.03508431552007\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 265\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.275957614183425e-13\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.185557742442115\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005012500497179897\n",
      "          policy_loss: 0.0010980346413739658\n",
      "          total_loss: 104.82432117138879\n",
      "          vf_explained_var: 0.9062783718109131\n",
      "          vf_loss: 104.82322345992266\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 795000\n",
      "    num_steps_sampled: 795000\n",
      "    num_steps_trained: 795000\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.022727272727273\n",
      "    ram_util_percent: 19.063636363636366\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415561123997196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.331053277483232\n",
      "    mean_inference_ms: 0.5107913033376659\n",
      "    mean_raw_obs_processing_ms: 4.290712265063346\n",
      "  time_since_restore: 1639.8241686820984\n",
      "  time_this_iter_s: 30.334751844406128\n",
      "  time_total_s: 1639.8241686820984\n",
      "  timers:\n",
      "    learn_throughput: 5943.714\n",
      "    learn_time_ms: 2523.675\n",
      "    sample_throughput: 533.546\n",
      "    sample_time_ms: 28113.807\n",
      "    update_time_ms: 0.936\n",
      "  timestamp: 1674280780\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 795000\n",
      "  training_iteration: 53\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         1639.82</td><td style=\"text-align: right;\">795000</td><td style=\"text-align: right;\"> 652.205</td><td style=\"text-align: right;\">             1794.89</td><td style=\"text-align: right;\">            -258.035</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 810000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-00-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1794.8856040758885\n",
      "  episode_reward_mean: 702.0424557143983\n",
      "  episode_reward_min: -174.34857147422375\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 270\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.6379788070917126e-13\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.2213019053814773\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00775379611200694\n",
      "          policy_loss: 0.001132541735482923\n",
      "          total_loss: 106.40994839425814\n",
      "          vf_explained_var: 0.884171187877655\n",
      "          vf_loss: 106.40881591732219\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 810000\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.41860465116279\n",
      "    ram_util_percent: 19.06046511627907\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415541108352271\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.329000766684054\n",
      "    mean_inference_ms: 0.5107277581715894\n",
      "    mean_raw_obs_processing_ms: 4.290576861918272\n",
      "  time_since_restore: 1670.0080301761627\n",
      "  time_this_iter_s: 30.18386149406433\n",
      "  time_total_s: 1670.0080301761627\n",
      "  timers:\n",
      "    learn_throughput: 5961.706\n",
      "    learn_time_ms: 2516.058\n",
      "    sample_throughput: 533.312\n",
      "    sample_time_ms: 28126.146\n",
      "    update_time_ms: 0.913\n",
      "  timestamp: 1674280810\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 54\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         1670.01</td><td style=\"text-align: right;\">810000</td><td style=\"text-align: right;\"> 702.042</td><td style=\"text-align: right;\">             1794.89</td><td style=\"text-align: right;\">            -174.349</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 825000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-00-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1794.8856040758885\n",
      "  episode_reward_mean: 759.2284723009999\n",
      "  episode_reward_min: 161.41285571907613\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 275\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.8189894035458563e-13\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.2325364411887474\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006836196305565742\n",
      "          policy_loss: -0.00021843543666872684\n",
      "          total_loss: 139.02715789019052\n",
      "          vf_explained_var: 0.8421655893325806\n",
      "          vf_loss: 139.02737634303207\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 825000\n",
      "    num_steps_sampled: 825000\n",
      "    num_steps_trained: 825000\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.511627906976745\n",
      "    ram_util_percent: 19.058139534883722\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415507300027087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.327114037344104\n",
      "    mean_inference_ms: 0.5106648541431942\n",
      "    mean_raw_obs_processing_ms: 4.2880418815852215\n",
      "  time_since_restore: 1700.626723766327\n",
      "  time_this_iter_s: 30.618693590164185\n",
      "  time_total_s: 1700.626723766327\n",
      "  timers:\n",
      "    learn_throughput: 5946.246\n",
      "    learn_time_ms: 2522.6\n",
      "    sample_throughput: 531.906\n",
      "    sample_time_ms: 28200.484\n",
      "    update_time_ms: 0.917\n",
      "  timestamp: 1674280841\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 825000\n",
      "  training_iteration: 55\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         1700.63</td><td style=\"text-align: right;\">825000</td><td style=\"text-align: right;\"> 759.228</td><td style=\"text-align: right;\">             1794.89</td><td style=\"text-align: right;\">             161.413</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 840000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-01-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 787.1454279591599\n",
      "  episode_reward_min: 161.41285571907613\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 280\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 9.094947017729282e-14\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.2779330655679866\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007905936660306761\n",
      "          policy_loss: -0.00024966789109600804\n",
      "          total_loss: 165.71007253355899\n",
      "          vf_explained_var: 0.7633082270622253\n",
      "          vf_loss: 165.7103223445052\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 840000\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.2\n",
      "    ram_util_percent: 19.061363636363637\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415426594571786\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.325372149241773\n",
      "    mean_inference_ms: 0.5106016825354738\n",
      "    mean_raw_obs_processing_ms: 4.285988455903385\n",
      "  time_since_restore: 1731.2316539287567\n",
      "  time_this_iter_s: 30.60493016242981\n",
      "  time_total_s: 1731.2316539287567\n",
      "  timers:\n",
      "    learn_throughput: 5939.862\n",
      "    learn_time_ms: 2525.311\n",
      "    sample_throughput: 531.069\n",
      "    sample_time_ms: 28244.919\n",
      "    update_time_ms: 0.959\n",
      "  timestamp: 1674280871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 56\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         1731.23</td><td style=\"text-align: right;\">840000</td><td style=\"text-align: right;\"> 787.145</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             161.413</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 855000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-01-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 822.4807372296148\n",
      "  episode_reward_min: 161.41285571907613\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 285\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 4.547473508864641e-14\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.270629912917897\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006103007672394855\n",
      "          policy_loss: -0.0003752682137034707\n",
      "          total_loss: 142.54266022504387\n",
      "          vf_explained_var: 0.7719100713729858\n",
      "          vf_loss: 142.54303514512918\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 855000\n",
      "    num_steps_sampled: 855000\n",
      "    num_steps_trained: 855000\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.06363636363636\n",
      "    ram_util_percent: 19.061363636363637\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415304175900922\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.323830248133384\n",
      "    mean_inference_ms: 0.5105380021101271\n",
      "    mean_raw_obs_processing_ms: 4.283949375776667\n",
      "  time_since_restore: 1761.7888026237488\n",
      "  time_this_iter_s: 30.557148694992065\n",
      "  time_total_s: 1761.7888026237488\n",
      "  timers:\n",
      "    learn_throughput: 5942.152\n",
      "    learn_time_ms: 2524.338\n",
      "    sample_throughput: 539.937\n",
      "    sample_time_ms: 27781.021\n",
      "    update_time_ms: 0.989\n",
      "  timestamp: 1674280902\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 855000\n",
      "  training_iteration: 57\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         1761.79</td><td style=\"text-align: right;\">855000</td><td style=\"text-align: right;\"> 822.481</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             161.413</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 870000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-02-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 832.1932506028122\n",
      "  episode_reward_min: 161.41285571907613\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 290\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2737367544323204e-14\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.2711951344700183\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006194910644512329\n",
      "          policy_loss: 0.00031306696266441024\n",
      "          total_loss: 133.92996665502\n",
      "          vf_explained_var: 0.8142141103744507\n",
      "          vf_loss: 133.92965398238877\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 870000\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 870000\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.952941176470592\n",
      "    ram_util_percent: 19.017647058823528\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415141745225064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.322295443171892\n",
      "    mean_inference_ms: 0.5104744309354428\n",
      "    mean_raw_obs_processing_ms: 4.283746496045012\n",
      "  time_since_restore: 1797.4236533641815\n",
      "  time_this_iter_s: 35.63485074043274\n",
      "  time_total_s: 1797.4236533641815\n",
      "  timers:\n",
      "    learn_throughput: 5935.274\n",
      "    learn_time_ms: 2527.263\n",
      "    sample_throughput: 529.857\n",
      "    sample_time_ms: 28309.539\n",
      "    update_time_ms: 1.001\n",
      "  timestamp: 1674280938\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 58\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         1797.42</td><td style=\"text-align: right;\">870000</td><td style=\"text-align: right;\"> 832.193</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             161.413</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 885000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-02-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 845.4324091148087\n",
      "  episode_reward_min: 161.41285571907613\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 295\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.1368683772161602e-14\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.3026984958325403\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008954918620163581\n",
      "          policy_loss: 0.00012438946671910206\n",
      "          total_loss: 103.41371551125737\n",
      "          vf_explained_var: 0.8059457540512085\n",
      "          vf_loss: 103.41359113272974\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 885000\n",
      "    num_steps_sampled: 885000\n",
      "    num_steps_trained: 885000\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.30697674418605\n",
      "    ram_util_percent: 19.06511627906977\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05414986763748875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.320766275950572\n",
      "    mean_inference_ms: 0.5104004144799734\n",
      "    mean_raw_obs_processing_ms: 4.283622759260229\n",
      "  time_since_restore: 1827.5335311889648\n",
      "  time_this_iter_s: 30.109877824783325\n",
      "  time_total_s: 1827.5335311889648\n",
      "  timers:\n",
      "    learn_throughput: 5941.603\n",
      "    learn_time_ms: 2524.571\n",
      "    sample_throughput: 529.144\n",
      "    sample_time_ms: 28347.684\n",
      "    update_time_ms: 1.032\n",
      "  timestamp: 1674280968\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 885000\n",
      "  training_iteration: 59\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         1827.53</td><td style=\"text-align: right;\">885000</td><td style=\"text-align: right;\"> 845.432</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             161.413</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 900000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-03-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 875.0844208670434\n",
      "  episode_reward_min: 161.41285571907613\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 300\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 5.684341886080801e-15\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.3437740804785387\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008831373658551661\n",
      "          policy_loss: 0.0007921540675590099\n",
      "          total_loss: 82.50812306484934\n",
      "          vf_explained_var: 0.6802354454994202\n",
      "          vf_loss: 82.50733083304712\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 900000\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.61395348837209\n",
      "    ram_util_percent: 19.055813953488375\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054148320759339945\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.319287301691865\n",
      "    mean_inference_ms: 0.5103292054798745\n",
      "    mean_raw_obs_processing_ms: 4.283458952988487\n",
      "  time_since_restore: 1857.7836146354675\n",
      "  time_this_iter_s: 30.250083446502686\n",
      "  time_total_s: 1857.7836146354675\n",
      "  timers:\n",
      "    learn_throughput: 5930.195\n",
      "    learn_time_ms: 2529.428\n",
      "    sample_throughput: 529.633\n",
      "    sample_time_ms: 28321.475\n",
      "    update_time_ms: 1.039\n",
      "  timestamp: 1674280998\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 60\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         1857.78</td><td style=\"text-align: right;\">900000</td><td style=\"text-align: right;\"> 875.084</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             161.413</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 915000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-03-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 872.656886491027\n",
      "  episode_reward_min: 161.41285571907613\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 305\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.8421709430404005e-15\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.384500479294082\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007053122370589983\n",
      "          policy_loss: 0.0006090306921593719\n",
      "          total_loss: 69.40494565155547\n",
      "          vf_explained_var: 0.36823487281799316\n",
      "          vf_loss: 69.40433636681509\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 915000\n",
      "    num_steps_sampled: 915000\n",
      "    num_steps_trained: 915000\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.251162790697666\n",
      "    ram_util_percent: 19.069767441860467\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05414695810239309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.317828263326355\n",
      "    mean_inference_ms: 0.5102607697203809\n",
      "    mean_raw_obs_processing_ms: 4.283230978749869\n",
      "  time_since_restore: 1887.8895070552826\n",
      "  time_this_iter_s: 30.105892419815063\n",
      "  time_total_s: 1887.8895070552826\n",
      "  timers:\n",
      "    learn_throughput: 5932.848\n",
      "    learn_time_ms: 2528.297\n",
      "    sample_throughput: 529.49\n",
      "    sample_time_ms: 28329.171\n",
      "    update_time_ms: 1.034\n",
      "  timestamp: 1674281028\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 915000\n",
      "  training_iteration: 61\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         1887.89</td><td style=\"text-align: right;\">915000</td><td style=\"text-align: right;\"> 872.657</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             161.413</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 930000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-04-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 897.4733820597714\n",
      "  episode_reward_min: 161.41285571907613\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 310\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.4210854715202003e-15\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.414164380905992\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007794165717849119\n",
      "          policy_loss: 9.79121265364653e-06\n",
      "          total_loss: 113.94349833666269\n",
      "          vf_explained_var: 0.8339182138442993\n",
      "          vf_loss: 113.94348895186084\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 930000\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 930000\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.011363636363637\n",
      "    ram_util_percent: 19.090909090909093\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05414631611515155\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.316577380615252\n",
      "    mean_inference_ms: 0.510203270736723\n",
      "    mean_raw_obs_processing_ms: 4.283269521143408\n",
      "  time_since_restore: 1918.2512457370758\n",
      "  time_this_iter_s: 30.361738681793213\n",
      "  time_total_s: 1918.2512457370758\n",
      "  timers:\n",
      "    learn_throughput: 5943.142\n",
      "    learn_time_ms: 2523.918\n",
      "    sample_throughput: 529.159\n",
      "    sample_time_ms: 28346.877\n",
      "    update_time_ms: 1.04\n",
      "  timestamp: 1674281059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 62\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         1918.25</td><td style=\"text-align: right;\">930000</td><td style=\"text-align: right;\"> 897.473</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             161.413</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 945000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-04-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 924.0774357816817\n",
      "  episode_reward_min: 374.3066943556106\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 315\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.105427357601001e-16\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.4177895291376923\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006441339753848792\n",
      "          policy_loss: 0.0003781930306705378\n",
      "          total_loss: 100.00955013339802\n",
      "          vf_explained_var: 0.5231322050094604\n",
      "          vf_loss: 100.00917195465605\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 945000\n",
      "    num_steps_sampled: 945000\n",
      "    num_steps_trained: 945000\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.524000000000004\n",
      "    ram_util_percent: 19.058000000000003\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05414712874516823\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.315487758696985\n",
      "    mean_inference_ms: 0.5101654908975132\n",
      "    mean_raw_obs_processing_ms: 4.284621705713748\n",
      "  time_since_restore: 1953.870085477829\n",
      "  time_this_iter_s: 35.618839740753174\n",
      "  time_total_s: 1953.870085477829\n",
      "  timers:\n",
      "    learn_throughput: 5913.551\n",
      "    learn_time_ms: 2536.547\n",
      "    sample_throughput: 519.702\n",
      "    sample_time_ms: 28862.699\n",
      "    update_time_ms: 1.034\n",
      "  timestamp: 1674281094\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 945000\n",
      "  training_iteration: 63\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         1953.87</td><td style=\"text-align: right;\">945000</td><td style=\"text-align: right;\"> 924.077</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             374.307</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 960000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-05-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 936.248194986457\n",
      "  episode_reward_min: 454.7115940457872\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 320\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.5527136788005006e-16\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.489526101492219\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009419928762912708\n",
      "          policy_loss: -0.000739204382002985\n",
      "          total_loss: 61.3487390776812\n",
      "          vf_explained_var: 0.33168479800224304\n",
      "          vf_loss: 61.34947810092215\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 960000\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.3953488372093\n",
      "    ram_util_percent: 19.06744186046512\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05414847737817761\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.31440187205344\n",
      "    mean_inference_ms: 0.5101337176603247\n",
      "    mean_raw_obs_processing_ms: 4.28613608304825\n",
      "  time_since_restore: 1983.9409794807434\n",
      "  time_this_iter_s: 30.07089400291443\n",
      "  time_total_s: 1983.9409794807434\n",
      "  timers:\n",
      "    learn_throughput: 5926.782\n",
      "    learn_time_ms: 2530.884\n",
      "    sample_throughput: 519.804\n",
      "    sample_time_ms: 28857.024\n",
      "    update_time_ms: 1.09\n",
      "  timestamp: 1674281125\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 64\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         1983.94</td><td style=\"text-align: right;\">960000</td><td style=\"text-align: right;\"> 936.248</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             454.712</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 975000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-05-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 936.5310820768173\n",
      "  episode_reward_min: 415.12469712010216\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 325\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.7763568394002503e-16\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.495287171662864\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008296748521530367\n",
      "          policy_loss: 0.0005506840420066048\n",
      "          total_loss: 63.26434451119374\n",
      "          vf_explained_var: 0.8053377866744995\n",
      "          vf_loss: 63.26379331491761\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 975000\n",
      "    num_steps_sampled: 975000\n",
      "    num_steps_trained: 975000\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.422727272727276\n",
      "    ram_util_percent: 19.07727272727273\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054150296928063356\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.313357434104968\n",
      "    mean_inference_ms: 0.510109712401023\n",
      "    mean_raw_obs_processing_ms: 4.287794280308742\n",
      "  time_since_restore: 2014.0921070575714\n",
      "  time_this_iter_s: 30.151127576828003\n",
      "  time_total_s: 2014.0921070575714\n",
      "  timers:\n",
      "    learn_throughput: 5932.638\n",
      "    learn_time_ms: 2528.386\n",
      "    sample_throughput: 520.603\n",
      "    sample_time_ms: 28812.733\n",
      "    update_time_ms: 1.091\n",
      "  timestamp: 1674281155\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 975000\n",
      "  training_iteration: 65\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         2014.09</td><td style=\"text-align: right;\">975000</td><td style=\"text-align: right;\"> 936.531</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">             415.125</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 990000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-06-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1950.4478066048139\n",
      "  episode_reward_mean: 914.0347270586522\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 330\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 8.881784197001252e-17\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.514909756385674\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0071422339462546905\n",
      "          policy_loss: 0.0014896387778917106\n",
      "          total_loss: 80.49570333917262\n",
      "          vf_explained_var: 0.9270685911178589\n",
      "          vf_loss: 80.49421383081857\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 990000\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 990000\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.572093023255817\n",
      "    ram_util_percent: 19.11860465116279\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415277785848609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.312351783309123\n",
      "    mean_inference_ms: 0.510094746943453\n",
      "    mean_raw_obs_processing_ms: 4.289642307637666\n",
      "  time_since_restore: 2044.442528963089\n",
      "  time_this_iter_s: 30.350421905517578\n",
      "  time_total_s: 2044.442528963089\n",
      "  timers:\n",
      "    learn_throughput: 5930.319\n",
      "    learn_time_ms: 2529.375\n",
      "    sample_throughput: 521.078\n",
      "    sample_time_ms: 28786.494\n",
      "    update_time_ms: 1.036\n",
      "  timestamp: 1674281185\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 66\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         2044.44</td><td style=\"text-align: right;\">990000</td><td style=\"text-align: right;\"> 914.035</td><td style=\"text-align: right;\">             1950.45</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1005000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-06-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2033.7322553222014\n",
      "  episode_reward_mean: 921.2900157136819\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 335\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 4.440892098500626e-17\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.5281876176090563\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007885026994692058\n",
      "          policy_loss: 0.0011927080605084362\n",
      "          total_loss: 114.42799650289244\n",
      "          vf_explained_var: 0.8094046115875244\n",
      "          vf_loss: 114.4268041481406\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1005000\n",
      "    num_steps_sampled: 1005000\n",
      "    num_steps_trained: 1005000\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.672727272727276\n",
      "    ram_util_percent: 19.10909090909091\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415583894596304\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.31151984025254\n",
      "    mean_inference_ms: 0.5100859254732731\n",
      "    mean_raw_obs_processing_ms: 4.289548279707747\n",
      "  time_since_restore: 2075.201105117798\n",
      "  time_this_iter_s: 30.758576154708862\n",
      "  time_total_s: 2075.201105117798\n",
      "  timers:\n",
      "    learn_throughput: 5928.496\n",
      "    learn_time_ms: 2530.153\n",
      "    sample_throughput: 520.728\n",
      "    sample_time_ms: 28805.829\n",
      "    update_time_ms: 1.037\n",
      "  timestamp: 1674281216\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1005000\n",
      "  training_iteration: 67\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">          2075.2</td><td style=\"text-align: right;\">1005000</td><td style=\"text-align: right;\">  921.29</td><td style=\"text-align: right;\">             2033.73</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1020000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-07-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 923.0457390077786\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 340\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.220446049250313e-17\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.5601893416905805\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008450263090520162\n",
      "          policy_loss: -6.0401902972104945e-05\n",
      "          total_loss: 139.21623681925112\n",
      "          vf_explained_var: 0.7311055660247803\n",
      "          vf_loss: 139.2162971496582\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1020000\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.190909090909088\n",
      "    ram_util_percent: 19.072727272727274\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415888716148325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.310752563248124\n",
      "    mean_inference_ms: 0.510080854573754\n",
      "    mean_raw_obs_processing_ms: 4.289570152496014\n",
      "  time_since_restore: 2105.784030199051\n",
      "  time_this_iter_s: 30.58292508125305\n",
      "  time_total_s: 2105.784030199051\n",
      "  timers:\n",
      "    learn_throughput: 5935.556\n",
      "    learn_time_ms: 2527.143\n",
      "    sample_throughput: 529.965\n",
      "    sample_time_ms: 28303.736\n",
      "    update_time_ms: 0.974\n",
      "  timestamp: 1674281247\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 68\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         2105.78</td><td style=\"text-align: right;\">1020000</td><td style=\"text-align: right;\"> 923.046</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1035000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-08-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 904.3561571668232\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 345\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.1102230246251564e-17\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.595196535425671\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008491242424012302\n",
      "          policy_loss: 0.0001786668342932806\n",
      "          total_loss: 98.53028551198669\n",
      "          vf_explained_var: 0.8944308757781982\n",
      "          vf_loss: 98.53010674816066\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1035000\n",
      "    num_steps_sampled: 1035000\n",
      "    num_steps_trained: 1035000\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.606122448979594\n",
      "    ram_util_percent: 19.059183673469388\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05416189828206532\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.309953291379663\n",
      "    mean_inference_ms: 0.5101042299540128\n",
      "    mean_raw_obs_processing_ms: 4.291052444062467\n",
      "  time_since_restore: 2140.611080646515\n",
      "  time_this_iter_s: 34.82705044746399\n",
      "  time_total_s: 2140.611080646515\n",
      "  timers:\n",
      "    learn_throughput: 6083.618\n",
      "    learn_time_ms: 2465.638\n",
      "    sample_throughput: 520.163\n",
      "    sample_time_ms: 28837.089\n",
      "    update_time_ms: 0.927\n",
      "  timestamp: 1674281282\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1035000\n",
      "  training_iteration: 69\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         2140.61</td><td style=\"text-align: right;\">1035000</td><td style=\"text-align: right;\"> 904.356</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1050000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-08-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 900.8613326412556\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 350\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 5.551115123125782e-18\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.630144268375332\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008547011552402712\n",
      "          policy_loss: 0.0010341444498685709\n",
      "          total_loss: 63.13240336725267\n",
      "          vf_explained_var: 0.5262989401817322\n",
      "          vf_loss: 63.131369618238026\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1050000\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1050000\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.893181818181816\n",
      "    ram_util_percent: 19.07045454545455\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05416565578477409\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.309126941552038\n",
      "    mean_inference_ms: 0.5101334850906292\n",
      "    mean_raw_obs_processing_ms: 4.292523627693096\n",
      "  time_since_restore: 2170.8862607479095\n",
      "  time_this_iter_s: 30.275180101394653\n",
      "  time_total_s: 2170.8862607479095\n",
      "  timers:\n",
      "    learn_throughput: 6078.199\n",
      "    learn_time_ms: 2467.836\n",
      "    sample_throughput: 520.158\n",
      "    sample_time_ms: 28837.367\n",
      "    update_time_ms: 0.922\n",
      "  timestamp: 1674281312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 70\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         2170.89</td><td style=\"text-align: right;\">1050000</td><td style=\"text-align: right;\"> 900.861</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1065000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-09-13\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 890.3023369302778\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 355\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.775557561562891e-18\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.650942558959379\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007675545015038201\n",
      "          policy_loss: 0.00015386858544612334\n",
      "          total_loss: 68.96787727646908\n",
      "          vf_explained_var: 0.6859857439994812\n",
      "          vf_loss: 68.9677236460023\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1065000\n",
      "    num_steps_sampled: 1065000\n",
      "    num_steps_trained: 1065000\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.0\n",
      "    ram_util_percent: 19.00172413793103\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05417011892921221\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.308323269846455\n",
      "    mean_inference_ms: 0.5101699777863379\n",
      "    mean_raw_obs_processing_ms: 4.296495770444708\n",
      "  time_since_restore: 2211.604493379593\n",
      "  time_this_iter_s: 40.71823263168335\n",
      "  time_total_s: 2211.604493379593\n",
      "  timers:\n",
      "    learn_throughput: 6079.34\n",
      "    learn_time_ms: 2467.373\n",
      "    sample_throughput: 501.688\n",
      "    sample_time_ms: 29899.05\n",
      "    update_time_ms: 0.927\n",
      "  timestamp: 1674281353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1065000\n",
      "  training_iteration: 71\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">          2211.6</td><td style=\"text-align: right;\">1065000</td><td style=\"text-align: right;\"> 890.302</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1080000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-09-43\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 895.6760455141603\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 360\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.3877787807814456e-18\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.671334307274576\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012176752202096961\n",
      "          policy_loss: -0.00045763179186289596\n",
      "          total_loss: 102.9008138769764\n",
      "          vf_explained_var: 0.8949189782142639\n",
      "          vf_loss: 102.90127098762383\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1080000\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.602325581395345\n",
      "    ram_util_percent: 19.158139534883723\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05417513715241883\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.30763860069197\n",
      "    mean_inference_ms: 0.5102116218555628\n",
      "    mean_raw_obs_processing_ms: 4.300334827196312\n",
      "  time_since_restore: 2241.75359916687\n",
      "  time_this_iter_s: 30.14910578727722\n",
      "  time_total_s: 2241.75359916687\n",
      "  timers:\n",
      "    learn_throughput: 6077.203\n",
      "    learn_time_ms: 2468.241\n",
      "    sample_throughput: 502.059\n",
      "    sample_time_ms: 29876.94\n",
      "    update_time_ms: 0.921\n",
      "  timestamp: 1674281383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 72\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         2241.75</td><td style=\"text-align: right;\">1080000</td><td style=\"text-align: right;\"> 895.676</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1095000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-10-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 880.2149237884038\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 365\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.3877787807814456e-18\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.724678174519943\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011658232197935344\n",
      "          policy_loss: 0.00033782870761292467\n",
      "          total_loss: 76.0508700677904\n",
      "          vf_explained_var: 0.8463124632835388\n",
      "          vf_loss: 76.05053226018356\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1095000\n",
      "    num_steps_sampled: 1095000\n",
      "    num_steps_trained: 1095000\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.749019607843138\n",
      "    ram_util_percent: 19.10980392156863\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05418027446922956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.306940766321553\n",
      "    mean_inference_ms: 0.51025666562132\n",
      "    mean_raw_obs_processing_ms: 4.30549795120945\n",
      "  time_since_restore: 2277.198271751404\n",
      "  time_this_iter_s: 35.44467258453369\n",
      "  time_total_s: 2277.198271751404\n",
      "  timers:\n",
      "    learn_throughput: 6095.527\n",
      "    learn_time_ms: 2460.821\n",
      "    sample_throughput: 502.23\n",
      "    sample_time_ms: 29866.814\n",
      "    update_time_ms: 0.979\n",
      "  timestamp: 1674281418\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1095000\n",
      "  training_iteration: 73\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">          2277.2</td><td style=\"text-align: right;\">1095000</td><td style=\"text-align: right;\"> 880.215</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1110000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-10-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 873.6303587190846\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 370\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.3877787807814456e-18\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.7379005036111606\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007570901721907388\n",
      "          policy_loss: 0.0005844117580297388\n",
      "          total_loss: 90.3317166974989\n",
      "          vf_explained_var: 0.8070512413978577\n",
      "          vf_loss: 90.33113211453971\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1110000\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1110000\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.971428571428575\n",
      "    ram_util_percent: 19.161904761904765\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054185559055978924\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.30625042947405\n",
      "    mean_inference_ms: 0.5103034326686126\n",
      "    mean_raw_obs_processing_ms: 4.31056374179116\n",
      "  time_since_restore: 2306.9196767807007\n",
      "  time_this_iter_s: 29.721405029296875\n",
      "  time_total_s: 2306.9196767807007\n",
      "  timers:\n",
      "    learn_throughput: 6156.056\n",
      "    learn_time_ms: 2436.625\n",
      "    sample_throughput: 502.409\n",
      "    sample_time_ms: 29856.166\n",
      "    update_time_ms: 0.927\n",
      "  timestamp: 1674281448\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 74\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         2306.92</td><td style=\"text-align: right;\">1110000</td><td style=\"text-align: right;\">  873.63</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1125000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-11-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 851.501684376713\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 375\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.938893903907228e-19\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.7376464637659366\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007927163777464438\n",
      "          policy_loss: 0.0007161791319958866\n",
      "          total_loss: 86.82359641123627\n",
      "          vf_explained_var: 0.8481884002685547\n",
      "          vf_loss: 86.82288080474078\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1125000\n",
      "    num_steps_sampled: 1125000\n",
      "    num_steps_trained: 1125000\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.32325581395348\n",
      "    ram_util_percent: 19.16744186046512\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054190864477401464\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.30553700727624\n",
      "    mean_inference_ms: 0.510353930909905\n",
      "    mean_raw_obs_processing_ms: 4.315470670013113\n",
      "  time_since_restore: 2336.856647491455\n",
      "  time_this_iter_s: 29.936970710754395\n",
      "  time_total_s: 2336.856647491455\n",
      "  timers:\n",
      "    learn_throughput: 6231.607\n",
      "    learn_time_ms: 2407.084\n",
      "    sample_throughput: 502.274\n",
      "    sample_time_ms: 29864.169\n",
      "    update_time_ms: 0.955\n",
      "  timestamp: 1674281478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1125000\n",
      "  training_iteration: 75\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         2336.86</td><td style=\"text-align: right;\">1125000</td><td style=\"text-align: right;\"> 851.502</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1140000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-11-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 828.3459912960831\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 380\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.469446951953614e-19\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.7533693646980546\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009484962401162443\n",
      "          policy_loss: 0.0008367044464448245\n",
      "          total_loss: 107.92259432259253\n",
      "          vf_explained_var: 0.8345099687576294\n",
      "          vf_loss: 107.92175804396807\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1140000\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.486046511627908\n",
      "    ram_util_percent: 19.167441860465118\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054196562764306566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.3047877229307225\n",
      "    mean_inference_ms: 0.5104083537847977\n",
      "    mean_raw_obs_processing_ms: 4.320336646941115\n",
      "  time_since_restore: 2367.3158111572266\n",
      "  time_this_iter_s: 30.459163665771484\n",
      "  time_total_s: 2367.3158111572266\n",
      "  timers:\n",
      "    learn_throughput: 6209.21\n",
      "    learn_time_ms: 2415.766\n",
      "    sample_throughput: 502.237\n",
      "    sample_time_ms: 29866.355\n",
      "    update_time_ms: 0.959\n",
      "  timestamp: 1674281509\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 76\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         2367.32</td><td style=\"text-align: right;\">1140000</td><td style=\"text-align: right;\"> 828.346</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1155000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-12-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 814.5967817756333\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 385\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.734723475976807e-19\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.767932250136036\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00971542176674253\n",
      "          policy_loss: 0.0014361466289008573\n",
      "          total_loss: 108.29803411677732\n",
      "          vf_explained_var: 0.8199159502983093\n",
      "          vf_loss: 108.2965981758247\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1155000\n",
      "    num_steps_sampled: 1155000\n",
      "    num_steps_trained: 1155000\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.09090909090909\n",
      "    ram_util_percent: 19.159090909090914\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05420216178161209\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.304025924333731\n",
      "    mean_inference_ms: 0.510462087940306\n",
      "    mean_raw_obs_processing_ms: 4.325122056752457\n",
      "  time_since_restore: 2397.869882106781\n",
      "  time_this_iter_s: 30.554070949554443\n",
      "  time_total_s: 2397.869882106781\n",
      "  timers:\n",
      "    learn_throughput: 6219.55\n",
      "    learn_time_ms: 2411.75\n",
      "    sample_throughput: 502.512\n",
      "    sample_time_ms: 29850.05\n",
      "    update_time_ms: 0.948\n",
      "  timestamp: 1674281539\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1155000\n",
      "  training_iteration: 77\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         2397.87</td><td style=\"text-align: right;\">1155000</td><td style=\"text-align: right;\"> 814.597</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1170000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-12-50\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 811.1644631636387\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 390\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 8.673617379884035e-20\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.815757413233741\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009349877290798699\n",
      "          policy_loss: -0.0006030276180955313\n",
      "          total_loss: 124.193884021953\n",
      "          vf_explained_var: 0.8236372470855713\n",
      "          vf_loss: 124.19448705123642\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1170000\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1170000\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.947727272727278\n",
      "    ram_util_percent: 19.16818181818182\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054207719702334345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.303259588778747\n",
      "    mean_inference_ms: 0.5105157068009494\n",
      "    mean_raw_obs_processing_ms: 4.328381037859211\n",
      "  time_since_restore: 2428.1913454532623\n",
      "  time_this_iter_s: 30.321463346481323\n",
      "  time_total_s: 2428.1913454532623\n",
      "  timers:\n",
      "    learn_throughput: 6243.492\n",
      "    learn_time_ms: 2402.502\n",
      "    sample_throughput: 502.797\n",
      "    sample_time_ms: 29833.109\n",
      "    update_time_ms: 0.948\n",
      "  timestamp: 1674281570\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 78\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         2428.19</td><td style=\"text-align: right;\">1170000</td><td style=\"text-align: right;\"> 811.164</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1185000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-13-20\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 807.5645499139729\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 395\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 4.3368086899420174e-20\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.8369415800450213\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00977001907433735\n",
      "          policy_loss: 0.0004373327982848731\n",
      "          total_loss: 109.11203708648682\n",
      "          vf_explained_var: 0.7494221925735474\n",
      "          vf_loss: 109.1115997896356\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1185000\n",
      "    num_steps_sampled: 1185000\n",
      "    num_steps_trained: 1185000\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.55348837209302\n",
      "    ram_util_percent: 19.16046511627907\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05421368065206887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.302537682568965\n",
      "    mean_inference_ms: 0.5105737229109513\n",
      "    mean_raw_obs_processing_ms: 4.331710262901749\n",
      "  time_since_restore: 2458.6110620498657\n",
      "  time_this_iter_s: 30.419716596603394\n",
      "  time_total_s: 2458.6110620498657\n",
      "  timers:\n",
      "    learn_throughput: 6080.553\n",
      "    learn_time_ms: 2466.881\n",
      "    sample_throughput: 511.457\n",
      "    sample_time_ms: 29328.004\n",
      "    update_time_ms: 0.951\n",
      "  timestamp: 1674281600\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1185000\n",
      "  training_iteration: 79\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         2458.61</td><td style=\"text-align: right;\">1185000</td><td style=\"text-align: right;\"> 807.565</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1200000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-13-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2327.3221164295965\n",
      "  episode_reward_mean: 806.9660729827638\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 400\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.1684043449710087e-20\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.864551997992952\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00995490398375813\n",
      "          policy_loss: 0.0017395486336959115\n",
      "          total_loss: 99.90399890511723\n",
      "          vf_explained_var: 0.5321102738380432\n",
      "          vf_loss: 99.90225939831491\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1200000\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1200000\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.238000000000003\n",
      "    ram_util_percent: 19.116\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05421967402735937\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.30183561660791\n",
      "    mean_inference_ms: 0.5106324918107488\n",
      "    mean_raw_obs_processing_ms: 4.336137887113507\n",
      "  time_since_restore: 2493.915448665619\n",
      "  time_this_iter_s: 35.304386615753174\n",
      "  time_total_s: 2493.915448665619\n",
      "  timers:\n",
      "    learn_throughput: 6150.405\n",
      "    learn_time_ms: 2438.864\n",
      "    sample_throughput: 502.362\n",
      "    sample_time_ms: 29858.966\n",
      "    update_time_ms: 0.958\n",
      "  timestamp: 1674281635\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 80\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2493.92</td><td style=\"text-align: right;\">1200000</td><td style=\"text-align: right;\"> 806.966</td><td style=\"text-align: right;\">             2327.32</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1215000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-14-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 823.7667818595073\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 405\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0842021724855043e-20\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.868079846390223\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008705226493222777\n",
      "          policy_loss: 0.0020313643378805433\n",
      "          total_loss: 167.23995640641553\n",
      "          vf_explained_var: 0.7984203100204468\n",
      "          vf_loss: 167.23792586892338\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1215000\n",
      "    num_steps_sampled: 1215000\n",
      "    num_steps_trained: 1215000\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.450000000000003\n",
      "    ram_util_percent: 19.136538461538468\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05422530692312351\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.3012433847482\n",
      "    mean_inference_ms: 0.5106889572966125\n",
      "    mean_raw_obs_processing_ms: 4.341463835995574\n",
      "  time_since_restore: 2529.6208374500275\n",
      "  time_this_iter_s: 35.70538878440857\n",
      "  time_total_s: 2529.6208374500275\n",
      "  timers:\n",
      "    learn_throughput: 6126.568\n",
      "    learn_time_ms: 2448.353\n",
      "    sample_throughput: 511.104\n",
      "    sample_time_ms: 29348.214\n",
      "    update_time_ms: 0.959\n",
      "  timestamp: 1674281671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1215000\n",
      "  training_iteration: 81\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         2529.62</td><td style=\"text-align: right;\">1215000</td><td style=\"text-align: right;\"> 823.767</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1230000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-15-08\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 819.0427512041613\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 410\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 5.421010862427522e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.907616707227998\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011876657791290912\n",
      "          policy_loss: 0.0016731291220097217\n",
      "          total_loss: 113.29210739620662\n",
      "          vf_explained_var: 0.6656308770179749\n",
      "          vf_loss: 113.2904344978979\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1230000\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1230000\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.199999999999996\n",
      "    ram_util_percent: 19.123076923076926\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05423061004641914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.300622606142936\n",
      "    mean_inference_ms: 0.5107414577202491\n",
      "    mean_raw_obs_processing_ms: 4.3479914271406095\n",
      "  time_since_restore: 2566.0063650608063\n",
      "  time_this_iter_s: 36.38552761077881\n",
      "  time_total_s: 2566.0063650608063\n",
      "  timers:\n",
      "    learn_throughput: 6111.884\n",
      "    learn_time_ms: 2454.235\n",
      "    sample_throughput: 500.568\n",
      "    sample_time_ms: 29965.965\n",
      "    update_time_ms: 0.96\n",
      "  timestamp: 1674281708\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 82\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         2566.01</td><td style=\"text-align: right;\">1230000</td><td style=\"text-align: right;\"> 819.043</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1245000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-15-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 823.8403158045304\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 415\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 5.421010862427522e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.922849872152684\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007818706638565485\n",
      "          policy_loss: 0.0016427361982543085\n",
      "          total_loss: 138.54537121724275\n",
      "          vf_explained_var: 0.7550708055496216\n",
      "          vf_loss: 138.543728013766\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1245000\n",
      "    num_steps_sampled: 1245000\n",
      "    num_steps_trained: 1245000\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.753488372093013\n",
      "    ram_util_percent: 19.16744186046512\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05423404291474609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2999769384591495\n",
      "    mean_inference_ms: 0.5107743027682299\n",
      "    mean_raw_obs_processing_ms: 4.352995525000047\n",
      "  time_since_restore: 2596.157732486725\n",
      "  time_this_iter_s: 30.15136742591858\n",
      "  time_total_s: 2596.157732486725\n",
      "  timers:\n",
      "    learn_throughput: 6131.215\n",
      "    learn_time_ms: 2446.497\n",
      "    sample_throughput: 509.433\n",
      "    sample_time_ms: 29444.478\n",
      "    update_time_ms: 0.903\n",
      "  timestamp: 1674281738\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1245000\n",
      "  training_iteration: 83\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         2596.16</td><td style=\"text-align: right;\">1245000</td><td style=\"text-align: right;\">  823.84</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1260000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-16-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 832.5203862454955\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 420\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.710505431213761e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.948013189283468\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01083101838101026\n",
      "          policy_loss: 0.0014337071207730825\n",
      "          total_loss: 119.21790934093929\n",
      "          vf_explained_var: 0.7987046837806702\n",
      "          vf_loss: 119.21647531541727\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1260000\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1260000\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.34222222222223\n",
      "    ram_util_percent: 19.164444444444452\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054237054833159035\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.299361517889933\n",
      "    mean_inference_ms: 0.5108046270534627\n",
      "    mean_raw_obs_processing_ms: 4.358118518929752\n",
      "  time_since_restore: 2627.576678752899\n",
      "  time_this_iter_s: 31.418946266174316\n",
      "  time_total_s: 2627.576678752899\n",
      "  timers:\n",
      "    learn_throughput: 6041.864\n",
      "    learn_time_ms: 2482.678\n",
      "    sample_throughput: 507.133\n",
      "    sample_time_ms: 29578.031\n",
      "    update_time_ms: 0.907\n",
      "  timestamp: 1674281769\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 84\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         2627.58</td><td style=\"text-align: right;\">1260000</td><td style=\"text-align: right;\">  832.52</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1275000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-16-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 859.9788808643585\n",
      "  episode_reward_min: 189.8595620566044\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 425\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.710505431213761e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.9780588137901436\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009713910315449804\n",
      "          policy_loss: 7.442246049137439e-05\n",
      "          total_loss: 123.09338705418473\n",
      "          vf_explained_var: 0.47615718841552734\n",
      "          vf_loss: 123.09331237340378\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1275000\n",
      "    num_steps_sampled: 1275000\n",
      "    num_steps_trained: 1275000\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.195238095238096\n",
      "    ram_util_percent: 19.17142857142857\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054239752508472246\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2988148207750125\n",
      "    mean_inference_ms: 0.5108312660985821\n",
      "    mean_raw_obs_processing_ms: 4.3631607073739325\n",
      "  time_since_restore: 2657.2298259735107\n",
      "  time_this_iter_s: 29.653147220611572\n",
      "  time_total_s: 2657.2298259735107\n",
      "  timers:\n",
      "    learn_throughput: 5964.126\n",
      "    learn_time_ms: 2515.037\n",
      "    sample_throughput: 508.175\n",
      "    sample_time_ms: 29517.388\n",
      "    update_time_ms: 0.889\n",
      "  timestamp: 1674281799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1275000\n",
      "  training_iteration: 85\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         2657.23</td><td style=\"text-align: right;\">1275000</td><td style=\"text-align: right;\"> 859.979</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">              189.86</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1290000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-17-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 893.8125312167434\n",
      "  episode_reward_min: 421.9072100529126\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 430\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.3552527156068804e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.988777529991279\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01039047711343634\n",
      "          policy_loss: 0.0008526508337265607\n",
      "          total_loss: 137.66247916787358\n",
      "          vf_explained_var: 0.6575086712837219\n",
      "          vf_loss: 137.66162653131\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1290000\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1290000\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.486046511627904\n",
      "    ram_util_percent: 19.176744186046516\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424207481429936\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.298270356394\n",
      "    mean_inference_ms: 0.5108541607005924\n",
      "    mean_raw_obs_processing_ms: 4.368111276270469\n",
      "  time_since_restore: 2687.26798081398\n",
      "  time_this_iter_s: 30.03815484046936\n",
      "  time_total_s: 2687.26798081398\n",
      "  timers:\n",
      "    learn_throughput: 5975.958\n",
      "    learn_time_ms: 2510.058\n",
      "    sample_throughput: 508.814\n",
      "    sample_time_ms: 29480.297\n",
      "    update_time_ms: 0.886\n",
      "  timestamp: 1674281829\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 86\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         2687.27</td><td style=\"text-align: right;\">1290000</td><td style=\"text-align: right;\"> 893.813</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             421.907</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1305000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-17-44\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 903.643547913747\n",
      "  episode_reward_min: 421.9072100529126\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 435\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.3552527156068804e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.011078056440515\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010212873416996976\n",
      "          policy_loss: 0.0008518116588120239\n",
      "          total_loss: 130.709392114413\n",
      "          vf_explained_var: 0.31457793712615967\n",
      "          vf_loss: 130.70853991104386\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1305000\n",
      "    num_steps_sampled: 1305000\n",
      "    num_steps_trained: 1305000\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.118\n",
      "    ram_util_percent: 19.130000000000003\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424374497149469\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.297667644487939\n",
      "    mean_inference_ms: 0.5108705687260158\n",
      "    mean_raw_obs_processing_ms: 4.374104421664759\n",
      "  time_since_restore: 2722.430839061737\n",
      "  time_this_iter_s: 35.16285824775696\n",
      "  time_total_s: 2722.430839061737\n",
      "  timers:\n",
      "    learn_throughput: 5970.427\n",
      "    learn_time_ms: 2512.383\n",
      "    sample_throughput: 501.024\n",
      "    sample_time_ms: 29938.715\n",
      "    update_time_ms: 0.933\n",
      "  timestamp: 1674281864\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1305000\n",
      "  training_iteration: 87\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         2722.43</td><td style=\"text-align: right;\">1305000</td><td style=\"text-align: right;\"> 903.644</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             421.907</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1320000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-18-15\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 896.4547161483363\n",
      "  episode_reward_min: 541.0367135623936\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 440\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.3552527156068804e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.0402769220077386\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01112752028304271\n",
      "          policy_loss: 0.0009051691286928826\n",
      "          total_loss: 115.90946195085169\n",
      "          vf_explained_var: 0.16911838948726654\n",
      "          vf_loss: 115.90855660357718\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1320000\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1320000\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.127272727272725\n",
      "    ram_util_percent: 19.22045454545455\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424512208040114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.296998482047657\n",
      "    mean_inference_ms: 0.5109034394053019\n",
      "    mean_raw_obs_processing_ms: 4.380165011391474\n",
      "  time_since_restore: 2752.8672544956207\n",
      "  time_this_iter_s: 30.436415433883667\n",
      "  time_total_s: 2752.8672544956207\n",
      "  timers:\n",
      "    learn_throughput: 5940.286\n",
      "    learn_time_ms: 2525.131\n",
      "    sample_throughput: 501.044\n",
      "    sample_time_ms: 29937.462\n",
      "    update_time_ms: 0.932\n",
      "  timestamp: 1674281895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 88\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         2752.87</td><td style=\"text-align: right;\">1320000</td><td style=\"text-align: right;\"> 896.455</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             541.037</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1335000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-18-45\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 921.3745703079098\n",
      "  episode_reward_min: 541.0367135623936\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 445\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.3552527156068804e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.049863589214066\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009241801638353314\n",
      "          policy_loss: 0.000891422191476923\n",
      "          total_loss: 176.9894886922028\n",
      "          vf_explained_var: 0.6612598299980164\n",
      "          vf_loss: 176.98859657675533\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1335000\n",
      "    num_steps_sampled: 1335000\n",
      "    num_steps_trained: 1335000\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.744186046511633\n",
      "    ram_util_percent: 19.188372093023254\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424645006443912\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.296405801169994\n",
      "    mean_inference_ms: 0.5109114467796684\n",
      "    mean_raw_obs_processing_ms: 4.38481312180637\n",
      "  time_since_restore: 2782.9813442230225\n",
      "  time_this_iter_s: 30.114089727401733\n",
      "  time_total_s: 2782.9813442230225\n",
      "  timers:\n",
      "    learn_throughput: 5939.249\n",
      "    learn_time_ms: 2525.572\n",
      "    sample_throughput: 501.567\n",
      "    sample_time_ms: 29906.29\n",
      "    update_time_ms: 0.968\n",
      "  timestamp: 1674281925\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1335000\n",
      "  training_iteration: 89\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         2782.98</td><td style=\"text-align: right;\">1335000</td><td style=\"text-align: right;\"> 921.375</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             541.037</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1350000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-19-16\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 958.4217675469409\n",
      "  episode_reward_min: 541.0367135623936\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 450\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.0759520160949836\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011494141095349606\n",
      "          policy_loss: 0.0008119411334411194\n",
      "          total_loss: 202.17284455380198\n",
      "          vf_explained_var: 0.6893036365509033\n",
      "          vf_loss: 202.17203237242617\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1350000\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1350000\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.30454545454546\n",
      "    ram_util_percent: 19.25681818181818\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424767299892093\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295919602696304\n",
      "    mean_inference_ms: 0.5109206461292835\n",
      "    mean_raw_obs_processing_ms: 4.38937132409082\n",
      "  time_since_restore: 2813.9269275665283\n",
      "  time_this_iter_s: 30.94558334350586\n",
      "  time_total_s: 2813.9269275665283\n",
      "  timers:\n",
      "    learn_throughput: 5882.725\n",
      "    learn_time_ms: 2549.839\n",
      "    sample_throughput: 509.404\n",
      "    sample_time_ms: 29446.175\n",
      "    update_time_ms: 0.97\n",
      "  timestamp: 1674281956\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 90\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         2813.93</td><td style=\"text-align: right;\">1350000</td><td style=\"text-align: right;\"> 958.422</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             541.037</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1365000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-19-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 979.1517779641622\n",
      "  episode_reward_min: 541.0367135623936\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 455\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.090340973765163\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012483311686338752\n",
      "          policy_loss: 0.0005772947361377084\n",
      "          total_loss: 151.34648801512637\n",
      "          vf_explained_var: 0.6171988844871521\n",
      "          vf_loss: 151.3459106671608\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1365000\n",
      "    num_steps_sampled: 1365000\n",
      "    num_steps_trained: 1365000\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.881818181818186\n",
      "    ram_util_percent: 19.26136363636363\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054248706950800925\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295489801667239\n",
      "    mean_inference_ms: 0.5109281821080699\n",
      "    mean_raw_obs_processing_ms: 4.391508945921475\n",
      "  time_since_restore: 2844.4231588840485\n",
      "  time_this_iter_s: 30.49623131752014\n",
      "  time_total_s: 2844.4231588840485\n",
      "  timers:\n",
      "    learn_throughput: 5898.49\n",
      "    learn_time_ms: 2543.024\n",
      "    sample_throughput: 518.459\n",
      "    sample_time_ms: 28931.908\n",
      "    update_time_ms: 1.019\n",
      "  timestamp: 1674281987\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1365000\n",
      "  training_iteration: 91\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         2844.42</td><td style=\"text-align: right;\">1365000</td><td style=\"text-align: right;\"> 979.152</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             541.037</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1380000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-20-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 996.4987697011617\n",
      "  episode_reward_min: 541.0367135623936\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 460\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.1264995777000815\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011609708112121383\n",
      "          policy_loss: 0.0014985597130084821\n",
      "          total_loss: 133.4802259655322\n",
      "          vf_explained_var: 0.4517723023891449\n",
      "          vf_loss: 133.47872689295625\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1380000\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1380000\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.432558139534876\n",
      "    ram_util_percent: 19.25348837209302\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054249553007006235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295056527130461\n",
      "    mean_inference_ms: 0.5109345129751169\n",
      "    mean_raw_obs_processing_ms: 4.393725708238182\n",
      "  time_since_restore: 2874.807510137558\n",
      "  time_this_iter_s: 30.38435125350952\n",
      "  time_total_s: 2874.807510137558\n",
      "  timers:\n",
      "    learn_throughput: 5917.399\n",
      "    learn_time_ms: 2534.897\n",
      "    sample_throughput: 529.288\n",
      "    sample_time_ms: 28339.954\n",
      "    update_time_ms: 1.015\n",
      "  timestamp: 1674282017\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 92\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         2874.81</td><td style=\"text-align: right;\">1380000</td><td style=\"text-align: right;\"> 996.499</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             541.037</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1395000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-20-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 1016.2254133881572\n",
      "  episode_reward_min: 649.1553488283403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 465\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.1355686905020375\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011680488064404701\n",
      "          policy_loss: 0.0012960875268741433\n",
      "          total_loss: 145.88162412158513\n",
      "          vf_explained_var: 0.7015079259872437\n",
      "          vf_loss: 145.88032829155355\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1395000\n",
      "    num_steps_sampled: 1395000\n",
      "    num_steps_trained: 1395000\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.318181818181817\n",
      "    ram_util_percent: 19.256818181818176\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425034378393409\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.29466792315425\n",
      "    mean_inference_ms: 0.5109404527563721\n",
      "    mean_raw_obs_processing_ms: 4.394777207309124\n",
      "  time_since_restore: 2905.4487364292145\n",
      "  time_this_iter_s: 30.641226291656494\n",
      "  time_total_s: 2905.4487364292145\n",
      "  timers:\n",
      "    learn_throughput: 5885.53\n",
      "    learn_time_ms: 2548.623\n",
      "    sample_throughput: 528.63\n",
      "    sample_time_ms: 28375.256\n",
      "    update_time_ms: 1.015\n",
      "  timestamp: 1674282048\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1395000\n",
      "  training_iteration: 93\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         2905.45</td><td style=\"text-align: right;\">1395000</td><td style=\"text-align: right;\"> 1016.23</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             649.155</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1410000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-21-19\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 1028.9380323546484\n",
      "  episode_reward_min: 649.1553488283403\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 470\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.168814568196313\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010716978597857906\n",
      "          policy_loss: 0.0017113162721586177\n",
      "          total_loss: 146.67609171139992\n",
      "          vf_explained_var: 0.44932422041893005\n",
      "          vf_loss: 146.6743809198929\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1410000\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1410000\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.15454545454545\n",
      "    ram_util_percent: 19.26136363636363\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425117891274842\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.294315258959504\n",
      "    mean_inference_ms: 0.5109466297462102\n",
      "    mean_raw_obs_processing_ms: 4.396055133540113\n",
      "  time_since_restore: 2936.008430957794\n",
      "  time_this_iter_s: 30.559694528579712\n",
      "  time_total_s: 2936.008430957794\n",
      "  timers:\n",
      "    learn_throughput: 5891.072\n",
      "    learn_time_ms: 2546.226\n",
      "    sample_throughput: 530.19\n",
      "    sample_time_ms: 28291.734\n",
      "    update_time_ms: 1.016\n",
      "  timestamp: 1674282079\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 94\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         2936.01</td><td style=\"text-align: right;\">1410000</td><td style=\"text-align: right;\"> 1028.94</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             649.155</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1425000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-21-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 1042.383055798219\n",
      "  episode_reward_min: 715.1992396627045\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 475\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.179508427038031\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011464295226518222\n",
      "          policy_loss: 0.0004916708186363517\n",
      "          total_loss: 147.74743996797983\n",
      "          vf_explained_var: 0.7513620257377625\n",
      "          vf_loss: 147.74694881439208\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1425000\n",
      "    num_steps_sampled: 1425000\n",
      "    num_steps_trained: 1425000\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.372093023255808\n",
      "    ram_util_percent: 19.260465116279065\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425197467843565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.294006700546913\n",
      "    mean_inference_ms: 0.5109518229219543\n",
      "    mean_raw_obs_processing_ms: 4.3974068048445\n",
      "  time_since_restore: 2966.1093349456787\n",
      "  time_this_iter_s: 30.10090398788452\n",
      "  time_total_s: 2966.1093349456787\n",
      "  timers:\n",
      "    learn_throughput: 5904.032\n",
      "    learn_time_ms: 2540.637\n",
      "    sample_throughput: 529.247\n",
      "    sample_time_ms: 28342.15\n",
      "    update_time_ms: 1.014\n",
      "  timestamp: 1674282109\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1425000\n",
      "  training_iteration: 95\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         2966.11</td><td style=\"text-align: right;\">1425000</td><td style=\"text-align: right;\"> 1042.38</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             715.199</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1440000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-22-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 1049.0392871364418\n",
      "  episode_reward_min: 715.1992396627045\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 480\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.223970840543003\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012669275241517\n",
      "          policy_loss: 0.0023920976967250897\n",
      "          total_loss: 146.27594923245704\n",
      "          vf_explained_var: 0.6129995584487915\n",
      "          vf_loss: 146.27355773085256\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1440000\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1440000\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.311999999999998\n",
      "    ram_util_percent: 19.203999999999997\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425296317026244\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.293711070063924\n",
      "    mean_inference_ms: 0.5109585634471085\n",
      "    mean_raw_obs_processing_ms: 4.399698706044917\n",
      "  time_since_restore: 3001.708562850952\n",
      "  time_this_iter_s: 35.59922790527344\n",
      "  time_total_s: 3001.708562850952\n",
      "  timers:\n",
      "    learn_throughput: 5949.483\n",
      "    learn_time_ms: 2521.228\n",
      "    sample_throughput: 518.714\n",
      "    sample_time_ms: 28917.644\n",
      "    update_time_ms: 1.021\n",
      "  timestamp: 1674282144\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 96\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         3001.71</td><td style=\"text-align: right;\">1440000</td><td style=\"text-align: right;\"> 1049.04</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             715.199</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1455000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-22-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 1057.3409259508246\n",
      "  episode_reward_min: 715.1992396627045\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 485\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.2507618372723206\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01215170180296247\n",
      "          policy_loss: 0.0019583305829378255\n",
      "          total_loss: 161.57195632417324\n",
      "          vf_explained_var: 0.7453130483627319\n",
      "          vf_loss: 161.56999771312132\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1455000\n",
      "    num_steps_sampled: 1455000\n",
      "    num_steps_trained: 1455000\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.48372093023256\n",
      "    ram_util_percent: 19.25348837209302\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425393086303546\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.293425579328129\n",
      "    mean_inference_ms: 0.5109651998242443\n",
      "    mean_raw_obs_processing_ms: 4.402007920054123\n",
      "  time_since_restore: 3031.7804634571075\n",
      "  time_this_iter_s: 30.071900606155396\n",
      "  time_total_s: 3031.7804634571075\n",
      "  timers:\n",
      "    learn_throughput: 6034.422\n",
      "    learn_time_ms: 2485.739\n",
      "    sample_throughput: 527.349\n",
      "    sample_time_ms: 28444.161\n",
      "    update_time_ms: 0.944\n",
      "  timestamp: 1674282174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1455000\n",
      "  training_iteration: 97\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         3031.78</td><td style=\"text-align: right;\">1455000</td><td style=\"text-align: right;\"> 1057.34</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             715.199</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1470000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-23-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 1056.3372703378084\n",
      "  episode_reward_min: 715.1992396627045\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 490\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.271073924686949\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01161127783333689\n",
      "          policy_loss: 0.0018097338832962185\n",
      "          total_loss: 151.8609485981828\n",
      "          vf_explained_var: 0.5975341796875\n",
      "          vf_loss: 151.85913829803468\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1470000\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1470000\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.975\n",
      "    ram_util_percent: 19.26136363636363\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425515209179701\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.293181824554234\n",
      "    mean_inference_ms: 0.5109743908019467\n",
      "    mean_raw_obs_processing_ms: 4.404241541093706\n",
      "  time_since_restore: 3062.115921974182\n",
      "  time_this_iter_s: 30.335458517074585\n",
      "  time_total_s: 3062.115921974182\n",
      "  timers:\n",
      "    learn_throughput: 6051.974\n",
      "    learn_time_ms: 2478.53\n",
      "    sample_throughput: 527.402\n",
      "    sample_time_ms: 28441.3\n",
      "    update_time_ms: 0.96\n",
      "  timestamp: 1674282205\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 98\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         3062.12</td><td style=\"text-align: right;\">1470000</td><td style=\"text-align: right;\"> 1056.34</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             715.199</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1485000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-23-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 1068.090037223854\n",
      "  episode_reward_min: 715.1992396627045\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 495\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.287192608138262\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011477652646688598\n",
      "          policy_loss: 0.00154459975320467\n",
      "          total_loss: 184.9582921108957\n",
      "          vf_explained_var: 0.8281874060630798\n",
      "          vf_loss: 184.95674780829478\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1485000\n",
      "    num_steps_sampled: 1485000\n",
      "    num_steps_trained: 1485000\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.599999999999994\n",
      "    ram_util_percent: 19.265116279069765\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425589079777123\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.292937723159651\n",
      "    mean_inference_ms: 0.5109791114403108\n",
      "    mean_raw_obs_processing_ms: 4.406421560023378\n",
      "  time_since_restore: 3092.3065123558044\n",
      "  time_this_iter_s: 30.190590381622314\n",
      "  time_total_s: 3092.3065123558044\n",
      "  timers:\n",
      "    learn_throughput: 6069.303\n",
      "    learn_time_ms: 2471.453\n",
      "    sample_throughput: 527.127\n",
      "    sample_time_ms: 28456.122\n",
      "    update_time_ms: 0.977\n",
      "  timestamp: 1674282235\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1485000\n",
      "  training_iteration: 99\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         3092.31</td><td style=\"text-align: right;\">1485000</td><td style=\"text-align: right;\"> 1068.09</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             715.199</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1500000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-24-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2416.7744909658045\n",
      "  episode_reward_mean: 1073.8565612622892\n",
      "  episode_reward_min: 715.1992396627045\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 500\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.308513470827523\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012578147256376286\n",
      "          policy_loss: 0.0016640295880309985\n",
      "          total_loss: 148.1177290851787\n",
      "          vf_explained_var: 0.5946527123451233\n",
      "          vf_loss: 148.11606531789747\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1500000\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1500000\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.152\n",
      "    ram_util_percent: 19.21\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054256466188870256\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2926982625541275\n",
      "    mean_inference_ms: 0.5109819148600642\n",
      "    mean_raw_obs_processing_ms: 4.408359553654586\n",
      "  time_since_restore: 3127.426873922348\n",
      "  time_this_iter_s: 35.12036156654358\n",
      "  time_total_s: 3127.426873922348\n",
      "  timers:\n",
      "    learn_throughput: 6081.899\n",
      "    learn_time_ms: 2466.335\n",
      "    sample_throughput: 519.415\n",
      "    sample_time_ms: 28878.668\n",
      "    update_time_ms: 0.969\n",
      "  timestamp: 1674282270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 100\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         3127.43</td><td style=\"text-align: right;\">1500000</td><td style=\"text-align: right;\"> 1073.86</td><td style=\"text-align: right;\">             2416.77</td><td style=\"text-align: right;\">             715.199</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1515000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-25-01\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1988.5465417575444\n",
      "  episode_reward_mean: 1064.6352419749535\n",
      "  episode_reward_min: 858.1537915979267\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 505\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.343588052159649\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014529925396755973\n",
      "          policy_loss: 0.0020219765583810918\n",
      "          total_loss: 139.95797374046455\n",
      "          vf_explained_var: 0.23643390834331512\n",
      "          vf_loss: 139.95595182160199\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1515000\n",
      "    num_steps_sampled: 1515000\n",
      "    num_steps_trained: 1515000\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.972727272727266\n",
      "    ram_util_percent: 19.265909090909087\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542571261464413\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.292389950345246\n",
      "    mean_inference_ms: 0.5109859191706478\n",
      "    mean_raw_obs_processing_ms: 4.409459862624992\n",
      "  time_since_restore: 3157.7042882442474\n",
      "  time_this_iter_s: 30.277414321899414\n",
      "  time_total_s: 3157.7042882442474\n",
      "  timers:\n",
      "    learn_throughput: 6074.119\n",
      "    learn_time_ms: 2469.494\n",
      "    sample_throughput: 519.863\n",
      "    sample_time_ms: 28853.755\n",
      "    update_time_ms: 0.918\n",
      "  timestamp: 1674282301\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1515000\n",
      "  training_iteration: 101\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">          3157.7</td><td style=\"text-align: right;\">1515000</td><td style=\"text-align: right;\"> 1064.64</td><td style=\"text-align: right;\">             1988.55</td><td style=\"text-align: right;\">             858.154</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1530000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-25-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1988.5465417575444\n",
      "  episode_reward_mean: 1059.6370577798216\n",
      "  episode_reward_min: 821.9940921463078\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 510\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.2867807200399497\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013080655476905977\n",
      "          policy_loss: 0.0025769551509549305\n",
      "          total_loss: 173.07167489003328\n",
      "          vf_explained_var: 0.8453719615936279\n",
      "          vf_loss: 173.06909776622967\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1530000\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1530000\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.64883720930232\n",
      "    ram_util_percent: 19.265116279069765\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425826125182266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.292144443899041\n",
      "    mean_inference_ms: 0.510994991995828\n",
      "    mean_raw_obs_processing_ms: 4.409409714507166\n",
      "  time_since_restore: 3188.3945825099945\n",
      "  time_this_iter_s: 30.69029426574707\n",
      "  time_total_s: 3188.3945825099945\n",
      "  timers:\n",
      "    learn_throughput: 6069.185\n",
      "    learn_time_ms: 2471.502\n",
      "    sample_throughput: 519.349\n",
      "    sample_time_ms: 28882.309\n",
      "    update_time_ms: 0.931\n",
      "  timestamp: 1674282331\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 102\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         3188.39</td><td style=\"text-align: right;\">1530000</td><td style=\"text-align: right;\"> 1059.64</td><td style=\"text-align: right;\">             1988.55</td><td style=\"text-align: right;\">             821.994</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1545000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-26-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1988.5465417575444\n",
      "  episode_reward_mean: 1047.6525568295187\n",
      "  episode_reward_min: 661.7536586634793\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 515\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.3329043010533868\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013498957300855248\n",
      "          policy_loss: 0.0005475597718525362\n",
      "          total_loss: 186.47692857031095\n",
      "          vf_explained_var: 0.7838039398193359\n",
      "          vf_loss: 186.4763812469224\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1545000\n",
      "    num_steps_sampled: 1545000\n",
      "    num_steps_trained: 1545000\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.888636363636355\n",
      "    ram_util_percent: 19.263636363636362\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425952347708517\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.291873760804506\n",
      "    mean_inference_ms: 0.5110053004393427\n",
      "    mean_raw_obs_processing_ms: 4.4094687990678\n",
      "  time_since_restore: 3218.789199113846\n",
      "  time_this_iter_s: 30.39461660385132\n",
      "  time_total_s: 3218.789199113846\n",
      "  timers:\n",
      "    learn_throughput: 6073.735\n",
      "    learn_time_ms: 2469.65\n",
      "    sample_throughput: 519.761\n",
      "    sample_time_ms: 28859.403\n",
      "    update_time_ms: 0.991\n",
      "  timestamp: 1674282362\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1545000\n",
      "  training_iteration: 103\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         3218.79</td><td style=\"text-align: right;\">1545000</td><td style=\"text-align: right;\"> 1047.65</td><td style=\"text-align: right;\">             1988.55</td><td style=\"text-align: right;\">             661.754</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1560000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-26-32\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1988.5465417575444\n",
      "  episode_reward_mean: 1033.6378466957854\n",
      "  episode_reward_min: 593.4032629631121\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 520\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.3518979444342145\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018015461526787825\n",
      "          policy_loss: 0.003238961279936829\n",
      "          total_loss: 131.72612677671142\n",
      "          vf_explained_var: 0.676192581653595\n",
      "          vf_loss: 131.72288746187243\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1560000\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1560000\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.274418604651167\n",
      "    ram_util_percent: 19.258139534883718\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05426095207335464\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.291610580995809\n",
      "    mean_inference_ms: 0.5110181523571531\n",
      "    mean_raw_obs_processing_ms: 4.4093490657039585\n",
      "  time_since_restore: 3248.8496856689453\n",
      "  time_this_iter_s: 30.060486555099487\n",
      "  time_total_s: 3248.8496856689453\n",
      "  timers:\n",
      "    learn_throughput: 6078.126\n",
      "    learn_time_ms: 2467.866\n",
      "    sample_throughput: 520.632\n",
      "    sample_time_ms: 28811.157\n",
      "    update_time_ms: 1.039\n",
      "  timestamp: 1674282392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 104\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         3248.85</td><td style=\"text-align: right;\">1560000</td><td style=\"text-align: right;\"> 1033.64</td><td style=\"text-align: right;\">             1988.55</td><td style=\"text-align: right;\">             593.403</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1575000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-27-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1988.5465417575444\n",
      "  episode_reward_mean: 1019.2441547273615\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 525\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.3770904361191443\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012858148666477588\n",
      "          policy_loss: 0.001924022368423767\n",
      "          total_loss: 204.0078917551849\n",
      "          vf_explained_var: 0.824940025806427\n",
      "          vf_loss: 204.00596829753812\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1575000\n",
      "    num_steps_sampled: 1575000\n",
      "    num_steps_trained: 1575000\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.390697674418607\n",
      "    ram_util_percent: 19.267441860465112\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05426230823255449\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.291351158198093\n",
      "    mean_inference_ms: 0.5110307080384897\n",
      "    mean_raw_obs_processing_ms: 4.40934674064935\n",
      "  time_since_restore: 3279.319914340973\n",
      "  time_this_iter_s: 30.470228672027588\n",
      "  time_total_s: 3279.319914340973\n",
      "  timers:\n",
      "    learn_throughput: 6069.441\n",
      "    learn_time_ms: 2471.397\n",
      "    sample_throughput: 520.031\n",
      "    sample_time_ms: 28844.427\n",
      "    update_time_ms: 1.069\n",
      "  timestamp: 1674282423\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1575000\n",
      "  training_iteration: 105\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         3279.32</td><td style=\"text-align: right;\">1575000</td><td style=\"text-align: right;\"> 1019.24</td><td style=\"text-align: right;\">             1988.55</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1590000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-27-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1988.5465417575444\n",
      "  episode_reward_mean: 999.3688102674662\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 530\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.4414619682198864\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01802026343419572\n",
      "          policy_loss: 0.002354507725212281\n",
      "          total_loss: 138.9045775567071\n",
      "          vf_explained_var: 0.705986499786377\n",
      "          vf_loss: 138.90222306089885\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1590000\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1590000\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.730232558139537\n",
      "    ram_util_percent: 19.27441860465116\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054263643335025195\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.291069581289789\n",
      "    mean_inference_ms: 0.5110433558466836\n",
      "    mean_raw_obs_processing_ms: 4.409496697612232\n",
      "  time_since_restore: 3309.3584179878235\n",
      "  time_this_iter_s: 30.038503646850586\n",
      "  time_total_s: 3309.3584179878235\n",
      "  timers:\n",
      "    learn_throughput: 6055.272\n",
      "    learn_time_ms: 2477.18\n",
      "    sample_throughput: 530.363\n",
      "    sample_time_ms: 28282.54\n",
      "    update_time_ms: 1.088\n",
      "  timestamp: 1674282453\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 106\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         3309.36</td><td style=\"text-align: right;\">1590000</td><td style=\"text-align: right;\"> 999.369</td><td style=\"text-align: right;\">             1988.55</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1605000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-28-08\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1988.5465417575444\n",
      "  episode_reward_mean: 992.1490454421196\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 535\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.4559064487279474\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015177768485909205\n",
      "          policy_loss: 0.001907487114165294\n",
      "          total_loss: 161.19789872250314\n",
      "          vf_explained_var: 0.6584768295288086\n",
      "          vf_loss: 161.19599198486844\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1605000\n",
      "    num_steps_sampled: 1605000\n",
      "    num_steps_trained: 1605000\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.988235294117647\n",
      "    ram_util_percent: 19.231372549019603\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05426511241340956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.290805322371634\n",
      "    mean_inference_ms: 0.5110755108134452\n",
      "    mean_raw_obs_processing_ms: 4.409506059077988\n",
      "  time_since_restore: 3344.82656955719\n",
      "  time_this_iter_s: 35.468151569366455\n",
      "  time_total_s: 3344.82656955719\n",
      "  timers:\n",
      "    learn_throughput: 5980.209\n",
      "    learn_time_ms: 2508.273\n",
      "    sample_throughput: 520.995\n",
      "    sample_time_ms: 28791.058\n",
      "    update_time_ms: 1.098\n",
      "  timestamp: 1674282488\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1605000\n",
      "  training_iteration: 107\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         3344.83</td><td style=\"text-align: right;\">1605000</td><td style=\"text-align: right;\"> 992.149</td><td style=\"text-align: right;\">             1988.55</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1620000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-28-38\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1988.5465417575444\n",
      "  episode_reward_mean: 989.6311412736085\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 540\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.475727341538769\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011647400930568381\n",
      "          policy_loss: 0.002140600348120334\n",
      "          total_loss: 166.3658711255607\n",
      "          vf_explained_var: 0.5790132284164429\n",
      "          vf_loss: 166.36373019784185\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1620000\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1620000\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.374418604651154\n",
      "    ram_util_percent: 19.269767441860463\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054266519661858095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.29056697447205\n",
      "    mean_inference_ms: 0.5110882073220304\n",
      "    mean_raw_obs_processing_ms: 4.4094491392458846\n",
      "  time_since_restore: 3374.990998983383\n",
      "  time_this_iter_s: 30.164429426193237\n",
      "  time_total_s: 3374.990998983383\n",
      "  timers:\n",
      "    learn_throughput: 5972.169\n",
      "    learn_time_ms: 2511.65\n",
      "    sample_throughput: 521.367\n",
      "    sample_time_ms: 28770.512\n",
      "    update_time_ms: 1.085\n",
      "  timestamp: 1674282518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 108\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         3374.99</td><td style=\"text-align: right;\">1620000</td><td style=\"text-align: right;\"> 989.631</td><td style=\"text-align: right;\">             1988.55</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1635000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-29-09\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1988.5465417575444\n",
      "  episode_reward_mean: 967.0126783459248\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 545\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.404889488624314\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014405700074303463\n",
      "          policy_loss: 0.0024590369313955305\n",
      "          total_loss: 160.6795419224238\n",
      "          vf_explained_var: 0.8472051024436951\n",
      "          vf_loss: 160.67708189689506\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1635000\n",
      "    num_steps_sampled: 1635000\n",
      "    num_steps_trained: 1635000\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.079545454545453\n",
      "    ram_util_percent: 19.268181818181816\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542679542585925\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2902998751679675\n",
      "    mean_inference_ms: 0.5111006303820091\n",
      "    mean_raw_obs_processing_ms: 4.409520302252017\n",
      "  time_since_restore: 3405.297398328781\n",
      "  time_this_iter_s: 30.30639934539795\n",
      "  time_total_s: 3405.297398328781\n",
      "  timers:\n",
      "    learn_throughput: 5983.958\n",
      "    learn_time_ms: 2506.702\n",
      "    sample_throughput: 521.069\n",
      "    sample_time_ms: 28786.97\n",
      "    update_time_ms: 1.079\n",
      "  timestamp: 1674282549\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1635000\n",
      "  training_iteration: 109\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">          3405.3</td><td style=\"text-align: right;\">1635000</td><td style=\"text-align: right;\"> 967.013</td><td style=\"text-align: right;\">             1988.55</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1650000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-29-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1965.203224198208\n",
      "  episode_reward_mean: 946.3764149872933\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 550\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.441864850965597\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016997909621352735\n",
      "          policy_loss: 0.0031172330096616583\n",
      "          total_loss: 173.33983950857387\n",
      "          vf_explained_var: 0.7104633450508118\n",
      "          vf_loss: 173.33672218969312\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1650000\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1650000\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.54651162790698\n",
      "    ram_util_percent: 19.27209302325581\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05426910586778701\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289981877771531\n",
      "    mean_inference_ms: 0.5111107847510027\n",
      "    mean_raw_obs_processing_ms: 4.4095830863825105\n",
      "  time_since_restore: 3435.66238117218\n",
      "  time_this_iter_s: 30.364982843399048\n",
      "  time_total_s: 3435.66238117218\n",
      "  timers:\n",
      "    learn_throughput: 5958.837\n",
      "    learn_time_ms: 2517.27\n",
      "    sample_throughput: 530.019\n",
      "    sample_time_ms: 28300.868\n",
      "    update_time_ms: 1.085\n",
      "  timestamp: 1674282579\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 110\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         3435.66</td><td style=\"text-align: right;\">1650000</td><td style=\"text-align: right;\"> 946.376</td><td style=\"text-align: right;\">              1965.2</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1665000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-30-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1965.203224198208\n",
      "  episode_reward_mean: 936.1768539893939\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 555\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.4692938244948954\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017301113705151052\n",
      "          policy_loss: 0.0022915863353064505\n",
      "          total_loss: 194.38284448849953\n",
      "          vf_explained_var: 0.8352037072181702\n",
      "          vf_loss: 194.38055290125183\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1665000\n",
      "    num_steps_sampled: 1665000\n",
      "    num_steps_trained: 1665000\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.031818181818185\n",
      "    ram_util_percent: 19.27045454545454\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427010618698214\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2896693293524\n",
      "    mean_inference_ms: 0.5111193069690387\n",
      "    mean_raw_obs_processing_ms: 4.409729820148129\n",
      "  time_since_restore: 3466.386308193207\n",
      "  time_this_iter_s: 30.72392702102661\n",
      "  time_total_s: 3466.386308193207\n",
      "  timers:\n",
      "    learn_throughput: 5941.372\n",
      "    learn_time_ms: 2524.669\n",
      "    sample_throughput: 529.323\n",
      "    sample_time_ms: 28338.087\n",
      "    update_time_ms: 1.112\n",
      "  timestamp: 1674282610\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1665000\n",
      "  training_iteration: 111\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         3466.39</td><td style=\"text-align: right;\">1665000</td><td style=\"text-align: right;\"> 936.177</td><td style=\"text-align: right;\">              1965.2</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1680000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-30-40\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1965.203224198208\n",
      "  episode_reward_mean: 929.9411822635079\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 560\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.4858415846097266\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01564152385057779\n",
      "          policy_loss: 0.0034667002309461013\n",
      "          total_loss: 179.86708590943934\n",
      "          vf_explained_var: 0.8067220449447632\n",
      "          vf_loss: 179.86361909801678\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1680000\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1680000\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.695348837209306\n",
      "    ram_util_percent: 19.281395348837208\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054270911737672296\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289390176403503\n",
      "    mean_inference_ms: 0.5111263384655129\n",
      "    mean_raw_obs_processing_ms: 4.4097640955260955\n",
      "  time_since_restore: 3496.6716413497925\n",
      "  time_this_iter_s: 30.285333156585693\n",
      "  time_total_s: 3496.6716413497925\n",
      "  timers:\n",
      "    learn_throughput: 5930.808\n",
      "    learn_time_ms: 2529.166\n",
      "    sample_throughput: 530.165\n",
      "    sample_time_ms: 28293.07\n",
      "    update_time_ms: 1.094\n",
      "  timestamp: 1674282640\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 112\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         3496.67</td><td style=\"text-align: right;\">1680000</td><td style=\"text-align: right;\"> 929.941</td><td style=\"text-align: right;\">              1965.2</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1695000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-31-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2345.559987701643\n",
      "  episode_reward_mean: 942.386733952445\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 565\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.526982297735699\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014689503296153558\n",
      "          policy_loss: 0.003997724592267393\n",
      "          total_loss: 243.40939757783534\n",
      "          vf_explained_var: 0.772362470626831\n",
      "          vf_loss: 243.40539849491444\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1695000\n",
      "    num_steps_sampled: 1695000\n",
      "    num_steps_trained: 1695000\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.261363636363637\n",
      "    ram_util_percent: 19.275\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427156296555122\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289134282347379\n",
      "    mean_inference_ms: 0.5111320024558048\n",
      "    mean_raw_obs_processing_ms: 4.40974027270686\n",
      "  time_since_restore: 3527.2728514671326\n",
      "  time_this_iter_s: 30.601210117340088\n",
      "  time_total_s: 3527.2728514671326\n",
      "  timers:\n",
      "    learn_throughput: 5949.596\n",
      "    learn_time_ms: 2521.179\n",
      "    sample_throughput: 529.628\n",
      "    sample_time_ms: 28321.764\n",
      "    update_time_ms: 1.042\n",
      "  timestamp: 1674282671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1695000\n",
      "  training_iteration: 113\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         3527.27</td><td style=\"text-align: right;\">1695000</td><td style=\"text-align: right;\"> 942.387</td><td style=\"text-align: right;\">             2345.56</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1710000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-31-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2345.559987701643\n",
      "  episode_reward_mean: 951.5687382653464\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 570\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.542035326715243\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01705878458268513\n",
      "          policy_loss: 0.004650461527526821\n",
      "          total_loss: 224.39239110461736\n",
      "          vf_explained_var: 0.6863146424293518\n",
      "          vf_loss: 224.38774000264831\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1710000\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1710000\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.60909090909092\n",
      "    ram_util_percent: 19.268181818181812\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054272155400232176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288925637138051\n",
      "    mean_inference_ms: 0.5111372028241058\n",
      "    mean_raw_obs_processing_ms: 4.409737342373137\n",
      "  time_since_restore: 3558.3068618774414\n",
      "  time_this_iter_s: 31.034010410308838\n",
      "  time_total_s: 3558.3068618774414\n",
      "  timers:\n",
      "    learn_throughput: 5943.729\n",
      "    learn_time_ms: 2523.668\n",
      "    sample_throughput: 527.859\n",
      "    sample_time_ms: 28416.702\n",
      "    update_time_ms: 0.992\n",
      "  timestamp: 1674282702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 114\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         3558.31</td><td style=\"text-align: right;\">1710000</td><td style=\"text-align: right;\"> 951.569</td><td style=\"text-align: right;\">             2345.56</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1725000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-32-13\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 981.0762178200968\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 575\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.602752274173801\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01406184501688832\n",
      "          policy_loss: 0.0023287920147117415\n",
      "          total_loss: 267.7162902961343\n",
      "          vf_explained_var: 0.33371561765670776\n",
      "          vf_loss: 267.7139606346518\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1725000\n",
      "    num_steps_sampled: 1725000\n",
      "    num_steps_trained: 1725000\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.222727272727273\n",
      "    ram_util_percent: 19.277272727272724\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427263812531624\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288755309688017\n",
      "    mean_inference_ms: 0.5111422442686773\n",
      "    mean_raw_obs_processing_ms: 4.409737390968936\n",
      "  time_since_restore: 3588.6463825702667\n",
      "  time_this_iter_s: 30.339520692825317\n",
      "  time_total_s: 3588.6463825702667\n",
      "  timers:\n",
      "    learn_throughput: 6009.975\n",
      "    learn_time_ms: 2495.851\n",
      "    sample_throughput: 527.582\n",
      "    sample_time_ms: 28431.614\n",
      "    update_time_ms: 0.941\n",
      "  timestamp: 1674282733\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1725000\n",
      "  training_iteration: 115\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         3588.65</td><td style=\"text-align: right;\">1725000</td><td style=\"text-align: right;\"> 981.076</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1740000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-32-43\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 988.210400707034\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 580\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.6069051625364916\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01433318268716887\n",
      "          policy_loss: 0.003816709544320228\n",
      "          total_loss: 208.71273606833765\n",
      "          vf_explained_var: 0.5897526741027832\n",
      "          vf_loss: 208.7089194119987\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1740000\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1740000\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.660465116279067\n",
      "    ram_util_percent: 19.265116279069765\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427291709492668\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2886026634338466\n",
      "    mean_inference_ms: 0.511149610443907\n",
      "    mean_raw_obs_processing_ms: 4.408885878937878\n",
      "  time_since_restore: 3618.841097354889\n",
      "  time_this_iter_s: 30.194714784622192\n",
      "  time_total_s: 3618.841097354889\n",
      "  timers:\n",
      "    learn_throughput: 6061.73\n",
      "    learn_time_ms: 2474.541\n",
      "    sample_throughput: 526.896\n",
      "    sample_time_ms: 28468.597\n",
      "    update_time_ms: 0.92\n",
      "  timestamp: 1674282763\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 116\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         3618.84</td><td style=\"text-align: right;\">1740000</td><td style=\"text-align: right;\">  988.21</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1755000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-33-13\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 995.7009529399639\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 585\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.599865004571818\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019668145326612353\n",
      "          policy_loss: 0.004315212101407223\n",
      "          total_loss: 220.46592485136904\n",
      "          vf_explained_var: 0.6714817881584167\n",
      "          vf_loss: 220.46160950741526\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1755000\n",
      "    num_steps_sampled: 1755000\n",
      "    num_steps_trained: 1755000\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.61395348837209\n",
      "    ram_util_percent: 19.2953488372093\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427313987391665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288464538470617\n",
      "    mean_inference_ms: 0.5111569184544691\n",
      "    mean_raw_obs_processing_ms: 4.407998384729293\n",
      "  time_since_restore: 3649.135035276413\n",
      "  time_this_iter_s: 30.293937921524048\n",
      "  time_total_s: 3649.135035276413\n",
      "  timers:\n",
      "    learn_throughput: 6055.824\n",
      "    learn_time_ms: 2476.954\n",
      "    sample_throughput: 536.699\n",
      "    sample_time_ms: 27948.622\n",
      "    update_time_ms: 0.953\n",
      "  timestamp: 1674282793\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1755000\n",
      "  training_iteration: 117\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         3649.14</td><td style=\"text-align: right;\">1755000</td><td style=\"text-align: right;\"> 995.701</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1770000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-33-45\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1003.6272783523856\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 590\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.6178988309229836\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014617215662579274\n",
      "          policy_loss: 0.0016437675065945013\n",
      "          total_loss: 214.30002004332462\n",
      "          vf_explained_var: 0.6997291445732117\n",
      "          vf_loss: 214.29837595406227\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1770000\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1770000\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.573333333333327\n",
      "    ram_util_percent: 19.259999999999994\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427318969990302\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288329442633481\n",
      "    mean_inference_ms: 0.5111625237544685\n",
      "    mean_raw_obs_processing_ms: 4.407354924646811\n",
      "  time_since_restore: 3680.6547989845276\n",
      "  time_this_iter_s: 31.519763708114624\n",
      "  time_total_s: 3680.6547989845276\n",
      "  timers:\n",
      "    learn_throughput: 6068.362\n",
      "    learn_time_ms: 2471.837\n",
      "    sample_throughput: 534.01\n",
      "    sample_time_ms: 28089.375\n",
      "    update_time_ms: 0.962\n",
      "  timestamp: 1674282825\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 118\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         3680.65</td><td style=\"text-align: right;\">1770000</td><td style=\"text-align: right;\"> 1003.63</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1785000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-34-16\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1002.0733462351653\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 595\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.632746602317034\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014840393499616886\n",
      "          policy_loss: 0.0030702480245223744\n",
      "          total_loss: 215.755572189719\n",
      "          vf_explained_var: 0.6736413836479187\n",
      "          vf_loss: 215.75250316231939\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1785000\n",
      "    num_steps_sampled: 1785000\n",
      "    num_steps_trained: 1785000\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.113636363636363\n",
      "    ram_util_percent: 19.354545454545452\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427342568942935\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288198502550363\n",
      "    mean_inference_ms: 0.5111703580872878\n",
      "    mean_raw_obs_processing_ms: 4.406849561770815\n",
      "  time_since_restore: 3711.217880010605\n",
      "  time_this_iter_s: 30.56308102607727\n",
      "  time_total_s: 3711.217880010605\n",
      "  timers:\n",
      "    learn_throughput: 6052.431\n",
      "    learn_time_ms: 2478.343\n",
      "    sample_throughput: 533.644\n",
      "    sample_time_ms: 28108.64\n",
      "    update_time_ms: 0.912\n",
      "  timestamp: 1674282856\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1785000\n",
      "  training_iteration: 119\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         3711.22</td><td style=\"text-align: right;\">1785000</td><td style=\"text-align: right;\"> 1002.07</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1800000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-34-46\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1012.5072550753208\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 600\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.6812645540399065\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022462363140741414\n",
      "          policy_loss: 0.004842552844182415\n",
      "          total_loss: 217.8560462919332\n",
      "          vf_explained_var: 0.6585092544555664\n",
      "          vf_loss: 217.85120498527914\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1800000\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1800000\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.231818181818184\n",
      "    ram_util_percent: 19.272727272727266\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427385865640508\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288099224685728\n",
      "    mean_inference_ms: 0.5111802541769049\n",
      "    mean_raw_obs_processing_ms: 4.4055154720409995\n",
      "  time_since_restore: 3741.6585478782654\n",
      "  time_this_iter_s: 30.440667867660522\n",
      "  time_total_s: 3741.6585478782654\n",
      "  timers:\n",
      "    learn_throughput: 6067.352\n",
      "    learn_time_ms: 2472.248\n",
      "    sample_throughput: 533.384\n",
      "    sample_time_ms: 28122.319\n",
      "    update_time_ms: 0.911\n",
      "  timestamp: 1674282886\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 120\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         3741.66</td><td style=\"text-align: right;\">1800000</td><td style=\"text-align: right;\"> 1012.51</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1815000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-35-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1024.287595431241\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 605\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.733628330796452\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018559382619658057\n",
      "          policy_loss: 0.002556785019272465\n",
      "          total_loss: 241.723640277022\n",
      "          vf_explained_var: 0.6686922907829285\n",
      "          vf_loss: 241.72108397403005\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1815000\n",
      "    num_steps_sampled: 1815000\n",
      "    num_steps_trained: 1815000\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.04186046511628\n",
      "    ram_util_percent: 19.35813953488372\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054274316045753786\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288044675650317\n",
      "    mean_inference_ms: 0.5111897683417596\n",
      "    mean_raw_obs_processing_ms: 4.4042229228388114\n",
      "  time_since_restore: 3772.2684762477875\n",
      "  time_this_iter_s: 30.609928369522095\n",
      "  time_total_s: 3772.2684762477875\n",
      "  timers:\n",
      "    learn_throughput: 6090.73\n",
      "    learn_time_ms: 2462.759\n",
      "    sample_throughput: 533.419\n",
      "    sample_time_ms: 28120.459\n",
      "    update_time_ms: 0.886\n",
      "  timestamp: 1674282917\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1815000\n",
      "  training_iteration: 121\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         3772.27</td><td style=\"text-align: right;\">1815000</td><td style=\"text-align: right;\"> 1024.29</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1830000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-35-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1045.521166123413\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 610\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.769322775380086\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018147226079937663\n",
      "          policy_loss: 0.003115076996520225\n",
      "          total_loss: 249.43290838144594\n",
      "          vf_explained_var: 0.6837807893753052\n",
      "          vf_loss: 249.42979269512628\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1830000\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1830000\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.977272727272727\n",
      "    ram_util_percent: 19.311363636363637\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427441796297745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.287959340231188\n",
      "    mean_inference_ms: 0.5111958723410228\n",
      "    mean_raw_obs_processing_ms: 4.4029232660358595\n",
      "  time_since_restore: 3802.59805893898\n",
      "  time_this_iter_s: 30.329582691192627\n",
      "  time_total_s: 3802.59805893898\n",
      "  timers:\n",
      "    learn_throughput: 6086.245\n",
      "    learn_time_ms: 2464.574\n",
      "    sample_throughput: 533.371\n",
      "    sample_time_ms: 28123.006\n",
      "    update_time_ms: 0.939\n",
      "  timestamp: 1674282947\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 122\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">          3802.6</td><td style=\"text-align: right;\">1830000</td><td style=\"text-align: right;\"> 1045.52</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1845000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-36-23\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1074.1909872132921\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 615\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.798620126813145\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019672081473587472\n",
      "          policy_loss: 0.0036679722268087\n",
      "          total_loss: 259.5448274515443\n",
      "          vf_explained_var: 0.6101309061050415\n",
      "          vf_loss: 259.54115974296957\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1845000\n",
      "    num_steps_sampled: 1845000\n",
      "    num_steps_trained: 1845000\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.93921568627451\n",
      "    ram_util_percent: 19.311764705882354\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054274502145994205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.287912815469025\n",
      "    mean_inference_ms: 0.5112020312725722\n",
      "    mean_raw_obs_processing_ms: 4.402374788612275\n",
      "  time_since_restore: 3838.3773272037506\n",
      "  time_this_iter_s: 35.77926826477051\n",
      "  time_total_s: 3838.3773272037506\n",
      "  timers:\n",
      "    learn_throughput: 6069.399\n",
      "    learn_time_ms: 2471.415\n",
      "    sample_throughput: 523.855\n",
      "    sample_time_ms: 28633.868\n",
      "    update_time_ms: 0.987\n",
      "  timestamp: 1674282983\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1845000\n",
      "  training_iteration: 123\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         3838.38</td><td style=\"text-align: right;\">1845000</td><td style=\"text-align: right;\"> 1074.19</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1860000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-36-54\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1104.0503537228976\n",
      "  episode_reward_min: 444.9859042925564\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 620\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8171709840580568\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018173223305073916\n",
      "          policy_loss: 0.004416115130534617\n",
      "          total_loss: 230.16257775193554\n",
      "          vf_explained_var: 0.32563117146492004\n",
      "          vf_loss: 230.15816156096378\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1860000\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1860000\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.218181818181815\n",
      "    ram_util_percent: 19.361363636363635\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427460583324278\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.287898299099843\n",
      "    mean_inference_ms: 0.5112067614820149\n",
      "    mean_raw_obs_processing_ms: 4.401895050228106\n",
      "  time_since_restore: 3868.9876976013184\n",
      "  time_this_iter_s: 30.61037039756775\n",
      "  time_total_s: 3868.9876976013184\n",
      "  timers:\n",
      "    learn_throughput: 6077.499\n",
      "    learn_time_ms: 2468.12\n",
      "    sample_throughput: 524.573\n",
      "    sample_time_ms: 28594.668\n",
      "    update_time_ms: 1.027\n",
      "  timestamp: 1674283014\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 124\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         3868.99</td><td style=\"text-align: right;\">1860000</td><td style=\"text-align: right;\"> 1104.05</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             444.986</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1875000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-37-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1129.2868961814324\n",
      "  episode_reward_min: 604.9123845716322\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 625\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.7662241487179773\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018430174852792316\n",
      "          policy_loss: 0.004197627780524919\n",
      "          total_loss: 255.0857417381416\n",
      "          vf_explained_var: 0.7393459677696228\n",
      "          vf_loss: 255.0815445657504\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1875000\n",
      "    num_steps_sampled: 1875000\n",
      "    num_steps_trained: 1875000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.51860465116279\n",
      "    ram_util_percent: 19.365116279069767\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427475931870197\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.287877561578323\n",
      "    mean_inference_ms: 0.5112122890720119\n",
      "    mean_raw_obs_processing_ms: 4.401454533935227\n",
      "  time_since_restore: 3899.4021692276\n",
      "  time_this_iter_s: 30.41447162628174\n",
      "  time_total_s: 3899.4021692276\n",
      "  timers:\n",
      "    learn_throughput: 6013.016\n",
      "    learn_time_ms: 2494.588\n",
      "    sample_throughput: 524.924\n",
      "    sample_time_ms: 28575.57\n",
      "    update_time_ms: 1.039\n",
      "  timestamp: 1674283044\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1875000\n",
      "  training_iteration: 125\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">          3899.4</td><td style=\"text-align: right;\">1875000</td><td style=\"text-align: right;\"> 1129.29</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             604.912</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1890000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1157.9383973321608\n",
      "  episode_reward_min: 604.9123845716322\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 630\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.805854893943011\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02104087652369128\n",
      "          policy_loss: 0.005223996470824389\n",
      "          total_loss: 240.986814818948\n",
      "          vf_explained_var: 0.44997119903564453\n",
      "          vf_loss: 240.98158952098782\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1890000\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1890000\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.263636363636362\n",
      "    ram_util_percent: 19.35909090909091\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427488471557635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.287901332647268\n",
      "    mean_inference_ms: 0.5112328188070913\n",
      "    mean_raw_obs_processing_ms: 4.401037573269975\n",
      "  time_since_restore: 3929.952633857727\n",
      "  time_this_iter_s: 30.550464630126953\n",
      "  time_total_s: 3929.952633857727\n",
      "  timers:\n",
      "    learn_throughput: 5949.045\n",
      "    learn_time_ms: 2521.413\n",
      "    sample_throughput: 524.765\n",
      "    sample_time_ms: 28584.239\n",
      "    update_time_ms: 1.085\n",
      "  timestamp: 1674283075\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 126\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         3929.95</td><td style=\"text-align: right;\">1890000</td><td style=\"text-align: right;\"> 1157.94</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             604.912</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1905000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-38-25\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1177.05692955725\n",
      "  episode_reward_min: 671.4059027026667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 635\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.7541312369249633\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016413536967941747\n",
      "          policy_loss: 0.0037944992972632585\n",
      "          total_loss: 297.5404902442027\n",
      "          vf_explained_var: 0.7905113697052002\n",
      "          vf_loss: 297.536695758367\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1905000\n",
      "    num_steps_sampled: 1905000\n",
      "    num_steps_trained: 1905000\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.979069767441864\n",
      "    ram_util_percent: 19.37209302325581\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427488469422043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.287965380625265\n",
      "    mean_inference_ms: 0.511235072417475\n",
      "    mean_raw_obs_processing_ms: 4.399772578860532\n",
      "  time_since_restore: 3960.357564687729\n",
      "  time_this_iter_s: 30.40493083000183\n",
      "  time_total_s: 3960.357564687729\n",
      "  timers:\n",
      "    learn_throughput: 5941.777\n",
      "    learn_time_ms: 2524.497\n",
      "    sample_throughput: 524.614\n",
      "    sample_time_ms: 28592.464\n",
      "    update_time_ms: 1.041\n",
      "  timestamp: 1674283105\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1905000\n",
      "  training_iteration: 127\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         3960.36</td><td style=\"text-align: right;\">1905000</td><td style=\"text-align: right;\"> 1177.06</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             671.406</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1920000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-38-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1200.0003330232278\n",
      "  episode_reward_min: 671.4059027026667\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 640\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.7718486608084985\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021207977285623864\n",
      "          policy_loss: 0.003812884199985508\n",
      "          total_loss: 298.5989029512567\n",
      "          vf_explained_var: 0.7927700877189636\n",
      "          vf_loss: 298.5950914027327\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1920000\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1920000\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.268181818181816\n",
      "    ram_util_percent: 19.354545454545452\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427477919231241\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288078714509957\n",
      "    mean_inference_ms: 0.51123602130212\n",
      "    mean_raw_obs_processing_ms: 4.398604620477427\n",
      "  time_since_restore: 3990.9661722183228\n",
      "  time_this_iter_s: 30.608607530593872\n",
      "  time_total_s: 3990.9661722183228\n",
      "  timers:\n",
      "    learn_throughput: 5938.09\n",
      "    learn_time_ms: 2526.065\n",
      "    sample_throughput: 526.321\n",
      "    sample_time_ms: 28499.708\n",
      "    update_time_ms: 1.043\n",
      "  timestamp: 1674283136\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 128\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         3990.97</td><td style=\"text-align: right;\">1920000</td><td style=\"text-align: right;\">    1200</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             671.406</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1935000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-39-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1220.7854569861206\n",
      "  episode_reward_min: 754.7960574024365\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 645\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8290397712739845\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02743556044849169\n",
      "          policy_loss: 0.0043845841061260745\n",
      "          total_loss: 251.29104667598918\n",
      "          vf_explained_var: 0.5388294458389282\n",
      "          vf_loss: 251.28666232804122\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1935000\n",
      "    num_steps_sampled: 1935000\n",
      "    num_steps_trained: 1935000\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.25454545454546\n",
      "    ram_util_percent: 19.361363636363635\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427469018356454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288181603155533\n",
      "    mean_inference_ms: 0.51123672225597\n",
      "    mean_raw_obs_processing_ms: 4.397496322677899\n",
      "  time_since_restore: 4021.5255501270294\n",
      "  time_this_iter_s: 30.559377908706665\n",
      "  time_total_s: 4021.5255501270294\n",
      "  timers:\n",
      "    learn_throughput: 5937.241\n",
      "    learn_time_ms: 2526.426\n",
      "    sample_throughput: 526.334\n",
      "    sample_time_ms: 28499.026\n",
      "    update_time_ms: 1.039\n",
      "  timestamp: 1674283167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1935000\n",
      "  training_iteration: 129\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         4021.53</td><td style=\"text-align: right;\">1935000</td><td style=\"text-align: right;\"> 1220.79</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             754.796</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1950000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-39-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1230.614258543742\n",
      "  episode_reward_min: 811.9834708502528\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 650\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.852419139369059\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017801157324865435\n",
      "          policy_loss: 0.004140439675874234\n",
      "          total_loss: 246.62000128535902\n",
      "          vf_explained_var: 0.5614736080169678\n",
      "          vf_loss: 246.6158600338435\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1950000\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1950000\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.476744186046506\n",
      "    ram_util_percent: 19.37441860465116\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427480352292666\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288284243730987\n",
      "    mean_inference_ms: 0.5112387778042471\n",
      "    mean_raw_obs_processing_ms: 4.396391743726384\n",
      "  time_since_restore: 4051.600666284561\n",
      "  time_this_iter_s: 30.07511615753174\n",
      "  time_total_s: 4051.600666284561\n",
      "  timers:\n",
      "    learn_throughput: 5924.7\n",
      "    learn_time_ms: 2531.774\n",
      "    sample_throughput: 527.109\n",
      "    sample_time_ms: 28457.098\n",
      "    update_time_ms: 1.05\n",
      "  timestamp: 1674283197\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 130\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">          4051.6</td><td style=\"text-align: right;\">1950000</td><td style=\"text-align: right;\"> 1230.61</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             811.983</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1965000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-40-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1253.8100683113944\n",
      "  episode_reward_min: 850.5123787208724\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 655\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.842421895366604\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018728040406129787\n",
      "          policy_loss: 0.005167182001987693\n",
      "          total_loss: 289.33588915032857\n",
      "          vf_explained_var: 0.7283036708831787\n",
      "          vf_loss: 289.33072049415716\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1965000\n",
      "    num_steps_sampled: 1965000\n",
      "    num_steps_trained: 1965000\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.884313725490195\n",
      "    ram_util_percent: 19.32941176470588\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427511162487928\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288413612263318\n",
      "    mean_inference_ms: 0.511243048203086\n",
      "    mean_raw_obs_processing_ms: 4.395924855858719\n",
      "  time_since_restore: 4087.2316076755524\n",
      "  time_this_iter_s: 35.63094139099121\n",
      "  time_total_s: 4087.2316076755524\n",
      "  timers:\n",
      "    learn_throughput: 5918.98\n",
      "    learn_time_ms: 2534.22\n",
      "    sample_throughput: 518.015\n",
      "    sample_time_ms: 28956.714\n",
      "    update_time_ms: 1.057\n",
      "  timestamp: 1674283233\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1965000\n",
      "  training_iteration: 131\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         4087.23</td><td style=\"text-align: right;\">1965000</td><td style=\"text-align: right;\"> 1253.81</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             850.512</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1980000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-41-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1276.7327201313335\n",
      "  episode_reward_min: 959.44757541356\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 660\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8489229238639444\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019325711068272744\n",
      "          policy_loss: 0.005275520147021734\n",
      "          total_loss: 288.36000912876455\n",
      "          vf_explained_var: 0.720988929271698\n",
      "          vf_loss: 288.35473294985496\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1980000\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1980000\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.284090909090903\n",
      "    ram_util_percent: 19.384090909090904\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427535296367868\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.28853549269879\n",
      "    mean_inference_ms: 0.5112469814952438\n",
      "    mean_raw_obs_processing_ms: 4.395567215267043\n",
      "  time_since_restore: 4117.755013465881\n",
      "  time_this_iter_s: 30.52340579032898\n",
      "  time_total_s: 4117.755013465881\n",
      "  timers:\n",
      "    learn_throughput: 5928.349\n",
      "    learn_time_ms: 2530.215\n",
      "    sample_throughput: 517.595\n",
      "    sample_time_ms: 28980.199\n",
      "    update_time_ms: 1.009\n",
      "  timestamp: 1674283263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 132\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         4117.76</td><td style=\"text-align: right;\">1980000</td><td style=\"text-align: right;\"> 1276.73</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             959.448</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 1995000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-41-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1280.6953836491393\n",
      "  episode_reward_min: 1004.5519977214445\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 665\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9267712772902796\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019954599726638114\n",
      "          policy_loss: 0.0042067615627074395\n",
      "          total_loss: 278.37640261245986\n",
      "          vf_explained_var: 0.49553853273391724\n",
      "          vf_loss: 278.3721957125906\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1995000\n",
      "    num_steps_sampled: 1995000\n",
      "    num_steps_trained: 1995000\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.064285714285717\n",
      "    ram_util_percent: 19.378571428571426\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427559075223619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288634135996171\n",
      "    mean_inference_ms: 0.5112512259307379\n",
      "    mean_raw_obs_processing_ms: 4.395166649383139\n",
      "  time_since_restore: 4147.48441195488\n",
      "  time_this_iter_s: 29.729398488998413\n",
      "  time_total_s: 4147.48441195488\n",
      "  timers:\n",
      "    learn_throughput: 5937.036\n",
      "    learn_time_ms: 2526.513\n",
      "    sample_throughput: 528.559\n",
      "    sample_time_ms: 28379.027\n",
      "    update_time_ms: 0.957\n",
      "  timestamp: 1674283293\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1995000\n",
      "  training_iteration: 133\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         4147.48</td><td style=\"text-align: right;\">1995000</td><td style=\"text-align: right;\">  1280.7</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             1004.55</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2010000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-42-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2420.918888845801\n",
      "  episode_reward_mean: 1281.0263355587335\n",
      "  episode_reward_min: 1034.6167270007634\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 670\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.94581303939981\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020045296465388676\n",
      "          policy_loss: 0.004256884778565648\n",
      "          total_loss: 288.5323101787244\n",
      "          vf_explained_var: 0.6876276731491089\n",
      "          vf_loss: 288.52805361343644\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2010000\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2010000\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.993181818181814\n",
      "    ram_util_percent: 19.36590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542758024760132\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.28870228978796\n",
      "    mean_inference_ms: 0.5112557019110221\n",
      "    mean_raw_obs_processing_ms: 4.394702721661762\n",
      "  time_since_restore: 4177.964475393295\n",
      "  time_this_iter_s: 30.480063438415527\n",
      "  time_total_s: 4177.964475393295\n",
      "  timers:\n",
      "    learn_throughput: 5927.202\n",
      "    learn_time_ms: 2530.705\n",
      "    sample_throughput: 528.878\n",
      "    sample_time_ms: 28361.946\n",
      "    update_time_ms: 0.92\n",
      "  timestamp: 1674283324\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 134\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         4177.96</td><td style=\"text-align: right;\">2010000</td><td style=\"text-align: right;\"> 1281.03</td><td style=\"text-align: right;\">             2420.92</td><td style=\"text-align: right;\">             1034.62</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2025000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-42-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1964.3332456820522\n",
      "  episode_reward_mean: 1264.0961130682326\n",
      "  episode_reward_min: 1034.6167270007634\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 675\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.932979149535551\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027794327695319643\n",
      "          policy_loss: 0.006756613415397577\n",
      "          total_loss: 283.0380885916241\n",
      "          vf_explained_var: 0.6170170307159424\n",
      "          vf_loss: 283.03133261729096\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2025000\n",
      "    num_steps_sampled: 2025000\n",
      "    num_steps_trained: 2025000\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.73488372093023\n",
      "    ram_util_percent: 19.37209302325581\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427607457882389\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288760022563452\n",
      "    mean_inference_ms: 0.5112601518716796\n",
      "    mean_raw_obs_processing_ms: 4.394320050049793\n",
      "  time_since_restore: 4208.204440116882\n",
      "  time_this_iter_s: 30.239964723587036\n",
      "  time_total_s: 4208.204440116882\n",
      "  timers:\n",
      "    learn_throughput: 6020.732\n",
      "    learn_time_ms: 2491.391\n",
      "    sample_throughput: 528.472\n",
      "    sample_time_ms: 28383.729\n",
      "    update_time_ms: 0.966\n",
      "  timestamp: 1674283354\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2025000\n",
      "  training_iteration: 135\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">          4208.2</td><td style=\"text-align: right;\">2025000</td><td style=\"text-align: right;\">  1264.1</td><td style=\"text-align: right;\">             1964.33</td><td style=\"text-align: right;\">             1034.62</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2040000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-43-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1964.3332456820522\n",
      "  episode_reward_mean: 1272.4309194186326\n",
      "  episode_reward_min: 1034.6167270007634\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 680\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9645052592633134\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01948152957277269\n",
      "          policy_loss: 0.005268431587492005\n",
      "          total_loss: 282.8471490956969\n",
      "          vf_explained_var: 0.5713105797767639\n",
      "          vf_loss: 282.84188120243914\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2040000\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2040000\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.169047619047618\n",
      "    ram_util_percent: 19.378571428571426\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427622442288321\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288819718180443\n",
      "    mean_inference_ms: 0.5112598841613619\n",
      "    mean_raw_obs_processing_ms: 4.393813358281998\n",
      "  time_since_restore: 4237.6830496788025\n",
      "  time_this_iter_s: 29.478609561920166\n",
      "  time_total_s: 4237.6830496788025\n",
      "  timers:\n",
      "    learn_throughput: 6024.946\n",
      "    learn_time_ms: 2489.649\n",
      "    sample_throughput: 530.444\n",
      "    sample_time_ms: 28278.199\n",
      "    update_time_ms: 0.972\n",
      "  timestamp: 1674283383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 136\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         4237.68</td><td style=\"text-align: right;\">2040000</td><td style=\"text-align: right;\"> 1272.43</td><td style=\"text-align: right;\">             1964.33</td><td style=\"text-align: right;\">             1034.62</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2055000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-43-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1964.3332456820522\n",
      "  episode_reward_mean: 1282.2367790848425\n",
      "  episode_reward_min: 1034.6167270007634\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 685\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.0158834301819235\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022709594911923446\n",
      "          policy_loss: 0.006186926481708632\n",
      "          total_loss: 293.168597512326\n",
      "          vf_explained_var: 0.5248357653617859\n",
      "          vf_loss: 293.1624097662457\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2055000\n",
      "    num_steps_sampled: 2055000\n",
      "    num_steps_trained: 2055000\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.143181818181823\n",
      "    ram_util_percent: 19.46590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427650720180047\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.288889798435085\n",
      "    mean_inference_ms: 0.5112610874923132\n",
      "    mean_raw_obs_processing_ms: 4.393295928463625\n",
      "  time_since_restore: 4267.90380692482\n",
      "  time_this_iter_s: 30.220757246017456\n",
      "  time_total_s: 4267.90380692482\n",
      "  timers:\n",
      "    learn_throughput: 6027.73\n",
      "    learn_time_ms: 2488.499\n",
      "    sample_throughput: 530.769\n",
      "    sample_time_ms: 28260.878\n",
      "    update_time_ms: 0.976\n",
      "  timestamp: 1674283414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2055000\n",
      "  training_iteration: 137\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">          4267.9</td><td style=\"text-align: right;\">2055000</td><td style=\"text-align: right;\"> 1282.24</td><td style=\"text-align: right;\">             1964.33</td><td style=\"text-align: right;\">             1034.62</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2070000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-44-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1996.3255678644755\n",
      "  episode_reward_mean: 1304.6424912820328\n",
      "  episode_reward_min: 1037.2537390940595\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 690\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.993631650027582\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01903922263577225\n",
      "          policy_loss: 0.005427726571866453\n",
      "          total_loss: 347.0605474310406\n",
      "          vf_explained_var: 0.5400962829589844\n",
      "          vf_loss: 347.0551208108158\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2070000\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2070000\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.611904761904764\n",
      "    ram_util_percent: 19.378571428571426\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427675201902188\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.28899181672029\n",
      "    mean_inference_ms: 0.5112622235835723\n",
      "    mean_raw_obs_processing_ms: 4.392541515969906\n",
      "  time_since_restore: 4297.749888420105\n",
      "  time_this_iter_s: 29.846081495285034\n",
      "  time_total_s: 4297.749888420105\n",
      "  timers:\n",
      "    learn_throughput: 6032.703\n",
      "    learn_time_ms: 2486.448\n",
      "    sample_throughput: 532.168\n",
      "    sample_time_ms: 28186.568\n",
      "    update_time_ms: 1.024\n",
      "  timestamp: 1674283444\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 138\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         4297.75</td><td style=\"text-align: right;\">2070000</td><td style=\"text-align: right;\"> 1304.64</td><td style=\"text-align: right;\">             1996.33</td><td style=\"text-align: right;\">             1037.25</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2085000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-44-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2084.773738689281\n",
      "  episode_reward_mean: 1326.946686249211\n",
      "  episode_reward_min: 1077.5773081400175\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 695\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.951507314585023\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01603732509342474\n",
      "          policy_loss: 0.003945058785868272\n",
      "          total_loss: 387.094312254049\n",
      "          vf_explained_var: 0.7872705459594727\n",
      "          vf_loss: 387.09036736569163\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2085000\n",
      "    num_steps_sampled: 2085000\n",
      "    num_steps_trained: 2085000\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.179545454545448\n",
      "    ram_util_percent: 19.37272727272727\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427697742700946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289137141777509\n",
      "    mean_inference_ms: 0.5112634773628011\n",
      "    mean_raw_obs_processing_ms: 4.391712835762798\n",
      "  time_since_restore: 4328.223837852478\n",
      "  time_this_iter_s: 30.473949432373047\n",
      "  time_total_s: 4328.223837852478\n",
      "  timers:\n",
      "    learn_throughput: 6024.736\n",
      "    learn_time_ms: 2489.736\n",
      "    sample_throughput: 532.394\n",
      "    sample_time_ms: 28174.613\n",
      "    update_time_ms: 1.101\n",
      "  timestamp: 1674283474\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2085000\n",
      "  training_iteration: 139\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         4328.22</td><td style=\"text-align: right;\">2085000</td><td style=\"text-align: right;\"> 1326.95</td><td style=\"text-align: right;\">             2084.77</td><td style=\"text-align: right;\">             1077.58</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2100000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-45-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2084.773738689281\n",
      "  episode_reward_mean: 1326.9373851702633\n",
      "  episode_reward_min: 1087.5898051544154\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 700\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.043718516018431\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02520988170644313\n",
      "          policy_loss: 0.006423691665690581\n",
      "          total_loss: 273.17207341921534\n",
      "          vf_explained_var: 0.3270478844642639\n",
      "          vf_loss: 273.16564961449575\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2100000\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2100000\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.362790697674416\n",
      "    ram_util_percent: 19.367441860465114\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427710265343118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289247554220234\n",
      "    mean_inference_ms: 0.5112641918016654\n",
      "    mean_raw_obs_processing_ms: 4.390899201787276\n",
      "  time_since_restore: 4358.328723669052\n",
      "  time_this_iter_s: 30.104885816574097\n",
      "  time_total_s: 4358.328723669052\n",
      "  timers:\n",
      "    learn_throughput: 6103.809\n",
      "    learn_time_ms: 2457.482\n",
      "    sample_throughput: 531.731\n",
      "    sample_time_ms: 28209.765\n",
      "    update_time_ms: 1.133\n",
      "  timestamp: 1674283504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 140\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         4358.33</td><td style=\"text-align: right;\">2100000</td><td style=\"text-align: right;\"> 1326.94</td><td style=\"text-align: right;\">             2084.77</td><td style=\"text-align: right;\">             1087.59</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2115000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-45-35\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2084.773738689281\n",
      "  episode_reward_mean: 1333.3016640952171\n",
      "  episode_reward_min: 1087.5898051544154\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 705\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.943958020614365\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020333480524377882\n",
      "          policy_loss: 0.005780124740864513\n",
      "          total_loss: 332.7292393894519\n",
      "          vf_explained_var: 0.7559261322021484\n",
      "          vf_loss: 332.7234598127462\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2115000\n",
      "    num_steps_sampled: 2115000\n",
      "    num_steps_trained: 2115000\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.29318181818182\n",
      "    ram_util_percent: 19.463636363636365\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542770990440196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289354122329738\n",
      "    mean_inference_ms: 0.5112645006661265\n",
      "    mean_raw_obs_processing_ms: 4.390062404642818\n",
      "  time_since_restore: 4388.906805276871\n",
      "  time_this_iter_s: 30.578081607818604\n",
      "  time_total_s: 4388.906805276871\n",
      "  timers:\n",
      "    learn_throughput: 6120.172\n",
      "    learn_time_ms: 2450.912\n",
      "    sample_throughput: 541.301\n",
      "    sample_time_ms: 27710.997\n",
      "    update_time_ms: 1.175\n",
      "  timestamp: 1674283535\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2115000\n",
      "  training_iteration: 141\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         4388.91</td><td style=\"text-align: right;\">2115000</td><td style=\"text-align: right;\">  1333.3</td><td style=\"text-align: right;\">             2084.77</td><td style=\"text-align: right;\">             1087.59</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2130000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-46-06\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2084.773738689281\n",
      "  episode_reward_mean: 1340.0454417803392\n",
      "  episode_reward_min: 1087.5898051544154\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 710\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9223670175520042\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027279923081837666\n",
      "          policy_loss: 0.0056973943832764554\n",
      "          total_loss: 358.6448273868884\n",
      "          vf_explained_var: 0.7290998101234436\n",
      "          vf_loss: 358.6391306343725\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2130000\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2130000\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.804651162790694\n",
      "    ram_util_percent: 19.41860465116279\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427704492805654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.28947160408989\n",
      "    mean_inference_ms: 0.5112644163838628\n",
      "    mean_raw_obs_processing_ms: 4.389322939165413\n",
      "  time_since_restore: 4419.480886220932\n",
      "  time_this_iter_s: 30.57408094406128\n",
      "  time_total_s: 4419.480886220932\n",
      "  timers:\n",
      "    learn_throughput: 6125.117\n",
      "    learn_time_ms: 2448.933\n",
      "    sample_throughput: 541.163\n",
      "    sample_time_ms: 27718.058\n",
      "    update_time_ms: 1.18\n",
      "  timestamp: 1674283566\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 142\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         4419.48</td><td style=\"text-align: right;\">2130000</td><td style=\"text-align: right;\"> 1340.05</td><td style=\"text-align: right;\">             2084.77</td><td style=\"text-align: right;\">             1087.59</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2145000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-46-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2084.773738689281\n",
      "  episode_reward_mean: 1338.3590465669863\n",
      "  episode_reward_min: 1087.5898051544154\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 715\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9058406043860874\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02043145532431454\n",
      "          policy_loss: 0.005226012131680687\n",
      "          total_loss: 341.26059622360486\n",
      "          vf_explained_var: 0.7513218522071838\n",
      "          vf_loss: 341.2553692736868\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2145000\n",
      "    num_steps_sampled: 2145000\n",
      "    num_steps_trained: 2145000\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.966666666666665\n",
      "    ram_util_percent: 19.4078431372549\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427681426551291\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289575453003786\n",
      "    mean_inference_ms: 0.5112637483949619\n",
      "    mean_raw_obs_processing_ms: 4.38849842743222\n",
      "  time_since_restore: 4454.83279633522\n",
      "  time_this_iter_s: 35.35191011428833\n",
      "  time_total_s: 4454.83279633522\n",
      "  timers:\n",
      "    learn_throughput: 6124.545\n",
      "    learn_time_ms: 2449.162\n",
      "    sample_throughput: 530.409\n",
      "    sample_time_ms: 28280.069\n",
      "    update_time_ms: 1.218\n",
      "  timestamp: 1674283601\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2145000\n",
      "  training_iteration: 143\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         4454.83</td><td style=\"text-align: right;\">2145000</td><td style=\"text-align: right;\"> 1338.36</td><td style=\"text-align: right;\">             2084.77</td><td style=\"text-align: right;\">             1087.59</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2160000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-47-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2084.773738689281\n",
      "  episode_reward_mean: 1338.0238724413034\n",
      "  episode_reward_min: 1087.5898051544154\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 720\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9978394447746926\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024103222395286537\n",
      "          policy_loss: 0.0062536312369787595\n",
      "          total_loss: 298.5312988766169\n",
      "          vf_explained_var: 0.4682579040527344\n",
      "          vf_loss: 298.5250443636361\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2160000\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2160000\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.050000000000004\n",
      "    ram_util_percent: 19.450000000000003\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427650090471794\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289662218040772\n",
      "    mean_inference_ms: 0.5112630560334219\n",
      "    mean_raw_obs_processing_ms: 4.387574517838931\n",
      "  time_since_restore: 4484.026994943619\n",
      "  time_this_iter_s: 29.194198608398438\n",
      "  time_total_s: 4484.026994943619\n",
      "  timers:\n",
      "    learn_throughput: 6138.311\n",
      "    learn_time_ms: 2443.669\n",
      "    sample_throughput: 532.728\n",
      "    sample_time_ms: 28156.976\n",
      "    update_time_ms: 1.208\n",
      "  timestamp: 1674283631\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 144\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         4484.03</td><td style=\"text-align: right;\">2160000</td><td style=\"text-align: right;\"> 1338.02</td><td style=\"text-align: right;\">             2084.77</td><td style=\"text-align: right;\">             1087.59</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2175000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-47-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2084.773738689281\n",
      "  episode_reward_mean: 1349.6865575275776\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 725\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9396923218743276\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01855463560471896\n",
      "          policy_loss: 0.003958819943511764\n",
      "          total_loss: 371.7162816775047\n",
      "          vf_explained_var: 0.762157142162323\n",
      "          vf_loss: 371.7123231144275\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2175000\n",
      "    num_steps_sampled: 2175000\n",
      "    num_steps_trained: 2175000\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.62558139534884\n",
      "    ram_util_percent: 19.472093023255812\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054276260506182054\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289777310645732\n",
      "    mean_inference_ms: 0.511262990420192\n",
      "    mean_raw_obs_processing_ms: 4.386625593280408\n",
      "  time_since_restore: 4514.243955612183\n",
      "  time_this_iter_s: 30.216960668563843\n",
      "  time_total_s: 4514.243955612183\n",
      "  timers:\n",
      "    learn_throughput: 6041.067\n",
      "    learn_time_ms: 2483.005\n",
      "    sample_throughput: 533.515\n",
      "    sample_time_ms: 28115.398\n",
      "    update_time_ms: 1.158\n",
      "  timestamp: 1674283661\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2175000\n",
      "  training_iteration: 145\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         4514.24</td><td style=\"text-align: right;\">2175000</td><td style=\"text-align: right;\"> 1349.69</td><td style=\"text-align: right;\">             2084.77</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2190000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-48-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2084.773738689281\n",
      "  episode_reward_mean: 1352.3708521543635\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 730\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9740035257097017\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02386963097422335\n",
      "          policy_loss: 0.005106230620768364\n",
      "          total_loss: 325.26440924951584\n",
      "          vf_explained_var: 0.6023127436637878\n",
      "          vf_loss: 325.2593026565293\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2190000\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2190000\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.697674418604645\n",
      "    ram_util_percent: 19.430232558139533\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427587142398349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289886827029494\n",
      "    mean_inference_ms: 0.5112576430924327\n",
      "    mean_raw_obs_processing_ms: 4.38563610935856\n",
      "  time_since_restore: 4544.6259598731995\n",
      "  time_this_iter_s: 30.382004261016846\n",
      "  time_total_s: 4544.6259598731995\n",
      "  timers:\n",
      "    learn_throughput: 6033.434\n",
      "    learn_time_ms: 2486.146\n",
      "    sample_throughput: 531.865\n",
      "    sample_time_ms: 28202.622\n",
      "    update_time_ms: 1.149\n",
      "  timestamp: 1674283691\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 146\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         4544.63</td><td style=\"text-align: right;\">2190000</td><td style=\"text-align: right;\"> 1352.37</td><td style=\"text-align: right;\">             2084.77</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2205000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-48-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2084.773738689281\n",
      "  episode_reward_mean: 1351.1804729459361\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 735\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 6.776263578034402e-22\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.975142300533036\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04508380619066036\n",
      "          policy_loss: 0.009927162390115466\n",
      "          total_loss: 367.74276373265155\n",
      "          vf_explained_var: 0.7157401442527771\n",
      "          vf_loss: 367.73283700134795\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2205000\n",
      "    num_steps_sampled: 2205000\n",
      "    num_steps_trained: 2205000\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.236363636363635\n",
      "    ram_util_percent: 19.45681818181818\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427548747970846\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.289963095044128\n",
      "    mean_inference_ms: 0.5112521388397552\n",
      "    mean_raw_obs_processing_ms: 4.384688220094987\n",
      "  time_since_restore: 4574.991684436798\n",
      "  time_this_iter_s: 30.365724563598633\n",
      "  time_total_s: 4574.991684436798\n",
      "  timers:\n",
      "    learn_throughput: 6042.508\n",
      "    learn_time_ms: 2482.413\n",
      "    sample_throughput: 531.524\n",
      "    sample_time_ms: 28220.721\n",
      "    update_time_ms: 1.199\n",
      "  timestamp: 1674283722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2205000\n",
      "  training_iteration: 147\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         4574.99</td><td style=\"text-align: right;\">2205000</td><td style=\"text-align: right;\"> 1351.18</td><td style=\"text-align: right;\">             2084.77</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2220000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-49-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1360.611473355279\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 740\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.0111253629296515\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02396208650908685\n",
      "          policy_loss: 0.004577874951853843\n",
      "          total_loss: 387.9800640429481\n",
      "          vf_explained_var: 0.7430951595306396\n",
      "          vf_loss: 387.97548705925374\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2220000\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2220000\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.337999999999997\n",
      "    ram_util_percent: 19.404\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427530771962785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2900406564270055\n",
      "    mean_inference_ms: 0.5112492207076486\n",
      "    mean_raw_obs_processing_ms: 4.384314218805736\n",
      "  time_since_restore: 4610.2667598724365\n",
      "  time_this_iter_s: 35.27507543563843\n",
      "  time_total_s: 4610.2667598724365\n",
      "  timers:\n",
      "    learn_throughput: 6138.801\n",
      "    learn_time_ms: 2443.474\n",
      "    sample_throughput: 520.785\n",
      "    sample_time_ms: 28802.679\n",
      "    update_time_ms: 1.175\n",
      "  timestamp: 1674283757\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 148\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         4610.27</td><td style=\"text-align: right;\">2220000</td><td style=\"text-align: right;\"> 1360.61</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 231\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.761192925277308\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2235000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-49-48\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1371.3302893096088\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 745\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.998222928128\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02366681866277756\n",
      "          policy_loss: 0.006261102242150612\n",
      "          total_loss: 380.21067702729823\n",
      "          vf_explained_var: 0.8030577301979065\n",
      "          vf_loss: 380.2044167340812\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2235000\n",
      "    num_steps_sampled: 2235000\n",
      "    num_steps_trained: 2235000\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.306818181818183\n",
      "    ram_util_percent: 19.46590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427514045406059\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.290147773402796\n",
      "    mean_inference_ms: 0.5112470346634503\n",
      "    mean_raw_obs_processing_ms: 4.383868550726811\n",
      "  time_since_restore: 4640.627036333084\n",
      "  time_this_iter_s: 30.360276460647583\n",
      "  time_total_s: 4640.627036333084\n",
      "  timers:\n",
      "    learn_throughput: 6122.292\n",
      "    learn_time_ms: 2450.063\n",
      "    sample_throughput: 521.108\n",
      "    sample_time_ms: 28784.809\n",
      "    update_time_ms: 1.102\n",
      "  timestamp: 1674283788\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2235000\n",
      "  training_iteration: 149\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         4640.63</td><td style=\"text-align: right;\">2235000</td><td style=\"text-align: right;\"> 1371.33</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2250000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-50-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1382.5897723898531\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 750\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.064850426932512\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01892822296081881\n",
      "          policy_loss: 0.005490496753067789\n",
      "          total_loss: 357.24086366103865\n",
      "          vf_explained_var: 0.6367874145507812\n",
      "          vf_loss: 357.23537358752753\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2250000\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2250000\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.056818181818183\n",
      "    ram_util_percent: 19.45909090909091\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054274864422008726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.290272633495037\n",
      "    mean_inference_ms: 0.5112439504000179\n",
      "    mean_raw_obs_processing_ms: 4.383527768775632\n",
      "  time_since_restore: 4671.323378324509\n",
      "  time_this_iter_s: 30.69634199142456\n",
      "  time_total_s: 4671.323378324509\n",
      "  timers:\n",
      "    learn_throughput: 6046.03\n",
      "    learn_time_ms: 2480.967\n",
      "    sample_throughput: 520.596\n",
      "    sample_time_ms: 28813.155\n",
      "    update_time_ms: 1.058\n",
      "  timestamp: 1674283818\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 150\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         4671.32</td><td style=\"text-align: right;\">2250000</td><td style=\"text-align: right;\"> 1382.59</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 234\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.903915223349057\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2265000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-50-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1387.9948244158932\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 755\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.064818807577683\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022644102169573087\n",
      "          policy_loss: 0.0038051272363607155\n",
      "          total_loss: 374.52611923217773\n",
      "          vf_explained_var: 0.7115007638931274\n",
      "          vf_loss: 374.52231414277674\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2265000\n",
      "    num_steps_sampled: 2265000\n",
      "    num_steps_trained: 2265000\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.029545454545453\n",
      "    ram_util_percent: 19.46590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427457107742875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.290400108391029\n",
      "    mean_inference_ms: 0.5112409033634996\n",
      "    mean_raw_obs_processing_ms: 4.382533151052271\n",
      "  time_since_restore: 4702.125565290451\n",
      "  time_this_iter_s: 30.802186965942383\n",
      "  time_total_s: 4702.125565290451\n",
      "  timers:\n",
      "    learn_throughput: 6027.366\n",
      "    learn_time_ms: 2488.649\n",
      "    sample_throughput: 520.328\n",
      "    sample_time_ms: 28827.954\n",
      "    update_time_ms: 1.022\n",
      "  timestamp: 1674283849\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2265000\n",
      "  training_iteration: 151\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         4702.13</td><td style=\"text-align: right;\">2265000</td><td style=\"text-align: right;\"> 1387.99</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2280000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-51-20\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1387.337668816471\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 760\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.01972868684995\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01979922129510807\n",
      "          policy_loss: 0.004124842155369598\n",
      "          total_loss: 369.24415962413207\n",
      "          vf_explained_var: 0.6566861271858215\n",
      "          vf_loss: 369.2400352575011\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2280000\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2280000\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.21363636363636\n",
      "    ram_util_percent: 19.481818181818184\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427432300576173\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.290536311769394\n",
      "    mean_inference_ms: 0.5112384386858047\n",
      "    mean_raw_obs_processing_ms: 4.381551429219814\n",
      "  time_since_restore: 4732.7371616363525\n",
      "  time_this_iter_s: 30.61159634590149\n",
      "  time_total_s: 4732.7371616363525\n",
      "  timers:\n",
      "    learn_throughput: 6016.345\n",
      "    learn_time_ms: 2493.208\n",
      "    sample_throughput: 520.343\n",
      "    sample_time_ms: 28827.138\n",
      "    update_time_ms: 1.016\n",
      "  timestamp: 1674283880\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 152\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         4732.74</td><td style=\"text-align: right;\">2280000</td><td style=\"text-align: right;\"> 1387.34</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2295000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-51-51\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1393.1570822586823\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 765\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.072568722700669\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029714023970896425\n",
      "          policy_loss: 0.00812193652599166\n",
      "          total_loss: 390.0662250939062\n",
      "          vf_explained_var: 0.6705925464630127\n",
      "          vf_loss: 390.05810421119304\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2295000\n",
      "    num_steps_sampled: 2295000\n",
      "    num_steps_trained: 2295000\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.776744186046503\n",
      "    ram_util_percent: 19.479069767441857\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054274067807636016\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.290682493816513\n",
      "    mean_inference_ms: 0.5112356656808252\n",
      "    mean_raw_obs_processing_ms: 4.380623120977164\n",
      "  time_since_restore: 4763.183753252029\n",
      "  time_this_iter_s: 30.44659161567688\n",
      "  time_total_s: 4763.183753252029\n",
      "  timers:\n",
      "    learn_throughput: 6016.653\n",
      "    learn_time_ms: 2493.081\n",
      "    sample_throughput: 529.35\n",
      "    sample_time_ms: 28336.643\n",
      "    update_time_ms: 0.999\n",
      "  timestamp: 1674283911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2295000\n",
      "  training_iteration: 153\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         4763.18</td><td style=\"text-align: right;\">2295000</td><td style=\"text-align: right;\"> 1393.16</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2310000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-52-22\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1402.8984354531067\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 770\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.073595199948651\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023465358154097157\n",
      "          policy_loss: 0.005098442465335257\n",
      "          total_loss: 395.92032946570447\n",
      "          vf_explained_var: 0.7290189862251282\n",
      "          vf_loss: 395.91523039219743\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2310000\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2310000\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.39090909090909\n",
      "    ram_util_percent: 19.461363636363636\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427374015231182\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.290841896266456\n",
      "    mean_inference_ms: 0.5112322306429092\n",
      "    mean_raw_obs_processing_ms: 4.37976864213241\n",
      "  time_since_restore: 4794.04657125473\n",
      "  time_this_iter_s: 30.862818002700806\n",
      "  time_total_s: 4794.04657125473\n",
      "  timers:\n",
      "    learn_throughput: 5986.612\n",
      "    learn_time_ms: 2505.591\n",
      "    sample_throughput: 526.482\n",
      "    sample_time_ms: 28491.009\n",
      "    update_time_ms: 1.0\n",
      "  timestamp: 1674283942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 154\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         4794.05</td><td style=\"text-align: right;\">2310000</td><td style=\"text-align: right;\">  1402.9</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2325000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-52-53\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1422.9198303685084\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 775\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.070617532730102\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028363989098246795\n",
      "          policy_loss: 0.007521707375960077\n",
      "          total_loss: 465.9162236876407\n",
      "          vf_explained_var: 0.706582248210907\n",
      "          vf_loss: 465.90870263697735\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2325000\n",
      "    num_steps_sampled: 2325000\n",
      "    num_steps_trained: 2325000\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.28260869565218\n",
      "    ram_util_percent: 19.463043478260868\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427315524531976\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.291004732791984\n",
      "    mean_inference_ms: 0.5112262565819111\n",
      "    mean_raw_obs_processing_ms: 4.3790401281535045\n",
      "  time_since_restore: 4825.850504398346\n",
      "  time_this_iter_s: 31.803933143615723\n",
      "  time_total_s: 4825.850504398346\n",
      "  timers:\n",
      "    learn_throughput: 5972.778\n",
      "    learn_time_ms: 2511.394\n",
      "    sample_throughput: 523.672\n",
      "    sample_time_ms: 28643.865\n",
      "    update_time_ms: 1.025\n",
      "  timestamp: 1674283973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2325000\n",
      "  training_iteration: 155\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         4825.85</td><td style=\"text-align: right;\">2325000</td><td style=\"text-align: right;\"> 1422.92</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2340000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-53-24\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1437.0415157883463\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 780\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.164747420003859\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028328915250035697\n",
      "          policy_loss: 0.00833294812522797\n",
      "          total_loss: 414.0609957290908\n",
      "          vf_explained_var: 0.6304357051849365\n",
      "          vf_loss: 414.0526624776549\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2340000\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2340000\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.16363636363636\n",
      "    ram_util_percent: 19.46590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427253256440669\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.291181928252268\n",
      "    mean_inference_ms: 0.5112200059601639\n",
      "    mean_raw_obs_processing_ms: 4.378446854999738\n",
      "  time_since_restore: 4856.468793392181\n",
      "  time_this_iter_s: 30.61828899383545\n",
      "  time_total_s: 4856.468793392181\n",
      "  timers:\n",
      "    learn_throughput: 5969.823\n",
      "    learn_time_ms: 2512.637\n",
      "    sample_throughput: 523.261\n",
      "    sample_time_ms: 28666.36\n",
      "    update_time_ms: 0.998\n",
      "  timestamp: 1674284004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 156\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         4856.47</td><td style=\"text-align: right;\">2340000</td><td style=\"text-align: right;\"> 1437.04</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2355000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-53-55\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1443.7129287061166\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 785\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.177808989508677\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.032109713882389444\n",
      "          policy_loss: 0.006953366643993847\n",
      "          total_loss: 397.97842865313515\n",
      "          vf_explained_var: 0.42450469732284546\n",
      "          vf_loss: 397.97147808074953\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2355000\n",
      "    num_steps_sampled: 2355000\n",
      "    num_steps_trained: 2355000\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.424444444444447\n",
      "    ram_util_percent: 19.466666666666665\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054271730998040314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.291359343828737\n",
      "    mean_inference_ms: 0.5112119316105496\n",
      "    mean_raw_obs_processing_ms: 4.377971931117141\n",
      "  time_since_restore: 4887.738959789276\n",
      "  time_this_iter_s: 31.270166397094727\n",
      "  time_total_s: 4887.738959789276\n",
      "  timers:\n",
      "    learn_throughput: 5997.137\n",
      "    learn_time_ms: 2501.193\n",
      "    sample_throughput: 521.405\n",
      "    sample_time_ms: 28768.435\n",
      "    update_time_ms: 0.941\n",
      "  timestamp: 1674284035\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2355000\n",
      "  training_iteration: 157\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         4887.74</td><td style=\"text-align: right;\">2355000</td><td style=\"text-align: right;\"> 1443.71</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2370000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-54-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1435.357107245911\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 790\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.152637882555945\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02498073445536138\n",
      "          policy_loss: 0.006083260748488039\n",
      "          total_loss: 387.2875716710495\n",
      "          vf_explained_var: 0.5905804634094238\n",
      "          vf_loss: 387.2814880371094\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2370000\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2370000\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.669767441860465\n",
      "    ram_util_percent: 19.46511627906977\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427095287066469\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.291504756917834\n",
      "    mean_inference_ms: 0.5112037508497985\n",
      "    mean_raw_obs_processing_ms: 4.377612834153216\n",
      "  time_since_restore: 4918.028398990631\n",
      "  time_this_iter_s: 30.28943920135498\n",
      "  time_total_s: 4918.028398990631\n",
      "  timers:\n",
      "    learn_throughput: 5902.365\n",
      "    learn_time_ms: 2541.354\n",
      "    sample_throughput: 531.357\n",
      "    sample_time_ms: 28229.62\n",
      "    update_time_ms: 0.95\n",
      "  timestamp: 1674284066\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 158\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         4918.03</td><td style=\"text-align: right;\">2370000</td><td style=\"text-align: right;\"> 1435.36</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2385000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-54-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1436.8786438930904\n",
      "  episode_reward_min: 1113.4622341413383\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 795\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.1348144183724616\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027131762670692217\n",
      "          policy_loss: 0.005554311556773166\n",
      "          total_loss: 420.800845039497\n",
      "          vf_explained_var: 0.7137677669525146\n",
      "          vf_loss: 420.7952893143993\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2385000\n",
      "    num_steps_sampled: 2385000\n",
      "    num_steps_trained: 2385000\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.380952380952387\n",
      "    ram_util_percent: 19.561904761904763\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054270118711943184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.291624268226559\n",
      "    mean_inference_ms: 0.5111943923565424\n",
      "    mean_raw_obs_processing_ms: 4.37724179921111\n",
      "  time_since_restore: 4947.658056974411\n",
      "  time_this_iter_s: 29.629657983779907\n",
      "  time_total_s: 4947.658056974411\n",
      "  timers:\n",
      "    learn_throughput: 5926.337\n",
      "    learn_time_ms: 2531.074\n",
      "    sample_throughput: 532.542\n",
      "    sample_time_ms: 28166.81\n",
      "    update_time_ms: 0.947\n",
      "  timestamp: 1674284096\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2385000\n",
      "  training_iteration: 159\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         4947.66</td><td style=\"text-align: right;\">2385000</td><td style=\"text-align: right;\"> 1436.88</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1113.46</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2400000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-55-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1449.9713031967926\n",
      "  episode_reward_min: 1114.7871013750937\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 800\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.1233457539041165\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02723357666198644\n",
      "          policy_loss: 0.0073522621708511674\n",
      "          total_loss: 398.8608960135508\n",
      "          vf_explained_var: 0.6234594583511353\n",
      "          vf_loss: 398.8535430455612\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2400000\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2400000\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.163636363636364\n",
      "    ram_util_percent: 19.470454545454547\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542691107627887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2917749142561235\n",
      "    mean_inference_ms: 0.5111834509432249\n",
      "    mean_raw_obs_processing_ms: 4.376887575903833\n",
      "  time_since_restore: 4978.1250467300415\n",
      "  time_this_iter_s: 30.466989755630493\n",
      "  time_total_s: 4978.1250467300415\n",
      "  timers:\n",
      "    learn_throughput: 5954.45\n",
      "    learn_time_ms: 2519.124\n",
      "    sample_throughput: 532.751\n",
      "    sample_time_ms: 28155.74\n",
      "    update_time_ms: 1.0\n",
      "  timestamp: 1674284126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 160\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         4978.13</td><td style=\"text-align: right;\">2400000</td><td style=\"text-align: right;\"> 1449.97</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1114.79</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2415000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-55-56\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2629.5696381523867\n",
      "  episode_reward_mean: 1456.5503540372397\n",
      "  episode_reward_min: 1114.7871013750937\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 805\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.0710019307621454\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03029983448639379\n",
      "          policy_loss: 0.009287818180302443\n",
      "          total_loss: 451.3713772919218\n",
      "          vf_explained_var: 0.7768067717552185\n",
      "          vf_loss: 451.3620892734851\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2415000\n",
      "    num_steps_sampled: 2415000\n",
      "    num_steps_trained: 2415000\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.786046511627905\n",
      "    ram_util_percent: 19.56511627906977\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054267998581681895\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2919236723631915\n",
      "    mean_inference_ms: 0.5111707624745964\n",
      "    mean_raw_obs_processing_ms: 4.376514094484176\n",
      "  time_since_restore: 5008.23844575882\n",
      "  time_this_iter_s: 30.113399028778076\n",
      "  time_total_s: 5008.23844575882\n",
      "  timers:\n",
      "    learn_throughput: 5970.665\n",
      "    learn_time_ms: 2512.283\n",
      "    sample_throughput: 533.928\n",
      "    sample_time_ms: 28093.697\n",
      "    update_time_ms: 0.989\n",
      "  timestamp: 1674284156\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2415000\n",
      "  training_iteration: 161\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         5008.24</td><td style=\"text-align: right;\">2415000</td><td style=\"text-align: right;\"> 1456.55</td><td style=\"text-align: right;\">             2629.57</td><td style=\"text-align: right;\">             1114.79</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2430000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-56-27\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1464.6713736595186\n",
      "  episode_reward_min: 1114.7871013750937\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 810\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.210253018443868\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03006057568205229\n",
      "          policy_loss: 0.007200160883445987\n",
      "          total_loss: 431.1610554969917\n",
      "          vf_explained_var: 0.6413397789001465\n",
      "          vf_loss: 431.15385608349817\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2430000\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2430000\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.143181818181816\n",
      "    ram_util_percent: 19.51590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05426686862982781\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.292075055951073\n",
      "    mean_inference_ms: 0.511158147757175\n",
      "    mean_raw_obs_processing_ms: 4.3761231420151105\n",
      "  time_since_restore: 5038.966768026352\n",
      "  time_this_iter_s: 30.72832226753235\n",
      "  time_total_s: 5038.966768026352\n",
      "  timers:\n",
      "    learn_throughput: 5983.721\n",
      "    learn_time_ms: 2506.802\n",
      "    sample_throughput: 533.601\n",
      "    sample_time_ms: 28110.884\n",
      "    update_time_ms: 0.993\n",
      "  timestamp: 1674284187\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 162\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         5038.97</td><td style=\"text-align: right;\">2430000</td><td style=\"text-align: right;\"> 1464.67</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1114.79</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2445000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-56-58\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1459.2290493045784\n",
      "  episode_reward_min: 1114.7871013750937\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 815\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.2199144266419495\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.038715970455611044\n",
      "          policy_loss: 0.009556956064366436\n",
      "          total_loss: 381.1034917976897\n",
      "          vf_explained_var: 0.5328148007392883\n",
      "          vf_loss: 381.09393419653685\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2445000\n",
      "    num_steps_sampled: 2445000\n",
      "    num_steps_trained: 2445000\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.236363636363635\n",
      "    ram_util_percent: 19.56136363636364\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05426586018616325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.292207667428608\n",
      "    mean_inference_ms: 0.5111462109931607\n",
      "    mean_raw_obs_processing_ms: 4.375169291686766\n",
      "  time_since_restore: 5069.486746072769\n",
      "  time_this_iter_s: 30.519978046417236\n",
      "  time_total_s: 5069.486746072769\n",
      "  timers:\n",
      "    learn_throughput: 5964.019\n",
      "    learn_time_ms: 2515.083\n",
      "    sample_throughput: 533.617\n",
      "    sample_time_ms: 28110.035\n",
      "    update_time_ms: 0.973\n",
      "  timestamp: 1674284218\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2445000\n",
      "  training_iteration: 163\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         5069.49</td><td style=\"text-align: right;\">2445000</td><td style=\"text-align: right;\"> 1459.23</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1114.79</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2460000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-57-29\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1465.8953691823253\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 820\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.187379758640871\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020599157169913517\n",
      "          policy_loss: 0.006055181599577289\n",
      "          total_loss: 420.6539410898241\n",
      "          vf_explained_var: 0.6469243168830872\n",
      "          vf_loss: 420.64788498959297\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2460000\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2460000\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.279545454545453\n",
      "    ram_util_percent: 19.472727272727273\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05426483140615577\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.29236994763516\n",
      "    mean_inference_ms: 0.511134152333406\n",
      "    mean_raw_obs_processing_ms: 4.374349183993749\n",
      "  time_since_restore: 5100.357166528702\n",
      "  time_this_iter_s: 30.870420455932617\n",
      "  time_total_s: 5100.357166528702\n",
      "  timers:\n",
      "    learn_throughput: 5971.897\n",
      "    learn_time_ms: 2511.765\n",
      "    sample_throughput: 533.54\n",
      "    sample_time_ms: 28114.12\n",
      "    update_time_ms: 0.969\n",
      "  timestamp: 1674284249\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 164\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         5100.36</td><td style=\"text-align: right;\">2460000</td><td style=\"text-align: right;\">  1465.9</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2475000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-57-59\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1462.9728139659096\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 825\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.170876952349129\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03083715640069572\n",
      "          policy_loss: 0.007509143493667055\n",
      "          total_loss: 450.1943472587456\n",
      "          vf_explained_var: 0.7013919353485107\n",
      "          vf_loss: 450.1868375875182\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2475000\n",
      "    num_steps_sampled: 2475000\n",
      "    num_steps_trained: 2475000\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.67441860465116\n",
      "    ram_util_percent: 19.469767441860466\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542635536175063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.292517793046764\n",
      "    mean_inference_ms: 0.5111217102750081\n",
      "    mean_raw_obs_processing_ms: 4.37364886948662\n",
      "  time_since_restore: 5130.821423768997\n",
      "  time_this_iter_s: 30.46425724029541\n",
      "  time_total_s: 5130.821423768997\n",
      "  timers:\n",
      "    learn_throughput: 5997.435\n",
      "    learn_time_ms: 2501.069\n",
      "    sample_throughput: 535.887\n",
      "    sample_time_ms: 27990.977\n",
      "    update_time_ms: 0.949\n",
      "  timestamp: 1674284279\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2475000\n",
      "  training_iteration: 165\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         5130.82</td><td style=\"text-align: right;\">2475000</td><td style=\"text-align: right;\"> 1462.97</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2490000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-58-30\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1464.9332929206428\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 830\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.254273875689102\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.035717930360556815\n",
      "          policy_loss: 0.007583870465070072\n",
      "          total_loss: 408.1246408139245\n",
      "          vf_explained_var: 0.644888162612915\n",
      "          vf_loss: 408.117057690378\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2490000\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2490000\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.797727272727265\n",
      "    ram_util_percent: 19.511363636363637\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542621944520248\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.292659322446077\n",
      "    mean_inference_ms: 0.5110971602834016\n",
      "    mean_raw_obs_processing_ms: 4.372980594592029\n",
      "  time_since_restore: 5160.9256756305695\n",
      "  time_this_iter_s: 30.104251861572266\n",
      "  time_total_s: 5160.9256756305695\n",
      "  timers:\n",
      "    learn_throughput: 6009.27\n",
      "    learn_time_ms: 2496.144\n",
      "    sample_throughput: 536.778\n",
      "    sample_time_ms: 27944.5\n",
      "    update_time_ms: 0.934\n",
      "  timestamp: 1674284310\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 166\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         5160.93</td><td style=\"text-align: right;\">2490000</td><td style=\"text-align: right;\"> 1464.93</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 228\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.618452967700356\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2505000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-59-00\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1467.0661619281482\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 835\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.0164395367051604e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.2787300833201005\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.10276036310645764\n",
      "          policy_loss: 0.014932113846022067\n",
      "          total_loss: 407.525466404931\n",
      "          vf_explained_var: 0.6346244812011719\n",
      "          vf_loss: 407.5105362229428\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2505000\n",
      "    num_steps_sampled: 2505000\n",
      "    num_steps_trained: 2505000\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.776744186046507\n",
      "    ram_util_percent: 19.553488372093025\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054260908414300583\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.292807439784021\n",
      "    mean_inference_ms: 0.5110734881863077\n",
      "    mean_raw_obs_processing_ms: 4.372383291319781\n",
      "  time_since_restore: 5191.48165678978\n",
      "  time_this_iter_s: 30.555981159210205\n",
      "  time_total_s: 5191.48165678978\n",
      "  timers:\n",
      "    learn_throughput: 5991.577\n",
      "    learn_time_ms: 2503.515\n",
      "    sample_throughput: 538.297\n",
      "    sample_time_ms: 27865.645\n",
      "    update_time_ms: 0.951\n",
      "  timestamp: 1674284340\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2505000\n",
      "  training_iteration: 167\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         5191.48</td><td style=\"text-align: right;\">2505000</td><td style=\"text-align: right;\"> 1467.07</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2520000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_00-59-31\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1459.3713451616704\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 840\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.524659305057741e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.2476866245269775\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.07696207586668007\n",
      "          policy_loss: 0.018250786692843284\n",
      "          total_loss: 432.2746189505367\n",
      "          vf_explained_var: 0.6949225068092346\n",
      "          vf_loss: 432.2563689021741\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2520000\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2520000\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.21590909090909\n",
      "    ram_util_percent: 19.55454545454546\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542596109161789\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2929479731305085\n",
      "    mean_inference_ms: 0.5110495887092809\n",
      "    mean_raw_obs_processing_ms: 4.371239447253248\n",
      "  time_since_restore: 5222.307927846909\n",
      "  time_this_iter_s: 30.826271057128906\n",
      "  time_total_s: 5222.307927846909\n",
      "  timers:\n",
      "    learn_throughput: 5979.492\n",
      "    learn_time_ms: 2508.574\n",
      "    sample_throughput: 537.36\n",
      "    sample_time_ms: 27914.249\n",
      "    update_time_ms: 0.944\n",
      "  timestamp: 1674284371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 168\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         5222.31</td><td style=\"text-align: right;\">2520000</td><td style=\"text-align: right;\"> 1459.37</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2535000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1459.2796962685636\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 845\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2869889575866107e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.19103035805589\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0308292443703978\n",
      "          policy_loss: 0.007554681792705304\n",
      "          total_loss: 443.8926454835019\n",
      "          vf_explained_var: 0.6909056305885315\n",
      "          vf_loss: 443.88508982900845\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2535000\n",
      "    num_steps_sampled: 2535000\n",
      "    num_steps_trained: 2535000\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.09090909090909\n",
      "    ram_util_percent: 19.55454545454546\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425840366683147\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.293077292560284\n",
      "    mean_inference_ms: 0.511026023248686\n",
      "    mean_raw_obs_processing_ms: 4.3701812943616725\n",
      "  time_since_restore: 5252.759147405624\n",
      "  time_this_iter_s: 30.45121955871582\n",
      "  time_total_s: 5252.759147405624\n",
      "  timers:\n",
      "    learn_throughput: 5975.574\n",
      "    learn_time_ms: 2510.219\n",
      "    sample_throughput: 535.815\n",
      "    sample_time_ms: 27994.757\n",
      "    update_time_ms: 0.947\n",
      "  timestamp: 1674284402\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2535000\n",
      "  training_iteration: 169\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         5252.76</td><td style=\"text-align: right;\">2535000</td><td style=\"text-align: right;\"> 1459.28</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2550000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-00-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1459.1178417374058\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 850\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2869889575866107e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.184911788116067\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025080806672295557\n",
      "          policy_loss: 0.005129382497299525\n",
      "          total_loss: 464.1738675069001\n",
      "          vf_explained_var: 0.5629579424858093\n",
      "          vf_loss: 464.16873920246707\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2550000\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2550000\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.51555555555555\n",
      "    ram_util_percent: 19.553333333333338\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425710620085814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2932011836455315\n",
      "    mean_inference_ms: 0.5110020459997066\n",
      "    mean_raw_obs_processing_ms: 4.369161414538552\n",
      "  time_since_restore: 5283.959458351135\n",
      "  time_this_iter_s: 31.200310945510864\n",
      "  time_total_s: 5283.959458351135\n",
      "  timers:\n",
      "    learn_throughput: 5960.248\n",
      "    learn_time_ms: 2516.674\n",
      "    sample_throughput: 534.536\n",
      "    sample_time_ms: 28061.739\n",
      "    update_time_ms: 0.894\n",
      "  timestamp: 1674284433\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 170\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         5283.96</td><td style=\"text-align: right;\">2550000</td><td style=\"text-align: right;\"> 1459.12</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2565000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-01-03\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1456.1257273363005\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 855\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2869889575866107e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.156693632723921\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028407888014565428\n",
      "          policy_loss: 0.0062830490230827325\n",
      "          total_loss: 447.77143184209274\n",
      "          vf_explained_var: 0.6307551264762878\n",
      "          vf_loss: 447.76514877707274\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2565000\n",
      "    num_steps_sampled: 2565000\n",
      "    num_steps_trained: 2565000\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.739534883720935\n",
      "    ram_util_percent: 19.56511627906977\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425587696300879\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.29331013992993\n",
      "    mean_inference_ms: 0.5109790372061142\n",
      "    mean_raw_obs_processing_ms: 4.36811766646445\n",
      "  time_since_restore: 5314.040695905685\n",
      "  time_this_iter_s: 30.08123755455017\n",
      "  time_total_s: 5314.040695905685\n",
      "  timers:\n",
      "    learn_throughput: 5949.288\n",
      "    learn_time_ms: 2521.31\n",
      "    sample_throughput: 534.686\n",
      "    sample_time_ms: 28053.85\n",
      "    update_time_ms: 0.895\n",
      "  timestamp: 1674284463\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2565000\n",
      "  training_iteration: 171\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         5314.04</td><td style=\"text-align: right;\">2565000</td><td style=\"text-align: right;\"> 1456.13</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2580000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-01-39\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1469.73026555816\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 860\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2869889575866107e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.142653750160993\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023424727266189577\n",
      "          policy_loss: 0.007632070744678504\n",
      "          total_loss: 459.69569698592363\n",
      "          vf_explained_var: 0.6909957528114319\n",
      "          vf_loss: 459.6880660364183\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2580000\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2580000\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.97450980392157\n",
      "    ram_util_percent: 19.50588235294118\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054254699882469205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.293432950690393\n",
      "    mean_inference_ms: 0.510956402819108\n",
      "    mean_raw_obs_processing_ms: 4.367595720204876\n",
      "  time_since_restore: 5349.720508337021\n",
      "  time_this_iter_s: 35.67981243133545\n",
      "  time_total_s: 5349.720508337021\n",
      "  timers:\n",
      "    learn_throughput: 5947.595\n",
      "    learn_time_ms: 2522.028\n",
      "    sample_throughput: 525.428\n",
      "    sample_time_ms: 28548.142\n",
      "    update_time_ms: 0.944\n",
      "  timestamp: 1674284499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 172\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         5349.72</td><td style=\"text-align: right;\">2580000</td><td style=\"text-align: right;\"> 1469.73</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2595000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-02-10\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1465.9687005070498\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 865\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2869889575866107e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.191064154091528\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.039022174433674964\n",
      "          policy_loss: 0.00952164876448401\n",
      "          total_loss: 456.25298115358515\n",
      "          vf_explained_var: 0.6702141761779785\n",
      "          vf_loss: 456.24346072956666\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2595000\n",
      "    num_steps_sampled: 2595000\n",
      "    num_steps_trained: 2595000\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.66744186046511\n",
      "    ram_util_percent: 19.562790697674423\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425353217937998\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.293550795658288\n",
      "    mean_inference_ms: 0.5109338666696732\n",
      "    mean_raw_obs_processing_ms: 4.367145847273855\n",
      "  time_since_restore: 5380.2427389621735\n",
      "  time_this_iter_s: 30.522230625152588\n",
      "  time_total_s: 5380.2427389621735\n",
      "  timers:\n",
      "    learn_throughput: 5968.908\n",
      "    learn_time_ms: 2513.023\n",
      "    sample_throughput: 525.258\n",
      "    sample_time_ms: 28557.393\n",
      "    update_time_ms: 0.97\n",
      "  timestamp: 1674284530\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2595000\n",
      "  training_iteration: 173\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         5380.24</td><td style=\"text-align: right;\">2595000</td><td style=\"text-align: right;\"> 1465.97</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 230\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.7136148111012934\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2610000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-02-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1471.4636289938405\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 870\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2869889575866107e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.1464014514017915\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025746887596459097\n",
      "          policy_loss: 0.00709270951417038\n",
      "          total_loss: 503.78671164431813\n",
      "          vf_explained_var: 0.723771333694458\n",
      "          vf_loss: 503.77961721905206\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2610000\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2610000\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.877777777777776\n",
      "    ram_util_percent: 19.560000000000002\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425231457786416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.293676142596085\n",
      "    mean_inference_ms: 0.5109129986225145\n",
      "    mean_raw_obs_processing_ms: 4.366702536437031\n",
      "  time_since_restore: 5411.1016166210175\n",
      "  time_this_iter_s: 30.858877658843994\n",
      "  time_total_s: 5411.1016166210175\n",
      "  timers:\n",
      "    learn_throughput: 5973.596\n",
      "    learn_time_ms: 2511.05\n",
      "    sample_throughput: 525.246\n",
      "    sample_time_ms: 28558.068\n",
      "    update_time_ms: 1.024\n",
      "  timestamp: 1674284561\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 174\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">          5411.1</td><td style=\"text-align: right;\">2610000</td><td style=\"text-align: right;\"> 1471.46</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2625000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-03-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1468.4241027797848\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 875\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2869889575866107e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.316144797357462\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03343514274217308\n",
      "          policy_loss: 0.007370775609703387\n",
      "          total_loss: 475.2408955654856\n",
      "          vf_explained_var: 0.5684601068496704\n",
      "          vf_loss: 475.2335248171273\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2625000\n",
      "    num_steps_sampled: 2625000\n",
      "    num_steps_trained: 2625000\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.156818181818178\n",
      "    ram_util_percent: 19.572727272727274\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542512064331546\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.293785401257045\n",
      "    mean_inference_ms: 0.5108939947763619\n",
      "    mean_raw_obs_processing_ms: 4.366163865465729\n",
      "  time_since_restore: 5441.768014192581\n",
      "  time_this_iter_s: 30.66639757156372\n",
      "  time_total_s: 5441.768014192581\n",
      "  timers:\n",
      "    learn_throughput: 5967.158\n",
      "    learn_time_ms: 2513.759\n",
      "    sample_throughput: 524.923\n",
      "    sample_time_ms: 28575.6\n",
      "    update_time_ms: 1.02\n",
      "  timestamp: 1674284591\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2625000\n",
      "  training_iteration: 175\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         5441.77</td><td style=\"text-align: right;\">2625000</td><td style=\"text-align: right;\"> 1468.42</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 238\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.094180836186086\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2640000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-03-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1460.7926346626582\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 880\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2869889575866107e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.208646880166005\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03779620733602928\n",
      "          policy_loss: 0.008885616092484887\n",
      "          total_loss: 527.1222852125006\n",
      "          vf_explained_var: 0.7778820991516113\n",
      "          vf_loss: 527.1133991403095\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2640000\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2640000\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.28636363636364\n",
      "    ram_util_percent: 19.56818181818182\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054250235163068386\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.293895066365225\n",
      "    mean_inference_ms: 0.5108767427840286\n",
      "    mean_raw_obs_processing_ms: 4.365644485244687\n",
      "  time_since_restore: 5472.562104940414\n",
      "  time_this_iter_s: 30.794090747833252\n",
      "  time_total_s: 5472.562104940414\n",
      "  timers:\n",
      "    learn_throughput: 5963.357\n",
      "    learn_time_ms: 2515.362\n",
      "    sample_throughput: 523.689\n",
      "    sample_time_ms: 28642.956\n",
      "    update_time_ms: 1.07\n",
      "  timestamp: 1674284622\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 176\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         5472.56</td><td style=\"text-align: right;\">2640000</td><td style=\"text-align: right;\"> 1460.79</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2655000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-04-18\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1456.5895275441321\n",
      "  episode_reward_min: 1128.2863639661211\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 885\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 2.2869889575866107e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.184805511620085\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0450291727565918\n",
      "          policy_loss: 0.008935184867942106\n",
      "          total_loss: 504.9049983719648\n",
      "          vf_explained_var: 0.7658095359802246\n",
      "          vf_loss: 504.89606354600295\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2655000\n",
      "    num_steps_sampled: 2655000\n",
      "    num_steps_trained: 2655000\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.0\n",
      "    ram_util_percent: 19.533333333333335\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542493091844473\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.294007705211403\n",
      "    mean_inference_ms: 0.510860372441302\n",
      "    mean_raw_obs_processing_ms: 4.365574190611321\n",
      "  time_since_restore: 5508.199751615524\n",
      "  time_this_iter_s: 35.63764667510986\n",
      "  time_total_s: 5508.199751615524\n",
      "  timers:\n",
      "    learn_throughput: 5928.928\n",
      "    learn_time_ms: 2529.968\n",
      "    sample_throughput: 514.817\n",
      "    sample_time_ms: 29136.554\n",
      "    update_time_ms: 1.057\n",
      "  timestamp: 1674284658\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2655000\n",
      "  training_iteration: 177\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">          5508.2</td><td style=\"text-align: right;\">2655000</td><td style=\"text-align: right;\"> 1456.59</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1128.29</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 260\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.139779427502188\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 267\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.472051563171826\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2670000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-04-49\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1454.58572456743\n",
      "  episode_reward_min: 1111.9491979458062\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 890\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.430483436379916e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.203948147014036\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03497506988070691\n",
      "          policy_loss: 0.00869886845358158\n",
      "          total_loss: 489.640075884027\n",
      "          vf_explained_var: 0.7689429521560669\n",
      "          vf_loss: 489.6313789626299\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2670000\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2670000\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.111363636363645\n",
      "    ram_util_percent: 19.563636363636366\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424846949890804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.294120364375406\n",
      "    mean_inference_ms: 0.5108449325188875\n",
      "    mean_raw_obs_processing_ms: 4.365513240982582\n",
      "  time_since_restore: 5538.864196777344\n",
      "  time_this_iter_s: 30.664445161819458\n",
      "  time_total_s: 5538.864196777344\n",
      "  timers:\n",
      "    learn_throughput: 5947.404\n",
      "    learn_time_ms: 2522.109\n",
      "    sample_throughput: 514.962\n",
      "    sample_time_ms: 29128.365\n",
      "    update_time_ms: 1.031\n",
      "  timestamp: 1674284689\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 178\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">         5538.86</td><td style=\"text-align: right;\">2670000</td><td style=\"text-align: right;\"> 1454.59</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1111.95</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2685000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-05-20\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1446.7500723393816\n",
      "  episode_reward_min: 1111.9491979458062\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 895\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.430483436379916e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.134978562088336\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03475800122339611\n",
      "          policy_loss: 0.01017777700809825\n",
      "          total_loss: 543.4070765252841\n",
      "          vf_explained_var: 0.8092445731163025\n",
      "          vf_loss: 543.3968966532561\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2685000\n",
      "    num_steps_sampled: 2685000\n",
      "    num_steps_trained: 2685000\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.579545454545453\n",
      "    ram_util_percent: 19.57045454545455\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054247758401163894\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.294243098572873\n",
      "    mean_inference_ms: 0.5108314884950801\n",
      "    mean_raw_obs_processing_ms: 4.365563176497854\n",
      "  time_since_restore: 5569.833986282349\n",
      "  time_this_iter_s: 30.969789505004883\n",
      "  time_total_s: 5569.833986282349\n",
      "  timers:\n",
      "    learn_throughput: 5950.133\n",
      "    learn_time_ms: 2520.952\n",
      "    sample_throughput: 514.026\n",
      "    sample_time_ms: 29181.38\n",
      "    update_time_ms: 1.053\n",
      "  timestamp: 1674284720\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2685000\n",
      "  training_iteration: 179\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         5569.83</td><td style=\"text-align: right;\">2685000</td><td style=\"text-align: right;\"> 1446.75</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1111.95</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 223\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.3805185755587788\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2700000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-05-50\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1438.6453436523764\n",
      "  episode_reward_min: 1098.6669780331508\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 900\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.430483436379916e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.312503265526336\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03855705843477893\n",
      "          policy_loss: 0.009638387615934519\n",
      "          total_loss: 475.33235941903064\n",
      "          vf_explained_var: 0.6670339703559875\n",
      "          vf_loss: 475.32271987785725\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2700000\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2700000\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.54418604651163\n",
      "    ram_util_percent: 19.56744186046512\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424722411706748\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.294359997809001\n",
      "    mean_inference_ms: 0.5108198594457233\n",
      "    mean_raw_obs_processing_ms: 4.365612360056148\n",
      "  time_since_restore: 5600.187929153442\n",
      "  time_this_iter_s: 30.35394287109375\n",
      "  time_total_s: 5600.187929153442\n",
      "  timers:\n",
      "    learn_throughput: 5959.272\n",
      "    learn_time_ms: 2517.086\n",
      "    sample_throughput: 515.453\n",
      "    sample_time_ms: 29100.625\n",
      "    update_time_ms: 1.049\n",
      "  timestamp: 1674284750\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 180\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         5600.19</td><td style=\"text-align: right;\">2700000</td><td style=\"text-align: right;\"> 1438.65</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1098.67</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2715000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-06-26\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2684.4888379300824\n",
      "  episode_reward_mean: 1433.59463985771\n",
      "  episode_reward_min: 1098.6669780331508\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 905\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.430483436379916e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.372273548982911\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03169881139827477\n",
      "          policy_loss: 0.00812902248314566\n",
      "          total_loss: 460.31624737270806\n",
      "          vf_explained_var: 0.4358251094818115\n",
      "          vf_loss: 460.3081184952946\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2715000\n",
      "    num_steps_sampled: 2715000\n",
      "    num_steps_trained: 2715000\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.734615384615385\n",
      "    ram_util_percent: 19.53846153846154\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424693215981969\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.29446597644522\n",
      "    mean_inference_ms: 0.5108108006431645\n",
      "    mean_raw_obs_processing_ms: 4.366128244324141\n",
      "  time_since_restore: 5636.190165519714\n",
      "  time_this_iter_s: 36.00223636627197\n",
      "  time_total_s: 5636.190165519714\n",
      "  timers:\n",
      "    learn_throughput: 5980.526\n",
      "    learn_time_ms: 2508.141\n",
      "    sample_throughput: 505.023\n",
      "    sample_time_ms: 29701.609\n",
      "    update_time_ms: 1.104\n",
      "  timestamp: 1674284786\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2715000\n",
      "  training_iteration: 181\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         5636.19</td><td style=\"text-align: right;\">2715000</td><td style=\"text-align: right;\"> 1433.59</td><td style=\"text-align: right;\">             2684.49</td><td style=\"text-align: right;\">             1098.67</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 262\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.234739483008334\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 248\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.569659527528101\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2730000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-06-57\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1421.2130467477318\n",
      "  episode_reward_min: 1098.6669780331508\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 910\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.430483436379916e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.138212387844668\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03106385670275288\n",
      "          policy_loss: 0.007213203661475267\n",
      "          total_loss: 533.6305542768058\n",
      "          vf_explained_var: 0.8165746927261353\n",
      "          vf_loss: 533.6233409687624\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2730000\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2730000\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.697674418604645\n",
      "    ram_util_percent: 19.569767441860467\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424667924324599\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2945637691477385\n",
      "    mean_inference_ms: 0.5108019950071562\n",
      "    mean_raw_obs_processing_ms: 4.366635581480047\n",
      "  time_since_restore: 5666.67965388298\n",
      "  time_this_iter_s: 30.48948836326599\n",
      "  time_total_s: 5666.67965388298\n",
      "  timers:\n",
      "    learn_throughput: 5986.646\n",
      "    learn_time_ms: 2505.577\n",
      "    sample_throughput: 513.959\n",
      "    sample_time_ms: 29185.232\n",
      "    update_time_ms: 1.044\n",
      "  timestamp: 1674284817\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 182\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         5666.68</td><td style=\"text-align: right;\">2730000</td><td style=\"text-align: right;\"> 1421.21</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             1098.67</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 232\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.8087690783250063\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m Could not connect to TraCI server at localhost:59297 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m Could not connect to TraCI server at localhost:35519 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2745000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-07-33\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1423.873421128521\n",
      "  episode_reward_min: 1098.6669780331508\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 915\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 3.430483436379916e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.0573490843934525\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.05366412868578509\n",
      "          policy_loss: 0.010140233100944404\n",
      "          total_loss: 590.4960006907835\n",
      "          vf_explained_var: 0.7842833399772644\n",
      "          vf_loss: 590.4858633429317\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2745000\n",
      "    num_steps_sampled: 2745000\n",
      "    num_steps_trained: 2745000\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.728846153846156\n",
      "    ram_util_percent: 19.575000000000003\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424653784964411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.294700956745808\n",
      "    mean_inference_ms: 0.5107940951530869\n",
      "    mean_raw_obs_processing_ms: 4.367593630848037\n",
      "  time_since_restore: 5702.496573925018\n",
      "  time_this_iter_s: 35.816920042037964\n",
      "  time_total_s: 5702.496573925018\n",
      "  timers:\n",
      "    learn_throughput: 5984.8\n",
      "    learn_time_ms: 2506.349\n",
      "    sample_throughput: 504.815\n",
      "    sample_time_ms: 29713.83\n",
      "    update_time_ms: 1.074\n",
      "  timestamp: 1674284853\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2745000\n",
      "  training_iteration: 183\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">          5702.5</td><td style=\"text-align: right;\">2745000</td><td style=\"text-align: right;\"> 1423.87</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             1098.67</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2760000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-08-04\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1425.25599148224\n",
      "  episode_reward_min: 1091.8270669282888\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 920\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 5.145725154569876e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.155845994060322\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03547665276786342\n",
      "          policy_loss: 0.006837020099056506\n",
      "          total_loss: 492.66661166821495\n",
      "          vf_explained_var: 0.6615985631942749\n",
      "          vf_loss: 492.6597775184502\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2760000\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2760000\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.452272727272724\n",
      "    ram_util_percent: 19.56590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424644020131513\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.294841030775825\n",
      "    mean_inference_ms: 0.510796127771266\n",
      "    mean_raw_obs_processing_ms: 4.368528845526255\n",
      "  time_since_restore: 5733.384894371033\n",
      "  time_this_iter_s: 30.888320446014404\n",
      "  time_total_s: 5733.384894371033\n",
      "  timers:\n",
      "    learn_throughput: 5996.643\n",
      "    learn_time_ms: 2501.399\n",
      "    sample_throughput: 504.679\n",
      "    sample_time_ms: 29721.858\n",
      "    update_time_ms: 1.026\n",
      "  timestamp: 1674284884\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 184\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">         5733.38</td><td style=\"text-align: right;\">2760000</td><td style=\"text-align: right;\"> 1425.26</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             1091.83</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 268\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.5194978538368025\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2775000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-08-34\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1408.4880161800966\n",
      "  episode_reward_min: 1040.1342216048897\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 925\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 5.145725154569876e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.138969217720678\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04090869540852289\n",
      "          policy_loss: 0.008683124783654081\n",
      "          total_loss: 491.75079595921403\n",
      "          vf_explained_var: 0.6244450211524963\n",
      "          vf_loss: 491.7421121015387\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2775000\n",
      "    num_steps_sampled: 2775000\n",
      "    num_steps_trained: 2775000\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.493023255813956\n",
      "    ram_util_percent: 19.630232558139536\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054246485711616076\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.294959996780775\n",
      "    mean_inference_ms: 0.5107977392483689\n",
      "    mean_raw_obs_processing_ms: 4.369405121887895\n",
      "  time_since_restore: 5763.640647172928\n",
      "  time_this_iter_s: 30.25575280189514\n",
      "  time_total_s: 5763.640647172928\n",
      "  timers:\n",
      "    learn_throughput: 5989.253\n",
      "    learn_time_ms: 2504.486\n",
      "    sample_throughput: 505.432\n",
      "    sample_time_ms: 29677.611\n",
      "    update_time_ms: 1.07\n",
      "  timestamp: 1674284914\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2775000\n",
      "  training_iteration: 185\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         5763.64</td><td style=\"text-align: right;\">2775000</td><td style=\"text-align: right;\"> 1408.49</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             1040.13</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.427046998576354\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 270\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.6143732387852054\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2790000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-09-05\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1398.344378828683\n",
      "  episode_reward_min: 1037.1580565690515\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 930\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.039609611438492\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025934123640887048\n",
      "          policy_loss: 0.005983675764557921\n",
      "          total_loss: 529.108924545676\n",
      "          vf_explained_var: 0.7682629227638245\n",
      "          vf_loss: 529.1029399289923\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2790000\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2790000\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.17954545454546\n",
      "    ram_util_percent: 19.56590909090909\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054246621244384174\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295089877616491\n",
      "    mean_inference_ms: 0.5108002358927414\n",
      "    mean_raw_obs_processing_ms: 4.370343174997963\n",
      "  time_since_restore: 5794.245730638504\n",
      "  time_this_iter_s: 30.605083465576172\n",
      "  time_total_s: 5794.245730638504\n",
      "  timers:\n",
      "    learn_throughput: 5998.064\n",
      "    learn_time_ms: 2500.807\n",
      "    sample_throughput: 505.69\n",
      "    sample_time_ms: 29662.444\n",
      "    update_time_ms: 1.022\n",
      "  timestamp: 1674284945\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 186\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         5794.25</td><td style=\"text-align: right;\">2790000</td><td style=\"text-align: right;\"> 1398.34</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             1037.16</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 241\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.236854288051661\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 244\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.379503211387676\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m Could not connect to TraCI server at localhost:37855 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m Could not connect to TraCI server at localhost:34299 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m Could not connect to TraCI server at localhost:40901 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 3 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2805000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-09-41\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1382.9032938575444\n",
      "  episode_reward_min: 1000.3312484075065\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 935\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.131789636611939\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03334719464229113\n",
      "          policy_loss: 0.008883548775190582\n",
      "          total_loss: 475.0510964652239\n",
      "          vf_explained_var: 0.6310979127883911\n",
      "          vf_loss: 475.0422132087966\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2805000\n",
      "    num_steps_sampled: 2805000\n",
      "    num_steps_trained: 2805000\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 25.21923076923077\n",
      "    ram_util_percent: 19.61346153846154\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054246891683659336\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.2952098837510695\n",
      "    mean_inference_ms: 0.5108038690944072\n",
      "    mean_raw_obs_processing_ms: 4.3717047564401845\n",
      "  time_since_restore: 5830.2696669101715\n",
      "  time_this_iter_s: 36.02393627166748\n",
      "  time_total_s: 5830.2696669101715\n",
      "  timers:\n",
      "    learn_throughput: 6021.788\n",
      "    learn_time_ms: 2490.955\n",
      "    sample_throughput: 504.865\n",
      "    sample_time_ms: 29710.924\n",
      "    update_time_ms: 1.02\n",
      "  timestamp: 1674284981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2805000\n",
      "  training_iteration: 187\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         5830.27</td><td style=\"text-align: right;\">2805000</td><td style=\"text-align: right;\">  1382.9</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             1000.33</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 247\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.522125250095652\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 254\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.854791141191876\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2820000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-10-11\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1350.1844770145728\n",
      "  episode_reward_min: 734.7776508180148\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 940\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.019008269148358\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03903065893283103\n",
      "          policy_loss: 0.009108955770636262\n",
      "          total_loss: 446.0672957933555\n",
      "          vf_explained_var: 0.7237807512283325\n",
      "          vf_loss: 446.05818842427203\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2820000\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2820000\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.555813953488375\n",
      "    ram_util_percent: 19.56511627906977\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424719249274629\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.29529814701144\n",
      "    mean_inference_ms: 0.5108079878895291\n",
      "    mean_raw_obs_processing_ms: 4.373066761055725\n",
      "  time_since_restore: 5860.434513568878\n",
      "  time_this_iter_s: 30.164846658706665\n",
      "  time_total_s: 5860.434513568878\n",
      "  timers:\n",
      "    learn_throughput: 6035.46\n",
      "    learn_time_ms: 2485.312\n",
      "    sample_throughput: 505.62\n",
      "    sample_time_ms: 29666.521\n",
      "    update_time_ms: 1.052\n",
      "  timestamp: 1674285011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 188\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">         5860.43</td><td style=\"text-align: right;\">2820000</td><td style=\"text-align: right;\"> 1350.18</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             734.778</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 250\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.664717904914125\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 256\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.949804327743507\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 249\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.617190445131122\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2835000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1335.0476656679268\n",
      "  episode_reward_min: 734.7776508180148\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 945\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9775448403116\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024359814021547833\n",
      "          policy_loss: 0.0036359303615103333\n",
      "          total_loss: 502.2996863413665\n",
      "          vf_explained_var: 0.8091704249382019\n",
      "          vf_loss: 502.2960487592018\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2835000\n",
      "    num_steps_sampled: 2835000\n",
      "    num_steps_trained: 2835000\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.17045454545454\n",
      "    ram_util_percent: 19.661363636363642\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424742858088403\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295392559710019\n",
      "    mean_inference_ms: 0.5108116158888681\n",
      "    mean_raw_obs_processing_ms: 4.374417355675576\n",
      "  time_since_restore: 5891.041863441467\n",
      "  time_this_iter_s: 30.60734987258911\n",
      "  time_total_s: 5891.041863441467\n",
      "  timers:\n",
      "    learn_throughput: 6034.493\n",
      "    learn_time_ms: 2485.71\n",
      "    sample_throughput: 506.246\n",
      "    sample_time_ms: 29629.877\n",
      "    update_time_ms: 1.04\n",
      "  timestamp: 1674285042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2835000\n",
      "  training_iteration: 189\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         5891.04</td><td style=\"text-align: right;\">2835000</td><td style=\"text-align: right;\"> 1335.05</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             734.778</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 224\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4281086136538996\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2850000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-11-12\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1319.4102406472164\n",
      "  episode_reward_min: 734.7776508180148\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 950\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.990633248676688\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017349473592308432\n",
      "          policy_loss: 0.004036489534546953\n",
      "          total_loss: 504.4075165829416\n",
      "          vf_explained_var: 0.814257800579071\n",
      "          vf_loss: 504.4034766989239\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2850000\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2850000\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.681395348837214\n",
      "    ram_util_percent: 19.634883720930237\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424775436446584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295489596116102\n",
      "    mean_inference_ms: 0.5108159151653344\n",
      "    mean_raw_obs_processing_ms: 4.375659601187511\n",
      "  time_since_restore: 5921.281666278839\n",
      "  time_this_iter_s: 30.239802837371826\n",
      "  time_total_s: 5921.281666278839\n",
      "  timers:\n",
      "    learn_throughput: 6034.806\n",
      "    learn_time_ms: 2485.581\n",
      "    sample_throughput: 506.439\n",
      "    sample_time_ms: 29618.553\n",
      "    update_time_ms: 1.044\n",
      "  timestamp: 1674285072\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 190\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   190</td><td style=\"text-align: right;\">         5921.28</td><td style=\"text-align: right;\">2850000</td><td style=\"text-align: right;\"> 1319.41</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             734.778</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 229\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.666034803266416\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2865000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-11-43\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1304.9518181888125\n",
      "  episode_reward_min: 734.7776508180148\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 955\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.109059925806725\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.036262458704855595\n",
      "          policy_loss: 0.00807942178818571\n",
      "          total_loss: 481.18415501319754\n",
      "          vf_explained_var: 0.7157102227210999\n",
      "          vf_loss: 481.17607860241907\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2865000\n",
      "    num_steps_sampled: 2865000\n",
      "    num_steps_trained: 2865000\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.861363636363645\n",
      "    ram_util_percent: 19.665909090909096\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424795859217428\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295581875839092\n",
      "    mean_inference_ms: 0.5108189979338682\n",
      "    mean_raw_obs_processing_ms: 4.376914449453796\n",
      "  time_since_restore: 5951.828787326813\n",
      "  time_this_iter_s: 30.547121047973633\n",
      "  time_total_s: 5951.828787326813\n",
      "  timers:\n",
      "    learn_throughput: 6010.338\n",
      "    learn_time_ms: 2495.7\n",
      "    sample_throughput: 516.119\n",
      "    sample_time_ms: 29063.047\n",
      "    update_time_ms: 1.001\n",
      "  timestamp: 1674285103\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2865000\n",
      "  training_iteration: 191\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">         5951.83</td><td style=\"text-align: right;\">2865000</td><td style=\"text-align: right;\"> 1304.95</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             734.778</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 265\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.37714246265477\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 236\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 3.999052674951912\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 240\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.189299083856172\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2880000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-12-14\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1259.7920357275104\n",
      "  episode_reward_min: 679.6023709381095\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 960\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.032025093143269\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03782185956031273\n",
      "          policy_loss: 0.008399260864332634\n",
      "          total_loss: 459.7037346152936\n",
      "          vf_explained_var: 0.7962245941162109\n",
      "          vf_loss: 459.6953341427496\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2880000\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2880000\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.54418604651163\n",
      "    ram_util_percent: 19.653488372093026\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424819719152663\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295628579253851\n",
      "    mean_inference_ms: 0.5108226031381767\n",
      "    mean_raw_obs_processing_ms: 4.377690488203233\n",
      "  time_since_restore: 5982.322456121445\n",
      "  time_this_iter_s: 30.493668794631958\n",
      "  time_total_s: 5982.322456121445\n",
      "  timers:\n",
      "    learn_throughput: 5972.371\n",
      "    learn_time_ms: 2511.565\n",
      "    sample_throughput: 516.393\n",
      "    sample_time_ms: 29047.629\n",
      "    update_time_ms: 1.005\n",
      "  timestamp: 1674285134\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 192\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">         5982.32</td><td style=\"text-align: right;\">2880000</td><td style=\"text-align: right;\"> 1259.79</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             679.602</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 261\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.187261846097525\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 259\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.092292348291853\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2895000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-12-44\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1226.4138525888318\n",
      "  episode_reward_min: 629.4332391860307\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 965\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9185806777517675\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02562419423607581\n",
      "          policy_loss: 0.004690681583686116\n",
      "          total_loss: 459.31168099096266\n",
      "          vf_explained_var: 0.7966905236244202\n",
      "          vf_loss: 459.3069899397381\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2895000\n",
      "    num_steps_sampled: 2895000\n",
      "    num_steps_trained: 2895000\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.21136363636363\n",
      "    ram_util_percent: 19.661363636363642\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424848429806218\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295665589351489\n",
      "    mean_inference_ms: 0.510826057877766\n",
      "    mean_raw_obs_processing_ms: 4.37849007990904\n",
      "  time_since_restore: 6012.733545780182\n",
      "  time_this_iter_s: 30.411089658737183\n",
      "  time_total_s: 6012.733545780182\n",
      "  timers:\n",
      "    learn_throughput: 5960.718\n",
      "    learn_time_ms: 2516.475\n",
      "    sample_throughput: 526.274\n",
      "    sample_time_ms: 28502.243\n",
      "    update_time_ms: 0.952\n",
      "  timestamp: 1674285164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2895000\n",
      "  training_iteration: 193\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">         6012.73</td><td style=\"text-align: right;\">2895000</td><td style=\"text-align: right;\"> 1226.41</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             629.433</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 257\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.997304682316517\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 221\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.285334164169417\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 235\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.9514850725282584\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2910000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-13-15\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2493.8438091888775\n",
      "  episode_reward_mean: 1179.72242494887\n",
      "  episode_reward_min: 584.6394074128102\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 970\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.919599458120637\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027320028213827154\n",
      "          policy_loss: 0.00553853106211429\n",
      "          total_loss: 439.72704593771596\n",
      "          vf_explained_var: 0.8315238356590271\n",
      "          vf_loss: 439.7215086338884\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2910000\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2910000\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.548837209302327\n",
      "    ram_util_percent: 19.658139534883727\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424886037408701\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295662925817787\n",
      "    mean_inference_ms: 0.510828293055936\n",
      "    mean_raw_obs_processing_ms: 4.379291931476228\n",
      "  time_since_restore: 6043.03263092041\n",
      "  time_this_iter_s: 30.29908514022827\n",
      "  time_total_s: 6043.03263092041\n",
      "  timers:\n",
      "    learn_throughput: 5958.006\n",
      "    learn_time_ms: 2517.621\n",
      "    sample_throughput: 527.385\n",
      "    sample_time_ms: 28442.209\n",
      "    update_time_ms: 0.943\n",
      "  timestamp: 1674285195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 194\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">         6043.03</td><td style=\"text-align: right;\">2910000</td><td style=\"text-align: right;\"> 1179.72</td><td style=\"text-align: right;\">             2493.84</td><td style=\"text-align: right;\">             584.639</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 246\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.474587708995648\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 226\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.5232840694769565\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2925000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-13-45\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2362.7642582374806\n",
      "  episode_reward_mean: 1132.086506044947\n",
      "  episode_reward_min: 575.1702706684322\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 975\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9615464657039965\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027486326852697383\n",
      "          policy_loss: 0.0058234001963667695\n",
      "          total_loss: 414.3838671126608\n",
      "          vf_explained_var: 0.7123578786849976\n",
      "          vf_loss: 414.3780434980231\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2925000\n",
      "    num_steps_sampled: 2925000\n",
      "    num_steps_trained: 2925000\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.83181818181818\n",
      "    ram_util_percent: 19.659090909090914\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054249361893358355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295626443279582\n",
      "    mean_inference_ms: 0.510831123227616\n",
      "    mean_raw_obs_processing_ms: 4.380124854295824\n",
      "  time_since_restore: 6073.385136842728\n",
      "  time_this_iter_s: 30.352505922317505\n",
      "  time_total_s: 6073.385136842728\n",
      "  timers:\n",
      "    learn_throughput: 5951.673\n",
      "    learn_time_ms: 2520.3\n",
      "    sample_throughput: 527.254\n",
      "    sample_time_ms: 28449.306\n",
      "    update_time_ms: 0.897\n",
      "  timestamp: 1674285225\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2925000\n",
      "  training_iteration: 195\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         6073.39</td><td style=\"text-align: right;\">2925000</td><td style=\"text-align: right;\"> 1132.09</td><td style=\"text-align: right;\">             2362.76</td><td style=\"text-align: right;\">              575.17</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 251\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.71224180704279\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 269\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.566938458220921\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 239\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.141741239205832\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2940000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-14-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2362.7642582374806\n",
      "  episode_reward_mean: 1106.1471410791594\n",
      "  episode_reward_min: 575.1702706684322\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 980\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.042011574971474\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.032373252956831154\n",
      "          policy_loss: 0.007099169085563902\n",
      "          total_loss: 452.27316681813386\n",
      "          vf_explained_var: 0.7855331301689148\n",
      "          vf_loss: 452.2660676762209\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2940000\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2940000\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 28.708888888888886\n",
      "    ram_util_percent: 19.660000000000007\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424989502825933\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295567005283943\n",
      "    mean_inference_ms: 0.5108340682397039\n",
      "    mean_raw_obs_processing_ms: 4.380976070107324\n",
      "  time_since_restore: 6104.761482954025\n",
      "  time_this_iter_s: 31.376346111297607\n",
      "  time_total_s: 6104.761482954025\n",
      "  timers:\n",
      "    learn_throughput: 5926.283\n",
      "    learn_time_ms: 2531.098\n",
      "    sample_throughput: 526.028\n",
      "    sample_time_ms: 28515.594\n",
      "    update_time_ms: 0.895\n",
      "  timestamp: 1674285257\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 196\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   196</td><td style=\"text-align: right;\">         6104.76</td><td style=\"text-align: right;\">2940000</td><td style=\"text-align: right;\"> 1106.15</td><td style=\"text-align: right;\">             2362.76</td><td style=\"text-align: right;\">              575.17</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 253\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 4.807278529691987\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 255\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 4.902299776966978\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2955000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-14-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2362.7642582374806\n",
      "  episode_reward_mean: 1081.59406698173\n",
      "  episode_reward_min: 572.3431550562859\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 985\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9988843354128174\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02800677299888727\n",
      "          policy_loss: 0.005170356044526038\n",
      "          total_loss: 435.9079145011255\n",
      "          vf_explained_var: 0.5793039202690125\n",
      "          vf_loss: 435.90274306151827\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2955000\n",
      "    num_steps_sampled: 2955000\n",
      "    num_steps_trained: 2955000\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.630232558139532\n",
      "    ram_util_percent: 19.658139534883727\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425064832054585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295505962186331\n",
      "    mean_inference_ms: 0.5108387967167738\n",
      "    mean_raw_obs_processing_ms: 4.381364206743926\n",
      "  time_since_restore: 6135.249577522278\n",
      "  time_this_iter_s: 30.488094568252563\n",
      "  time_total_s: 6135.249577522278\n",
      "  timers:\n",
      "    learn_throughput: 5996.509\n",
      "    learn_time_ms: 2501.455\n",
      "    sample_throughput: 535.875\n",
      "    sample_time_ms: 27991.599\n",
      "    update_time_ms: 0.897\n",
      "  timestamp: 1674285287\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2955000\n",
      "  training_iteration: 197\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">         6135.25</td><td style=\"text-align: right;\">2955000</td><td style=\"text-align: right;\"> 1081.59</td><td style=\"text-align: right;\">             2362.76</td><td style=\"text-align: right;\">             572.343</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 225\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.4756971311168834\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 222\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 3.3329270738617227\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 258\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.044800727535787\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 242\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 4.2844067680020546\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 227\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 3.570869368805752\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2970000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-15-17\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2362.7642582374806\n",
      "  episode_reward_mean: 1049.0247450643108\n",
      "  episode_reward_min: 572.3431550562859\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 990\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 7.718587731854811e-21\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.926145679869894\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.043517121981195804\n",
      "          policy_loss: 0.008313633771455388\n",
      "          total_loss: 407.30544696581563\n",
      "          vf_explained_var: 0.7690498232841492\n",
      "          vf_loss: 407.2971338061963\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2970000\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2970000\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.97142857142857\n",
      "    ram_util_percent: 19.673809523809528\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425143515976637\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295437157978407\n",
      "    mean_inference_ms: 0.5108439745270255\n",
      "    mean_raw_obs_processing_ms: 4.381654591985245\n",
      "  time_since_restore: 6164.641993522644\n",
      "  time_this_iter_s: 29.39241600036621\n",
      "  time_total_s: 6164.641993522644\n",
      "  timers:\n",
      "    learn_throughput: 5957.743\n",
      "    learn_time_ms: 2517.732\n",
      "    sample_throughput: 537.674\n",
      "    sample_time_ms: 27897.921\n",
      "    update_time_ms: 0.908\n",
      "  timestamp: 1674285317\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 198\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   198</td><td style=\"text-align: right;\">         6164.64</td><td style=\"text-align: right;\">2970000</td><td style=\"text-align: right;\"> 1049.02</td><td style=\"text-align: right;\">             2362.76</td><td style=\"text-align: right;\">             572.343</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 237\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.04661795519353\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 264\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.329679917416892\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 243\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 4.331956438196479\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 233\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 3.856343201216534\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 2985000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-15-47\n",
      "  done: false\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2362.7642582374806\n",
      "  episode_reward_mean: 1012.5512003196916\n",
      "  episode_reward_min: 572.3431550562859\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 995\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.1577881597782219e-20\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9855383959867186\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.034367914854765924\n",
      "          policy_loss: 0.007325846600638292\n",
      "          total_loss: 400.69765627343776\n",
      "          vf_explained_var: 0.6969638466835022\n",
      "          vf_loss: 400.69033200457943\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2985000\n",
      "    num_steps_sampled: 2985000\n",
      "    num_steps_trained: 2985000\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.08409090909091\n",
      "    ram_util_percent: 19.686363636363634\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054252204589882363\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295314005546955\n",
      "    mean_inference_ms: 0.5108482799294886\n",
      "    mean_raw_obs_processing_ms: 4.381954120740591\n",
      "  time_since_restore: 6195.001776456833\n",
      "  time_this_iter_s: 30.359782934188843\n",
      "  time_total_s: 6195.001776456833\n",
      "  timers:\n",
      "    learn_throughput: 5957.547\n",
      "    learn_time_ms: 2517.815\n",
      "    sample_throughput: 538.154\n",
      "    sample_time_ms: 27873.085\n",
      "    update_time_ms: 0.928\n",
      "  timestamp: 1674285347\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2985000\n",
      "  training_iteration: 199\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">            6195</td><td style=\"text-align: right;\">2985000</td><td style=\"text-align: right;\"> 1012.55</td><td style=\"text-align: right;\">             2362.76</td><td style=\"text-align: right;\">             572.343</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m ring length: 220\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m v_max: 3.2377399006821497\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m ring length: 266\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m v_max: 5.42459972166245\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m ring length: 252\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m v_max: 4.759762049824181\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m ring length: 263\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m v_max: 5.282212215151455\n",
      "\u001b[2m\u001b[36m(pid=14938)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=14941)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14939)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14937)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=14940)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_WaveAttenuationPOEnv-v0_f5ceb_00000:\n",
      "  agent_timesteps_total: 3000000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-21_01-16-18\n",
      "  done: true\n",
      "  episode_len_mean: 3000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2913.7741153307957\n",
      "  episode_reward_mean: 1011.178692884439\n",
      "  episode_reward_min: 572.3431550562859\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 1000\n",
      "  experiment_id: d3f77eb9a51340fbbd34c77a4441b14d\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 1.1577881597782219e-20\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9783795837628637\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021767238687484262\n",
      "          policy_loss: 0.004166749862054268\n",
      "          total_loss: 466.57175742650435\n",
      "          vf_explained_var: 0.7713456153869629\n",
      "          vf_loss: 466.56758964021327\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3000000\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 3000000\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.318181818181817\n",
      "    ram_util_percent: 19.72045454545455\n",
      "  pid: 14936\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05425302478887763\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 4.295208066767768\n",
      "    mean_inference_ms: 0.5108526335775995\n",
      "    mean_raw_obs_processing_ms: 4.3822632154007115\n",
      "  time_since_restore: 6225.852924585342\n",
      "  time_this_iter_s: 30.85114812850952\n",
      "  time_total_s: 6225.852924585342\n",
      "  timers:\n",
      "    learn_throughput: 5940.084\n",
      "    learn_time_ms: 2525.217\n",
      "    sample_throughput: 537.119\n",
      "    sample_time_ms: 27926.792\n",
      "    update_time_ms: 0.966\n",
      "  timestamp: 1674285378\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 200\n",
      "  trial_id: f5ceb_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>RUNNING </td><td>192.168.1.65:14936</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         6225.85</td><td style=\"text-align: right;\">3000000</td><td style=\"text-align: right;\"> 1011.18</td><td style=\"text-align: right;\">             2913.77</td><td style=\"text-align: right;\">             572.343</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/10.3 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_2_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_1_efed2202c64caccc2cbfb63def732e98, 0.0/6.0 CPU_group_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_3_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_0_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 CPU_group_5_efed2202c64caccc2cbfb63def732e98, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_ring<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                             </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WaveAttenuationPOEnv-v0_f5ceb_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         6225.85</td><td style=\"text-align: right;\">3000000</td><td style=\"text-align: right;\"> 1011.18</td><td style=\"text-align: right;\">             2913.77</td><td style=\"text-align: right;\">             572.343</td><td style=\"text-align: right;\">              3000</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 01:16:18,947\tINFO tune.py:550 -- Total run time: 6245.07 seconds (6244.71 seconds for the tuning loop).\n",
      "2023-01-21 14:39:38,162\tWARNING worker.py:1189 -- The node with node id: 50665bb70f4e9f14abbe2d04557fa0b9d1c5136c33a50153e2f51558 and ip: 192.168.1.65 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a raylet crashes unexpectedly or has lagging heartbeats.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-21 14:40:10,555 C 14888 14888] node_manager.cc:165: This node has beem marked as dead.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     ray::rpc::ClientCallImpl<>::OnReplyReceived()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     main\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m     __libc_start_main\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "2023-01-21 14:40:16,683\tWARNING worker.py:1189 -- The autoscaler failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/autoscaler/_private/monitor.py\", line 317, in run\n",
      "    self._run()\n",
      "  File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/autoscaler/_private/monitor.py\", line 207, in _run\n",
      "    self.update_load_metrics()\n",
      "  File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/autoscaler/_private/monitor.py\", line 170, in update_load_metrics\n",
      "    request, timeout=4)\n",
      "  File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/grpc/_channel.py\", line 946, in __call__\n",
      "    return _end_unary_response_blocking(state, call, False, None)\n",
      "  File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/grpc/_channel.py\", line 849, in _end_unary_response_blocking\n",
      "    raise _InactiveRpcError(state)\n",
      "grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.DEADLINE_EXCEEDED\n",
      "\tdetails = \"Deadline Exceeded\"\n",
      "\tdebug_error_string = \"UNKNOWN:Deadline Exceeded {created_time:\"2023-01-21T14:38:29.696264344-06:00\", grpc_status:4}\"\n",
      ">\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ../../examples/train.py singleagent_ring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c6143c",
   "metadata": {},
   "source": [
    "## Training Multiagent Ring Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee41dfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run ../../examples/train.py multiagent_ring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6e1176",
   "metadata": {},
   "source": [
    "## Training Single Agent Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce197386",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run ../../examples/train.py singleagent_figure_eight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a7b2a",
   "metadata": {},
   "source": [
    "## Training Intersection Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1789eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../examples/train.py intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51244303",
   "metadata": {},
   "source": [
    "## Training Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6692bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../examples/train.py bottleneck0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5d45a",
   "metadata": {},
   "source": [
    "## Training Merge Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6cf15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ../../examples/train.py merge0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376dbf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
