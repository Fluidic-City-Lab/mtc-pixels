{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42a295e",
   "metadata": {},
   "source": [
    "## Training Single Agent Ring Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ccd1f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run ../../examples/train.py singleagent_ring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449d17c",
   "metadata": {},
   "source": [
    "## Training Multiagent Ring Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72311496",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run ../../examples/train.py multiagent_ring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1ba77",
   "metadata": {},
   "source": [
    "## Training Single Agent Figure 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4cf0b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_workers': 5, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'gamma': 0.999, 'lr': 5e-05, 'train_batch_size': 15000, 'model': {'_use_default_native_models': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': [[16, [8, 8], 4], [32, [4, 4], 2], [256, [11, 11], 1]], 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'horizon': 1500, 'soft_horizon': False, 'no_done_at_end': False, 'env': None, 'observation_space': None, 'action_space': None, 'env_config': {}, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'simple_optimizer': -1, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.97, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.02, 'vf_share_layers': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 09:22:45,785\tINFO services.py:1247 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 09:22:48,098\tINFO trainer.py:720 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 09:22:51,137\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 26.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.4\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 24.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 27.4\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 27.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.8\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 25.3\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 27.8\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.2\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 27.1\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 24.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 15000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_09-28-01\n",
      "  done: false\n",
      "  episode_len_mean: 1396.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2225.765403546098\n",
      "  episode_reward_mean: -7246.738585793607\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 10\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.349643569982658\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006643003581313555\n",
      "          policy_loss: -0.00506187957924617\n",
      "          total_loss: 19465.356886420817\n",
      "          vf_explained_var: -1.2678614780270436e-07\n",
      "          vf_loss: 19465.36054356462\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 15000\n",
      "    num_steps_sampled: 15000\n",
      "    num_steps_trained: 15000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.252927927927928\n",
      "    ram_util_percent: 26.515990990990993\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0884782072306871\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.76873432275097\n",
      "    mean_inference_ms: 1.7819352167441582\n",
      "    mean_raw_obs_processing_ms: 19.013425216242617\n",
      "  time_since_restore: 310.57365560531616\n",
      "  time_this_iter_s: 310.57365560531616\n",
      "  time_total_s: 310.57365560531616\n",
      "  timers:\n",
      "    learn_throughput: 154.208\n",
      "    learn_time_ms: 97271.012\n",
      "    sample_throughput: 70.328\n",
      "    sample_time_ms: 213286.352\n",
      "    update_time_ms: 2.931\n",
      "  timestamp: 1673105281\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 1\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         310.574</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\">-7246.74</td><td style=\"text-align: right;\">            -2225.77</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">            1396.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 09:28:01,751\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 725.0x the scale of `vf_clip_param`. This means that it will take more than 725.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 20.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 22.0\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.9\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 21.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 21.4\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_09-33-14\n",
      "  done: false\n",
      "  episode_len_mean: 1448.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2225.765403546098\n",
      "  episode_reward_mean: -7419.973993410998\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 20\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.268593695709261\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0120794106896558\n",
      "          policy_loss: -0.0064244064983864455\n",
      "          total_loss: 18192.231027376853\n",
      "          vf_explained_var: -1.702268193071177e-08\n",
      "          vf_loss: 18192.23618743379\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.3085201793722\n",
      "    ram_util_percent: 29.854932735426008\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0885467909014815\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 38.57285950852829\n",
      "    mean_inference_ms: 1.7809421538590047\n",
      "    mean_raw_obs_processing_ms: 19.03054723965611\n",
      "  time_since_restore: 623.5297744274139\n",
      "  time_this_iter_s: 312.9561188220978\n",
      "  time_total_s: 623.5297744274139\n",
      "  timers:\n",
      "    learn_throughput: 153.008\n",
      "    learn_time_ms: 98033.9\n",
      "    sample_throughput: 70.187\n",
      "    sample_time_ms: 213715.83\n",
      "    update_time_ms: 3.037\n",
      "  timestamp: 1673105594\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 2\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 09:33:14,778\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 742.0x the scale of `vf_clip_param`. This means that it will take more than 742.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">          623.53</td><td style=\"text-align: right;\">30000</td><td style=\"text-align: right;\">-7419.97</td><td style=\"text-align: right;\">            -2225.77</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">           1448.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.4\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 26.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 25.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 26.3\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 45000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_09-38-53\n",
      "  done: false\n",
      "  episode_len_mean: 1432.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2225.765403546098\n",
      "  episode_reward_mean: -7243.032864721435\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 30\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1689056734917527\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012550538898872452\n",
      "          policy_loss: -0.007379485476935693\n",
      "          total_loss: 16772.916018935382\n",
      "          vf_explained_var: -8.435572240728106e-09\n",
      "          vf_loss: 16772.922176244705\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 45000\n",
      "    num_steps_sampled: 45000\n",
      "    num_steps_trained: 45000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.237603305785123\n",
      "    ram_util_percent: 29.8198347107438\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08862117254007812\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 37.37495913400577\n",
      "    mean_inference_ms: 1.7821030155355837\n",
      "    mean_raw_obs_processing_ms: 19.01057782476562\n",
      "  time_since_restore: 962.5407664775848\n",
      "  time_this_iter_s: 339.0109920501709\n",
      "  time_total_s: 962.5407664775848\n",
      "  timers:\n",
      "    learn_throughput: 153.263\n",
      "    learn_time_ms: 97871.227\n",
      "    sample_throughput: 67.276\n",
      "    sample_time_ms: 222960.902\n",
      "    update_time_ms: 3.069\n",
      "  timestamp: 1673105933\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45000\n",
      "  training_iteration: 3\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         962.541</td><td style=\"text-align: right;\">45000</td><td style=\"text-align: right;\">-7243.03</td><td style=\"text-align: right;\">            -2225.77</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">            1432.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 09:38:53,831\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 724.0x the scale of `vf_clip_param`. This means that it will take more than 724.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 28.3\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.2\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.8\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 20.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 25.3\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.9\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_09-44-34\n",
      "  done: false\n",
      "  episode_len_mean: 1449.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2225.765403546098\n",
      "  episode_reward_mean: -7174.0756220979065\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 40\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.075692591828815\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010739686521093852\n",
      "          policy_loss: -0.005106668710171924\n",
      "          total_loss: 14662.945217326536\n",
      "          vf_explained_var: -6.5161009921155255e-09\n",
      "          vf_loss: 14662.949267578126\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.227310061601644\n",
      "    ram_util_percent: 29.93593429158111\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08864097867644397\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.610113465199305\n",
      "    mean_inference_ms: 1.7813446883054564\n",
      "    mean_raw_obs_processing_ms: 18.996604125476306\n",
      "  time_since_restore: 1303.4958379268646\n",
      "  time_this_iter_s: 340.9550714492798\n",
      "  time_total_s: 1303.4958379268646\n",
      "  timers:\n",
      "    learn_throughput: 152.707\n",
      "    learn_time_ms: 98227.578\n",
      "    sample_throughput: 65.896\n",
      "    sample_time_ms: 227631.694\n",
      "    update_time_ms: 3.069\n",
      "  timestamp: 1673106274\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 4\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">          1303.5</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-7174.08</td><td style=\"text-align: right;\">            -2225.77</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">            1449.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 09:44:34,827\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 717.0x the scale of `vf_clip_param`. This means that it will take more than 717.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 28.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 27.6\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 21.0\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.2\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 21.3\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 27.3\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.4\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 75000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_09-50-14\n",
      "  done: false\n",
      "  episode_len_mean: 1459.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2225.765403546098\n",
      "  episode_reward_mean: -7017.2563842880245\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 50\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.981490854944213\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012796436696229097\n",
      "          policy_loss: -0.007122577306167301\n",
      "          total_loss: 12057.038928429554\n",
      "          vf_explained_var: -5.4048281405982834e-09\n",
      "          vf_loss: 12057.044820908368\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 75000\n",
      "    num_steps_sampled: 75000\n",
      "    num_steps_trained: 75000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.227010309278347\n",
      "    ram_util_percent: 29.926597938144333\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0886489223854966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.08133573907111\n",
      "    mean_inference_ms: 1.7809630749834682\n",
      "    mean_raw_obs_processing_ms: 18.985558866174426\n",
      "  time_since_restore: 1643.599825143814\n",
      "  time_this_iter_s: 340.10398721694946\n",
      "  time_total_s: 1643.599825143814\n",
      "  timers:\n",
      "    learn_throughput: 152.904\n",
      "    learn_time_ms: 98100.723\n",
      "    sample_throughput: 65.046\n",
      "    sample_time_ms: 230604.434\n",
      "    update_time_ms: 3.046\n",
      "  timestamp: 1673106614\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 75000\n",
      "  training_iteration: 5\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">          1643.6</td><td style=\"text-align: right;\">75000</td><td style=\"text-align: right;\">-7017.26</td><td style=\"text-align: right;\">            -2225.77</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">           1459.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 09:50:14,979\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 702.0x the scale of `vf_clip_param`. This means that it will take more than 702.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 26.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 23.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.5\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 20.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 29.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m Could not connect to TraCI server at localhost:57243 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m Could not connect to TraCI server at localhost:46325 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.7\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 20.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 24.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 90000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_09-56-25\n",
      "  done: false\n",
      "  episode_len_mean: 1453.0819672131147\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2225.765403546098\n",
      "  episode_reward_mean: -6772.638226110775\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 61\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.8818473792177136\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012361753120389412\n",
      "          policy_loss: -0.007973966779881868\n",
      "          total_loss: 10465.801023735434\n",
      "          vf_explained_var: -8.334548162736155e-09\n",
      "          vf_loss: 10465.807776085805\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 14.518714555765596\n",
      "    ram_util_percent: 29.955576559546316\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08862192788459446\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.66396995564726\n",
      "    mean_inference_ms: 1.7805075632348335\n",
      "    mean_raw_obs_processing_ms: 19.05926705502849\n",
      "  time_since_restore: 2014.4571783542633\n",
      "  time_this_iter_s: 370.8573532104492\n",
      "  time_total_s: 2014.4571783542633\n",
      "  timers:\n",
      "    learn_throughput: 152.664\n",
      "    learn_time_ms: 98255.132\n",
      "    sample_throughput: 63.165\n",
      "    sample_time_ms: 237472.922\n",
      "    update_time_ms: 3.042\n",
      "  timestamp: 1673106985\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 6\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         2014.46</td><td style=\"text-align: right;\">90000</td><td style=\"text-align: right;\">-6772.64</td><td style=\"text-align: right;\">            -2225.77</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">           1453.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 09:56:25,884\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 677.0x the scale of `vf_clip_param`. This means that it will take more than 677.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 27.7\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 25.1\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 21.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 30.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 26.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.2\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 20.9\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m Could not connect to TraCI server at localhost:45601 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 105000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_10-02-36\n",
      "  done: false\n",
      "  episode_len_mean: 1459.6901408450703\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2225.765403546098\n",
      "  episode_reward_mean: -6588.506841943894\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 71\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.7936914785433624\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01260353670092119\n",
      "          policy_loss: -0.007953188715549975\n",
      "          total_loss: 8536.682083388507\n",
      "          vf_explained_var: -2.4245956353752263e-09\n",
      "          vf_loss: 8536.688774083024\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 105000\n",
      "    num_steps_sampled: 105000\n",
      "    num_steps_trained: 105000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 14.279395085066165\n",
      "    ram_util_percent: 29.95274102079395\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08863020426708643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.37887337243218\n",
      "    mean_inference_ms: 1.7806278735394463\n",
      "    mean_raw_obs_processing_ms: 19.089458270888734\n",
      "  time_since_restore: 2385.448178768158\n",
      "  time_this_iter_s: 370.99100041389465\n",
      "  time_total_s: 2385.448178768158\n",
      "  timers:\n",
      "    learn_throughput: 152.648\n",
      "    learn_time_ms: 98265.068\n",
      "    sample_throughput: 61.856\n",
      "    sample_time_ms: 242498.484\n",
      "    update_time_ms: 3.038\n",
      "  timestamp: 1673107356\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 105000\n",
      "  training_iteration: 7\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         2385.45</td><td style=\"text-align: right;\">105000</td><td style=\"text-align: right;\">-6588.51</td><td style=\"text-align: right;\">            -2225.77</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">           1459.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 10:02:36,917\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 659.0x the scale of `vf_clip_param`. This means that it will take more than 659.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.1\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 30.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.4\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 23.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 120000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_10-09-13\n",
      "  done: false\n",
      "  episode_len_mean: 1452.9876543209878\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1832.483650600684\n",
      "  episode_reward_mean: -6345.18753379041\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 81\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.6829056298833782\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011768583838853626\n",
      "          policy_loss: -0.007406224272908422\n",
      "          total_loss: 6667.031745729608\n",
      "          vf_explained_var: -1.5153722721095164e-10\n",
      "          vf_loss: 6667.037977108713\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.41058201058201\n",
      "    ram_util_percent: 30.218518518518522\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08863740186738447\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.15347380995849\n",
      "    mean_inference_ms: 1.7813539284346973\n",
      "    mean_raw_obs_processing_ms: 19.10659606249109\n",
      "  time_since_restore: 2782.3157296180725\n",
      "  time_this_iter_s: 396.86755084991455\n",
      "  time_total_s: 2782.3157296180725\n",
      "  timers:\n",
      "    learn_throughput: 152.721\n",
      "    learn_time_ms: 98218.153\n",
      "    sample_throughput: 60.107\n",
      "    sample_time_ms: 249556.628\n",
      "    update_time_ms: 3.027\n",
      "  timestamp: 1673107753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 8\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 10:09:13,835\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 635.0x the scale of `vf_clip_param`. This means that it will take more than 635.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         2782.32</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-6345.19</td><td style=\"text-align: right;\">            -1832.48</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">           1452.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 20.1\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.2\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 25.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 22.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 135000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_10-15-24\n",
      "  done: false\n",
      "  episode_len_mean: 1452.857142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1832.483650600684\n",
      "  episode_reward_mean: -6104.901427967355\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 91\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.5815030159081442\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01600279217311825\n",
      "          policy_loss: -0.009615740788334949\n",
      "          total_loss: 5047.3543132200075\n",
      "          vf_explained_var: -1.2122978176876131e-09\n",
      "          vf_loss: 5047.362348136256\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 135000\n",
      "    num_steps_sampled: 135000\n",
      "    num_steps_trained: 135000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 14.434848484848484\n",
      "    ram_util_percent: 30.277840909090912\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08864242659721201\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.971209278510905\n",
      "    mean_inference_ms: 1.7818184206438716\n",
      "    mean_raw_obs_processing_ms: 19.11848050501523\n",
      "  time_since_restore: 3152.704344511032\n",
      "  time_this_iter_s: 370.3886148929596\n",
      "  time_total_s: 3152.704344511032\n",
      "  timers:\n",
      "    learn_throughput: 152.632\n",
      "    learn_time_ms: 98275.499\n",
      "    sample_throughput: 59.521\n",
      "    sample_time_ms: 252010.265\n",
      "    update_time_ms: 3.096\n",
      "  timestamp: 1673108124\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 135000\n",
      "  training_iteration: 9\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">          3152.7</td><td style=\"text-align: right;\">135000</td><td style=\"text-align: right;\"> -6104.9</td><td style=\"text-align: right;\">            -1832.48</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">           1452.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 10:15:24,267\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 610.0x the scale of `vf_clip_param`. This means that it will take more than 610.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 26.7\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 26.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 22.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 28.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 25.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.1\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.1\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 150000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_10-22-02\n",
      "  done: false\n",
      "  episode_len_mean: 1457.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1832.483650600684\n",
      "  episode_reward_mean: -5873.232609801056\n",
      "  episode_reward_min: -7969.35763538984\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 101\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.49886522490089225\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014236816282018333\n",
      "          policy_loss: -0.008845728064366317\n",
      "          total_loss: 4169.995488364009\n",
      "          vf_explained_var: -9.092234187768611e-10\n",
      "          vf_loss: 4170.002912721796\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 150000\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.545598591549295\n",
      "    ram_util_percent: 30.309683098591552\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0886381740251603\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.76174923721894\n",
      "    mean_inference_ms: 1.7819602662361087\n",
      "    mean_raw_obs_processing_ms: 19.12733563557171\n",
      "  time_since_restore: 3551.0194251537323\n",
      "  time_this_iter_s: 398.3150806427002\n",
      "  time_total_s: 3551.0194251537323\n",
      "  timers:\n",
      "    learn_throughput: 152.608\n",
      "    learn_time_ms: 98291.327\n",
      "    sample_throughput: 58.412\n",
      "    sample_time_ms: 256795.879\n",
      "    update_time_ms: 3.092\n",
      "  timestamp: 1673108522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 10\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3551.02</td><td style=\"text-align: right;\">150000</td><td style=\"text-align: right;\">-5873.23</td><td style=\"text-align: right;\">            -1832.48</td><td style=\"text-align: right;\">            -7969.36</td><td style=\"text-align: right;\">            1457.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 10:22:02,629\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 587.0x the scale of `vf_clip_param`. This means that it will take more than 587.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 26.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 27.7\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 26.3\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.4\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 21.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 165000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_10-28-40\n",
      "  done: false\n",
      "  episode_len_mean: 1456.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -982.3556761270161\n",
      "  episode_reward_mean: -5460.624152228994\n",
      "  episode_reward_min: -7917.516614405632\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 111\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.4166150367866128\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017907051780912883\n",
      "          policy_loss: -0.009283275182272102\n",
      "          total_loss: 2642.7696414236293\n",
      "          vf_explained_var: -5.051241092068892e-10\n",
      "          vf_loss: 2642.777132092492\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 165000\n",
      "    num_steps_sampled: 165000\n",
      "    num_steps_trained: 165000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.342781690140843\n",
      "    ram_util_percent: 30.305985915492958\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08866880640272314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.074175508611916\n",
      "    mean_inference_ms: 1.7818723717175091\n",
      "    mean_raw_obs_processing_ms: 19.14423646828888\n",
      "  time_since_restore: 3948.9501061439514\n",
      "  time_this_iter_s: 397.9306809902191\n",
      "  time_total_s: 3948.9501061439514\n",
      "  timers:\n",
      "    learn_throughput: 152.456\n",
      "    learn_time_ms: 98388.977\n",
      "    sample_throughput: 56.511\n",
      "    sample_time_ms: 265434.081\n",
      "    update_time_ms: 3.1\n",
      "  timestamp: 1673108920\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 165000\n",
      "  training_iteration: 11\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         3948.95</td><td style=\"text-align: right;\">165000</td><td style=\"text-align: right;\">-5460.62</td><td style=\"text-align: right;\">            -982.356</td><td style=\"text-align: right;\">            -7917.52</td><td style=\"text-align: right;\">           1456.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 10:28:40,603\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 546.0x the scale of `vf_clip_param`. This means that it will take more than 546.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 26.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 20.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 25.3\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 22.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_10-35-17\n",
      "  done: false\n",
      "  episode_len_mean: 1447.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -982.3556761270161\n",
      "  episode_reward_mean: -4993.3826867688695\n",
      "  episode_reward_min: -7511.619656878976\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 121\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.3199548948619325\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015021408207169363\n",
      "          policy_loss: -0.007764842324511354\n",
      "          total_loss: 2477.3876061391024\n",
      "          vf_explained_var: -8.587109912028268e-10\n",
      "          vf_loss: 2477.393876828986\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.399823633156968\n",
      "    ram_util_percent: 30.398412698412702\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0886765824799124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.79475234259895\n",
      "    mean_inference_ms: 1.7819258489877847\n",
      "    mean_raw_obs_processing_ms: 19.156572737436917\n",
      "  time_since_restore: 4346.09197473526\n",
      "  time_this_iter_s: 397.1418685913086\n",
      "  time_total_s: 4346.09197473526\n",
      "  timers:\n",
      "    learn_throughput: 152.546\n",
      "    learn_time_ms: 98330.724\n",
      "    sample_throughput: 54.762\n",
      "    sample_time_ms: 273910.861\n",
      "    update_time_ms: 3.092\n",
      "  timestamp: 1673109317\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 12\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 10:35:17,789\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 499.0x the scale of `vf_clip_param`. This means that it will take more than 499.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         4346.09</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">-4993.38</td><td style=\"text-align: right;\">            -982.356</td><td style=\"text-align: right;\">            -7511.62</td><td style=\"text-align: right;\">           1447.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 21.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 23.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 24.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 21.7\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 20.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 27.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 195000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_10-41-54\n",
      "  done: false\n",
      "  episode_len_mean: 1457.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -982.3556761270161\n",
      "  episode_reward_mean: -4588.725139892941\n",
      "  episode_reward_min: -7335.470510023885\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 131\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.22557384270732686\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014728752736163628\n",
      "          policy_loss: -0.006291979949100543\n",
      "          total_loss: 1716.7222449868411\n",
      "          vf_explained_var: -9.597358463508954e-10\n",
      "          vf_loss: 1716.727068005578\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 195000\n",
      "    num_steps_sampled: 195000\n",
      "    num_steps_trained: 195000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.398586572438163\n",
      "    ram_util_percent: 30.449646643109542\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08867211562366611\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.644111509807324\n",
      "    mean_inference_ms: 1.781585794527752\n",
      "    mean_raw_obs_processing_ms: 19.17257340523443\n",
      "  time_since_restore: 4742.9552710056305\n",
      "  time_this_iter_s: 396.8632962703705\n",
      "  time_total_s: 4742.9552710056305\n",
      "  timers:\n",
      "    learn_throughput: 152.318\n",
      "    learn_time_ms: 98478.176\n",
      "    sample_throughput: 53.658\n",
      "    sample_time_ms: 279548.565\n",
      "    update_time_ms: 3.085\n",
      "  timestamp: 1673109714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 195000\n",
      "  training_iteration: 13\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 10:41:54,693\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 459.0x the scale of `vf_clip_param`. This means that it will take more than 459.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         4742.96</td><td style=\"text-align: right;\">195000</td><td style=\"text-align: right;\">-4588.73</td><td style=\"text-align: right;\">            -982.356</td><td style=\"text-align: right;\">            -7335.47</td><td style=\"text-align: right;\">           1457.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.2\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.1\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 23.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 30.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.4\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 27.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.3\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.9\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 210000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_10-48-33\n",
      "  done: false\n",
      "  episode_len_mean: 1457.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -982.3556761270161\n",
      "  episode_reward_mean: -4153.094271369338\n",
      "  episode_reward_min: -6803.707145801231\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 141\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.10148853510302508\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015436872572422176\n",
      "          policy_loss: -0.007425315244225943\n",
      "          total_loss: 1517.1121702549822\n",
      "          vf_explained_var: -2.4751081184604118e-09\n",
      "          vf_loss: 1517.1180495439949\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 210000\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.46274165202109\n",
      "    ram_util_percent: 30.430228471001755\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0886713077418216\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.55811817758547\n",
      "    mean_inference_ms: 1.781629990705093\n",
      "    mean_raw_obs_processing_ms: 19.190297208703324\n",
      "  time_since_restore: 5141.339056015015\n",
      "  time_this_iter_s: 398.38378500938416\n",
      "  time_total_s: 5141.339056015015\n",
      "  timers:\n",
      "    learn_throughput: 152.515\n",
      "    learn_time_ms: 98351.023\n",
      "    sample_throughput: 52.554\n",
      "    sample_time_ms: 285418.481\n",
      "    update_time_ms: 3.095\n",
      "  timestamp: 1673110113\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 14\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 10:48:33,120\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 415.0x the scale of `vf_clip_param`. This means that it will take more than 415.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         5141.34</td><td style=\"text-align: right;\">210000</td><td style=\"text-align: right;\">-4153.09</td><td style=\"text-align: right;\">            -982.356</td><td style=\"text-align: right;\">            -6803.71</td><td style=\"text-align: right;\">           1457.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 24.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 22.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 26.8\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 26.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.2\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 225000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_10-55-09\n",
      "  done: false\n",
      "  episode_len_mean: 1457.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -982.3556761270161\n",
      "  episode_reward_mean: -3725.2238875703124\n",
      "  episode_reward_min: -6204.452348115233\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 151\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.04498743002216127\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017152561465915987\n",
      "          policy_loss: -0.006785717655478392\n",
      "          total_loss: 924.2464583057468\n",
      "          vf_explained_var: -3.535868819959376e-10\n",
      "          vf_loss: 924.2515290082512\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 225000\n",
      "    num_steps_sampled: 225000\n",
      "    num_steps_trained: 225000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.51749116607774\n",
      "    ram_util_percent: 30.583215547703183\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.088670680292275\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.50388786222645\n",
      "    mean_inference_ms: 1.781549244708455\n",
      "    mean_raw_obs_processing_ms: 19.192028349708792\n",
      "  time_since_restore: 5537.9561855793\n",
      "  time_this_iter_s: 396.6171295642853\n",
      "  time_total_s: 5537.9561855793\n",
      "  timers:\n",
      "    learn_throughput: 152.505\n",
      "    learn_time_ms: 98357.528\n",
      "    sample_throughput: 51.535\n",
      "    sample_time_ms: 291063.414\n",
      "    update_time_ms: 3.119\n",
      "  timestamp: 1673110509\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 225000\n",
      "  training_iteration: 15\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         5537.96</td><td style=\"text-align: right;\">225000</td><td style=\"text-align: right;\">-3725.22</td><td style=\"text-align: right;\">            -982.356</td><td style=\"text-align: right;\">            -6204.45</td><td style=\"text-align: right;\">           1457.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 10:55:09,788\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 373.0x the scale of `vf_clip_param`. This means that it will take more than 373.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.5\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.8\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 21.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 28.1\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 23.5\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.9\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 21.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.1\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 240000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_11-02-15\n",
      "  done: false\n",
      "  episode_len_mean: 1459.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -982.3556761270161\n",
      "  episode_reward_mean: -3278.0328159689334\n",
      "  episode_reward_min: -5850.462853560407\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 162\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.0870286067047993\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01703584305993769\n",
      "          policy_loss: -0.006230390759952509\n",
      "          total_loss: 694.4768021405754\n",
      "          vf_explained_var: -3.2833067376003555e-09\n",
      "          vf_loss: 694.4813268887794\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 240000\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 13.000988467874794\n",
      "    ram_util_percent: 30.528665568369032\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08869618311642533\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.466297121043866\n",
      "    mean_inference_ms: 1.7813245746698447\n",
      "    mean_raw_obs_processing_ms: 19.179136732078007\n",
      "  time_since_restore: 5964.025771617889\n",
      "  time_this_iter_s: 426.0695860385895\n",
      "  time_total_s: 5964.025771617889\n",
      "  timers:\n",
      "    learn_throughput: 152.677\n",
      "    learn_time_ms: 98246.533\n",
      "    sample_throughput: 50.557\n",
      "    sample_time_ms: 296695.652\n",
      "    update_time_ms: 3.189\n",
      "  timestamp: 1673110935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 16\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         5964.03</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-3278.03</td><td style=\"text-align: right;\">            -982.356</td><td style=\"text-align: right;\">            -5850.46</td><td style=\"text-align: right;\">           1459.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 11:02:15,901\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 328.0x the scale of `vf_clip_param`. This means that it will take more than 328.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 29.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.8\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 25.4\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 255000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_11-09-21\n",
      "  done: false\n",
      "  episode_len_mean: 1459.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -760.8787549977552\n",
      "  episode_reward_mean: -2874.185221221263\n",
      "  episode_reward_min: -5297.551163767239\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 172\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.1987334294844482\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018541692689171434\n",
      "          policy_loss: -0.005655034387215846\n",
      "          total_loss: 551.2863475734905\n",
      "          vf_explained_var: -7.071737639918751e-10\n",
      "          vf_loss: 551.2901487835383\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 255000\n",
      "    num_steps_sampled: 255000\n",
      "    num_steps_trained: 255000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.799176276771005\n",
      "    ram_util_percent: 30.534266886326186\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0886945528838969\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.44537154196081\n",
      "    mean_inference_ms: 1.7808186958467647\n",
      "    mean_raw_obs_processing_ms: 19.174905271759425\n",
      "  time_since_restore: 6389.346870422363\n",
      "  time_this_iter_s: 425.3210988044739\n",
      "  time_total_s: 6389.346870422363\n",
      "  timers:\n",
      "    learn_throughput: 152.717\n",
      "    learn_time_ms: 98220.622\n",
      "    sample_throughput: 49.643\n",
      "    sample_time_ms: 302154.548\n",
      "    update_time_ms: 3.199\n",
      "  timestamp: 1673111361\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 255000\n",
      "  training_iteration: 17\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         6389.35</td><td style=\"text-align: right;\">255000</td><td style=\"text-align: right;\">-2874.19</td><td style=\"text-align: right;\">            -760.879</td><td style=\"text-align: right;\">            -5297.55</td><td style=\"text-align: right;\">           1459.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 11:09:21,271\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 287.0x the scale of `vf_clip_param`. This means that it will take more than 287.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 27.2\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 23.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 25.7\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 22.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.4\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 270000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_11-16-22\n",
      "  done: false\n",
      "  episode_len_mean: 1469.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -760.8787549977552\n",
      "  episode_reward_mean: -2554.9067595460465\n",
      "  episode_reward_min: -4776.936074690172\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 182\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.30908091508988605\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011065187769788104\n",
      "          policy_loss: -0.002888148381982504\n",
      "          total_loss: 599.3883511171503\n",
      "          vf_explained_var: -3.586381192022259e-09\n",
      "          vf_loss: 599.3901325549109\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 270000\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.587188019966721\n",
      "    ram_util_percent: 30.63610648918469\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0886908914958151\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.42800026949084\n",
      "    mean_inference_ms: 1.7796847228444996\n",
      "    mean_raw_obs_processing_ms: 19.171112275176178\n",
      "  time_since_restore: 6810.4830639362335\n",
      "  time_this_iter_s: 421.13619351387024\n",
      "  time_total_s: 6810.4830639362335\n",
      "  timers:\n",
      "    learn_throughput: 152.691\n",
      "    learn_time_ms: 98237.364\n",
      "    sample_throughput: 49.251\n",
      "    sample_time_ms: 304564.646\n",
      "    update_time_ms: 3.195\n",
      "  timestamp: 1673111782\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 18\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 11:16:22,453\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 255.0x the scale of `vf_clip_param`. This means that it will take more than 255.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         6810.48</td><td style=\"text-align: right;\">270000</td><td style=\"text-align: right;\">-2554.91</td><td style=\"text-align: right;\">            -760.879</td><td style=\"text-align: right;\">            -4776.94</td><td style=\"text-align: right;\">           1469.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.1\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 26.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 27.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 29.3\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.7\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 22.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 27.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.4\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 285000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_11-23-28\n",
      "  done: false\n",
      "  episode_len_mean: 1474.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -760.8787549977552\n",
      "  episode_reward_mean: -2308.4025031215288\n",
      "  episode_reward_min: -4393.670624591621\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 192\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.31404593413916687\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008592141833959434\n",
      "          policy_loss: -0.00238630837737188\n",
      "          total_loss: 784.2857915070098\n",
      "          vf_explained_var: -1.4648599000466334e-09\n",
      "          vf_loss: 784.287319868702\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 285000\n",
      "    num_steps_sampled: 285000\n",
      "    num_steps_trained: 285000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.59654605263158\n",
      "    ram_util_percent: 30.662500000000005\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08868999678234671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.416699380034885\n",
      "    mean_inference_ms: 1.7784824183692527\n",
      "    mean_raw_obs_processing_ms: 19.167640888983332\n",
      "  time_since_restore: 7236.203653335571\n",
      "  time_this_iter_s: 425.72058939933777\n",
      "  time_total_s: 7236.203653335571\n",
      "  timers:\n",
      "    learn_throughput: 152.718\n",
      "    learn_time_ms: 98220.075\n",
      "    sample_throughput: 48.369\n",
      "    sample_time_ms: 310115.224\n",
      "    update_time_ms: 3.136\n",
      "  timestamp: 1673112208\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 285000\n",
      "  training_iteration: 19\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">          7236.2</td><td style=\"text-align: right;\">285000</td><td style=\"text-align: right;\"> -2308.4</td><td style=\"text-align: right;\">            -760.879</td><td style=\"text-align: right;\">            -4393.67</td><td style=\"text-align: right;\">              1474</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 11:23:28,218\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 231.0x the scale of `vf_clip_param`. This means that it will take more than 231.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 26.3\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 20.3\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.2\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 26.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 22.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_11-30-34\n",
      "  done: false\n",
      "  episode_len_mean: 1474.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -760.8787549977552\n",
      "  episode_reward_mean: -2084.311811112864\n",
      "  episode_reward_min: -3799.6000919748826\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 202\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.3626045770564322\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01101877994842655\n",
      "          policy_loss: -0.001274481886145422\n",
      "          total_loss: 722.1128349692135\n",
      "          vf_explained_var: -3.8389433854035815e-09\n",
      "          vf_loss: 722.1135593737586\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.75328947368421\n",
      "    ram_util_percent: 30.709210526315786\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08869182399269146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.410919234806094\n",
      "    mean_inference_ms: 1.777344513952321\n",
      "    mean_raw_obs_processing_ms: 19.16442294118927\n",
      "  time_since_restore: 7662.375471353531\n",
      "  time_this_iter_s: 426.1718180179596\n",
      "  time_total_s: 7662.375471353531\n",
      "  timers:\n",
      "    learn_throughput: 152.776\n",
      "    learn_time_ms: 98182.813\n",
      "    sample_throughput: 47.933\n",
      "    sample_time_ms: 312938.22\n",
      "    update_time_ms: 3.165\n",
      "  timestamp: 1673112634\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 20\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19001)\u001b[0m 2023-01-07 11:30:34,431\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 208.0x the scale of `vf_clip_param`. This means that it will take more than 208.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7662.38</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-2084.31</td><td style=\"text-align: right;\">            -760.879</td><td style=\"text-align: right;\">             -3799.6</td><td style=\"text-align: right;\">              1474</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.7\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 23.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 21.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.3\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 26.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 27.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.8\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 315000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_11-37-39\n",
      "  done: false\n",
      "  episode_len_mean: 1493.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -760.8787549977552\n",
      "  episode_reward_mean: -1950.8065631353536\n",
      "  episode_reward_min: -3567.552440884976\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 212\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.4715881183490915\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013324301606880319\n",
      "          policy_loss: -0.002701206523056884\n",
      "          total_loss: 735.687795529123\n",
      "          vf_explained_var: -2.6266453456713634e-09\n",
      "          vf_loss: 735.6898285946603\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 315000\n",
      "    num_steps_sampled: 315000\n",
      "    num_steps_trained: 315000\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.851320132013202\n",
      "    ram_util_percent: 30.695379537953798\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08869791612406268\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.406074255958835\n",
      "    mean_inference_ms: 1.776657764836861\n",
      "    mean_raw_obs_processing_ms: 19.162129999906128\n",
      "  time_since_restore: 8087.474230051041\n",
      "  time_this_iter_s: 425.09875869750977\n",
      "  time_total_s: 8087.474230051041\n",
      "  timers:\n",
      "    learn_throughput: 152.944\n",
      "    learn_time_ms: 98075.196\n",
      "    sample_throughput: 47.504\n",
      "    sample_time_ms: 315762.69\n",
      "    update_time_ms: 3.183\n",
      "  timestamp: 1673113059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 315000\n",
      "  training_iteration: 21\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         8087.47</td><td style=\"text-align: right;\">315000</td><td style=\"text-align: right;\">-1950.81</td><td style=\"text-align: right;\">            -760.879</td><td style=\"text-align: right;\">            -3567.55</td><td style=\"text-align: right;\">           1493.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 26.6\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.9\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 21.3\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 27.9\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 21.8\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 330000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_11-44-44\n",
      "  done: false\n",
      "  episode_len_mean: 1493.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -760.8787549977552\n",
      "  episode_reward_mean: -1778.3647723770898\n",
      "  episode_reward_min: -3166.8245601178705\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 222\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.5732596843677052\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016314939650895897\n",
      "          policy_loss: -0.004664329939592882\n",
      "          total_loss: 705.7837448378741\n",
      "          vf_explained_var: -5.55636514576463e-09\n",
      "          vf_loss: 705.7875945527675\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 330000\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.747281713344316\n",
      "    ram_util_percent: 30.471169686985174\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08870596084581432\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.40414846392841\n",
      "    mean_inference_ms: 1.7760396787724857\n",
      "    mean_raw_obs_processing_ms: 19.160976053455578\n",
      "  time_since_restore: 8512.540257692337\n",
      "  time_this_iter_s: 425.0660276412964\n",
      "  time_total_s: 8512.540257692337\n",
      "  timers:\n",
      "    learn_throughput: 152.879\n",
      "    learn_time_ms: 98117.011\n",
      "    sample_throughput: 47.094\n",
      "    sample_time_ms: 318513.256\n",
      "    update_time_ms: 3.185\n",
      "  timestamp: 1673113484\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 22\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         8512.54</td><td style=\"text-align: right;\">330000</td><td style=\"text-align: right;\">-1778.36</td><td style=\"text-align: right;\">            -760.879</td><td style=\"text-align: right;\">            -3166.82</td><td style=\"text-align: right;\">           1493.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.4\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 21.1\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 26.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 23.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 24.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 345000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_11-51-48\n",
      "  done: false\n",
      "  episode_len_mean: 1493.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -760.8787549977552\n",
      "  episode_reward_mean: -1623.8801092349759\n",
      "  episode_reward_min: -2804.4507803880074\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 232\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.6962408182479567\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012506158932746569\n",
      "          policy_loss: -0.002135393264608742\n",
      "          total_loss: 666.9511241201627\n",
      "          vf_explained_var: 2.0204964090719812e-10\n",
      "          vf_loss: 666.9526335247492\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 345000\n",
      "    num_steps_sampled: 345000\n",
      "    num_steps_trained: 345000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.76099173553719\n",
      "    ram_util_percent: 30.91305785123967\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08871296080892364\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.40420698547471\n",
      "    mean_inference_ms: 1.775454404255067\n",
      "    mean_raw_obs_processing_ms: 19.16138054195955\n",
      "  time_since_restore: 8936.756227254868\n",
      "  time_this_iter_s: 424.2159695625305\n",
      "  time_total_s: 8936.756227254868\n",
      "  timers:\n",
      "    learn_throughput: 153.026\n",
      "    learn_time_ms: 98022.528\n",
      "    sample_throughput: 46.679\n",
      "    sample_time_ms: 321343.083\n",
      "    update_time_ms: 3.177\n",
      "  timestamp: 1673113908\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 345000\n",
      "  training_iteration: 23\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         8936.76</td><td style=\"text-align: right;\">345000</td><td style=\"text-align: right;\">-1623.88</td><td style=\"text-align: right;\">            -760.879</td><td style=\"text-align: right;\">            -2804.45</td><td style=\"text-align: right;\">           1493.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 25.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.6\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.4\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 27.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 22.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 29.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 23.1\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 20.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 30.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 22.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 360000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_11-58-54\n",
      "  done: false\n",
      "  episode_len_mean: 1493.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -760.8787549977552\n",
      "  episode_reward_mean: -1465.7998947604685\n",
      "  episode_reward_min: -2485.4631763230523\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 242\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.8099230363712473\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015539477470335135\n",
      "          policy_loss: -0.0039014938883325558\n",
      "          total_loss: 672.398596430633\n",
      "          vf_explained_var: -4.344067328077017e-09\n",
      "          vf_loss: 672.4017205836409\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 360000\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.740362438220757\n",
      "    ram_util_percent: 30.953377265238874\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08872182990670252\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.403819753283976\n",
      "    mean_inference_ms: 1.774809457654571\n",
      "    mean_raw_obs_processing_ms: 19.161311975303246\n",
      "  time_since_restore: 9362.350148200989\n",
      "  time_this_iter_s: 425.5939209461212\n",
      "  time_total_s: 9362.350148200989\n",
      "  timers:\n",
      "    learn_throughput: 152.967\n",
      "    learn_time_ms: 98060.474\n",
      "    sample_throughput: 46.293\n",
      "    sample_time_ms: 324026.263\n",
      "    update_time_ms: 3.171\n",
      "  timestamp: 1673114334\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 24\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         9362.35</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -1465.8</td><td style=\"text-align: right;\">            -760.879</td><td style=\"text-align: right;\">            -2485.46</td><td style=\"text-align: right;\">           1493.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 25.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 21.1\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 27.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.3\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 20.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 28.7\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.2\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 375000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_12-06-02\n",
      "  done: false\n",
      "  episode_len_mean: 1493.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -760.8787549977552\n",
      "  episode_reward_mean: -1352.9777099094586\n",
      "  episode_reward_min: -1856.8229958852048\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 252\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.9099971817206528\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015167599369142009\n",
      "          policy_loss: -0.002599477512027942\n",
      "          total_loss: 689.5540894912461\n",
      "          vf_explained_var: -1.0051969923097204e-08\n",
      "          vf_loss: 689.5559319318351\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 375000\n",
      "    num_steps_sampled: 375000\n",
      "    num_steps_trained: 375000\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.556628477905074\n",
      "    ram_util_percent: 30.958265139116204\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08873184404336118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.4060293761011\n",
      "    mean_inference_ms: 1.774096174890609\n",
      "    mean_raw_obs_processing_ms: 19.16247908088909\n",
      "  time_since_restore: 9790.110682964325\n",
      "  time_this_iter_s: 427.7605347633362\n",
      "  time_total_s: 9790.110682964325\n",
      "  timers:\n",
      "    learn_throughput: 152.684\n",
      "    learn_time_ms: 98242.263\n",
      "    sample_throughput: 45.877\n",
      "    sample_time_ms: 326958.74\n",
      "    update_time_ms: 3.22\n",
      "  timestamp: 1673114762\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 375000\n",
      "  training_iteration: 25\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         9790.11</td><td style=\"text-align: right;\">375000</td><td style=\"text-align: right;\">-1352.98</td><td style=\"text-align: right;\">            -760.879</td><td style=\"text-align: right;\">            -1856.82</td><td style=\"text-align: right;\">           1493.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 26.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.3\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 28.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 27.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 21.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.3\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 390000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_12-13-06\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -617.3959026050136\n",
      "  episode_reward_mean: -1282.4545841016982\n",
      "  episode_reward_min: -1778.9149944880871\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 262\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.0267274760088678\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008612529908689761\n",
      "          policy_loss: 0.0009838147785404098\n",
      "          total_loss: 690.7449483127917\n",
      "          vf_explained_var: -6.364563542859969e-09\n",
      "          vf_loss: 690.7435349609892\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 390000\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.694370860927151\n",
      "    ram_util_percent: 31.050662251655627\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0887033341852695\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.4070771491852\n",
      "    mean_inference_ms: 1.77326105395699\n",
      "    mean_raw_obs_processing_ms: 19.149743300511563\n",
      "  time_since_restore: 10213.667999982834\n",
      "  time_this_iter_s: 423.5573170185089\n",
      "  time_total_s: 10213.667999982834\n",
      "  timers:\n",
      "    learn_throughput: 152.589\n",
      "    learn_time_ms: 98303.318\n",
      "    sample_throughput: 45.921\n",
      "    sample_time_ms: 326646.456\n",
      "    update_time_ms: 3.164\n",
      "  timestamp: 1673115186\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 26\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         10213.7</td><td style=\"text-align: right;\">390000</td><td style=\"text-align: right;\">-1282.45</td><td style=\"text-align: right;\">            -617.396</td><td style=\"text-align: right;\">            -1778.91</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 23.2\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 26.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 27.8\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 23.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.9\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 405000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_12-20-14\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -603.4883951060353\n",
      "  episode_reward_mean: -1217.8760702925833\n",
      "  episode_reward_min: -1778.9149944880871\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 272\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.076368865926387\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010253753709104719\n",
      "          policy_loss: 0.0005315577133827038\n",
      "          total_loss: 686.7499672970529\n",
      "          vf_explained_var: -7.071737639918751e-10\n",
      "          vf_loss: 686.749179917675\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 405000\n",
      "    num_steps_sampled: 405000\n",
      "    num_steps_trained: 405000\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.752700490998363\n",
      "    ram_util_percent: 31.134860883797057\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0887107492379809\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.4083253190999\n",
      "    mean_inference_ms: 1.7726450860709422\n",
      "    mean_raw_obs_processing_ms: 19.13919348505608\n",
      "  time_since_restore: 10641.801400184631\n",
      "  time_this_iter_s: 428.1334002017975\n",
      "  time_total_s: 10641.801400184631\n",
      "  timers:\n",
      "    learn_throughput: 152.451\n",
      "    learn_time_ms: 98392.136\n",
      "    sample_throughput: 45.894\n",
      "    sample_time_ms: 326838.773\n",
      "    update_time_ms: 3.217\n",
      "  timestamp: 1673115614\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 405000\n",
      "  training_iteration: 27\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         10641.8</td><td style=\"text-align: right;\">405000</td><td style=\"text-align: right;\">-1217.88</td><td style=\"text-align: right;\">            -603.488</td><td style=\"text-align: right;\">            -1778.91</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 26.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.6\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 21.9\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 28.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 25.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 420000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_12-27-21\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -592.2540154129863\n",
      "  episode_reward_mean: -1144.5861798397664\n",
      "  episode_reward_min: -1778.9149944880871\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 282\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.1032630760790938\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010286460280643768\n",
      "          policy_loss: 0.00015257171560394562\n",
      "          total_loss: 695.6577907562256\n",
      "          vf_explained_var: -3.990480390569928e-09\n",
      "          vf_loss: 695.6573854349427\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 420000\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.685878489326766\n",
      "    ram_util_percent: 31.16535303776683\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.088717066393365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.41576436420156\n",
      "    mean_inference_ms: 1.7721538264665002\n",
      "    mean_raw_obs_processing_ms: 19.131629807188904\n",
      "  time_since_restore: 11068.610846281052\n",
      "  time_this_iter_s: 426.8094460964203\n",
      "  time_total_s: 11068.610846281052\n",
      "  timers:\n",
      "    learn_throughput: 152.364\n",
      "    learn_time_ms: 98448.455\n",
      "    sample_throughput: 45.823\n",
      "    sample_time_ms: 327349.765\n",
      "    update_time_ms: 3.235\n",
      "  timestamp: 1673116041\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 28\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         11068.6</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">-1144.59</td><td style=\"text-align: right;\">            -592.254</td><td style=\"text-align: right;\">            -1778.91</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.1\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 21.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 21.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 26.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 435000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_12-34-25\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -573.121541328681\n",
      "  episode_reward_mean: -1042.3393239919353\n",
      "  episode_reward_min: -1778.9149944880871\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 292\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.1483285388704074\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009677327887575204\n",
      "          policy_loss: 0.00025973361778720204\n",
      "          total_loss: 684.9338243581481\n",
      "          vf_explained_var: -4.798679231754477e-09\n",
      "          vf_loss: 684.9333241802151\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 435000\n",
      "    num_steps_sampled: 435000\n",
      "    num_steps_trained: 435000\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.728052805280528\n",
      "    ram_util_percent: 31.206435643564355\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08872299813847805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.42329563941385\n",
      "    mean_inference_ms: 1.7718883453189398\n",
      "    mean_raw_obs_processing_ms: 19.12415320187689\n",
      "  time_since_restore: 11493.338319778442\n",
      "  time_this_iter_s: 424.72747349739075\n",
      "  time_total_s: 11493.338319778442\n",
      "  timers:\n",
      "    learn_throughput: 152.514\n",
      "    learn_time_ms: 98351.591\n",
      "    sample_throughput: 45.823\n",
      "    sample_time_ms: 327347.307\n",
      "    update_time_ms: 3.25\n",
      "  timestamp: 1673116465\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 435000\n",
      "  training_iteration: 29\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         11493.3</td><td style=\"text-align: right;\">435000</td><td style=\"text-align: right;\">-1042.34</td><td style=\"text-align: right;\">            -573.122</td><td style=\"text-align: right;\">            -1778.91</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 21.1\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.0\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 27.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 25.1\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 29.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 26.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 450000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_12-41-33\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -572.1813484488824\n",
      "  episode_reward_mean: -942.0654134125975\n",
      "  episode_reward_min: -1734.2159007919608\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 302\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.2064809719384726\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01280621523042954\n",
      "          policy_loss: -0.0008877409377403684\n",
      "          total_loss: 706.5002556170448\n",
      "          vf_explained_var: -2.879207317008081e-09\n",
      "          vf_loss: 706.5009809332379\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 450000\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.718330605564647\n",
      "    ram_util_percent: 30.974795417348606\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08872607722457398\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.430110916016226\n",
      "    mean_inference_ms: 1.7716903459130209\n",
      "    mean_raw_obs_processing_ms: 19.117607566167862\n",
      "  time_since_restore: 11921.262009620667\n",
      "  time_this_iter_s: 427.9236898422241\n",
      "  time_total_s: 11921.262009620667\n",
      "  timers:\n",
      "    learn_throughput: 152.412\n",
      "    learn_time_ms: 98417.569\n",
      "    sample_throughput: 45.808\n",
      "    sample_time_ms: 327456.501\n",
      "    update_time_ms: 3.234\n",
      "  timestamp: 1673116893\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 30\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         11921.3</td><td style=\"text-align: right;\">450000</td><td style=\"text-align: right;\">-942.065</td><td style=\"text-align: right;\">            -572.181</td><td style=\"text-align: right;\">            -1734.22</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.4\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.3\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 26.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 22.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 20.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 465000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_12-48-39\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -423.1775044254517\n",
      "  episode_reward_mean: -839.8531830272187\n",
      "  episode_reward_min: -1508.0661359323667\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 312\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.2212503658512892\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012517680632114815\n",
      "          policy_loss: 0.0004421744888285333\n",
      "          total_loss: 689.868198116755\n",
      "          vf_explained_var: -1.111273073561847e-09\n",
      "          vf_loss: 689.8675990153167\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 465000\n",
      "    num_steps_sampled: 465000\n",
      "    num_steps_trained: 465000\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.622075782537069\n",
      "    ram_util_percent: 31.046787479406916\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0887270894211622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.43653832516591\n",
      "    mean_inference_ms: 1.77133696751618\n",
      "    mean_raw_obs_processing_ms: 19.11155223833514\n",
      "  time_since_restore: 12347.069757938385\n",
      "  time_this_iter_s: 425.8077483177185\n",
      "  time_total_s: 12347.069757938385\n",
      "  timers:\n",
      "    learn_throughput: 152.177\n",
      "    learn_time_ms: 98569.721\n",
      "    sample_throughput: 45.819\n",
      "    sample_time_ms: 327375.275\n",
      "    update_time_ms: 3.213\n",
      "  timestamp: 1673117319\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 465000\n",
      "  training_iteration: 31\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         12347.1</td><td style=\"text-align: right;\">465000</td><td style=\"text-align: right;\">-839.853</td><td style=\"text-align: right;\">            -423.178</td><td style=\"text-align: right;\">            -1508.07</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 21.3\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 27.2\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 29.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.2\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 26.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 25.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 480000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_12-55-46\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -393.56122970246764\n",
      "  episode_reward_mean: -746.4816909521161\n",
      "  episode_reward_min: -1406.7558733462567\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 322\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.2926110690933164\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010198798549070052\n",
      "          policy_loss: 0.0012173165567219257\n",
      "          total_loss: 681.1338348647296\n",
      "          vf_explained_var: -2.1720336640385085e-09\n",
      "          vf_loss: 681.1324911214538\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 480000\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.62775041050903\n",
      "    ram_util_percent: 31.053037766830876\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08872724443815688\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.4425041946165\n",
      "    mean_inference_ms: 1.771031153599972\n",
      "    mean_raw_obs_processing_ms: 19.106428525779407\n",
      "  time_since_restore: 12773.79535150528\n",
      "  time_this_iter_s: 426.72559356689453\n",
      "  time_total_s: 12773.79535150528\n",
      "  timers:\n",
      "    learn_throughput: 152.075\n",
      "    learn_time_ms: 98635.556\n",
      "    sample_throughput: 45.805\n",
      "    sample_time_ms: 327475.397\n",
      "    update_time_ms: 3.214\n",
      "  timestamp: 1673117746\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 32\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         12773.8</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\">-746.482</td><td style=\"text-align: right;\">            -393.561</td><td style=\"text-align: right;\">            -1406.76</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.2\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 27.3\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 26.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.3\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.2\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.0\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 25.9\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 495000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_13-02-52\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -393.56122970246764\n",
      "  episode_reward_mean: -673.1652067109753\n",
      "  episode_reward_min: -1183.592082876155\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 332\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.3795928819704864\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013295564348811966\n",
      "          policy_loss: 0.002428816452867083\n",
      "          total_loss: 650.0691146268683\n",
      "          vf_explained_var: -2.0710089199127424e-09\n",
      "          vf_loss: 650.0665176197634\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 495000\n",
      "    num_steps_sampled: 495000\n",
      "    num_steps_trained: 495000\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.693924466338258\n",
      "    ram_util_percent: 31.12495894909688\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08872687529594113\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.44947073721867\n",
      "    mean_inference_ms: 1.7707593479043924\n",
      "    mean_raw_obs_processing_ms: 19.10218497785533\n",
      "  time_since_restore: 13200.193573951721\n",
      "  time_this_iter_s: 426.39822244644165\n",
      "  time_total_s: 13200.193573951721\n",
      "  timers:\n",
      "    learn_throughput: 151.889\n",
      "    learn_time_ms: 98756.337\n",
      "    sample_throughput: 45.791\n",
      "    sample_time_ms: 327572.759\n",
      "    update_time_ms: 3.269\n",
      "  timestamp: 1673118172\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 495000\n",
      "  training_iteration: 33\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         13200.2</td><td style=\"text-align: right;\">495000</td><td style=\"text-align: right;\">-673.165</td><td style=\"text-align: right;\">            -393.561</td><td style=\"text-align: right;\">            -1183.59</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 23.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 27.7\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 21.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.7\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.4\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.4\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.9\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 510000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_13-09-58\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -393.56122970246764\n",
      "  episode_reward_mean: -618.9537901189294\n",
      "  episode_reward_min: -1062.52407482553\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 342\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.3937081897662857\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012729824930715653\n",
      "          policy_loss: 0.0005632265976046101\n",
      "          total_loss: 641.0462650363728\n",
      "          vf_explained_var: -4.091505356740299e-09\n",
      "          vf_loss: 641.0455455198127\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 510000\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.707742998352554\n",
      "    ram_util_percent: 31.18747940691927\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08872581430674151\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.454962044741926\n",
      "    mean_inference_ms: 1.7706085754107859\n",
      "    mean_raw_obs_processing_ms: 19.09871731682059\n",
      "  time_since_restore: 13626.056165456772\n",
      "  time_this_iter_s: 425.86259150505066\n",
      "  time_total_s: 13626.056165456772\n",
      "  timers:\n",
      "    learn_throughput: 151.833\n",
      "    learn_time_ms: 98792.859\n",
      "    sample_throughput: 45.793\n",
      "    sample_time_ms: 327563.127\n",
      "    update_time_ms: 3.259\n",
      "  timestamp: 1673118598\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 34\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         13626.1</td><td style=\"text-align: right;\">510000</td><td style=\"text-align: right;\">-618.954</td><td style=\"text-align: right;\">            -393.561</td><td style=\"text-align: right;\">            -1062.52</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 27.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 24.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.3\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.6\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 28.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 22.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 525000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_13-17-03\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -318.4893926423635\n",
      "  episode_reward_mean: -567.7631188526074\n",
      "  episode_reward_min: -951.1690867710885\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 352\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.48424074528581\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013685335702065498\n",
      "          policy_loss: 0.0011116713541954504\n",
      "          total_loss: 622.6183255599717\n",
      "          vf_explained_var: -2.222546147123694e-09\n",
      "          vf_loss: 622.6170416363215\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 525000\n",
      "    num_steps_sampled: 525000\n",
      "    num_steps_trained: 525000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.654200988467876\n",
      "    ram_util_percent: 31.21169686985173\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08872525163731396\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.45819377559179\n",
      "    mean_inference_ms: 1.7705466985312461\n",
      "    mean_raw_obs_processing_ms: 19.095096956573244\n",
      "  time_since_restore: 14050.94357252121\n",
      "  time_this_iter_s: 424.88740706443787\n",
      "  time_total_s: 14050.94357252121\n",
      "  timers:\n",
      "    learn_throughput: 151.958\n",
      "    learn_time_ms: 98711.752\n",
      "    sample_throughput: 45.822\n",
      "    sample_time_ms: 327356.973\n",
      "    update_time_ms: 3.192\n",
      "  timestamp: 1673119023\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 525000\n",
      "  training_iteration: 35\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         14050.9</td><td style=\"text-align: right;\">525000</td><td style=\"text-align: right;\">-567.763</td><td style=\"text-align: right;\">            -318.489</td><td style=\"text-align: right;\">            -951.169</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 24.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.4\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 25.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.9\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 25.3\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 28.4\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 25.2\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 540000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_13-24-10\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -318.4893926423635\n",
      "  episode_reward_mean: -532.7911827408907\n",
      "  episode_reward_min: -784.2210116917909\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 362\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.515447939755553\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012033204038472611\n",
      "          policy_loss: 0.0006068066958243312\n",
      "          total_loss: 622.5728353662006\n",
      "          vf_explained_var: -6.667638441371082e-09\n",
      "          vf_loss: 622.5720763901533\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 540000\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.622331691297209\n",
      "    ram_util_percent: 30.012643678160916\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08872786063617343\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.463914814090316\n",
      "    mean_inference_ms: 1.7704530713311117\n",
      "    mean_raw_obs_processing_ms: 19.09273035185359\n",
      "  time_since_restore: 14477.827293872833\n",
      "  time_this_iter_s: 426.88372135162354\n",
      "  time_total_s: 14477.827293872833\n",
      "  timers:\n",
      "    learn_throughput: 151.941\n",
      "    learn_time_ms: 98722.393\n",
      "    sample_throughput: 45.777\n",
      "    sample_time_ms: 327678.984\n",
      "    update_time_ms: 3.205\n",
      "  timestamp: 1673119450\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 36\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         14477.8</td><td style=\"text-align: right;\">540000</td><td style=\"text-align: right;\">-532.791</td><td style=\"text-align: right;\">            -318.489</td><td style=\"text-align: right;\">            -784.221</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 23.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.7\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 22.6\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 27.9\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 21.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.3\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 555000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_13-31-15\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -313.5442943983469\n",
      "  episode_reward_mean: -500.0885224612414\n",
      "  episode_reward_min: -763.9945324518347\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 372\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.5836924283181206\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013950968397715594\n",
      "          policy_loss: 0.0006520297725574445\n",
      "          total_loss: 589.1690148822332\n",
      "          vf_explained_var: -4.1925298788214604e-09\n",
      "          vf_loss: 589.1681883084572\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 555000\n",
      "    num_steps_sampled: 555000\n",
      "    num_steps_trained: 555000\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.846534653465346\n",
      "    ram_util_percent: 29.914851485148517\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08873162864967313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.467814398822966\n",
      "    mean_inference_ms: 1.7704858033112967\n",
      "    mean_raw_obs_processing_ms: 19.08967135185094\n",
      "  time_since_restore: 14902.511241912842\n",
      "  time_this_iter_s: 424.68394804000854\n",
      "  time_total_s: 14902.511241912842\n",
      "  timers:\n",
      "    learn_throughput: 152.017\n",
      "    learn_time_ms: 98673.318\n",
      "    sample_throughput: 45.818\n",
      "    sample_time_ms: 327383.275\n",
      "    update_time_ms: 3.137\n",
      "  timestamp: 1673119875\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 555000\n",
      "  training_iteration: 37\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         14902.5</td><td style=\"text-align: right;\">555000</td><td style=\"text-align: right;\">-500.089</td><td style=\"text-align: right;\">            -313.544</td><td style=\"text-align: right;\">            -763.995</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 30.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 21.5\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 20.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 24.2\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 29.6\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 25.7\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 21.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 25.0\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 28.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 570000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_13-38-22\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -313.5442943983469\n",
      "  episode_reward_mean: -478.10865404792503\n",
      "  episode_reward_min: -735.2812369650342\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 382\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.6798308103771533\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013857986925365258\n",
      "          policy_loss: 0.0007903787986201755\n",
      "          total_loss: 573.3278660014524\n",
      "          vf_explained_var: -4.2935548449918315e-09\n",
      "          vf_loss: 573.3269034531157\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 570000\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.93431855500821\n",
      "    ram_util_percent: 29.930541871921182\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08873786795536955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.47142223109388\n",
      "    mean_inference_ms: 1.7705215930241978\n",
      "    mean_raw_obs_processing_ms: 19.086764693688917\n",
      "  time_since_restore: 15329.886075258255\n",
      "  time_this_iter_s: 427.3748333454132\n",
      "  time_total_s: 15329.886075258255\n",
      "  timers:\n",
      "    learn_throughput: 152.089\n",
      "    learn_time_ms: 98626.361\n",
      "    sample_throughput: 45.803\n",
      "    sample_time_ms: 327486.814\n",
      "    update_time_ms: 3.137\n",
      "  timestamp: 1673120302\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 38\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         15329.9</td><td style=\"text-align: right;\">570000</td><td style=\"text-align: right;\">-478.109</td><td style=\"text-align: right;\">            -313.544</td><td style=\"text-align: right;\">            -735.281</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 26.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.2\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.5\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 27.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 26.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.8\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 585000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_13-45-30\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -313.5442943983469\n",
      "  episode_reward_mean: -460.08833934389173\n",
      "  episode_reward_min: -664.6587760310307\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 392\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.6425264137276148\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011269983469741236\n",
      "          policy_loss: 0.0008467702159531793\n",
      "          total_loss: 579.7898806361828\n",
      "          vf_explained_var: -4.9502162369208236e-09\n",
      "          vf_loss: 579.7888894226592\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 585000\n",
      "    num_steps_sampled: 585000\n",
      "    num_steps_trained: 585000\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.69\n",
      "    ram_util_percent: 29.990000000000002\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08874233787587812\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.475370921390315\n",
      "    mean_inference_ms: 1.7704786241158328\n",
      "    mean_raw_obs_processing_ms: 19.084486430444603\n",
      "  time_since_restore: 15757.48681139946\n",
      "  time_this_iter_s: 427.60073614120483\n",
      "  time_total_s: 15757.48681139946\n",
      "  timers:\n",
      "    learn_throughput: 151.816\n",
      "    learn_time_ms: 98804.132\n",
      "    sample_throughput: 45.788\n",
      "    sample_time_ms: 327596.359\n",
      "    update_time_ms: 3.12\n",
      "  timestamp: 1673120730\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 585000\n",
      "  training_iteration: 39\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         15757.5</td><td style=\"text-align: right;\">585000</td><td style=\"text-align: right;\">-460.088</td><td style=\"text-align: right;\">            -313.544</td><td style=\"text-align: right;\">            -664.659</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.2\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.0\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 29.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 22.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 21.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 23.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 20.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 600000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_13-52-36\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -313.5442943983469\n",
      "  episode_reward_mean: -440.55736255894794\n",
      "  episode_reward_min: -617.0188435594047\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 402\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.6433503585346674\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011526009131866032\n",
      "          policy_loss: 0.0018819417415770812\n",
      "          total_loss: 556.6040282103975\n",
      "          vf_explained_var: -6.566613475200711e-09\n",
      "          vf_loss: 556.6020007181976\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 600000\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.668750000000001\n",
      "    ram_util_percent: 30.12417763157895\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08874786304192891\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.477781927299986\n",
      "    mean_inference_ms: 1.770397620663033\n",
      "    mean_raw_obs_processing_ms: 19.081682537283342\n",
      "  time_since_restore: 16183.25801539421\n",
      "  time_this_iter_s: 425.771203994751\n",
      "  time_total_s: 16183.25801539421\n",
      "  timers:\n",
      "    learn_throughput: 151.824\n",
      "    learn_time_ms: 98798.859\n",
      "    sample_throughput: 45.817\n",
      "    sample_time_ms: 327386.393\n",
      "    update_time_ms: 3.125\n",
      "  timestamp: 1673121156\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 40\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         16183.3</td><td style=\"text-align: right;\">600000</td><td style=\"text-align: right;\">-440.557</td><td style=\"text-align: right;\">            -313.544</td><td style=\"text-align: right;\">            -617.019</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 26.3\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 23.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 26.3\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 27.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 23.8\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 25.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 615000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_13-59-40\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -313.5442943983469\n",
      "  episode_reward_mean: -427.9653677536273\n",
      "  episode_reward_min: -566.7899408395564\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 412\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.012499999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7010038835517431\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009804601025406616\n",
      "          policy_loss: 0.0008873144292935603\n",
      "          total_loss: 550.788521478944\n",
      "          vf_explained_var: -5.303803174427912e-09\n",
      "          vf_loss: 550.7875121100474\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 615000\n",
      "    num_steps_sampled: 615000\n",
      "    num_steps_trained: 615000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.669752066115702\n",
      "    ram_util_percent: 30.458842975206608\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08875439761220033\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.47923869220053\n",
      "    mean_inference_ms: 1.7704014438253495\n",
      "    mean_raw_obs_processing_ms: 19.07880533828813\n",
      "  time_since_restore: 16607.341509580612\n",
      "  time_this_iter_s: 424.08349418640137\n",
      "  time_total_s: 16607.341509580612\n",
      "  timers:\n",
      "    learn_throughput: 151.957\n",
      "    learn_time_ms: 98712.251\n",
      "    sample_throughput: 45.829\n",
      "    sample_time_ms: 327300.525\n",
      "    update_time_ms: 3.181\n",
      "  timestamp: 1673121580\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 615000\n",
      "  training_iteration: 41\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         16607.3</td><td style=\"text-align: right;\">615000</td><td style=\"text-align: right;\">-427.965</td><td style=\"text-align: right;\">            -313.544</td><td style=\"text-align: right;\">             -566.79</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 26.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.0\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 24.7\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 20.6\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 26.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 23.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.3\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 28.3\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 630000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_14-06-46\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -313.5442943983469\n",
      "  episode_reward_mean: -423.5086787225817\n",
      "  episode_reward_min: -566.7899408395564\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 422\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0062499999999999995\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7080931075548722\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010429722462388739\n",
      "          policy_loss: 0.0017313644970704059\n",
      "          total_loss: 534.5424704729501\n",
      "          vf_explained_var: -4.142017839825485e-09\n",
      "          vf_loss: 534.5406730457888\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 630000\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.777924217462932\n",
      "    ram_util_percent: 30.107742998352556\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08876029088117626\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.480900645253435\n",
      "    mean_inference_ms: 1.7704523695278938\n",
      "    mean_raw_obs_processing_ms: 19.07589653265584\n",
      "  time_since_restore: 17032.929579257965\n",
      "  time_this_iter_s: 425.5880696773529\n",
      "  time_total_s: 17032.929579257965\n",
      "  timers:\n",
      "    learn_throughput: 152.101\n",
      "    learn_time_ms: 98618.702\n",
      "    sample_throughput: 45.832\n",
      "    sample_time_ms: 327280.336\n",
      "    update_time_ms: 3.19\n",
      "  timestamp: 1673122006\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 42\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         17032.9</td><td style=\"text-align: right;\">630000</td><td style=\"text-align: right;\">-423.509</td><td style=\"text-align: right;\">            -313.544</td><td style=\"text-align: right;\">             -566.79</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.4\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 29.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 22.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 23.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 24.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 27.3\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.7\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.0\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 645000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_14-13-48\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -313.5442943983469\n",
      "  episode_reward_mean: -418.8290659887634\n",
      "  episode_reward_min: -566.7899408395564\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 432\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0062499999999999995\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.69066145389767\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012190529980518727\n",
      "          policy_loss: 0.0005195218442260462\n",
      "          total_loss: 533.7864729347875\n",
      "          vf_explained_var: -4.5461170938843054e-10\n",
      "          vf_loss: 533.7858757600945\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 645000\n",
      "    num_steps_sampled: 645000\n",
      "    num_steps_trained: 645000\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.666943521594684\n",
      "    ram_util_percent: 30.277906976744184\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08876686025296414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.48050518938685\n",
      "    mean_inference_ms: 1.7705011362018999\n",
      "    mean_raw_obs_processing_ms: 19.072364476001834\n",
      "  time_since_restore: 17454.923537254333\n",
      "  time_this_iter_s: 421.9939579963684\n",
      "  time_total_s: 17454.923537254333\n",
      "  timers:\n",
      "    learn_throughput: 152.178\n",
      "    learn_time_ms: 98569.003\n",
      "    sample_throughput: 45.887\n",
      "    sample_time_ms: 326889.712\n",
      "    update_time_ms: 3.124\n",
      "  timestamp: 1673122428\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 645000\n",
      "  training_iteration: 43\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         17454.9</td><td style=\"text-align: right;\">645000</td><td style=\"text-align: right;\">-418.829</td><td style=\"text-align: right;\">            -313.544</td><td style=\"text-align: right;\">             -566.79</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 20.5\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 26.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 24.4\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 20.3\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 23.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 22.3\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 23.4\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 25.7\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 22.9\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 27.8\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 660000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_14-20-55\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -313.5442943983469\n",
      "  episode_reward_mean: -412.4725703608078\n",
      "  episode_reward_min: -566.7899408395564\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 442\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0062499999999999995\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7108786344528197\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01112836250908078\n",
      "          policy_loss: 0.00207436269216271\n",
      "          total_loss: 508.21002144894356\n",
      "          vf_explained_var: -1.7679343544685366e-09\n",
      "          vf_loss: 508.2078805438543\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 660000\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.671639344262294\n",
      "    ram_util_percent: 30.392459016393445\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08877415513348322\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.48153122325911\n",
      "    mean_inference_ms: 1.7705266201357484\n",
      "    mean_raw_obs_processing_ms: 19.069028041063305\n",
      "  time_since_restore: 17882.233470201492\n",
      "  time_this_iter_s: 427.3099329471588\n",
      "  time_total_s: 17882.233470201492\n",
      "  timers:\n",
      "    learn_throughput: 152.136\n",
      "    learn_time_ms: 98596.056\n",
      "    sample_throughput: 45.871\n",
      "    sample_time_ms: 327007.298\n",
      "    update_time_ms: 3.181\n",
      "  timestamp: 1673122855\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 44\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         17882.2</td><td style=\"text-align: right;\">660000</td><td style=\"text-align: right;\">-412.473</td><td style=\"text-align: right;\">            -313.544</td><td style=\"text-align: right;\">             -566.79</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 30.0\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 20.3\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 25.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 21.3\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 28.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 25.9\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 29.5\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 21.8\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 29.5\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 675000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_14-28-01\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -300.48382586170703\n",
      "  episode_reward_mean: -407.72155299429534\n",
      "  episode_reward_min: -566.7899408395564\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 452\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0062499999999999995\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7130629180851629\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011709913983133416\n",
      "          policy_loss: 0.0003871930157371118\n",
      "          total_loss: 506.5842372894287\n",
      "          vf_explained_var: -4.2935548449918315e-09\n",
      "          vf_loss: 506.58377748263086\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 675000\n",
      "    num_steps_sampled: 675000\n",
      "    num_steps_trained: 675000\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.806095551894565\n",
      "    ram_util_percent: 30.43443163097199\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08878037056645079\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.48319198829134\n",
      "    mean_inference_ms: 1.7705640675002585\n",
      "    mean_raw_obs_processing_ms: 19.065907587340433\n",
      "  time_since_restore: 18307.777096271515\n",
      "  time_this_iter_s: 425.5436260700226\n",
      "  time_total_s: 18307.777096271515\n",
      "  timers:\n",
      "    learn_throughput: 152.196\n",
      "    learn_time_ms: 98557.3\n",
      "    sample_throughput: 45.856\n",
      "    sample_time_ms: 327111.706\n",
      "    update_time_ms: 3.19\n",
      "  timestamp: 1673123281\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 675000\n",
      "  training_iteration: 45\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         18307.8</td><td style=\"text-align: right;\">675000</td><td style=\"text-align: right;\">-407.722</td><td style=\"text-align: right;\">            -300.484</td><td style=\"text-align: right;\">             -566.79</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 27.9\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 21.8\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 26.1\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 23.6\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 24.8\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 29.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 27.0\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m ring radius: 28.6\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19002)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m ring radius: 20.4\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19004)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m ring radius: 26.7\n",
      "\u001b[2m\u001b[36m(pid=19003)\u001b[0m -----------------------\n",
      "Result for PPO_AccelEnv-v0_23785_00000:\n",
      "  agent_timesteps_total: 690000\n",
      "  custom_metrics: {}\n",
      "  date: 2023-01-07_14-35-05\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -220.32119215447548\n",
      "  episode_reward_mean: -395.3423714948516\n",
      "  episode_reward_min: -566.7899408395564\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 462\n",
      "  experiment_id: 5537b2bf245b486ab5c095c0a9924546\n",
      "  hostname: michael-villarreal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.0062499999999999995\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7231806098404576\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009453978977707313\n",
      "          policy_loss: 0.001332677452296208\n",
      "          total_loss: 487.9547067027981\n",
      "          vf_explained_var: -3.990480390569928e-09\n",
      "          vf_loss: 487.95331472623144\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 690000\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.1.65\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 12.604125412541254\n",
      "    ram_util_percent: 30.63844884488449\n",
      "  pid: 19001\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08878524294275829\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.48357542699407\n",
      "    mean_inference_ms: 1.7705790547186655\n",
      "    mean_raw_obs_processing_ms: 19.062586751684858\n",
      "  time_since_restore: 18732.62962770462\n",
      "  time_this_iter_s: 424.85253143310547\n",
      "  time_total_s: 18732.62962770462\n",
      "  timers:\n",
      "    learn_throughput: 152.208\n",
      "    learn_time_ms: 98549.205\n",
      "    sample_throughput: 45.883\n",
      "    sample_time_ms: 326916.715\n",
      "    update_time_ms: 3.169\n",
      "  timestamp: 1673123705\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 46\n",
      "  trial_id: '23785_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/9.05 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_3_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_1_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_2_332af4e054b6663f3ed8c3bea05bffa3, 0.0/6.0 CPU_group_332af4e054b6663f3ed8c3bea05bffa3, 0.0/1.0 CPU_group_0_332af4e054b6663f3ed8c3bea05bffa3)<br>Result logdir: /home/michael/ray_results/singleagent_figure_eight<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_AccelEnv-v0_23785_00000</td><td>RUNNING </td><td>192.168.1.65:19001</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         18732.6</td><td style=\"text-align: right;\">690000</td><td style=\"text-align: right;\">-395.342</td><td style=\"text-align: right;\">            -220.321</td><td style=\"text-align: right;\">             -566.79</td><td style=\"text-align: right;\">              1500</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m ring radius: 24.1\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19000)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m ring radius: 28.2\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m -----------------------\n",
      "\u001b[2m\u001b[36m(pid=19005)\u001b[0m  Retrying in 1 seconds\n"
     ]
    }
   ],
   "source": [
    "%run ../../examples/train.py singleagent_figure_eight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88355ae6",
   "metadata": {},
   "source": [
    "## Training Intersection Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1465038",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../examples/train.py intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714bbe13",
   "metadata": {},
   "source": [
    "## Training Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../examples/train.py bottleneck0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72caf94c",
   "metadata": {},
   "source": [
    "## Training Merge Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../examples/train.py merge0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
