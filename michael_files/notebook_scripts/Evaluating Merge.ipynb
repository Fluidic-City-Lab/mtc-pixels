{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c712e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 11:26:03,463\tINFO services.py:1247 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
      "2023-01-19 11:26:04,027\tWARNING ppo.py:143 -- `train_batch_size` (7500) cannot be achieved with your other settings (num_workers=0 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 7500.\n",
      "2023-01-19 11:26:04,028\tINFO trainer.py:720 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2023-01-19 11:26:05,324\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2023-01-19 11:26:05,380\tINFO trainable.py:383 -- Restored on 192.168.1.65 from checkpoint: /home/michael/ray_results/merge_0/PPO_MergePOEnv-v0_1d3be_00000_0_2023-01-18_17-16-19/checkpoint_188/checkpoint-188\n",
      "2023-01-19 11:26:05,381\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 188, '_timesteps_total': None, '_time_total': 37147.062621831894, '_episodes_total': 1880}\n",
      "2023-01-19 11:26:07,660\tWARNING deprecation.py:34 -- DeprecationWarning: `compute_action` has been deprecated. Use `compute_single_action` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0, Return: 248.93842790251088\n",
      "Round 1, Return: 246.52906158081615\n",
      "Round 2, Return: 254.25208120358613\n",
      "Round 3, Return: 297.28235993657137\n",
      "Round 4, Return: 251.07224136135986\n",
      "Round 5, Return: 237.99600540654367\n",
      "Round 6, Return: 247.17182278388415\n",
      "Round 7, Return: 277.38969852112973\n",
      "Round 8, Return: 228.17245666716244\n",
      "Round 9, Return: 342.9604346521444\n",
      "==== Summary of results ====\n",
      "Return:\n",
      "[9.396559485143124, 9.076114989451746, 9.401792250965945, 11.219691122461677, 9.417650456682418, 8.781314291339967, 9.087533782099516, 10.026322960089422, 8.288516502182523, 13.059009583634237]\n",
      "[248.93842790251088, 246.52906158081615, 254.25208120358613, 297.28235993657137, 251.07224136135986, 237.99600540654367, 247.17182278388415, 277.38969852112973, 228.17245666716244, 342.9604346521444]\n",
      "Average, std: 263.17645900157083, 32.48416414840301\n",
      "\n",
      "Speed, mean (m/s):\n",
      "[9.396559485143124, 9.076114989451746, 9.401792250965945, 11.219691122461677, 9.417650456682418, 8.781314291339967, 9.087533782099516, 10.026322960089422, 8.288516502182523, 13.059009583634237]\n",
      "Average, std: 9.775450542405057, 1.3230006448993294\n",
      "\n",
      "Speed, std (m/s):\n",
      "[5.2626204338027245, 4.729155700131739, 5.040295071194775, 5.954408473668877, 4.905676559121467, 4.588811169741464, 4.6935714502078785, 5.025361537971445, 4.826938589885146, 5.941066626610386]\n",
      "Average, std: 5.096790561233591, 0.4635981777047442\n",
      "\n",
      "Outflows (veh/hr):\n",
      "[979.2, 969.6, 960.0, 1008.0, 979.2, 979.2, 988.8, 1008.0, 950.4, 1065.6]\n",
      "Average, std: 988.8, 30.959069753466405\n",
      "Inflows (veh/hr):\n",
      "[1315.2, 1315.2, 1315.2, 1315.2, 1315.2, 1315.2, 1315.2, 1315.2, 1315.2, 1315.2]\n",
      "Average, std: 1315.2000000000003, 2.2737367544323206e-13\n",
      "Throughput efficiency (veh/hr):\n",
      "[0.7445255474452555, 0.7372262773722628, 0.7299270072992701, 0.7664233576642335, 0.7445255474452555, 0.7445255474452555, 0.7518248175182481, 0.7664233576642335, 0.7226277372262774, 0.8102189781021897]\n",
      "Average, std: 0.751824817518248, 0.02353943868116362\n"
     ]
    }
   ],
   "source": [
    "%run ../../flow/visualize/visualizer_rllib.py\\\n",
    "/home/michael/ray_results/merge_0/PPO_MergePOEnv-v0_1d3be_00000_0_2023-01-18_17-16-19/ 188\\\n",
    "--num_rollouts 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef9ffb",
   "metadata": {},
   "source": [
    "### Trial Results Directory Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_name = \"trial_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea54c9",
   "metadata": {},
   "source": [
    "## Mean Over Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e41319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_collector = []\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/avg_velocity.txt\", \"r+\") as f:\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "        mean_vehs = np.mean(data)\n",
    "        mean_collector.append(mean_vehs)\n",
    "        print(f\"Mean Velocity Over Rollout: {mean_vehs}\")\n",
    "        with open(f\"../../michael_files/{results_dir_name}/mean_rollout_velocity.txt\", \"a\") as g:\n",
    "            g.write(f\"Mean Velocity Over Rollout: {mean_vehs}\\n\")\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/mean_rollout_velocity.txt\", \"a\") as g:\n",
    "    mean_rollout = np.mean(mean_collector)\n",
    "    std_rollout = np.std(mean_collector)\n",
    "    var_rollout = np.var(mean_collector)\n",
    "    \n",
    "    g.write(f\"Mean of Rollouts: {mean_rollout}\\n\")\n",
    "    g.write(f\"Std of Rollouts: {std_rollout}\\n\")\n",
    "    g.write(f\"Variance of Rollouts: {var_rollout}\\n\")\n",
    "    \n",
    "    print(f\"Mean of Rollouts: {mean_rollout}\\n\")\n",
    "    print(f\"Std of Rollouts: {std_rollout}\\n\")\n",
    "    print(f\"Variance of Rollouts: {var_rollout}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d89b2",
   "metadata": {},
   "source": [
    "## Mean and Min for Last 100 Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_collector = []\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/avg_velocity.txt\", \"r+\") as f:\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "        mean_last_100_seconds = np.mean(data[-1000:])\n",
    "        mean_collector.append(mean_last_100_seconds)\n",
    "        print(f\"Mean Last 100 Seconds: {mean_last_100_seconds}\")\n",
    "        with open(f\"../../michael_files/{results_dir_name}/last_100_seconds.txt\", \"a\") as g:\n",
    "            g.write(f\"Mean Last 100 Seconds: {mean_last_100_seconds}\\n\")\n",
    "\n",
    "print(f\"Mean of last 100 secs over rollouts: {np.mean(mean_collector)}\")\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/last_100_seconds.txt\", \"a\") as g:\n",
    "    g.write(f\"Mean of last 100 secs over rollouts: {np.mean(mean_collector)}\\n\")\n",
    "    \n",
    "    std_100 = np.std(mean_collector)\n",
    "    var_100 = np.var(mean_collector)\n",
    "    \n",
    "    g.write(f\"Std of last 100 secs over rollouts: {std_100}\\n\")\n",
    "    g.write(f\"Variance of last 100 secs over rollouts: {var_100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/min_velocity.txt\", \"r+\") as f:\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "        min_last_100_seconds = np.min(data[-1000:])\n",
    "        print(f\"Min Last 100 Seconds: {min_last_100_seconds}\")\n",
    "        with open(f\"../../michael_files/{results_dir_name}/last_100_seconds.txt\", \"a\") as g:\n",
    "            g.write(f\"Min Last 100 Seconds: {min_last_100_seconds}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53987b3",
   "metadata": {},
   "source": [
    "## Charting Avg. Velocity for All Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/avg_velocity.txt\", \"r+\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8,8), dpi=100)\n",
    "        xticks = np.arange(0,len(data)+1,500)\n",
    "        ax.set_ylabel(\"Avg. Velocity\")\n",
    "        ax.set_xlabel(\"Timesteps\")\n",
    "        ax.plot(data)\n",
    "        ax.set_xticks(xticks) \n",
    "        fig.savefig(f\"../../michael_files/{results_dir_name}/avg_velocity{count}.png\")\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00782b",
   "metadata": {},
   "source": [
    "## Charting RL Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cb027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/rl_velocity.txt\", \"r+\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8,8), dpi=100)\n",
    "        xticks = np.arange(0,len(data)+1,500)\n",
    "        ax.set_ylabel(\"RL Velocity\")\n",
    "        ax.set_xlabel(\"Timesteps\")\n",
    "        ax.plot(data)\n",
    "        ax.set_xticks(xticks) \n",
    "        fig.savefig(f\"../../michael_files/{results_dir_name}/rl_velocity{count}.png\")\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9214ce",
   "metadata": {},
   "source": [
    "## Charting RL Realized Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118991a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/rl_accel_realized.txt\", \"r+\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8,8), dpi=100)\n",
    "        xticks = np.arange(0,len(data)+1,500)\n",
    "        ax.set_ylabel(\"RL Accel. Realized\")\n",
    "        ax.set_xlabel(\"Timesteps\")\n",
    "        ax.plot(data)\n",
    "        ax.set_xticks(xticks) \n",
    "        fig.savefig(f\"../../michael_files/{results_dir_name}/rl_accel_realized{count}.png\")\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be1823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
