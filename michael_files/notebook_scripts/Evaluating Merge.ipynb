{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c712e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 15:58:04,611\tINFO services.py:1247 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8267\u001b[39m\u001b[22m\n",
      "2023-01-10 15:58:05,198\tINFO trainer.py:720 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2023-01-10 15:58:06,330\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2023-01-10 15:58:06,354\tINFO trainable.py:383 -- Restored on 192.168.1.65 from checkpoint: /home/michael/ray_results/merge_0/PPO_MergePOEnv-v0_79abf_00000_0_2023-01-10_11-16-09/checkpoint_182/checkpoint-182\n",
      "2023-01-10 15:58:06,355\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 182, '_timesteps_total': None, '_time_total': 2739.936455011368, '_episodes_total': 1820}\n",
      "2023-01-10 15:58:08,871\tWARNING deprecation.py:34 -- DeprecationWarning: `compute_action` has been deprecated. Use `compute_single_action` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0, Return: 133.8025752142936\n",
      "Round 1, Return: 144.88371848395175\n",
      "Round 2, Return: 142.89538177025244\n",
      "Round 3, Return: 132.18853970369418\n",
      "Round 4, Return: 132.5631019167493\n",
      "Round 5, Return: 135.0704210658768\n",
      " Retrying in 1 seconds\n",
      "Round 6, Return: 139.37275547665465\n",
      "Round 7, Return: 140.04016393642198\n",
      " Retrying in 1 seconds\n",
      "Round 8, Return: 138.9738522982398\n",
      "Round 9, Return: 141.21850197943286\n",
      "==== Summary of results ====\n",
      "Return:\n",
      "[4.417936544020719, 4.820099323103931, 4.713972042765172, 4.347615771143584, 4.367576903950963, 4.473682747839555, 4.610237126951399, 4.654221089092892, 4.576304968005237, 4.6824498245887165]\n",
      "[133.8025752142936, 144.88371848395175, 142.89538177025244, 132.18853970369418, 132.5631019167493, 135.0704210658768, 139.37275547665465, 140.04016393642198, 138.9738522982398, 141.21850197943286]\n",
      "Average, std: 138.10090118455673, 4.22061774193123\n",
      "\n",
      "Speed, mean (m/s):\n",
      "[4.417936544020719, 4.820099323103931, 4.713972042765172, 4.347615771143584, 4.367576903950963, 4.473682747839555, 4.610237126951399, 4.654221089092892, 4.576304968005237, 4.6824498245887165]\n",
      "Average, std: 4.566409634146217, 0.15078985705825806\n",
      "\n",
      "Speed, std (m/s):\n",
      "[1.0130472952931238, 1.6604156241016788, 1.3370158353469996, 1.0546899051096965, 1.170371891163023, 1.340661187817929, 1.3554648388256183, 1.4166895168176585, 1.1843178383895654, 1.3849718924784844]\n",
      "Average, std: 1.2917645825343778, 0.18134564402023384\n",
      "\n",
      "Outflows (veh/hr):\n",
      "[1304.0, 1344.0, 1344.0, 1280.0, 1280.0, 1296.0, 1320.0, 1328.0, 1320.0, 1336.0]\n",
      "Average, std: 1315.2, 22.96432015105172\n",
      "Inflows (veh/hr):\n",
      "[2304.0, 2304.0, 2304.0, 2304.0, 2304.0, 2304.0, 2304.0, 2304.0, 2304.0, 2304.0]\n",
      "Average, std: 2304.0, 0.0\n",
      "Throughput efficiency (veh/hr):\n",
      "[0.5659722222222222, 0.5833333333333334, 0.5833333333333334, 0.5555555555555556, 0.5555555555555556, 0.5625, 0.5729166666666666, 0.5763888888888888, 0.5729166666666666, 0.5798611111111112]\n",
      "Average, std: 0.5708333333333334, 0.009967152843338422\n"
     ]
    }
   ],
   "source": [
    "%run ../../flow/visualize/visualizer_rllib.py\\\n",
    "/home/michael/ray_results/merge_0/PPO_MergePOEnv-v0_79abf_00000_0_2023-01-10_11-16-09/ 182\\\n",
    "--num_rollouts 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef9ffb",
   "metadata": {},
   "source": [
    "### Trial Results Directory Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir_name = \"trial_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea54c9",
   "metadata": {},
   "source": [
    "## Mean Over Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e41319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_collector = []\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/avg_velocity.txt\", \"r+\") as f:\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "        mean_vehs = np.mean(data)\n",
    "        mean_collector.append(mean_vehs)\n",
    "        print(f\"Mean Velocity Over Rollout: {mean_vehs}\")\n",
    "        with open(f\"../../michael_files/{results_dir_name}/mean_rollout_velocity.txt\", \"a\") as g:\n",
    "            g.write(f\"Mean Velocity Over Rollout: {mean_vehs}\\n\")\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/mean_rollout_velocity.txt\", \"a\") as g:\n",
    "    mean_rollout = np.mean(mean_collector)\n",
    "    std_rollout = np.std(mean_collector)\n",
    "    var_rollout = np.var(mean_collector)\n",
    "    \n",
    "    g.write(f\"Mean of Rollouts: {mean_rollout}\\n\")\n",
    "    g.write(f\"Std of Rollouts: {std_rollout}\\n\")\n",
    "    g.write(f\"Variance of Rollouts: {var_rollout}\\n\")\n",
    "    \n",
    "    print(f\"Mean of Rollouts: {mean_rollout}\\n\")\n",
    "    print(f\"Std of Rollouts: {std_rollout}\\n\")\n",
    "    print(f\"Variance of Rollouts: {var_rollout}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d89b2",
   "metadata": {},
   "source": [
    "## Mean and Min for Last 100 Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_collector = []\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/avg_velocity.txt\", \"r+\") as f:\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "        mean_last_100_seconds = np.mean(data[-1000:])\n",
    "        mean_collector.append(mean_last_100_seconds)\n",
    "        print(f\"Mean Last 100 Seconds: {mean_last_100_seconds}\")\n",
    "        with open(f\"../../michael_files/{results_dir_name}/last_100_seconds.txt\", \"a\") as g:\n",
    "            g.write(f\"Mean Last 100 Seconds: {mean_last_100_seconds}\\n\")\n",
    "\n",
    "print(f\"Mean of last 100 secs over rollouts: {np.mean(mean_collector)}\")\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/last_100_seconds.txt\", \"a\") as g:\n",
    "    g.write(f\"Mean of last 100 secs over rollouts: {np.mean(mean_collector)}\\n\")\n",
    "    \n",
    "    std_100 = np.std(mean_collector)\n",
    "    var_100 = np.var(mean_collector)\n",
    "    \n",
    "    g.write(f\"Std of last 100 secs over rollouts: {std_100}\\n\")\n",
    "    g.write(f\"Variance of last 100 secs over rollouts: {var_100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/min_velocity.txt\", \"r+\") as f:\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "        min_last_100_seconds = np.min(data[-1000:])\n",
    "        print(f\"Min Last 100 Seconds: {min_last_100_seconds}\")\n",
    "        with open(f\"../../michael_files/{results_dir_name}/last_100_seconds.txt\", \"a\") as g:\n",
    "            g.write(f\"Min Last 100 Seconds: {min_last_100_seconds}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53987b3",
   "metadata": {},
   "source": [
    "## Charting Avg. Velocity for All Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/avg_velocity.txt\", \"r+\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8,8), dpi=100)\n",
    "        xticks = np.arange(0,len(data)+1,500)\n",
    "        ax.set_ylabel(\"Avg. Velocity\")\n",
    "        ax.set_xlabel(\"Timesteps\")\n",
    "        ax.plot(data)\n",
    "        ax.set_xticks(xticks) \n",
    "        fig.savefig(f\"../../michael_files/{results_dir_name}/avg_velocity{count}.png\")\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00782b",
   "metadata": {},
   "source": [
    "## Charting RL Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cb027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/rl_velocity.txt\", \"r+\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8,8), dpi=100)\n",
    "        xticks = np.arange(0,len(data)+1,500)\n",
    "        ax.set_ylabel(\"RL Velocity\")\n",
    "        ax.set_xlabel(\"Timesteps\")\n",
    "        ax.plot(data)\n",
    "        ax.set_xticks(xticks) \n",
    "        fig.savefig(f\"../../michael_files/{results_dir_name}/rl_velocity{count}.png\")\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9214ce",
   "metadata": {},
   "source": [
    "## Charting RL Realized Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118991a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(f\"../../michael_files/{results_dir_name}/rl_accel_realized.txt\", \"r+\") as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        data = line.split(\",\")\n",
    "        data = data[:len(data)-1]\n",
    "        data = np.asarray([float(i) for i in data])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8,8), dpi=100)\n",
    "        xticks = np.arange(0,len(data)+1,500)\n",
    "        ax.set_ylabel(\"RL Accel. Realized\")\n",
    "        ax.set_xlabel(\"Timesteps\")\n",
    "        ax.plot(data)\n",
    "        ax.set_xticks(xticks) \n",
    "        fig.savefig(f\"../../michael_files/{results_dir_name}/rl_accel_realized{count}.png\")\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be1823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
