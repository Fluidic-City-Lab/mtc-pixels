{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5efa5b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "{'num_workers': 5, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'gamma': 0.999, 'lr': 5e-05, 'train_batch_size': 30000, 'model': {'_use_default_native_models': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': [[16, [8, 8], 4], [32, [4, 4], 2], [256, [11, 11], 1]], 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'horizon': 1500, 'soft_horizon': False, 'no_done_at_end': False, 'env': None, 'observation_space': None, 'action_space': None, 'env_config': {}, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'simple_optimizer': -1, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.97, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.02, 'vf_share_layers': -1}\n",
      "2022-09-11 20:50:10,504\tINFO services.py:1247 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 7.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "+-----------------------------+----------+-------+\n",
      "| Trial name                  | status   | loc   |\n",
      "|-----------------------------+----------+-------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | PENDING  |       |\n",
      "+-----------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m or from the matplotlib source distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 20:50:13,041\tINFO trainer.py:720 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m or from the matplotlib source distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 20:50:16,467\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_20-55-24\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -9914.566381460814\n",
      "  episode_reward_mean: -10475.983158399331\n",
      "  episode_reward_min: -10834.432628256329\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 20\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.349164976008395\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005208655590305422\n",
      "          policy_loss: -0.0034489202735192596\n",
      "          total_loss: 35452.49221575798\n",
      "          vf_explained_var: -8.572923704264213e-09\n",
      "          vf_loss: 35452.49463846409\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.125681818181818\n",
      "    ram_util_percent: 34.99136363636364\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08750932054943965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.542324372240547\n",
      "    mean_inference_ms: 1.8163388777804204\n",
      "    mean_raw_obs_processing_ms: 1.1596569159173544\n",
      "  time_since_restore: 307.8962776660919\n",
      "  time_this_iter_s: 307.8962776660919\n",
      "  time_total_s: 307.8962776660919\n",
      "  timers:\n",
      "    learn_throughput: 302.346\n",
      "    learn_time_ms: 99224.036\n",
      "    sample_throughput: 143.78\n",
      "    sample_time_ms: 208651.694\n",
      "    update_time_ms: 3.276\n",
      "  timestamp: 1662947724\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 1\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |      1 |          307.896 | 30000 |   -10476 |             -9914.57 |             -10834.4 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 20:55:24,404\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 1048.0x the scale of `vf_clip_param`. This means that it will take more than 1048.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_21-00-30\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -9820.942130306981\n",
      "  episode_reward_mean: -10353.288261564845\n",
      "  episode_reward_min: -10834.432628256329\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 40\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2739871972672483\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009361932981509613\n",
      "          policy_loss: -0.004882307041317541\n",
      "          total_loss: 33357.07995013298\n",
      "          vf_explained_var: -9.612834084293809e-09\n",
      "          vf_loss: 33357.083887965426\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.302517162471393\n",
      "    ram_util_percent: 41.29977116704806\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08750156703553136\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.48726802422871\n",
      "    mean_inference_ms: 1.8148247189265867\n",
      "    mean_raw_obs_processing_ms: 1.1624284415427326\n",
      "  time_since_restore: 614.1418220996857\n",
      "  time_this_iter_s: 306.24554443359375\n",
      "  time_total_s: 614.1418220996857\n",
      "  timers:\n",
      "    learn_throughput: 303.01\n",
      "    learn_time_ms: 99006.573\n",
      "    sample_throughput: 144.199\n",
      "    sample_time_ms: 208045.89\n",
      "    update_time_ms: 3.144\n",
      "  timestamp: 1662948030\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 2\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |      2 |          614.142 | 60000 | -10353.3 |             -9820.94 |             -10834.4 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 21:00:30,714\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 1035.0x the scale of `vf_clip_param`. This means that it will take more than 1035.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 90000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_21-05-36\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -8907.23258421013\n",
      "  episode_reward_mean: -10077.433692367156\n",
      "  episode_reward_min: -10834.432628256329\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 60\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1632392139637724\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012379389995026129\n",
      "          policy_loss: -0.005476627876744309\n",
      "          total_loss: 28598.577745179522\n",
      "          vf_explained_var: -5.047371853805771e-09\n",
      "          vf_loss: 28598.58258643617\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.413073394495413\n",
      "    ram_util_percent: 41.45160550458716\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08749361350072005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.45595154457485\n",
      "    mean_inference_ms: 1.8150142973975274\n",
      "    mean_raw_obs_processing_ms: 1.1634500318187677\n",
      "  time_since_restore: 919.900148153305\n",
      "  time_this_iter_s: 305.7583260536194\n",
      "  time_total_s: 919.900148153305\n",
      "  timers:\n",
      "    learn_throughput: 303.527\n",
      "    learn_time_ms: 98838.142\n",
      "    sample_throughput: 144.385\n",
      "    sample_time_ms: 207777.37\n",
      "    update_time_ms: 3.17\n",
      "  timestamp: 1662948336\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 3\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |      3 |            919.9 | 90000 | -10077.4 |             -8907.23 |             -10834.4 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 21:05:36,522\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 1008.0x the scale of `vf_clip_param`. This means that it will take more than 1008.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 120000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_21-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -8302.342186432263\n",
      "  episode_reward_mean: -9799.573304640615\n",
      "  episode_reward_min: -10834.432628256329\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 80\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0561944222450257\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013522060720684516\n",
      "          policy_loss: -0.005743714477074273\n",
      "          total_loss: 25154.846557513298\n",
      "          vf_explained_var: -9.272390161640942e-05\n",
      "          vf_loss: 25154.851637300533\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.384439359267734\n",
      "    ram_util_percent: 41.492906178489704\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08753380997131217\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.435298325021375\n",
      "    mean_inference_ms: 1.8161173283109129\n",
      "    mean_raw_obs_processing_ms: 1.1641605308136065\n",
      "  time_since_restore: 1226.2922332286835\n",
      "  time_this_iter_s: 306.3920850753784\n",
      "  time_total_s: 1226.2922332286835\n",
      "  timers:\n",
      "    learn_throughput: 303.476\n",
      "    learn_time_ms: 98854.76\n",
      "    sample_throughput: 144.439\n",
      "    sample_time_ms: 207700.655\n",
      "    update_time_ms: 3.141\n",
      "  timestamp: 1662948642\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 4\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 13.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |      4 |          1226.29 | 120000 | -9799.57 |             -8302.34 |             -10834.4 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 21:10:42,955\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 980.0x the scale of `vf_clip_param`. This means that it will take more than 980.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 150000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_21-15-49\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -7399.982584750591\n",
      "  episode_reward_mean: -9438.025108005524\n",
      "  episode_reward_min: -10834.432628256329\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 100\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.9752680928656395\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013978449550272333\n",
      "          policy_loss: -0.006171366009623446\n",
      "          total_loss: 19585.68079537899\n",
      "          vf_explained_var: -5.351736387382289e-09\n",
      "          vf_loss: 19585.686253740027\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 150000\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.283752860411898\n",
      "    ram_util_percent: 41.494965675057216\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08755264183268181\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.42166833773248\n",
      "    mean_inference_ms: 1.8157600839872914\n",
      "    mean_raw_obs_processing_ms: 1.1644679035103993\n",
      "  time_since_restore: 1532.6538002490997\n",
      "  time_this_iter_s: 306.36156702041626\n",
      "  time_total_s: 1532.6538002490997\n",
      "  timers:\n",
      "    learn_throughput: 303.419\n",
      "    learn_time_ms: 98873.268\n",
      "    sample_throughput: 144.481\n",
      "    sample_time_ms: 207639.943\n",
      "    update_time_ms: 3.144\n",
      "  timestamp: 1662948949\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 5\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |      5 |          1532.65 | 150000 | -9438.03 |             -7399.98 |             -10834.4 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 21:15:49,359\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 944.0x the scale of `vf_clip_param`. This means that it will take more than 944.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 1 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 2 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 3 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 4 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 5 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 6 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 7 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 8 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 9 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 10 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 11 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 12 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 13 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 14 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 15 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 16 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 17 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 18 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 19 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 20 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 21 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 22 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 23 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 24 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 25 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 26 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 27 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 28 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 29 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 30 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 31 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 32 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 33 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 34 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 35 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 36 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 37 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 38 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 39 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 40 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 41 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 42 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 43 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 44 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 45 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 46 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 47 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 48 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 49 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 50 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 51 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 52 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 53 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 54 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 55 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 56 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 57 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 58 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 59 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 60 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 61 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 62 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 63 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 64 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 65 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 66 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 67 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 68 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 69 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 70 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 71 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 72 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 73 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 74 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 75 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 76 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 77 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 78 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 79 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 80 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 81 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 82 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 83 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 84 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 85 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 86 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 87 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 88 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 89 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 90 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 91 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 92 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 93 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 94 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 95 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 96 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 97 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 98 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 99 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m  Retrying in 100 seconds\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Could not connect to TraCI server at localhost:34363 [Errno 111] Connection refused\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Error during start: Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/Desktop/flow/flow/core/kernel/simulation/traci.py\", line 296, in start_simulation\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     traci_connection = traci.connect(port, numRetries=100)\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/traci/__init__.py\", line 75, in connect\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     raise FatalTraCIError(\"Could not connect in %s tries\" % (numRetries + 1))\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m traci.exceptions.FatalTraCIError: Could not connect in 101 tries\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Error during teardown: [Errno 3] No such process\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_22-45-10\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -6835.780649373583\n",
      "  episode_reward_mean: -8792.33763084089\n",
      "  episode_reward_min: -10589.95215077123\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 120\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.8557788916344339\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020946941298093696\n",
      "          policy_loss: -0.009333985692603474\n",
      "          total_loss: 15802.161776097075\n",
      "          vf_explained_var: -9.81574377334482e-09\n",
      "          vf_loss: 15802.170049035904\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 2.263537717348673\n",
      "    ram_util_percent: 38.37676820499412\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08757263241492697\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.384195153936393\n",
      "    mean_inference_ms: 1.8162168412787245\n",
      "    mean_raw_obs_processing_ms: 6.781920913115896\n",
      "  time_since_restore: 6893.601195335388\n",
      "  time_this_iter_s: 5360.947395086288\n",
      "  time_total_s: 6893.601195335388\n",
      "  timers:\n",
      "    learn_throughput: 303.492\n",
      "    learn_time_ms: 98849.238\n",
      "    sample_throughput: 28.57\n",
      "    sample_time_ms: 1050066.931\n",
      "    update_time_ms: 3.138\n",
      "  timestamp: 1662954310\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 6\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 22:45:10,355\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 879.0x the scale of `vf_clip_param`. This means that it will take more than 879.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 13.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |      6 |           6893.6 | 180000 | -8792.34 |             -6835.78 |               -10590 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 210000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_22-50-16\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -5770.486486361593\n",
      "  episode_reward_mean: -7971.897280027085\n",
      "  episode_reward_min: -10274.539290219123\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 140\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.6845584720499972\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021813594898320837\n",
      "          policy_loss: -0.010205033192054389\n",
      "          total_loss: 10913.495406831782\n",
      "          vf_explained_var: -1.0652745352501825e-09\n",
      "          vf_loss: 10913.504543716756\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 210000\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.360869565217392\n",
      "    ram_util_percent: 42.07528604118993\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08758641227100206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.36769345157515\n",
      "    mean_inference_ms: 1.817271882334772\n",
      "    mean_raw_obs_processing_ms: 11.595991877113624\n",
      "  time_since_restore: 7200.188105583191\n",
      "  time_this_iter_s: 306.58691024780273\n",
      "  time_total_s: 7200.188105583191\n",
      "  timers:\n",
      "    learn_throughput: 303.329\n",
      "    learn_time_ms: 98902.484\n",
      "    sample_throughput: 32.269\n",
      "    sample_time_ms: 929678.637\n",
      "    update_time_ms: 3.124\n",
      "  timestamp: 1662954616\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 7\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 22:50:16,994\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 797.0x the scale of `vf_clip_param`. This means that it will take more than 797.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 13.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |      7 |          7200.19 | 210000 |  -7971.9 |             -5770.49 |             -10274.5 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 240000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_22-55-23\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -4988.253569262437\n",
      "  episode_reward_mean: -7132.2268708232405\n",
      "  episode_reward_min: -9674.581519834104\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 160\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.5751713078326367\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01987876842340542\n",
      "          policy_loss: -0.00934066034645397\n",
      "          total_loss: 7971.627568982713\n",
      "          vf_explained_var: -1.800821158859378e-09\n",
      "          vf_loss: 7971.635914020944\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 240000\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.273684210526316\n",
      "    ram_util_percent: 42.18123569794051\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08759612263903477\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.358544611864275\n",
      "    mean_inference_ms: 1.8176509230107813\n",
      "    mean_raw_obs_processing_ms: 15.808484111379693\n",
      "  time_since_restore: 7506.160286664963\n",
      "  time_this_iter_s: 305.97218108177185\n",
      "  time_total_s: 7506.160286664963\n",
      "  timers:\n",
      "    learn_throughput: 303.497\n",
      "    learn_time_ms: 98847.623\n",
      "    sample_throughput: 35.74\n",
      "    sample_time_ms: 839405.336\n",
      "    update_time_ms: 3.129\n",
      "  timestamp: 1662954923\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 8\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 22:55:23,018\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 713.0x the scale of `vf_clip_param`. This means that it will take more than 713.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |      8 |          7506.16 | 240000 | -7132.23 |             -4988.25 |             -9674.58 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 270000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-00-28\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -4235.164896172811\n",
      "  episode_reward_mean: -6270.842030738095\n",
      "  episode_reward_min: -8559.567079390381\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 180\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.4399549356546808\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02679643120272303\n",
      "          policy_loss: -0.010995969025497423\n",
      "          total_loss: 5943.260828000332\n",
      "          vf_explained_var: -1.4710933582406938e-09\n",
      "          vf_loss: 5943.270491605718\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 270000\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.361926605504586\n",
      "    ram_util_percent: 42.14701834862385\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08756360335457117\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.352658235162007\n",
      "    mean_inference_ms: 1.817095742723747\n",
      "    mean_raw_obs_processing_ms: 19.552639240754946\n",
      "  time_since_restore: 7811.814437627792\n",
      "  time_this_iter_s: 305.6541509628296\n",
      "  time_total_s: 7811.814437627792\n",
      "  timers:\n",
      "    learn_throughput: 303.643\n",
      "    learn_time_ms: 98800.318\n",
      "    sample_throughput: 39.003\n",
      "    sample_time_ms: 769161.94\n",
      "    update_time_ms: 3.128\n",
      "  timestamp: 1662955228\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 9\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:00:28,719\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 627.0x the scale of `vf_clip_param`. This means that it will take more than 627.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 13.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |      9 |          7811.81 | 270000 | -6270.84 |             -4235.16 |             -8559.57 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-05-39\n",
      "  done: false\n",
      "  episode_len_mean: 1490.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1390.5864626329328\n",
      "  episode_reward_mean: -5410.299901560087\n",
      "  episode_reward_min: -7574.999487785624\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 200\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.3293437920732701\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01919377541589431\n",
      "          policy_loss: -0.007668347014807799\n",
      "          total_loss: 3761.497758581283\n",
      "          vf_explained_var: -1.2681838912342869e-09\n",
      "          vf_loss: 3761.5044626828458\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.947629796839728\n",
      "    ram_util_percent: 42.2176072234763\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08753246731174759\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.347649980782304\n",
      "    mean_inference_ms: 1.8175972971634975\n",
      "    mean_raw_obs_processing_ms: 22.922339958000098\n",
      "  time_since_restore: 8122.623721599579\n",
      "  time_this_iter_s: 310.8092839717865\n",
      "  time_total_s: 8122.623721599579\n",
      "  timers:\n",
      "    learn_throughput: 303.514\n",
      "    learn_time_ms: 98842.353\n",
      "    sample_throughput: 42.052\n",
      "    sample_time_ms: 713402.899\n",
      "    update_time_ms: 3.128\n",
      "  timestamp: 1662955539\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 10\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     10 |          8122.62 | 300000 |  -5410.3 |             -1390.59 |                -7575 |            1490.41 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:05:39,575\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 541.0x the scale of `vf_clip_param`. This means that it will take more than 541.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 330000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-10-51\n",
      "  done: false\n",
      "  episode_len_mean: 1490.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1390.5864626329328\n",
      "  episode_reward_mean: -4681.9845227013575\n",
      "  episode_reward_min: -6473.07869485173\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 220\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.20822564489663917\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021544350055379802\n",
      "          policy_loss: -0.008232247627419519\n",
      "          total_loss: 3386.3716446766953\n",
      "          vf_explained_var: -0.0004035105521325022\n",
      "          vf_loss: 3386.37880017869\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 330000\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.849213483146066\n",
      "    ram_util_percent: 42.614382022471915\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08750465513416802\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.344826712930818\n",
      "    mean_inference_ms: 1.8172434930713341\n",
      "    mean_raw_obs_processing_ms: 20.369498067883857\n",
      "  time_since_restore: 8434.052612781525\n",
      "  time_this_iter_s: 311.4288911819458\n",
      "  time_total_s: 8434.052612781525\n",
      "  timers:\n",
      "    learn_throughput: 303.787\n",
      "    learn_time_ms: 98753.363\n",
      "    sample_throughput: 42.026\n",
      "    sample_time_ms: 713845.508\n",
      "    update_time_ms: 3.105\n",
      "  timestamp: 1662955851\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 11\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     11 |          8434.05 | 330000 | -4681.98 |             -1390.59 |             -6473.08 |            1490.41 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:10:51,047\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 468.0x the scale of `vf_clip_param`. This means that it will take more than 468.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 360000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-16-02\n",
      "  done: false\n",
      "  episode_len_mean: 1490.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1390.5864626329328\n",
      "  episode_reward_mean: -4000.9367862662057\n",
      "  episode_reward_min: -5641.024854202022\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 240\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.023659851042593414\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03765543344607648\n",
      "          policy_loss: -0.009753463873639703\n",
      "          total_loss: 1903.0277707883145\n",
      "          vf_explained_var: -8.116377014921738e-10\n",
      "          vf_loss: 1903.0356371550865\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 360000\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.951910112359553\n",
      "    ram_util_percent: 42.662022471910106\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08748761738528771\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.342907431455547\n",
      "    mean_inference_ms: 1.8167479742895194\n",
      "    mean_raw_obs_processing_ms: 18.363730296361126\n",
      "  time_since_restore: 8745.815070152283\n",
      "  time_this_iter_s: 311.76245737075806\n",
      "  time_total_s: 8745.815070152283\n",
      "  timers:\n",
      "    learn_throughput: 303.818\n",
      "    learn_time_ms: 98743.395\n",
      "    sample_throughput: 41.993\n",
      "    sample_time_ms: 714407.094\n",
      "    update_time_ms: 3.105\n",
      "  timestamp: 1662956162\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 12\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     12 |          8745.82 | 360000 | -4000.94 |             -1390.59 |             -5641.02 |            1490.41 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:16:02,853\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 400.0x the scale of `vf_clip_param`. This means that it will take more than 400.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 390000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-21-15\n",
      "  done: false\n",
      "  episode_len_mean: 1490.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1390.5864626329328\n",
      "  episode_reward_mean: -3475.1923040530737\n",
      "  episode_reward_min: -5104.958550171924\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 260\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.08380803935427932\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02317989544686924\n",
      "          policy_loss: -0.005167265837378007\n",
      "          total_loss: 1981.3069861099568\n",
      "          vf_explained_var: -0.0004253725637681782\n",
      "          vf_loss: 1981.3109990546043\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 390000\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.95820224719101\n",
      "    ram_util_percent: 42.72089887640448\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08748027574290784\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.341167876357417\n",
      "    mean_inference_ms: 1.8165608758212022\n",
      "    mean_raw_obs_processing_ms: 16.743502130359328\n",
      "  time_since_restore: 9058.173510789871\n",
      "  time_this_iter_s: 312.3584406375885\n",
      "  time_total_s: 9058.173510789871\n",
      "  timers:\n",
      "    learn_throughput: 303.583\n",
      "    learn_time_ms: 98819.709\n",
      "    sample_throughput: 41.959\n",
      "    sample_time_ms: 714990.858\n",
      "    update_time_ms: 3.09\n",
      "  timestamp: 1662956475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 13\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:21:15,262\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 348.0x the scale of `vf_clip_param`. This means that it will take more than 348.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     13 |          9058.17 | 390000 | -3475.19 |             -1390.59 |             -5104.96 |            1490.41 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 420000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-26-26\n",
      "  done: false\n",
      "  episode_len_mean: 1490.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1390.5864626329328\n",
      "  episode_reward_mean: -3108.2615204608405\n",
      "  episode_reward_min: -4287.08672573492\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 280\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.21083019079046048\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014613679307529203\n",
      "          policy_loss: -0.004119565190668119\n",
      "          total_loss: 2150.082121062583\n",
      "          vf_explained_var: -1.0145471129874295e-09\n",
      "          vf_loss: 2150.0855162795046\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 420000\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.83056179775281\n",
      "    ram_util_percent: 42.68651685393258\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08748875620570004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.340125711173272\n",
      "    mean_inference_ms: 1.8164796964928085\n",
      "    mean_raw_obs_processing_ms: 15.406381484613526\n",
      "  time_since_restore: 9369.767986536026\n",
      "  time_this_iter_s: 311.5944757461548\n",
      "  time_total_s: 9369.767986536026\n",
      "  timers:\n",
      "    learn_throughput: 303.735\n",
      "    learn_time_ms: 98770.388\n",
      "    sample_throughput: 41.925\n",
      "    sample_time_ms: 715560.336\n",
      "    update_time_ms: 3.163\n",
      "  timestamp: 1662956786\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 14\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     14 |          9369.77 | 420000 | -3108.26 |             -1390.59 |             -4287.09 |            1490.41 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:26:26,903\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 311.0x the scale of `vf_clip_param`. This means that it will take more than 311.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 450000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-31-39\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1663.2889943668506\n",
      "  episode_reward_mean: -2851.950974341243\n",
      "  episode_reward_min: -4265.502349655751\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 300\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.29737608790397646\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022389866633103404\n",
      "          policy_loss: -0.004156186858915348\n",
      "          total_loss: 1745.8785869971741\n",
      "          vf_explained_var: -1.4203660470002433e-09\n",
      "          vf_loss: 1745.8816228598737\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 450000\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.87780269058296\n",
      "    ram_util_percent: 42.81614349775784\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08750522727231416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3392096314265\n",
      "    mean_inference_ms: 1.8164589163125555\n",
      "    mean_raw_obs_processing_ms: 14.283530976453198\n",
      "  time_since_restore: 9682.444630861282\n",
      "  time_this_iter_s: 312.67664432525635\n",
      "  time_total_s: 9682.444630861282\n",
      "  timers:\n",
      "    learn_throughput: 303.559\n",
      "    learn_time_ms: 98827.524\n",
      "    sample_throughput: 41.892\n",
      "    sample_time_ms: 716134.711\n",
      "    update_time_ms: 3.148\n",
      "  timestamp: 1662957099\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 15\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     15 |          9682.44 | 450000 | -2851.95 |             -1663.29 |              -4265.5 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:31:39,623\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 285.0x the scale of `vf_clip_param`. This means that it will take more than 285.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 480000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-36-52\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1652.7375242261726\n",
      "  episode_reward_mean: -2529.181583847695\n",
      "  episode_reward_min: -3613.352078728283\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 320\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.5285955363638858\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023328520855891155\n",
      "          policy_loss: -0.004375941315863995\n",
      "          total_loss: 1080.2537420004987\n",
      "          vf_explained_var: -0.0008374341996386647\n",
      "          vf_loss: 1080.2569512030418\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 480000\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.794394618834083\n",
      "    ram_util_percent: 42.78183856502241\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08752912169389823\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33851863280641\n",
      "    mean_inference_ms: 1.8163502575982182\n",
      "    mean_raw_obs_processing_ms: 13.326607256796429\n",
      "  time_since_restore: 9995.123326539993\n",
      "  time_this_iter_s: 312.67869567871094\n",
      "  time_total_s: 9995.123326539993\n",
      "  timers:\n",
      "    learn_throughput: 303.311\n",
      "    learn_time_ms: 98908.455\n",
      "    sample_throughput: 142.027\n",
      "    sample_time_ms: 211226.852\n",
      "    update_time_ms: 3.143\n",
      "  timestamp: 1662957412\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 16\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     16 |          9995.12 | 480000 | -2529.18 |             -1652.74 |             -3613.35 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:36:52,350\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 253.0x the scale of `vf_clip_param`. This means that it will take more than 253.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 510000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-42-04\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1356.0937288806708\n",
      "  episode_reward_mean: -2331.037930572924\n",
      "  episode_reward_min: -3613.352078728283\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 340\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.6440982688234207\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02319076942435983\n",
      "          policy_loss: -0.002273645214439231\n",
      "          total_loss: 951.083887420005\n",
      "          vf_explained_var: -3.8045516737028606e-10\n",
      "          vf_loss: 951.0850014544548\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 510000\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.893483146067418\n",
      "    ram_util_percent: 42.79325842696629\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08755489501697036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33784363606199\n",
      "    mean_inference_ms: 1.8165303957301984\n",
      "    mean_raw_obs_processing_ms: 12.501077103782618\n",
      "  time_since_restore: 10306.847412109375\n",
      "  time_this_iter_s: 311.7240855693817\n",
      "  time_total_s: 10306.847412109375\n",
      "  timers:\n",
      "    learn_throughput: 303.528\n",
      "    learn_time_ms: 98837.549\n",
      "    sample_throughput: 141.635\n",
      "    sample_time_ms: 211811.36\n",
      "    update_time_ms: 3.203\n",
      "  timestamp: 1662957724\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 17\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:42:04,116\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 233.0x the scale of `vf_clip_param`. This means that it will take more than 233.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     17 |          10306.8 | 510000 | -2331.04 |             -1356.09 |             -3613.35 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 540000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-47-16\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1111.3494820358026\n",
      "  episode_reward_mean: -2085.982261056747\n",
      "  episode_reward_min: -3283.1982405694844\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 360\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.7885818915417854\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01614777524911453\n",
      "          policy_loss: -0.0012094754727676193\n",
      "          total_loss: 798.8970396520737\n",
      "          vf_explained_var: -0.00042964398744516075\n",
      "          vf_loss: 798.8974395622091\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 540000\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.838116591928248\n",
      "    ram_util_percent: 42.83968609865471\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08758215055882676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33743141107444\n",
      "    mean_inference_ms: 1.8166878873119248\n",
      "    mean_raw_obs_processing_ms: 11.781589490777385\n",
      "  time_since_restore: 10619.178738832474\n",
      "  time_this_iter_s: 312.33132672309875\n",
      "  time_total_s: 10619.178738832474\n",
      "  timers:\n",
      "    learn_throughput: 303.338\n",
      "    learn_time_ms: 98899.678\n",
      "    sample_throughput: 141.253\n",
      "    sample_time_ms: 212385.181\n",
      "    update_time_ms: 3.19\n",
      "  timestamp: 1662958036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 18\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=2392)\u001b[0m 2022-09-11 23:47:16,490\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 209.0x the scale of `vf_clip_param`. This means that it will take more than 209.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     18 |          10619.2 | 540000 | -2085.98 |             -1111.35 |              -3283.2 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 570000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-52-28\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -863.9424408450778\n",
      "  episode_reward_mean: -1703.8141952244725\n",
      "  episode_reward_min: -3210.3397441912725\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 380\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.119881156784423\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012142254444820087\n",
      "          policy_loss: 3.0587237288660194e-05\n",
      "          total_loss: 511.98076575096616\n",
      "          vf_explained_var: -0.0008323657093569636\n",
      "          vf_loss: 511.98012823875916\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 570000\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.906067415730337\n",
      "    ram_util_percent: 42.895280898876415\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08760455157822339\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33725596121435\n",
      "    mean_inference_ms: 1.8168100271527206\n",
      "    mean_raw_obs_processing_ms: 11.148523639920768\n",
      "  time_since_restore: 10931.24609041214\n",
      "  time_this_iter_s: 312.06735157966614\n",
      "  time_total_s: 10931.24609041214\n",
      "  timers:\n",
      "    learn_throughput: 303.198\n",
      "    learn_time_ms: 98945.207\n",
      "    sample_throughput: 140.858\n",
      "    sample_time_ms: 212981.014\n",
      "    update_time_ms: 3.194\n",
      "  timestamp: 1662958348\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 19\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     19 |          10931.2 | 570000 | -1703.81 |             -863.942 |             -3210.34 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 600000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-11_23-57-40\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -815.4959875689937\n",
      "  episode_reward_mean: -1445.679639426328\n",
      "  episode_reward_min: -2580.722253550444\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 400\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.9578714382902105\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01450419375603896\n",
      "          policy_loss: -0.0009983606835668709\n",
      "          total_loss: 768.3152135126642\n",
      "          vf_explained_var: -3.271914517100072e-09\n",
      "          vf_loss: 768.3154858658162\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 600000\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.86089887640449\n",
      "    ram_util_percent: 42.89393258426966\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08762886822036525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33716953500277\n",
      "    mean_inference_ms: 1.8169279476202922\n",
      "    mean_raw_obs_processing_ms: 10.587256513841053\n",
      "  time_since_restore: 11242.894187688828\n",
      "  time_this_iter_s: 311.6480972766876\n",
      "  time_total_s: 11242.894187688828\n",
      "  timers:\n",
      "    learn_throughput: 303.445\n",
      "    learn_time_ms: 98864.637\n",
      "    sample_throughput: 140.749\n",
      "    sample_time_ms: 213145.397\n",
      "    update_time_ms: 3.2\n",
      "  timestamp: 1662958660\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 20\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     20 |          11242.9 | 600000 | -1445.68 |             -815.496 |             -2580.72 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 630000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-02-52\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -564.5552357092982\n",
      "  episode_reward_mean: -1215.2848120302945\n",
      "  episode_reward_min: -2580.722253550444\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 420\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.8726572247261697\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016764209253145066\n",
      "          policy_loss: -0.0012220268581617385\n",
      "          total_loss: 1025.0923052848655\n",
      "          vf_explained_var: -1.927639603493958e-09\n",
      "          vf_loss: 1025.092688806412\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 630000\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.96509009009009\n",
      "    ram_util_percent: 42.900000000000006\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0876500456225245\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.337070144564883\n",
      "    mean_inference_ms: 1.8172864837758393\n",
      "    mean_raw_obs_processing_ms: 10.086205115683955\n",
      "  time_since_restore: 11554.75032711029\n",
      "  time_this_iter_s: 311.856139421463\n",
      "  time_total_s: 11554.75032711029\n",
      "  timers:\n",
      "    learn_throughput: 303.374\n",
      "    learn_time_ms: 98887.875\n",
      "    sample_throughput: 140.736\n",
      "    sample_time_ms: 213164.968\n",
      "    update_time_ms: 3.211\n",
      "  timestamp: 1662958972\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 21\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     21 |          11554.8 | 630000 | -1215.28 |             -564.555 |             -2580.72 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 660000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-08-03\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -27.90281303225726\n",
      "  episode_reward_mean: -946.1855390593871\n",
      "  episode_reward_min: -2056.4360607412837\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 440\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.9784192094143401\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017451023405833946\n",
      "          policy_loss: -0.0013602988065240232\n",
      "          total_loss: 985.074003399788\n",
      "          vf_explained_var: -0.0002895320940297097\n",
      "          vf_loss: 985.0744918238863\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 660000\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.855280898876405\n",
      "    ram_util_percent: 43.025393258426966\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08766571450116839\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33707641661951\n",
      "    mean_inference_ms: 1.8173993050669974\n",
      "    mean_raw_obs_processing_ms: 9.636121261440023\n",
      "  time_since_restore: 11866.333392858505\n",
      "  time_this_iter_s: 311.5830657482147\n",
      "  time_total_s: 11866.333392858505\n",
      "  timers:\n",
      "    learn_throughput: 303.449\n",
      "    learn_time_ms: 98863.358\n",
      "    sample_throughput: 140.732\n",
      "    sample_time_ms: 213171.636\n",
      "    update_time_ms: 3.22\n",
      "  timestamp: 1662959283\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 22\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 13.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     22 |          11866.3 | 660000 | -946.186 |             -27.9028 |             -2056.44 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 690000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-13-16\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -27.90281303225726\n",
      "  episode_reward_mean: -826.7616897263886\n",
      "  episode_reward_min: -1483.55171799676\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 460\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.0786035951401325\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015237785672788795\n",
      "          policy_loss: -0.0007352044079650907\n",
      "          total_loss: 876.4203774959483\n",
      "          vf_explained_var: -0.0003077341243624687\n",
      "          vf_loss: 876.4203512508311\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 690000\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.96561797752809\n",
      "    ram_util_percent: 43.028988764044946\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08768091962315046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3371396637584\n",
      "    mean_inference_ms: 1.817474712328156\n",
      "    mean_raw_obs_processing_ms: 9.229510898097907\n",
      "  time_since_restore: 12178.509579181671\n",
      "  time_this_iter_s: 312.1761863231659\n",
      "  time_total_s: 12178.509579181671\n",
      "  timers:\n",
      "    learn_throughput: 303.596\n",
      "    learn_time_ms: 98815.396\n",
      "    sample_throughput: 140.712\n",
      "    sample_time_ms: 213201.357\n",
      "    update_time_ms: 3.21\n",
      "  timestamp: 1662959596\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 23\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     23 |          12178.5 | 690000 | -826.762 |             -27.9028 |             -1483.55 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 720000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-18-27\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -27.90281303225726\n",
      "  episode_reward_mean: -799.5037386326798\n",
      "  episode_reward_min: -1483.55171799676\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 480\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.255340066159025\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01727101694698699\n",
      "          policy_loss: -0.001089747869905005\n",
      "          total_loss: 748.1007245002909\n",
      "          vf_explained_var: -0.00021869649935979396\n",
      "          vf_loss: 748.1009524925719\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 720000\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.923648648648648\n",
      "    ram_util_percent: 43.030855855855854\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08769377045347064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33699855918564\n",
      "    mean_inference_ms: 1.817577993229098\n",
      "    mean_raw_obs_processing_ms: 8.860591214945671\n",
      "  time_since_restore: 12489.721604585648\n",
      "  time_this_iter_s: 311.21202540397644\n",
      "  time_total_s: 12489.721604585648\n",
      "  timers:\n",
      "    learn_throughput: 303.734\n",
      "    learn_time_ms: 98770.548\n",
      "    sample_throughput: 140.708\n",
      "    sample_time_ms: 213208.055\n",
      "    update_time_ms: 3.157\n",
      "  timestamp: 1662959907\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 24\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     24 |          12489.7 | 720000 | -799.504 |             -27.9028 |             -1483.55 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 750000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-23-39\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -27.90281303225726\n",
      "  episode_reward_mean: -666.2572921396409\n",
      "  episode_reward_min: -1356.658645396517\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 500\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.2591900939637042\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01688025116508377\n",
      "          policy_loss: -0.00035392672635931917\n",
      "          total_loss: 925.3492389565325\n",
      "          vf_explained_var: -3.9820977626447984e-09\n",
      "          vf_loss: 925.3487486754073\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 750000\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.882921348314607\n",
      "    ram_util_percent: 43.09438202247191\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08770388150666523\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.336977460609347\n",
      "    mean_inference_ms: 1.8176605894264721\n",
      "    mean_raw_obs_processing_ms: 8.524012882534661\n",
      "  time_since_restore: 12801.597108364105\n",
      "  time_this_iter_s: 311.87550377845764\n",
      "  time_total_s: 12801.597108364105\n",
      "  timers:\n",
      "    learn_throughput: 303.997\n",
      "    learn_time_ms: 98685.129\n",
      "    sample_throughput: 140.704\n",
      "    sample_time_ms: 213213.458\n",
      "    update_time_ms: 3.175\n",
      "  timestamp: 1662960219\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 25\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     25 |          12801.6 | 750000 | -666.257 |             -27.9028 |             -1356.66 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 780000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-28-52\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -27.90281303225726\n",
      "  episode_reward_mean: -643.3817578028716\n",
      "  episode_reward_min: -1193.0511752762745\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 520\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.2983578125466693\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012908893976774864\n",
      "          policy_loss: 0.0009583617907334515\n",
      "          total_loss: 725.6106767045691\n",
      "          vf_explained_var: -0.0002577777486294508\n",
      "          vf_loss: 725.6090732655626\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 780000\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.74575892857143\n",
      "    ram_util_percent: 43.19642857142857\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08771171515313396\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33689859620245\n",
      "    mean_inference_ms: 1.8176063722099056\n",
      "    mean_raw_obs_processing_ms: 8.21579728930119\n",
      "  time_since_restore: 13115.122361421585\n",
      "  time_this_iter_s: 313.52525305747986\n",
      "  time_total_s: 13115.122361421585\n",
      "  timers:\n",
      "    learn_throughput: 303.762\n",
      "    learn_time_ms: 98761.639\n",
      "    sample_throughput: 140.699\n",
      "    sample_time_ms: 213221.606\n",
      "    update_time_ms: 3.183\n",
      "  timestamp: 1662960532\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 26\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     26 |          13115.1 | 780000 | -643.382 |             -27.9028 |             -1193.05 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 810000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-34-07\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -178.43189834377583\n",
      "  episode_reward_mean: -637.8907507411803\n",
      "  episode_reward_min: -1193.0511752762745\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 540\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.8007275689409135\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012138817935539305\n",
      "          policy_loss: 0.0015864136711040394\n",
      "          total_loss: 590.7809963047758\n",
      "          vf_explained_var: -1.7247301364875511e-09\n",
      "          vf_loss: 590.7788040226064\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 810000\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.806473214285713\n",
      "    ram_util_percent: 43.160714285714285\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08772348941117818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.336775212656875\n",
      "    mean_inference_ms: 1.8177473537880728\n",
      "    mean_raw_obs_processing_ms: 7.932435310002539\n",
      "  time_since_restore: 13429.421447753906\n",
      "  time_this_iter_s: 314.29908633232117\n",
      "  time_total_s: 13429.421447753906\n",
      "  timers:\n",
      "    learn_throughput: 302.993\n",
      "    learn_time_ms: 99012.309\n",
      "    sample_throughput: 140.694\n",
      "    sample_time_ms: 213228.484\n",
      "    update_time_ms: 3.136\n",
      "  timestamp: 1662960847\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 27\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 13.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     27 |          13429.4 | 810000 | -637.891 |             -178.432 |             -1193.05 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 840000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-39-21\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -178.43189834377583\n",
      "  episode_reward_mean: -535.6641680593447\n",
      "  episode_reward_min: -1180.527144477434\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 560\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.849369579325331\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0104276257759797\n",
      "          policy_loss: 0.0013332229587893457\n",
      "          total_loss: 564.0779232885483\n",
      "          vf_explained_var: -4.26109814100073e-09\n",
      "          vf_loss: 564.0760692060754\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 840000\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.804454342984407\n",
      "    ram_util_percent: 43.2599109131403\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08773299804581271\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.336558931082507\n",
      "    mean_inference_ms: 1.8179056721228528\n",
      "    mean_raw_obs_processing_ms: 7.670972936208305\n",
      "  time_since_restore: 13743.890059709549\n",
      "  time_this_iter_s: 314.4686119556427\n",
      "  time_total_s: 13743.890059709549\n",
      "  timers:\n",
      "    learn_throughput: 302.316\n",
      "    learn_time_ms: 99233.959\n",
      "    sample_throughput: 140.699\n",
      "    sample_time_ms: 213220.541\n",
      "    update_time_ms: 3.144\n",
      "  timestamp: 1662961161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 28\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     28 |          13743.9 | 840000 | -535.664 |             -178.432 |             -1180.53 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 870000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-44-37\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -178.43189834377583\n",
      "  episode_reward_mean: -438.987234479188\n",
      "  episode_reward_min: -1180.527144477434\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 580\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.8776275685492982\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010346686295809785\n",
      "          policy_loss: 0.0014110878898088443\n",
      "          total_loss: 539.8504558449603\n",
      "          vf_explained_var: -0.00021890665811952204\n",
      "          vf_loss: 539.848526958709\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 870000\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 870000\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.792888888888886\n",
      "    ram_util_percent: 43.25711111111111\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08774282594139765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33634168044947\n",
      "    mean_inference_ms: 1.8181022999795402\n",
      "    mean_raw_obs_processing_ms: 7.429040564293311\n",
      "  time_since_restore: 14059.69759297371\n",
      "  time_this_iter_s: 315.80753326416016\n",
      "  time_total_s: 14059.69759297371\n",
      "  timers:\n",
      "    learn_throughput: 301.245\n",
      "    learn_time_ms: 99586.827\n",
      "    sample_throughput: 140.685\n",
      "    sample_time_ms: 213241.781\n",
      "    update_time_ms: 3.15\n",
      "  timestamp: 1662961477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 29\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     29 |          14059.7 | 870000 | -438.987 |             -178.432 |             -1180.53 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 900000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-49-56\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -272.76029184704834\n",
      "  episode_reward_mean: -430.47184376915715\n",
      "  episode_reward_min: -1180.527144477434\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 600\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.6121666782460313\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017011459555595826\n",
      "          policy_loss: 0.0013902833973592583\n",
      "          total_loss: 575.9204352520882\n",
      "          vf_explained_var: -3.652369739981509e-09\n",
      "          vf_loss: 575.9181944372299\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 900000\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.59406593406593\n",
      "    ram_util_percent: 43.33318681318681\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08775211507779464\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33596277801361\n",
      "    mean_inference_ms: 1.8182124974594709\n",
      "    mean_raw_obs_processing_ms: 7.204599287464492\n",
      "  time_since_restore: 14378.416685581207\n",
      "  time_this_iter_s: 318.71909260749817\n",
      "  time_total_s: 14378.416685581207\n",
      "  timers:\n",
      "    learn_throughput: 299.09\n",
      "    learn_time_ms: 100304.194\n",
      "    sample_throughput: 140.692\n",
      "    sample_time_ms: 213231.705\n",
      "    update_time_ms: 3.143\n",
      "  timestamp: 1662961796\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 30\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     30 |          14378.4 | 900000 | -430.472 |              -272.76 |             -1180.53 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 930000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_00-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -208.88572443028505\n",
      "  episode_reward_mean: -369.68858137724476\n",
      "  episode_reward_min: -718.5829020090055\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 620\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.4563658121798901\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013979957377611813\n",
      "          policy_loss: -0.00019043829009689867\n",
      "          total_loss: 629.5474995000312\n",
      "          vf_explained_var: -7.960664515849203e-05\n",
      "          vf_loss: 629.5469910901658\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 930000\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 930000\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.436285097192226\n",
      "    ram_util_percent: 43.55421166306696\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08776331414889287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33566765404119\n",
      "    mean_inference_ms: 1.8184343871737383\n",
      "    mean_raw_obs_processing_ms: 6.995824174547976\n",
      "  time_since_restore: 14702.705684900284\n",
      "  time_this_iter_s: 324.28899931907654\n",
      "  time_total_s: 14702.705684900284\n",
      "  timers:\n",
      "    learn_throughput: 295.451\n",
      "    learn_time_ms: 101539.606\n",
      "    sample_throughput: 140.687\n",
      "    sample_time_ms: 213239.616\n",
      "    update_time_ms: 3.138\n",
      "  timestamp: 1662962120\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 31\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     31 |          14702.7 | 930000 | -369.689 |             -208.886 |             -718.583 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 960000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_01-00-55\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -208.88572443028505\n",
      "  episode_reward_mean: -361.90882477249664\n",
      "  episode_reward_min: -656.9633586923212\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 640\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.7577502642286584\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012687398545998896\n",
      "          policy_loss: -1.6413779453711305e-05\n",
      "          total_loss: 550.4854143637799\n",
      "          vf_explained_var: -1.3696386247374903e-09\n",
      "          vf_loss: 550.4847963633435\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 960000\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 20.9356394129979\n",
      "    ram_util_percent: 43.593710691823894\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08777204867398025\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33518097279684\n",
      "    mean_inference_ms: 1.8186542498036875\n",
      "    mean_raw_obs_processing_ms: 6.801075892142915\n",
      "  time_since_restore: 15037.382768392563\n",
      "  time_this_iter_s: 334.67708349227905\n",
      "  time_total_s: 15037.382768392563\n",
      "  timers:\n",
      "    learn_throughput: 288.879\n",
      "    learn_time_ms: 103849.642\n",
      "    sample_throughput: 140.687\n",
      "    sample_time_ms: 213238.774\n",
      "    update_time_ms: 3.163\n",
      "  timestamp: 1662962455\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 32\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     32 |          15037.4 | 960000 | -361.909 |             -208.886 |             -656.963 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 990000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_01-07-12\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -55.85499188926646\n",
      "  episode_reward_mean: -305.22752738840995\n",
      "  episode_reward_min: -656.9633586923212\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 660\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.3290510171525023\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015499410365034497\n",
      "          policy_loss: 0.001341604708713737\n",
      "          total_loss: 488.5576261414873\n",
      "          vf_explained_var: -1.4203660470002433e-09\n",
      "          vf_loss: 488.5555095558978\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 990000\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 990000\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 19.513197026022304\n",
      "    ram_util_percent: 44.024349442379176\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08778229254173295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.334491942705935\n",
      "    mean_inference_ms: 1.8190252477154218\n",
      "    mean_raw_obs_processing_ms: 6.619014457692356\n",
      "  time_since_restore: 15414.188630580902\n",
      "  time_this_iter_s: 376.80586218833923\n",
      "  time_total_s: 15414.188630580902\n",
      "  timers:\n",
      "    learn_throughput: 271.882\n",
      "    learn_time_ms: 110341.814\n",
      "    sample_throughput: 140.707\n",
      "    sample_time_ms: 213209.491\n",
      "    update_time_ms: 3.175\n",
      "  timestamp: 1662962832\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 33\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     33 |          15414.2 | 990000 | -305.228 |              -55.855 |             -656.963 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1020000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_01-14-27\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -23.389556620120043\n",
      "  episode_reward_mean: -260.39182619090354\n",
      "  episode_reward_min: -656.9633586923212\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 680\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.3001698317426316\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017239237406360453\n",
      "          policy_loss: 0.002155430238654322\n",
      "          total_loss: 464.06202857159553\n",
      "          vf_explained_var: -5.5685221013845876e-05\n",
      "          vf_loss: 464.05901106489466\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1020000\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.886129032258065\n",
      "    ram_util_percent: 44.127096774193554\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08779126546441336\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33382822675896\n",
      "    mean_inference_ms: 1.8195288315596572\n",
      "    mean_raw_obs_processing_ms: 6.448377928666508\n",
      "  time_since_restore: 15849.116192817688\n",
      "  time_this_iter_s: 434.9275622367859\n",
      "  time_total_s: 15849.116192817688\n",
      "  timers:\n",
      "    learn_throughput: 244.499\n",
      "    learn_time_ms: 122699.668\n",
      "    sample_throughput: 140.698\n",
      "    sample_time_ms: 213223.28\n",
      "    update_time_ms: 3.146\n",
      "  timestamp: 1662963267\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 34\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     34 |          15849.1 | 1020000 | -260.392 |             -23.3896 |             -656.963 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1050000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_01-21-55\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -20.312611059266835\n",
      "  episode_reward_mean: -187.85326431456716\n",
      "  episode_reward_min: -656.9633586923212\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 700\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.385348539656781\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014578349194117912\n",
      "          policy_loss: 0.001620086898749813\n",
      "          total_loss: 433.3374290920826\n",
      "          vf_explained_var: -3.1450961834877944e-09\n",
      "          vf_loss: 433.3350805631597\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1050000\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1050000\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.601875\n",
      "    ram_util_percent: 44.33078125000001\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08779923571216319\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3333333644818\n",
      "    mean_inference_ms: 1.8201159263427322\n",
      "    mean_raw_obs_processing_ms: 6.288115060331388\n",
      "  time_since_restore: 16297.8513712883\n",
      "  time_this_iter_s: 448.7351784706116\n",
      "  time_total_s: 16297.8513712883\n",
      "  timers:\n",
      "    learn_throughput: 219.992\n",
      "    learn_time_ms: 136368.494\n",
      "    sample_throughput: 140.686\n",
      "    sample_time_ms: 213240.439\n",
      "    update_time_ms: 3.138\n",
      "  timestamp: 1662963715\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 35\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     35 |          16297.9 | 1050000 | -187.853 |             -20.3126 |             -656.963 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1080000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_01-29-24\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -20.312611059266835\n",
      "  episode_reward_mean: -123.6257670295981\n",
      "  episode_reward_min: -431.6708957012434\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 720\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.089976911291163\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01697534789088523\n",
      "          policy_loss: 0.00122858113272393\n",
      "          total_loss: 415.94198756116504\n",
      "          vf_explained_var: -1.0145471268652173e-10\n",
      "          vf_loss: 415.93991120034076\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1080000\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.505616224648985\n",
      "    ram_util_percent: 44.325429017160694\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08780395113202978\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33288428394735\n",
      "    mean_inference_ms: 1.8205508918132858\n",
      "    mean_raw_obs_processing_ms: 6.137213129462886\n",
      "  time_since_restore: 16746.670103788376\n",
      "  time_this_iter_s: 448.8187325000763\n",
      "  time_total_s: 16746.670103788376\n",
      "  timers:\n",
      "    learn_throughput: 200.142\n",
      "    learn_time_ms: 149893.881\n",
      "    sample_throughput: 140.684\n",
      "    sample_time_ms: 213244.514\n",
      "    update_time_ms: 3.132\n",
      "  timestamp: 1662964164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 36\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     36 |          16746.7 | 1080000 | -123.626 |             -20.3126 |             -431.671 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1110000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_01-36-54\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -20.312611059266835\n",
      "  episode_reward_mean: -78.24006058053979\n",
      "  episode_reward_min: -311.2263386316801\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 740\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.063396343271783\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013446453016250132\n",
      "          policy_loss: 0.0012134199694512373\n",
      "          total_loss: 403.45710322603264\n",
      "          vf_explained_var: -3.0943687612250415e-09\n",
      "          vf_loss: 403.45521716503384\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1110000\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1110000\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.533229329173167\n",
      "    ram_util_percent: 44.37597503900156\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0878095121319556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332751831087485\n",
      "    mean_inference_ms: 1.8209729926262748\n",
      "    mean_raw_obs_processing_ms: 5.994923161144725\n",
      "  time_since_restore: 17195.844645261765\n",
      "  time_this_iter_s: 449.1745414733887\n",
      "  time_total_s: 17195.844645261765\n",
      "  timers:\n",
      "    learn_throughput: 183.625\n",
      "    learn_time_ms: 163376.504\n",
      "    sample_throughput: 140.68\n",
      "    sample_time_ms: 213249.373\n",
      "    update_time_ms: 3.193\n",
      "  timestamp: 1662964614\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 37\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     37 |          17195.8 | 1110000 | -78.2401 |             -20.3126 |             -311.226 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1140000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_01-44-24\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -20.312611059266835\n",
      "  episode_reward_mean: -80.69189444103938\n",
      "  episode_reward_min: -158.8356159486318\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 760\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.0529710662111325\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012626048546517313\n",
      "          policy_loss: 0.0020434396092760118\n",
      "          total_loss: 385.71194151858066\n",
      "          vf_explained_var: -3.8806429181192925e-09\n",
      "          vf_loss: 385.7092668638838\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1140000\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.609034267912772\n",
      "    ram_util_percent: 44.433956386292834\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08781368254965376\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332899841727507\n",
      "    mean_inference_ms: 1.821259427141712\n",
      "    mean_raw_obs_processing_ms: 5.860557232476608\n",
      "  time_since_restore: 17646.133561849594\n",
      "  time_this_iter_s: 450.2889165878296\n",
      "  time_total_s: 17646.133561849594\n",
      "  timers:\n",
      "    learn_throughput: 169.552\n",
      "    learn_time_ms: 176936.746\n",
      "    sample_throughput: 140.666\n",
      "    sample_time_ms: 213271.191\n",
      "    update_time_ms: 3.183\n",
      "  timestamp: 1662965064\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 38\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     38 |          17646.1 | 1140000 | -80.6919 |             -20.3126 |             -158.836 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1170000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_01-51-54\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 217.5263783637911\n",
      "  episode_reward_mean: -47.31484465427141\n",
      "  episode_reward_min: -158.8356159486318\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 780\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.1228023655363852\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01719361177120522\n",
      "          policy_loss: 0.002100359733176834\n",
      "          total_loss: 362.6458525247777\n",
      "          vf_explained_var: -3.9820977626447984e-09\n",
      "          vf_loss: 362.6428927904494\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1170000\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1170000\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.51197511664075\n",
      "    ram_util_percent: 44.46842923794713\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08781827283802116\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.333001323788753\n",
      "    mean_inference_ms: 1.8213312078646056\n",
      "    mean_raw_obs_processing_ms: 5.733387049269686\n",
      "  time_since_restore: 18096.67783498764\n",
      "  time_this_iter_s: 450.54427313804626\n",
      "  time_total_s: 18096.67783498764\n",
      "  timers:\n",
      "    learn_throughput: 157.529\n",
      "    learn_time_ms: 190440.934\n",
      "    sample_throughput: 140.686\n",
      "    sample_time_ms: 213240.298\n",
      "    update_time_ms: 3.198\n",
      "  timestamp: 1662965514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 39\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     39 |          18096.7 | 1170000 | -47.3148 |              217.526 |             -158.836 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1200000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_01-59-26\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 311.9477736538936\n",
      "  episode_reward_mean: 2.6503197883848575\n",
      "  episode_reward_min: -158.8356159486318\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 800\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.265631437200181\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017989370613309432\n",
      "          policy_loss: 0.002287812216722585\n",
      "          total_loss: 345.5377739342223\n",
      "          vf_explained_var: -2.967550427612764e-09\n",
      "          vf_loss: 345.53458702574386\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1200000\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1200000\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.54534161490683\n",
      "    ram_util_percent: 44.567546583850934\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08782227043435034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.333171185445984\n",
      "    mean_inference_ms: 1.821294529287898\n",
      "    mean_raw_obs_processing_ms: 5.612885990372486\n",
      "  time_since_restore: 18548.529388666153\n",
      "  time_this_iter_s: 451.8515536785126\n",
      "  time_total_s: 18548.529388666153\n",
      "  timers:\n",
      "    learn_throughput: 147.252\n",
      "    learn_time_ms: 203732.026\n",
      "    sample_throughput: 140.672\n",
      "    sample_time_ms: 213262.479\n",
      "    update_time_ms: 3.182\n",
      "  timestamp: 1662965966\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 40\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     40 |          18548.5 | 1200000 |  2.65032 |              311.948 |             -158.836 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1230000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_02-07-00\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 311.9477736538936\n",
      "  episode_reward_mean: 41.53319946373867\n",
      "  episode_reward_min: -140.92443068561778\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 820\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.184638352241922\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015687707430742562\n",
      "          policy_loss: 0.003900141142150189\n",
      "          total_loss: 328.52425414714406\n",
      "          vf_explained_var: -2.7900046717377336e-09\n",
      "          vf_loss: 328.5195696631898\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1230000\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1230000\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.467697063369396\n",
      "    ram_util_percent: 44.62519319938176\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08782728518048566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33335977538811\n",
      "    mean_inference_ms: 1.8213098073434262\n",
      "    mean_raw_obs_processing_ms: 5.498617195528753\n",
      "  time_since_restore: 19001.697338104248\n",
      "  time_this_iter_s: 453.1679494380951\n",
      "  time_total_s: 19001.697338104248\n",
      "  timers:\n",
      "    learn_throughput: 138.498\n",
      "    learn_time_ms: 216610.044\n",
      "    sample_throughput: 140.665\n",
      "    sample_time_ms: 213272.35\n",
      "    update_time_ms: 3.162\n",
      "  timestamp: 1662966420\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 41\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     41 |          19001.7 | 1230000 |  41.5332 |              311.948 |             -140.924 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1260000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_02-14-37\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 311.9477736538936\n",
      "  episode_reward_mean: 50.208135881684875\n",
      "  episode_reward_min: -140.92443068561778\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 840\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.191622713880336\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01341982983134474\n",
      "          policy_loss: 0.0025035554965205016\n",
      "          total_loss: 310.9899257611214\n",
      "          vf_explained_var: -8.116377014921738e-10\n",
      "          vf_loss: 310.98675146549306\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1260000\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1260000\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.398621745788667\n",
      "    ram_util_percent: 44.63307810107197\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08783334565451596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33356851028404\n",
      "    mean_inference_ms: 1.8212349350134471\n",
      "    mean_raw_obs_processing_ms: 5.390142055953593\n",
      "  time_since_restore: 19459.128932237625\n",
      "  time_this_iter_s: 457.4315941333771\n",
      "  time_total_s: 19459.128932237625\n",
      "  timers:\n",
      "    learn_throughput: 131.085\n",
      "    learn_time_ms: 228859.185\n",
      "    sample_throughput: 140.648\n",
      "    sample_time_ms: 213298.77\n",
      "    update_time_ms: 3.134\n",
      "  timestamp: 1662966877\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 42\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 13.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     42 |          19459.1 | 1260000 |  50.2081 |              311.948 |             -140.924 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1290000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_02-22-19\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 311.9477736538936\n",
      "  episode_reward_mean: 51.48012705625037\n",
      "  episode_reward_min: -108.79754791356368\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 860\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.2917079749005906\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018566264437977275\n",
      "          policy_loss: 0.001687298900190186\n",
      "          total_loss: 306.849414192362\n",
      "          vf_explained_var: -2.5617314935999502e-09\n",
      "          vf_loss: 306.84679860216505\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1290000\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1290000\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.36352583586626\n",
      "    ram_util_percent: 44.71686930091185\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08784015171472351\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33363133963984\n",
      "    mean_inference_ms: 1.8211534503843043\n",
      "    mean_raw_obs_processing_ms: 5.287014104504668\n",
      "  time_since_restore: 19920.795786857605\n",
      "  time_this_iter_s: 461.66685461997986\n",
      "  time_total_s: 19920.795786857605\n",
      "  timers:\n",
      "    learn_throughput: 126.41\n",
      "    learn_time_ms: 237322.328\n",
      "    sample_throughput: 140.633\n",
      "    sample_time_ms: 213321.81\n",
      "    update_time_ms: 3.149\n",
      "  timestamp: 1662967339\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 43\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     43 |          19920.8 | 1290000 |  51.4801 |              311.948 |             -108.798 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1320000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_02-30-02\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 311.9477736538936\n",
      "  episode_reward_mean: 12.34695156747397\n",
      "  episode_reward_min: -138.34406310350758\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 880\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.1787708788222453\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013276437904457922\n",
      "          policy_loss: 0.0033688933900656534\n",
      "          total_loss: 300.14175134537066\n",
      "          vf_explained_var: -5.287921339913737e-06\n",
      "          vf_loss: 300.1377176974682\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1320000\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1320000\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.337518910741302\n",
      "    ram_util_percent: 44.8284417549168\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08784967993669948\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.333597001547766\n",
      "    mean_inference_ms: 1.8212506066496745\n",
      "    mean_raw_obs_processing_ms: 5.188888701761352\n",
      "  time_since_restore: 20383.831929922104\n",
      "  time_this_iter_s: 463.0361430644989\n",
      "  time_total_s: 20383.831929922104\n",
      "  timers:\n",
      "    learn_throughput: 124.923\n",
      "    learn_time_ms: 240146.996\n",
      "    sample_throughput: 140.642\n",
      "    sample_time_ms: 213308.003\n",
      "    update_time_ms: 3.153\n",
      "  timestamp: 1662967802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 44\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     44 |          20383.8 | 1320000 |   12.347 |              311.948 |             -138.344 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1350000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_02-37-46\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 221.77321955517442\n",
      "  episode_reward_mean: -20.030453904372465\n",
      "  episode_reward_min: -138.34406310350758\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 900\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.2283529515976603\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012914281399336069\n",
      "          policy_loss: 0.003390568092544662\n",
      "          total_loss: 282.32918875511655\n",
      "          vf_explained_var: 1.0906381353592565e-09\n",
      "          vf_loss: 282.3251521074011\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1350000\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1350000\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.249321266968327\n",
      "    ram_util_percent: 44.83831070889894\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08785997982397152\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.333572584107532\n",
      "    mean_inference_ms: 1.821374025614213\n",
      "    mean_raw_obs_processing_ms: 5.095362558774101\n",
      "  time_since_restore: 20848.412019968033\n",
      "  time_this_iter_s: 464.58009004592896\n",
      "  time_total_s: 20848.412019968033\n",
      "  timers:\n",
      "    learn_throughput: 124.101\n",
      "    learn_time_ms: 241739.151\n",
      "    sample_throughput: 140.647\n",
      "    sample_time_ms: 213300.369\n",
      "    update_time_ms: 3.135\n",
      "  timestamp: 1662968266\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 45\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     45 |          20848.4 | 1350000 | -20.0305 |              221.773 |             -138.344 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1380000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_02-45-31\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 160.55243000283323\n",
      "  episode_reward_mean: -32.28535336879545\n",
      "  episode_reward_min: -138.34406310350758\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 920\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -2.3686590391524294\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01626246082792165\n",
      "          policy_loss: 0.0043881568195734254\n",
      "          total_loss: 264.2052893488458\n",
      "          vf_explained_var: -1.0906381353592565e-09\n",
      "          vf_loss: 264.2000885659076\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1380000\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1380000\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.281447963800904\n",
      "    ram_util_percent: 44.86998491704374\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08787043339460275\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.333507898407632\n",
      "    mean_inference_ms: 1.8215144721681333\n",
      "    mean_raw_obs_processing_ms: 5.006126331807284\n",
      "  time_since_restore: 21313.278447151184\n",
      "  time_this_iter_s: 464.86642718315125\n",
      "  time_total_s: 21313.278447151184\n",
      "  timers:\n",
      "    learn_throughput: 123.292\n",
      "    learn_time_ms: 243323.845\n",
      "    sample_throughput: 140.633\n",
      "    sample_time_ms: 213320.461\n",
      "    update_time_ms: 3.112\n",
      "  timestamp: 1662968731\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 46\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     46 |          21313.3 | 1380000 | -32.2854 |              160.552 |             -138.344 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1410000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_02-53-16\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 189.79686789296733\n",
      "  episode_reward_mean: 9.392210448365294\n",
      "  episode_reward_min: -138.34406310350758\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 940\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.348990491704738\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021165390302615456\n",
      "          policy_loss: 0.006012559589531095\n",
      "          total_loss: 221.0146989830504\n",
      "          vf_explained_var: 6.276318345044274e-06\n",
      "          vf_loss: 221.00762875171418\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1410000\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1410000\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.213574660633483\n",
      "    ram_util_percent: 44.9185520361991\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08787946934881073\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33334320733773\n",
      "    mean_inference_ms: 1.8217403233278395\n",
      "    mean_raw_obs_processing_ms: 4.920907459689593\n",
      "  time_since_restore: 21778.1316947937\n",
      "  time_this_iter_s: 464.8532476425171\n",
      "  time_total_s: 21778.1316947937\n",
      "  timers:\n",
      "    learn_throughput: 122.508\n",
      "    learn_time_ms: 244882.129\n",
      "    sample_throughput: 140.627\n",
      "    sample_time_ms: 213330.213\n",
      "    update_time_ms: 3.016\n",
      "  timestamp: 1662969196\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 47\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 13.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     47 |          21778.1 | 1410000 |  9.39221 |              189.797 |             -138.344 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1440000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_03-01-03\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 196.4181391495902\n",
      "  episode_reward_mean: 64.52218002593588\n",
      "  episode_reward_min: -138.34406310350758\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 960\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.6414478905657504\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023107222592769545\n",
      "          policy_loss: 0.006778877555650283\n",
      "          total_loss: 201.49438173009995\n",
      "          vf_explained_var: -1.4710933582406938e-09\n",
      "          vf_loss: 201.48644813050615\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1440000\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1440000\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.187537537537537\n",
      "    ram_util_percent: 45.04189189189189\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08788619199498085\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.333222878907726\n",
      "    mean_inference_ms: 1.8219569527103618\n",
      "    mean_raw_obs_processing_ms: 4.839413501641879\n",
      "  time_since_restore: 22244.846210241318\n",
      "  time_this_iter_s: 466.7145154476166\n",
      "  time_total_s: 22244.846210241318\n",
      "  timers:\n",
      "    learn_throughput: 121.688\n",
      "    learn_time_ms: 246531.32\n",
      "    sample_throughput: 140.631\n",
      "    sample_time_ms: 213323.601\n",
      "    update_time_ms: 3.017\n",
      "  timestamp: 1662969663\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 48\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     48 |          22244.8 | 1440000 |  64.5222 |              196.418 |             -138.344 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1470000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_03-08-51\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 196.4181391495902\n",
      "  episode_reward_mean: 121.73706536567052\n",
      "  episode_reward_min: -57.61088642858364\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 980\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.6377895810756278\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019040258796405845\n",
      "          policy_loss: 0.005120106078486176\n",
      "          total_loss: 191.2737985521682\n",
      "          vf_explained_var: 5.580009232453165e-10\n",
      "          vf_loss: 191.26772633491677\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1470000\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1470000\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.147376311844077\n",
      "    ram_util_percent: 45.029985007496244\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08788858538231768\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33318203991226\n",
      "    mean_inference_ms: 1.8220944521371072\n",
      "    mean_raw_obs_processing_ms: 4.761451582081876\n",
      "  time_since_restore: 22712.62030339241\n",
      "  time_this_iter_s: 467.77409315109253\n",
      "  time_total_s: 22712.62030339241\n",
      "  timers:\n",
      "    learn_throughput: 120.858\n",
      "    learn_time_ms: 248225.982\n",
      "    sample_throughput: 140.613\n",
      "    sample_time_ms: 213352.23\n",
      "    update_time_ms: 3.014\n",
      "  timestamp: 1662970131\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 49\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     49 |          22712.6 | 1470000 |  121.737 |              196.418 |             -57.6109 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1500000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_03-16-40\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 196.4181391495902\n",
      "  episode_reward_mean: 150.79040898019056\n",
      "  episode_reward_min: -38.57938530585829\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1000\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.663755037835304\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019689122899598285\n",
      "          policy_loss: 0.006944400397069911\n",
      "          total_loss: 178.67709868410802\n",
      "          vf_explained_var: -2.7392772494749806e-09\n",
      "          vf_loss: 178.66916998680603\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1500000\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1500000\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.18878923766816\n",
      "    ram_util_percent: 45.45156950672646\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08789113407575458\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33308716875315\n",
      "    mean_inference_ms: 1.8222514861977468\n",
      "    mean_raw_obs_processing_ms: 4.6867683167889185\n",
      "  time_since_restore: 23181.356114149094\n",
      "  time_this_iter_s: 468.73581075668335\n",
      "  time_total_s: 23181.356114149094\n",
      "  timers:\n",
      "    learn_throughput: 120.034\n",
      "    learn_time_ms: 249928.554\n",
      "    sample_throughput: 140.622\n",
      "    sample_time_ms: 213338.08\n",
      "    update_time_ms: 3.009\n",
      "  timestamp: 1662970600\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 50\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     50 |          23181.4 | 1500000 |   150.79 |              196.418 |             -38.5794 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1530000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_03-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 196.4181391495902\n",
      "  episode_reward_mean: 181.87816457525324\n",
      "  episode_reward_min: 66.99794494116628\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1020\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.7432452087199435\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019349302429545426\n",
      "          policy_loss: 0.006096725062209558\n",
      "          total_loss: 167.65338118857525\n",
      "          vf_explained_var: -3.652369739981509e-09\n",
      "          vf_loss: 167.6463174406011\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1530000\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1530000\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.119581464872944\n",
      "    ram_util_percent: 45.46696562032885\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0878921073699168\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332940429595702\n",
      "    mean_inference_ms: 1.8223051397181211\n",
      "    mean_raw_obs_processing_ms: 4.615093578475804\n",
      "  time_since_restore: 23649.980400562286\n",
      "  time_this_iter_s: 468.62428641319275\n",
      "  time_total_s: 23649.980400562286\n",
      "  timers:\n",
      "    learn_throughput: 119.277\n",
      "    learn_time_ms: 251514.606\n",
      "    sample_throughput: 140.649\n",
      "    sample_time_ms: 213297.597\n",
      "    update_time_ms: 3.028\n",
      "  timestamp: 1662971068\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 51\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     51 |            23650 | 1530000 |  181.878 |              196.418 |              66.9979 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1560000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_03-32-19\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 196.4181391495902\n",
      "  episode_reward_mean: 185.52044018197378\n",
      "  episode_reward_min: 106.30235356544372\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1040\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8012128016289246\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019997131983139182\n",
      "          policy_loss: 0.006359710755381495\n",
      "          total_loss: 160.31903037213266\n",
      "          vf_explained_var: 1.054913445841521e-05\n",
      "          vf_loss: 160.3116708925937\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1560000\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1560000\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.089120715350223\n",
      "    ram_util_percent: 45.49493293591654\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08789303380782286\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332723793691233\n",
      "    mean_inference_ms: 1.8223116498310088\n",
      "    mean_raw_obs_processing_ms: 4.546219779477086\n",
      "  time_since_restore: 24120.079419612885\n",
      "  time_this_iter_s: 470.09901905059814\n",
      "  time_total_s: 24120.079419612885\n",
      "  timers:\n",
      "    learn_throughput: 118.665\n",
      "    learn_time_ms: 252811.841\n",
      "    sample_throughput: 140.669\n",
      "    sample_time_ms: 213267.231\n",
      "    update_time_ms: 3.018\n",
      "  timestamp: 1662971539\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 52\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 13.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     52 |          24120.1 | 1560000 |   185.52 |              196.418 |              106.302 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1590000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_03-40-10\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 195.82966905926924\n",
      "  episode_reward_mean: 186.3430666490075\n",
      "  episode_reward_min: 172.6845466509149\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1060\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8238317574845984\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02135502660347637\n",
      "          policy_loss: 0.007441786531993049\n",
      "          total_loss: 152.91960171638652\n",
      "          vf_explained_var: -2.1492674022738356e-06\n",
      "          vf_loss: 152.91109176635743\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1590000\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1590000\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.027232142857144\n",
      "    ram_util_percent: 45.268452380952375\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08789309415317566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332638313971316\n",
      "    mean_inference_ms: 1.8222298386541353\n",
      "    mean_raw_obs_processing_ms: 4.47997728810522\n",
      "  time_since_restore: 24591.03395462036\n",
      "  time_this_iter_s: 470.9545350074768\n",
      "  time_total_s: 24591.03395462036\n",
      "  timers:\n",
      "    learn_throughput: 118.227\n",
      "    learn_time_ms: 253748.653\n",
      "    sample_throughput: 140.674\n",
      "    sample_time_ms: 213259.103\n",
      "    update_time_ms: 3.03\n",
      "  timestamp: 1662972010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 53\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     53 |            24591 | 1590000 |  186.343 |               195.83 |              172.685 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1620000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_03-48-01\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 199.10616090681228\n",
      "  episode_reward_mean: 187.88467473741872\n",
      "  episode_reward_min: 172.6845466509149\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1080\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.826457925451563\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02015444385347296\n",
      "          policy_loss: 0.006738980027074192\n",
      "          total_loss: 147.82726937963608\n",
      "          vf_explained_var: -4.515926775638945e-06\n",
      "          vf_loss: 147.81952295993236\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1620000\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1620000\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.152678571428574\n",
      "    ram_util_percent: 45.35818452380953\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08789557463981575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332580679579195\n",
      "    mean_inference_ms: 1.8221967869777544\n",
      "    mean_raw_obs_processing_ms: 4.4162905441792555\n",
      "  time_since_restore: 25062.671528577805\n",
      "  time_this_iter_s: 471.63757395744324\n",
      "  time_total_s: 25062.671528577805\n",
      "  timers:\n",
      "    learn_throughput: 117.841\n",
      "    learn_time_ms: 254579.529\n",
      "    sample_throughput: 140.655\n",
      "    sample_time_ms: 213288.397\n",
      "    update_time_ms: 3.024\n",
      "  timestamp: 1662972481\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 54\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     54 |          25062.7 | 1620000 |  187.885 |              199.106 |              172.685 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1650000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_03-55-52\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 199.10616090681228\n",
      "  episode_reward_mean: 189.6278633599739\n",
      "  episode_reward_min: 172.6845466509149\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1100\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8173657418311913\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02053693488974659\n",
      "          policy_loss: 0.007168337039431517\n",
      "          total_loss: 140.25591365733044\n",
      "          vf_explained_var: -1.0906381353592565e-09\n",
      "          vf_loss: 140.24771814549223\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1650000\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1650000\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.156845238095237\n",
      "    ram_util_percent: 45.47366071428572\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08789709588255015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332517897230343\n",
      "    mean_inference_ms: 1.8222395790365453\n",
      "    mean_raw_obs_processing_ms: 4.35503863809492\n",
      "  time_since_restore: 25533.529166698456\n",
      "  time_this_iter_s: 470.85763812065125\n",
      "  time_total_s: 25533.529166698456\n",
      "  timers:\n",
      "    learn_throughput: 117.557\n",
      "    learn_time_ms: 255195.496\n",
      "    sample_throughput: 140.647\n",
      "    sample_time_ms: 213300.165\n",
      "    update_time_ms: 3.036\n",
      "  timestamp: 1662972952\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 55\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     55 |          25533.5 | 1650000 |  189.628 |              199.106 |              172.685 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1680000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_04-03-46\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 209.28968434329423\n",
      "  episode_reward_mean: 193.23844630307107\n",
      "  episode_reward_min: 172.6845466509149\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1120\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.863747028695776\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021309162106964385\n",
      "          policy_loss: 0.006610928132555428\n",
      "          total_loss: 136.73581849443153\n",
      "          vf_explained_var: -4.819099008734895e-10\n",
      "          vf_loss: 136.7281423722937\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1680000\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1680000\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.090828402366867\n",
      "    ram_util_percent: 45.49097633136096\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08789967187165942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332472412153912\n",
      "    mean_inference_ms: 1.822373102748628\n",
      "    mean_raw_obs_processing_ms: 4.296078359456526\n",
      "  time_since_restore: 26006.914513111115\n",
      "  time_this_iter_s: 473.3853464126587\n",
      "  time_total_s: 26006.914513111115\n",
      "  timers:\n",
      "    learn_throughput: 117.157\n",
      "    learn_time_ms: 256067.737\n",
      "    sample_throughput: 140.66\n",
      "    sample_time_ms: 213279.719\n",
      "    update_time_ms: 3.043\n",
      "  timestamp: 1662973426\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 56\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 13.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     56 |          26006.9 | 1680000 |  193.238 |               209.29 |              172.685 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1710000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_04-11-40\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 209.28968434329423\n",
      "  episode_reward_mean: 197.45087964306455\n",
      "  episode_reward_min: 180.55945840140214\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1140\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8869508170066998\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019924179266421115\n",
      "          policy_loss: 0.006643107440124483\n",
      "          total_loss: 132.1389836412795\n",
      "          vf_explained_var: 7.262077815539669e-06\n",
      "          vf_loss: 132.1313444064526\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1710000\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1710000\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.074704142011832\n",
      "    ram_util_percent: 45.526331360946756\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08790310293421796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332420890539208\n",
      "    mean_inference_ms: 1.8225567056463108\n",
      "    mean_raw_obs_processing_ms: 4.239324791842367\n",
      "  time_since_restore: 26481.432826280594\n",
      "  time_this_iter_s: 474.51831316947937\n",
      "  time_total_s: 26481.432826280594\n",
      "  timers:\n",
      "    learn_throughput: 116.709\n",
      "    learn_time_ms: 257048.813\n",
      "    sample_throughput: 140.67\n",
      "    sample_time_ms: 213265.128\n",
      "    update_time_ms: 3.058\n",
      "  timestamp: 1662973900\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 57\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 13.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     57 |          26481.4 | 1710000 |  197.451 |               209.29 |              180.559 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1740000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_04-19-35\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 209.28968434329423\n",
      "  episode_reward_mean: 199.02217926219583\n",
      "  episode_reward_min: 183.6762116216347\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1160\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.900331976464454\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020597515281489925\n",
      "          policy_loss: 0.00697511735699199\n",
      "          total_loss: 131.64764480103838\n",
      "          vf_explained_var: -2.81536838286911e-09\n",
      "          vf_loss: 131.63964015554873\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1740000\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1740000\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.02920353982301\n",
      "    ram_util_percent: 45.571386430678466\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08790762351218977\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33227138229342\n",
      "    mean_inference_ms: 1.8227968588281511\n",
      "    mean_raw_obs_processing_ms: 4.184650240327732\n",
      "  time_since_restore: 26955.932713747025\n",
      "  time_this_iter_s: 474.49988746643066\n",
      "  time_total_s: 26955.932713747025\n",
      "  timers:\n",
      "    learn_throughput: 116.356\n",
      "    learn_time_ms: 257828.328\n",
      "    sample_throughput: 140.671\n",
      "    sample_time_ms: 213264.049\n",
      "    update_time_ms: 3.051\n",
      "  timestamp: 1662974375\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 58\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     58 |          26955.9 | 1740000 |  199.022 |               209.29 |              183.676 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1770000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_04-27-31\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 209.28968434329423\n",
      "  episode_reward_mean: 198.8924222108288\n",
      "  episode_reward_min: 190.00474765302948\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1180\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9125053182561347\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02086583212934174\n",
      "          policy_loss: 0.007228591714371392\n",
      "          total_loss: 129.09062773197255\n",
      "          vf_explained_var: -2.6885498272122277e-09\n",
      "          vf_loss: 129.08235598300365\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1770000\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1770000\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 17.05640648011782\n",
      "    ram_util_percent: 45.66053019145803\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08791137521420808\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332155993150263\n",
      "    mean_inference_ms: 1.8230202725699696\n",
      "    mean_raw_obs_processing_ms: 4.131835771790693\n",
      "  time_since_restore: 27432.00146961212\n",
      "  time_this_iter_s: 476.06875586509705\n",
      "  time_total_s: 27432.00146961212\n",
      "  timers:\n",
      "    learn_throughput: 115.98\n",
      "    learn_time_ms: 258664.445\n",
      "    sample_throughput: 140.675\n",
      "    sample_time_ms: 213257.484\n",
      "    update_time_ms: 3.024\n",
      "  timestamp: 1662974851\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 59\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     59 |            27432 | 1770000 |  198.892 |               209.29 |              190.005 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1800000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_04-35-29\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 209.28968434329423\n",
      "  episode_reward_mean: 197.61729287612576\n",
      "  episode_reward_min: 185.9459546970595\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1200\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9686821413040163\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020582669400096166\n",
      "          policy_loss: 0.006016115923511221\n",
      "          total_loss: 126.10113034025152\n",
      "          vf_explained_var: -2.5617314935999502e-09\n",
      "          vf_loss: 126.0940847340036\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1800000\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1800000\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.95850439882698\n",
      "    ram_util_percent: 45.72888563049854\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0879144053819049\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33210878694553\n",
      "    mean_inference_ms: 1.8231734806720155\n",
      "    mean_raw_obs_processing_ms: 4.080821248583982\n",
      "  time_since_restore: 27910.337455034256\n",
      "  time_this_iter_s: 478.3359854221344\n",
      "  time_total_s: 27910.337455034256\n",
      "  timers:\n",
      "    learn_throughput: 115.564\n",
      "    learn_time_ms: 259596.317\n",
      "    sample_throughput: 140.656\n",
      "    sample_time_ms: 213285.579\n",
      "    update_time_ms: 3.03\n",
      "  timestamp: 1662975329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 60\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     60 |          27910.3 | 1800000 |  197.617 |               209.29 |              185.946 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1830000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_04-43-32\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 206.05260536072623\n",
      "  episode_reward_mean: 196.9890754396482\n",
      "  episode_reward_min: 185.9459546970595\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1220\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.000928864986339\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020851507738568236\n",
      "          policy_loss: 0.007344326044016696\n",
      "          total_loss: 123.7772730839506\n",
      "          vf_explained_var: -3.1450961834877944e-09\n",
      "          vf_loss: 123.76888611976136\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1830000\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1830000\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.886502177068213\n",
      "    ram_util_percent: 45.81683599419448\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08791724491474834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332022392931776\n",
      "    mean_inference_ms: 1.8233302048050337\n",
      "    mean_raw_obs_processing_ms: 4.031537754193021\n",
      "  time_since_restore: 28393.424220085144\n",
      "  time_this_iter_s: 483.08676505088806\n",
      "  time_total_s: 28393.424220085144\n",
      "  timers:\n",
      "    learn_throughput: 114.929\n",
      "    learn_time_ms: 261031.092\n",
      "    sample_throughput: 140.649\n",
      "    sample_time_ms: 213297.032\n",
      "    update_time_ms: 3.019\n",
      "  timestamp: 1662975812\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 61\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     61 |          28393.4 | 1830000 |  196.989 |              206.053 |              185.946 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1860000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_04-51-42\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 217.01060380263684\n",
      "  episode_reward_mean: 200.36832103596697\n",
      "  episode_reward_min: 185.9459546970595\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1240\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.01521467330608\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02202774781360665\n",
      "          policy_loss: 0.007539593128170422\n",
      "          total_loss: 125.37367607441354\n",
      "          vf_explained_var: -2.7392772494749806e-09\n",
      "          vf_loss: 125.36503530624066\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1860000\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1860000\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.694992846924176\n",
      "    ram_util_percent: 46.221888412017165\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08791960585559026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332057522726526\n",
      "    mean_inference_ms: 1.8233559536840425\n",
      "    mean_raw_obs_processing_ms: 3.983848426676425\n",
      "  time_since_restore: 28882.88196706772\n",
      "  time_this_iter_s: 489.45774698257446\n",
      "  time_total_s: 28882.88196706772\n",
      "  timers:\n",
      "    learn_throughput: 114.081\n",
      "    learn_time_ms: 262970.595\n",
      "    sample_throughput: 140.651\n",
      "    sample_time_ms: 213293.276\n",
      "    update_time_ms: 3.026\n",
      "  timestamp: 1662976302\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 62\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     62 |          28882.9 | 1860000 |  200.368 |              217.011 |              185.946 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1890000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_05-00-07\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 254.89677304172287\n",
      "  episode_reward_mean: 207.75159467653\n",
      "  episode_reward_min: 185.9459546970595\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1260\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8382718304370314\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04718070793312372\n",
      "          policy_loss: 0.006506162173451578\n",
      "          total_loss: 121.10682641536631\n",
      "          vf_explained_var: -3.1450961834877944e-09\n",
      "          vf_loss: 121.09796116281063\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1890000\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1890000\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.469722222222224\n",
      "    ram_util_percent: 45.981944444444444\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08792238724357052\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33205154969359\n",
      "    mean_inference_ms: 1.823428448660584\n",
      "    mean_raw_obs_processing_ms: 3.9376970571843937\n",
      "  time_since_restore: 29387.677635908127\n",
      "  time_this_iter_s: 504.7956688404083\n",
      "  time_total_s: 29387.677635908127\n",
      "  timers:\n",
      "    learn_throughput: 112.634\n",
      "    learn_time_ms: 266349.337\n",
      "    sample_throughput: 140.648\n",
      "    sample_time_ms: 213298.781\n",
      "    update_time_ms: 2.994\n",
      "  timestamp: 1662976807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 63\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     63 |          29387.7 | 1890000 |  207.752 |              254.897 |              185.946 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1920000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_05-08-56\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 254.89677304172287\n",
      "  episode_reward_mean: 214.2573549566706\n",
      "  episode_reward_min: 185.9459546970595\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1280\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.853070829168279\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030915186319827245\n",
      "          policy_loss: 0.007076822768381619\n",
      "          total_loss: 128.426151866507\n",
      "          vf_explained_var: -4.286461852132106e-09\n",
      "          vf_loss: 128.4167568482744\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1920000\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1920000\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.09019867549669\n",
      "    ram_util_percent: 46.2164238410596\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08792370895329625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332054854490043\n",
      "    mean_inference_ms: 1.8234645898962074\n",
      "    mean_raw_obs_processing_ms: 3.893050634562581\n",
      "  time_since_restore: 29916.682970285416\n",
      "  time_this_iter_s: 529.0053343772888\n",
      "  time_total_s: 29916.682970285416\n",
      "  timers:\n",
      "    learn_throughput: 110.254\n",
      "    learn_time_ms: 272098.145\n",
      "    sample_throughput: 140.656\n",
      "    sample_time_ms: 213286.614\n",
      "    update_time_ms: 3.053\n",
      "  timestamp: 1662977336\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 64\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     64 |          29916.7 | 1920000 |  214.257 |              254.897 |              185.946 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1950000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_05-17-56\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 254.89677304172287\n",
      "  episode_reward_mean: 220.966704678518\n",
      "  episode_reward_min: 189.87223550711488\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1300\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8929547065369627\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029996952199250446\n",
      "          policy_loss: 0.0068854130112982175\n",
      "          total_loss: 127.79962505259412\n",
      "          vf_explained_var: -2.4856405822504257e-09\n",
      "          vf_loss: 127.79049029573481\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1950000\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1950000\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.96909090909091\n",
      "    ram_util_percent: 46.282987012987014\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08792598652309075\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.331988822552177\n",
      "    mean_inference_ms: 1.8235415969740123\n",
      "    mean_raw_obs_processing_ms: 3.8498271411922627\n",
      "  time_since_restore: 30456.89241528511\n",
      "  time_this_iter_s: 540.2094449996948\n",
      "  time_total_s: 30456.89241528511\n",
      "  timers:\n",
      "    learn_throughput: 107.514\n",
      "    learn_time_ms: 279032.655\n",
      "    sample_throughput: 140.655\n",
      "    sample_time_ms: 213287.164\n",
      "    update_time_ms: 3.043\n",
      "  timestamp: 1662977876\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 65\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     65 |          30456.9 | 1950000 |  220.967 |              254.897 |              189.872 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 1980000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_05-27-00\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 254.89677304172287\n",
      "  episode_reward_mean: 227.40376880077872\n",
      "  episode_reward_min: 208.92789321072468\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1320\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.700849812994612\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.038066557117024565\n",
      "          policy_loss: 0.009560265180635009\n",
      "          total_loss: 126.66303525559445\n",
      "          vf_explained_var: -7.380830613357148e-09\n",
      "          vf_loss: 126.6506202162073\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 1980000\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1980000\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.844787644787647\n",
      "    ram_util_percent: 46.36177606177607\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08792742922049446\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33204847925221\n",
      "    mean_inference_ms: 1.823570970578396\n",
      "    mean_raw_obs_processing_ms: 3.807971928435451\n",
      "  time_since_restore: 31000.889971494675\n",
      "  time_this_iter_s: 543.9975562095642\n",
      "  time_total_s: 31000.889971494675\n",
      "  timers:\n",
      "    learn_throughput: 104.87\n",
      "    learn_time_ms: 286068.917\n",
      "    sample_throughput: 140.639\n",
      "    sample_time_ms: 213312.109\n",
      "    update_time_ms: 3.038\n",
      "  timestamp: 1662978420\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 66\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     66 |          31000.9 | 1980000 |  227.404 |              254.897 |              208.928 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2010000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_05-36-06\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 254.89677304172287\n",
      "  episode_reward_mean: 231.85523429084395\n",
      "  episode_reward_min: 214.76526413346562\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1340\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.5903575482267014\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02339156777023347\n",
      "          policy_loss: 0.012435309659253727\n",
      "          total_loss: 130.63454643574167\n",
      "          vf_explained_var: -3.855279206987916e-09\n",
      "          vf_loss: 130.62035673425552\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2010000\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2010000\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.871593830334193\n",
      "    ram_util_percent: 46.73958868894601\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08792895942872703\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33203481680476\n",
      "    mean_inference_ms: 1.8237195389067518\n",
      "    mean_raw_obs_processing_ms: 3.767415456348578\n",
      "  time_since_restore: 31546.30911397934\n",
      "  time_this_iter_s: 545.4191424846649\n",
      "  time_total_s: 31546.30911397934\n",
      "  timers:\n",
      "    learn_throughput: 102.331\n",
      "    learn_time_ms: 293165.615\n",
      "    sample_throughput: 140.643\n",
      "    sample_time_ms: 213305.495\n",
      "    update_time_ms: 3.038\n",
      "  timestamp: 1662978966\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 67\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     67 |          31546.3 | 2010000 |  231.855 |              254.897 |              214.765 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2040000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_05-45-12\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 252.5930148041941\n",
      "  episode_reward_mean: 230.8029557812064\n",
      "  episode_reward_min: 190.42864710817736\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1360\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.198628126509647\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03874756579708447\n",
      "          policy_loss: 0.009279314713512964\n",
      "          total_loss: 131.92048164367677\n",
      "          vf_explained_var: -3.1824567940930137e-06\n",
      "          vf_loss: 131.908296679233\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2040000\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2040000\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.823333333333334\n",
      "    ram_util_percent: 46.742564102564096\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08792981645671452\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.332058024570024\n",
      "    mean_inference_ms: 1.8238164950797415\n",
      "    mean_raw_obs_processing_ms: 3.7280796709325377\n",
      "  time_since_restore: 32093.128930330276\n",
      "  time_this_iter_s: 546.8198163509369\n",
      "  time_total_s: 32093.128930330276\n",
      "  timers:\n",
      "    learn_throughput: 99.859\n",
      "    learn_time_ms: 300423.145\n",
      "    sample_throughput: 140.66\n",
      "    sample_time_ms: 213279.967\n",
      "    update_time_ms: 3.058\n",
      "  timestamp: 1662979512\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 68\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     68 |          32093.1 | 2040000 |  230.803 |              252.593 |              190.429 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2070000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_05-54-22\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 252.5930148041941\n",
      "  episode_reward_mean: 227.02196937571208\n",
      "  episode_reward_min: 190.42864710817736\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1380\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.530603957987846\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0247375299832092\n",
      "          policy_loss: 0.009443370036463788\n",
      "          total_loss: 135.4895862952699\n",
      "          vf_explained_var: -5.580009232453165e-10\n",
      "          vf_loss: 135.4782875142199\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2070000\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2070000\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.786845466155812\n",
      "    ram_util_percent: 46.77394636015325\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08793156995691058\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.331978667426466\n",
      "    mean_inference_ms: 1.8239127094055902\n",
      "    mean_raw_obs_processing_ms: 3.6899211218944323\n",
      "  time_since_restore: 32642.188936948776\n",
      "  time_this_iter_s: 549.0600066184998\n",
      "  time_total_s: 32642.188936948776\n",
      "  timers:\n",
      "    learn_throughput: 97.484\n",
      "    learn_time_ms: 307742.386\n",
      "    sample_throughput: 140.673\n",
      "    sample_time_ms: 213259.864\n",
      "    update_time_ms: 3.047\n",
      "  timestamp: 1662980062\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 69\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     69 |          32642.2 | 2070000 |  227.022 |              252.593 |              190.429 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2100000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_06-03-31\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 252.5930148041941\n",
      "  episode_reward_mean: 221.9404766090793\n",
      "  episode_reward_min: 182.05389712364982\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1400\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.676277001259175\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02630854212872181\n",
      "          policy_loss: 0.008263945149733349\n",
      "          total_loss: 142.06495075144667\n",
      "          vf_explained_var: -2.0544579371062355e-09\n",
      "          vf_loss: 142.0547136185017\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2100000\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2100000\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.77079081632653\n",
      "    ram_util_percent: 46.852551020408164\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08793278874115007\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33179430129604\n",
      "    mean_inference_ms: 1.8239988282829729\n",
      "    mean_raw_obs_processing_ms: 3.6528742942170163\n",
      "  time_since_restore: 33191.96879887581\n",
      "  time_this_iter_s: 549.7798619270325\n",
      "  time_total_s: 33191.96879887581\n",
      "  timers:\n",
      "    learn_throughput: 95.26\n",
      "    learn_time_ms: 314927.799\n",
      "    sample_throughput: 140.701\n",
      "    sample_time_ms: 213218.73\n",
      "    update_time_ms: 3.048\n",
      "  timestamp: 1662980611\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 70\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     70 |            33192 | 2100000 |   221.94 |              252.593 |              182.054 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2130000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_06-12-42\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 252.5930148041941\n",
      "  episode_reward_mean: 213.5693944849285\n",
      "  episode_reward_min: 182.05389712364982\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1420\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.681316612426271\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02373548176945848\n",
      "          policy_loss: 0.009812318779072387\n",
      "          total_loss: 141.21747157320064\n",
      "          vf_explained_var: -2.5870952047313267e-09\n",
      "          vf_loss: 141.2058791367551\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2130000\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2130000\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.77404580152672\n",
      "    ram_util_percent: 46.9148854961832\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08793511117491494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.331558805677687\n",
      "    mean_inference_ms: 1.8240462442271785\n",
      "    mean_raw_obs_processing_ms: 3.6168806069242554\n",
      "  time_since_restore: 33742.654599905014\n",
      "  time_this_iter_s: 550.6858010292053\n",
      "  time_total_s: 33742.654599905014\n",
      "  timers:\n",
      "    learn_throughput: 93.257\n",
      "    learn_time_ms: 321693.138\n",
      "    sample_throughput: 140.704\n",
      "    sample_time_ms: 213213.375\n",
      "    update_time_ms: 3.048\n",
      "  timestamp: 1662981162\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 71\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     71 |          33742.7 | 2130000 |  213.569 |              252.593 |              182.054 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2160000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_06-21-55\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 240.6797058518821\n",
      "  episode_reward_mean: 200.27407802289045\n",
      "  episode_reward_min: 142.410905854035\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1440\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.4639848854186686\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024567873193238533\n",
      "          policy_loss: 0.010873343031655283\n",
      "          total_loss: 149.30392715778757\n",
      "          vf_explained_var: -6.001857855153503e-06\n",
      "          vf_loss: 149.29121153811192\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2160000\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2160000\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.766116751269037\n",
      "    ram_util_percent: 47.011167512690356\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08793811354298947\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.331289165862938\n",
      "    mean_inference_ms: 1.8240575254486402\n",
      "    mean_raw_obs_processing_ms: 3.581939978345052\n",
      "  time_since_restore: 34295.1620554924\n",
      "  time_this_iter_s: 552.5074555873871\n",
      "  time_total_s: 34295.1620554924\n",
      "  timers:\n",
      "    learn_throughput: 91.469\n",
      "    learn_time_ms: 327980.309\n",
      "    sample_throughput: 140.693\n",
      "    sample_time_ms: 213230.978\n",
      "    update_time_ms: 3.1\n",
      "  timestamp: 1662981715\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 72\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     72 |          34295.2 | 2160000 |  200.274 |               240.68 |              142.411 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2190000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_06-31-09\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 227.47553385879866\n",
      "  episode_reward_mean: 189.43884789193268\n",
      "  episode_reward_min: 142.410905854035\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1460\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.5542925491738826\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030248377917909217\n",
      "          policy_loss: 0.017388180031817645\n",
      "          total_loss: 146.98693824768065\n",
      "          vf_explained_var: -2.4557621145504527e-06\n",
      "          vf_loss: 146.967281390251\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2190000\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2190000\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.753982300884958\n",
      "    ram_util_percent: 46.877623261694055\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08794099629789005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.331108949816688\n",
      "    mean_inference_ms: 1.824032456691375\n",
      "    mean_raw_obs_processing_ms: 3.5480164240010605\n",
      "  time_since_restore: 34849.25253820419\n",
      "  time_this_iter_s: 554.090482711792\n",
      "  time_total_s: 34849.25253820419\n",
      "  timers:\n",
      "    learn_throughput: 90.118\n",
      "    learn_time_ms: 332896.142\n",
      "    sample_throughput: 140.684\n",
      "    sample_time_ms: 213244.571\n",
      "    update_time_ms: 3.132\n",
      "  timestamp: 1662982269\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 73\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     73 |          34849.3 | 2190000 |  189.439 |              227.476 |              142.411 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2220000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_06-40-22\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 205.62112440559662\n",
      "  episode_reward_mean: 184.531852127825\n",
      "  episode_reward_min: 142.410905854035\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1480\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.65483049646337\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03155637026199735\n",
      "          policy_loss: 0.015787361697987355\n",
      "          total_loss: 152.74233859772377\n",
      "          vf_explained_var: -1.876912181231205e-09\n",
      "          vf_loss: 152.7241845248608\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2220000\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2220000\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.744866920152091\n",
      "    ram_util_percent: 47.096831432192644\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08794359678206129\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33103597677752\n",
      "    mean_inference_ms: 1.8239415512760269\n",
      "    mean_raw_obs_processing_ms: 3.515049042995498\n",
      "  time_since_restore: 35402.646610975266\n",
      "  time_this_iter_s: 553.3940727710724\n",
      "  time_total_s: 35402.646610975266\n",
      "  timers:\n",
      "    learn_throughput: 89.461\n",
      "    learn_time_ms: 335341.944\n",
      "    sample_throughput: 140.688\n",
      "    sample_time_ms: 213237.668\n",
      "    update_time_ms: 3.078\n",
      "  timestamp: 1662982822\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 74\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     74 |          35402.6 | 2220000 |  184.532 |              205.621 |              142.411 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2250000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_06-49-36\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 198.0208014033423\n",
      "  episode_reward_mean: 182.01364950263195\n",
      "  episode_reward_min: 142.410905854035\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1500\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.7498795713262356\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03457940019667168\n",
      "          policy_loss: 0.015432480158522091\n",
      "          total_loss: 153.5285699771313\n",
      "          vf_explained_var: -7.132773589546559e-07\n",
      "          vf_loss: 153.51054376480428\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2250000\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2250000\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.705822784810124\n",
      "    ram_util_percent: 47.38962025316456\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08794566721830382\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330965330491352\n",
      "    mean_inference_ms: 1.823839677200949\n",
      "    mean_raw_obs_processing_ms: 3.4830382597399048\n",
      "  time_since_restore: 35956.318984508514\n",
      "  time_this_iter_s: 553.6723735332489\n",
      "  time_total_s: 35956.318984508514\n",
      "  timers:\n",
      "    learn_throughput: 89.096\n",
      "    learn_time_ms: 336716.155\n",
      "    sample_throughput: 140.706\n",
      "    sample_time_ms: 213209.878\n",
      "    update_time_ms: 3.077\n",
      "  timestamp: 1662983376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 75\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     75 |          35956.3 | 2250000 |  182.014 |              198.021 |              142.411 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2280000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_06-58-50\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 256.83357414108207\n",
      "  episode_reward_mean: 190.9704364561719\n",
      "  episode_reward_min: 142.410905854035\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1520\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.075\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.5430250827302325\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.06666514914898994\n",
      "          policy_loss: 0.016007041751030595\n",
      "          total_loss: 147.08496521320748\n",
      "          vf_explained_var: -1.116001846490633e-09\n",
      "          vf_loss: 147.06395815585523\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2280000\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2280000\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.685587863463969\n",
      "    ram_util_percent: 47.4811630847029\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08794751709305391\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330918223960285\n",
      "    mean_inference_ms: 1.8237618069175965\n",
      "    mean_raw_obs_processing_ms: 3.4519051825559415\n",
      "  time_since_restore: 36510.49991250038\n",
      "  time_this_iter_s: 554.1809279918671\n",
      "  time_total_s: 36510.49991250038\n",
      "  timers:\n",
      "    learn_throughput: 88.821\n",
      "    learn_time_ms: 337756.138\n",
      "    sample_throughput: 140.721\n",
      "    sample_time_ms: 213188.362\n",
      "    update_time_ms: 3.079\n",
      "  timestamp: 1662983930\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 76\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     76 |          36510.5 | 2280000 |   190.97 |              256.834 |              142.411 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2310000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_07-08-05\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 259.75132471769473\n",
      "  episode_reward_mean: 208.59761239903088\n",
      "  episode_reward_min: 159.6438542244641\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1540\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.11250000000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.983370880167535\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.07859715276010755\n",
      "          policy_loss: 0.024235387833868253\n",
      "          total_loss: 143.3475816280284\n",
      "          vf_explained_var: -1.565699818684152e-07\n",
      "          vf_loss: 143.31450422895716\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2310000\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2310000\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.711251580278127\n",
      "    ram_util_percent: 47.217067003792664\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08794943889542128\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33092819734132\n",
      "    mean_inference_ms: 1.8237122457214474\n",
      "    mean_raw_obs_processing_ms: 3.4216057466824226\n",
      "  time_since_restore: 37065.031501054764\n",
      "  time_this_iter_s: 554.5315885543823\n",
      "  time_total_s: 37065.031501054764\n",
      "  timers:\n",
      "    learn_throughput: 88.588\n",
      "    learn_time_ms: 338645.98\n",
      "    sample_throughput: 140.707\n",
      "    sample_time_ms: 213209.764\n",
      "    update_time_ms: 3.095\n",
      "  timestamp: 1662984485\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 77\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     77 |            37065 | 2310000 |  208.598 |              259.751 |              159.644 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2340000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_07-16-07\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 346.22137085988913\n",
      "  episode_reward_mean: 228.34201093612054\n",
      "  episode_reward_min: 167.20702575889229\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1560\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.16874999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.922240309715271\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024309501133932356\n",
      "          policy_loss: 0.009758481170704707\n",
      "          total_loss: 142.6443653999491\n",
      "          vf_explained_var: -1.0678108708361833e-07\n",
      "          vf_loss: 142.63050473476977\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2340000\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2340000\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.97409024745269\n",
      "    ram_util_percent: 46.9042212518195\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.087952553064084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330867439513987\n",
      "    mean_inference_ms: 1.8237744743513782\n",
      "    mean_raw_obs_processing_ms: 3.3921040259362485\n",
      "  time_since_restore: 37546.63970756531\n",
      "  time_this_iter_s: 481.6082065105438\n",
      "  time_total_s: 37546.63970756531\n",
      "  timers:\n",
      "    learn_throughput: 90.336\n",
      "    learn_time_ms: 332094.24\n",
      "    sample_throughput: 140.686\n",
      "    sample_time_ms: 213240.398\n",
      "    update_time_ms: 3.098\n",
      "  timestamp: 1662984967\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 78\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     78 |          37546.6 | 2340000 |  228.342 |              346.221 |              167.207 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2370000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_07-24-07\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 346.22137085988913\n",
      "  episode_reward_mean: 244.15256615661372\n",
      "  episode_reward_min: 179.43027890066023\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1580\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.16874999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -5.027406472956881\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.04450755457313348\n",
      "          policy_loss: 0.01690195552449911\n",
      "          total_loss: 148.6460629873073\n",
      "          vf_explained_var: -1.0180980325458222e-07\n",
      "          vf_loss: 148.62165047341205\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2370000\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2370000\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.955830903790087\n",
      "    ram_util_percent: 47.29883381924199\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08795611024189537\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330751507474204\n",
      "    mean_inference_ms: 1.8238733662110878\n",
      "    mean_raw_obs_processing_ms: 3.3633611058516912\n",
      "  time_since_restore: 38027.01714372635\n",
      "  time_this_iter_s: 480.37743616104126\n",
      "  time_total_s: 38027.01714372635\n",
      "  timers:\n",
      "    learn_throughput: 92.245\n",
      "    learn_time_ms: 325220.283\n",
      "    sample_throughput: 140.683\n",
      "    sample_time_ms: 213245.985\n",
      "    update_time_ms: 3.115\n",
      "  timestamp: 1662985447\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 79\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     79 |            38027 | 2370000 |  244.153 |              346.221 |               179.43 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2400000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_07-32-08\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 346.22137085988913\n",
      "  episode_reward_mean: 259.3142907020128\n",
      "  episode_reward_min: 180.7234415992929\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1600\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -5.167344106917685\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030196945283570486\n",
      "          policy_loss: 0.011863884363481974\n",
      "          total_loss: 152.7489485233388\n",
      "          vf_explained_var: -2.3715038821592316e-08\n",
      "          vf_loss: 152.72944104458423\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2400000\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2400000\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.93600583090379\n",
      "    ram_util_percent: 47.30364431486881\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08795980768170578\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33070931541265\n",
      "    mean_inference_ms: 1.823929187086221\n",
      "    mean_raw_obs_processing_ms: 3.3353166716907343\n",
      "  time_since_restore: 38507.77930879593\n",
      "  time_this_iter_s: 480.7621650695801\n",
      "  time_total_s: 38507.77930879593\n",
      "  timers:\n",
      "    learn_throughput: 94.248\n",
      "    learn_time_ms: 318307.888\n",
      "    sample_throughput: 140.676\n",
      "    sample_time_ms: 213256.724\n",
      "    update_time_ms: 3.109\n",
      "  timestamp: 1662985928\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 80\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     80 |          38507.8 | 2400000 |  259.314 |              346.221 |              180.723 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2430000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_07-40-08\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 346.22137085988913\n",
      "  episode_reward_mean: 264.1491241275491\n",
      "  episode_reward_min: 253.53318415689643\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1620\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -5.1854451936356565\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02823089619736225\n",
      "          policy_loss: 0.00963219840713638\n",
      "          total_loss: 156.2002510914904\n",
      "          vf_explained_var: 1.0145471268652173e-10\n",
      "          vf_loss: 156.18347287117166\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2430000\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2430000\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.92978102189781\n",
      "    ram_util_percent: 47.0429197080292\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08796234521298209\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33056968328892\n",
      "    mean_inference_ms: 1.8240387896840498\n",
      "    mean_raw_obs_processing_ms: 3.307985101487826\n",
      "  time_since_restore: 38988.279242277145\n",
      "  time_this_iter_s: 480.49993348121643\n",
      "  time_total_s: 38988.279242277145\n",
      "  timers:\n",
      "    learn_throughput: 96.376\n",
      "    learn_time_ms: 311280.821\n",
      "    sample_throughput: 140.67\n",
      "    sample_time_ms: 213265.214\n",
      "    update_time_ms: 3.106\n",
      "  timestamp: 1662986408\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 81\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     81 |          38988.3 | 2430000 |  264.149 |              346.221 |              253.533 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2460000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_07-48-10\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 346.22137085988913\n",
      "  episode_reward_mean: 264.2599891369728\n",
      "  episode_reward_min: 256.81292371366436\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1640\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -5.07923132652932\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027494735909699308\n",
      "          policy_loss: 0.009572685125600944\n",
      "          total_loss: 157.43810232608877\n",
      "          vf_explained_var: -1.9149577923371908e-08\n",
      "          vf_loss: 157.42156970084983\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2460000\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2460000\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.911935953420667\n",
      "    ram_util_percent: 47.095196506550224\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08796443547934527\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330449031212833\n",
      "    mean_inference_ms: 1.8241373744766178\n",
      "    mean_raw_obs_processing_ms: 3.281352048519734\n",
      "  time_since_restore: 39469.36965250969\n",
      "  time_this_iter_s: 481.09041023254395\n",
      "  time_total_s: 39469.36965250969\n",
      "  timers:\n",
      "    learn_throughput: 98.648\n",
      "    learn_time_ms: 304110.133\n",
      "    sample_throughput: 140.651\n",
      "    sample_time_ms: 213294.54\n",
      "    update_time_ms: 3.053\n",
      "  timestamp: 1662986890\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 82\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     82 |          39469.4 | 2460000 |   264.26 |              346.221 |              256.813 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2490000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_07-56-11\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 272.33723681773944\n",
      "  episode_reward_mean: 261.28462201446456\n",
      "  episode_reward_min: 257.1031868759991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1660\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -5.167065948729819\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029940097976253615\n",
      "          policy_loss: 0.010867490304158406\n",
      "          total_loss: 160.97073852539063\n",
      "          vf_explained_var: -6.087282899969182e-10\n",
      "          vf_loss: 160.9522923863188\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2490000\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2490000\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.95451895043732\n",
      "    ram_util_percent: 47.143148688046644\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08796673579671314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33033622671797\n",
      "    mean_inference_ms: 1.8242098132862992\n",
      "    mean_raw_obs_processing_ms: 3.2553790740870725\n",
      "  time_since_restore: 39950.58882379532\n",
      "  time_this_iter_s: 481.2191712856293\n",
      "  time_total_s: 39950.58882379532\n",
      "  timers:\n",
      "    learn_throughput: 101.072\n",
      "    learn_time_ms: 296818.731\n",
      "    sample_throughput: 140.648\n",
      "    sample_time_ms: 213298.849\n",
      "    update_time_ms: 3.015\n",
      "  timestamp: 1662987371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 83\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     83 |          39950.6 | 2490000 |  261.285 |              272.337 |              257.103 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2520000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_08-04-12\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 262.71163767829273\n",
      "  episode_reward_mean: 260.9253318857533\n",
      "  episode_reward_min: 257.1031868759991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1680\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -5.1999435499881175\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02904222255727884\n",
      "          policy_loss: 0.009709566837236127\n",
      "          total_loss: 162.1689569741107\n",
      "          vf_explained_var: -7.862740458719486e-10\n",
      "          vf_loss: 162.15189632009952\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2520000\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2520000\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.86472303206997\n",
      "    ram_util_percent: 47.214723032069976\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08796819094373878\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330284515836937\n",
      "    mean_inference_ms: 1.8242634304789374\n",
      "    mean_raw_obs_processing_ms: 3.2300374924013\n",
      "  time_since_restore: 40431.34018826485\n",
      "  time_this_iter_s: 480.7513644695282\n",
      "  time_total_s: 40431.34018826485\n",
      "  timers:\n",
      "    learn_throughput: 103.609\n",
      "    learn_time_ms: 289549.268\n",
      "    sample_throughput: 140.644\n",
      "    sample_time_ms: 213304.112\n",
      "    update_time_ms: 3.018\n",
      "  timestamp: 1662987852\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 84\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     84 |          40431.3 | 2520000 |  260.925 |              262.712 |              257.103 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2550000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_08-12-12\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 263.4835719378886\n",
      "  episode_reward_mean: 261.1507320633642\n",
      "  episode_reward_min: 257.1031868759991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1700\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -5.227822759100731\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03100848556470505\n",
      "          policy_loss: 0.010581724819370565\n",
      "          total_loss: 164.85452876801187\n",
      "          vf_explained_var: -5.326372676250912e-09\n",
      "          vf_loss: 164.83609763287484\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2550000\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2550000\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.918221574344024\n",
      "    ram_util_percent: 47.29912536443148\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08796936802773367\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330233169389402\n",
      "    mean_inference_ms: 1.8243395495132728\n",
      "    mean_raw_obs_processing_ms: 3.2052910058014517\n",
      "  time_since_restore: 40911.79370093346\n",
      "  time_this_iter_s: 480.4535126686096\n",
      "  time_total_s: 40911.79370093346\n",
      "  timers:\n",
      "    learn_throughput: 106.301\n",
      "    learn_time_ms: 282217.537\n",
      "    sample_throughput: 140.638\n",
      "    sample_time_ms: 213313.969\n",
      "    update_time_ms: 3.03\n",
      "  timestamp: 1662988332\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 85\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     85 |          40911.8 | 2550000 |  261.151 |              263.484 |              257.103 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2580000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_08-20-14\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 263.6196294769263\n",
      "  episode_reward_mean: 261.3651518105686\n",
      "  episode_reward_min: 257.1031868759991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1720\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.253125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -5.240658745461322\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0589528946015808\n",
      "          policy_loss: 0.01887529567795548\n",
      "          total_loss: 166.88270025375041\n",
      "          vf_explained_var: -7.355466791203469e-10\n",
      "          vf_loss: 166.84890278917678\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2580000\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2580000\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.920699708454812\n",
      "    ram_util_percent: 47.348833819241975\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0879701634107271\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3302197341441\n",
      "    mean_inference_ms: 1.8244328563266579\n",
      "    mean_raw_obs_processing_ms: 3.18112941803086\n",
      "  time_since_restore: 41393.0501935482\n",
      "  time_this_iter_s: 481.2564926147461\n",
      "  time_total_s: 41393.0501935482\n",
      "  timers:\n",
      "    learn_throughput: 109.12\n",
      "    learn_time_ms: 274925.858\n",
      "    sample_throughput: 140.638\n",
      "    sample_time_ms: 213313.074\n",
      "    update_time_ms: 3.021\n",
      "  timestamp: 1662988814\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 86\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     86 |          41393.1 | 2580000 |  261.365 |               263.62 |              257.103 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2610000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_08-28-15\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 299.049574796081\n",
      "  episode_reward_mean: 264.28338606593826\n",
      "  episode_reward_min: 260.2527615397335\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1740\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -5.054369010925293\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03185074002427515\n",
      "          policy_loss: 0.005179348562626128\n",
      "          total_loss: 169.1580393754675\n",
      "          vf_explained_var: -4.1342795853438474e-09\n",
      "          vf_loss: 169.14076641326255\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2610000\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2610000\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.914410480349346\n",
      "    ram_util_percent: 47.722707423580786\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797004497856814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330194063284736\n",
      "    mean_inference_ms: 1.82447317513037\n",
      "    mean_raw_obs_processing_ms: 3.157527954947349\n",
      "  time_since_restore: 41874.40160751343\n",
      "  time_this_iter_s: 481.3514139652252\n",
      "  time_total_s: 41874.40160751343\n",
      "  timers:\n",
      "    learn_throughput: 112.092\n",
      "    learn_time_ms: 267636.378\n",
      "    sample_throughput: 140.657\n",
      "    sample_time_ms: 213284.547\n",
      "    update_time_ms: 3.003\n",
      "  timestamp: 1662989295\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 87\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     87 |          41874.4 | 2610000 |  264.283 |               299.05 |              260.253 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2640000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_08-36-16\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 299.049574796081\n",
      "  episode_reward_mean: 268.3382046040692\n",
      "  episode_reward_min: 260.42539796661106\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1760\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.932898827410759\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029564506216346334\n",
      "          policy_loss: 0.009884168800917711\n",
      "          total_loss: 169.5773714885306\n",
      "          vf_explained_var: 7.609103624961477e-11\n",
      "          vf_loss: 169.5562624148105\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2640000\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2640000\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.992285298398837\n",
      "    ram_util_percent: 47.53377001455604\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0879696599068522\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33013107894013\n",
      "    mean_inference_ms: 1.8245211536745785\n",
      "    mean_raw_obs_processing_ms: 3.1344772599413955\n",
      "  time_since_restore: 42355.45267081261\n",
      "  time_this_iter_s: 481.0510632991791\n",
      "  time_total_s: 42355.45267081261\n",
      "  timers:\n",
      "    learn_throughput: 112.109\n",
      "    learn_time_ms: 267595.988\n",
      "    sample_throughput: 140.667\n",
      "    sample_time_ms: 213269.253\n",
      "    update_time_ms: 2.972\n",
      "  timestamp: 1662989776\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 88\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     88 |          42355.5 | 2640000 |  268.338 |               299.05 |              260.425 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2670000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_08-44-19\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 302.4982695895852\n",
      "  episode_reward_mean: 275.18828637856257\n",
      "  episode_reward_min: 261.25435971426094\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1780\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.800488886934645\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028887397662062886\n",
      "          policy_loss: 0.011887217548259712\n",
      "          total_loss: 170.6381535972433\n",
      "          vf_explained_var: -1.0145471129874295e-09\n",
      "          vf_loss: 170.6152983872434\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2670000\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2670000\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.930914368650217\n",
      "    ram_util_percent: 47.24020319303338\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08796976851838637\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33005585922278\n",
      "    mean_inference_ms: 1.8245571242962968\n",
      "    mean_raw_obs_processing_ms: 3.1119577770095463\n",
      "  time_since_restore: 42838.57715964317\n",
      "  time_this_iter_s: 483.1244888305664\n",
      "  time_total_s: 42838.57715964317\n",
      "  timers:\n",
      "    learn_throughput: 111.999\n",
      "    learn_time_ms: 267858.819\n",
      "    sample_throughput: 140.659\n",
      "    sample_time_ms: 213281.12\n",
      "    update_time_ms: 2.957\n",
      "  timestamp: 1662990259\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 89\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     89 |          42838.6 | 2670000 |  275.188 |              302.498 |              261.254 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2700000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_08-52-23\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 302.4982695895852\n",
      "  episode_reward_mean: 279.7951876266976\n",
      "  episode_reward_min: 262.50775446339185\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1800\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.828233736525191\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027866441770630305\n",
      "          policy_loss: 0.008867585098512095\n",
      "          total_loss: 176.60920274450424\n",
      "          vf_explained_var: -1.775457558750304e-09\n",
      "          vf_loss: 176.58975454776845\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2700000\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2700000\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.92753623188406\n",
      "    ram_util_percent: 47.33971014492753\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797031014612781\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32999128998022\n",
      "    mean_inference_ms: 1.8245898481468408\n",
      "    mean_raw_obs_processing_ms: 3.089955909793391\n",
      "  time_since_restore: 43322.22019171715\n",
      "  time_this_iter_s: 483.6430320739746\n",
      "  time_total_s: 43322.22019171715\n",
      "  timers:\n",
      "    learn_throughput: 111.885\n",
      "    learn_time_ms: 268133.039\n",
      "    sample_throughput: 140.65\n",
      "    sample_time_ms: 213294.894\n",
      "    update_time_ms: 2.97\n",
      "  timestamp: 1662990743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 90\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     90 |          43322.2 | 2700000 |  279.795 |              302.498 |              262.508 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2730000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_09-00-27\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 302.4982695895852\n",
      "  episode_reward_mean: 286.0837886252241\n",
      "  episode_reward_min: 265.63565224521955\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1820\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.682659744709096\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02639859243048408\n",
      "          policy_loss: 0.010159720244440944\n",
      "          total_loss: 177.98949882507324\n",
      "          vf_explained_var: -2.2066399818498894e-09\n",
      "          vf_loss: 177.9693159630958\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2730000\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2730000\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.901304347826088\n",
      "    ram_util_percent: 47.45217391304348\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797184698129894\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32993528801836\n",
      "    mean_inference_ms: 1.8245730617112992\n",
      "    mean_raw_obs_processing_ms: 3.06843983888903\n",
      "  time_since_restore: 43806.01724290848\n",
      "  time_this_iter_s: 483.79705119132996\n",
      "  time_total_s: 43806.01724290848\n",
      "  timers:\n",
      "    learn_throughput: 111.749\n",
      "    learn_time_ms: 268458.138\n",
      "    sample_throughput: 140.647\n",
      "    sample_time_ms: 213299.496\n",
      "    update_time_ms: 2.968\n",
      "  timestamp: 1662991227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 91\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     91 |            43806 | 2730000 |  286.084 |              302.498 |              265.636 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2760000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_09-08-32\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 302.4982695895852\n",
      "  episode_reward_mean: 286.5551228946466\n",
      "  episode_reward_min: 269.98511577763963\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1840\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.856199950157328\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027935728861038928\n",
      "          policy_loss: 0.01181425059229096\n",
      "          total_loss: 183.55449330106694\n",
      "          vf_explained_var: -1.19209286886246e-09\n",
      "          vf_loss: 183.5320722214719\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2760000\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2760000\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.76965317919075\n",
      "    ram_util_percent: 47.408092485549126\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797322592067715\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329930609498188\n",
      "    mean_inference_ms: 1.8245360228277532\n",
      "    mean_raw_obs_processing_ms: 3.0473874247309714\n",
      "  time_since_restore: 44290.82352352142\n",
      "  time_this_iter_s: 484.80628061294556\n",
      "  time_total_s: 44290.82352352142\n",
      "  timers:\n",
      "    learn_throughput: 111.586\n",
      "    learn_time_ms: 268850.743\n",
      "    sample_throughput: 140.661\n",
      "    sample_time_ms: 213278.358\n",
      "    update_time_ms: 2.963\n",
      "  timestamp: 1662991712\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 92\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     92 |          44290.8 | 2760000 |  286.555 |              302.498 |              269.985 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2790000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_09-16-40\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 302.4982695895852\n",
      "  episode_reward_mean: 285.9713314887242\n",
      "  episode_reward_min: 269.98511577763963\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1860\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.808149173209007\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02357059464131082\n",
      "          policy_loss: 0.008543146051506096\n",
      "          total_loss: 183.40511648299847\n",
      "          vf_explained_var: -2.38418573772492e-09\n",
      "          vf_loss: 183.38762383643618\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2790000\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2790000\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.772988505747126\n",
      "    ram_util_percent: 47.45502873563218\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797344919401291\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32997904732572\n",
      "    mean_inference_ms: 1.8245005524227151\n",
      "    mean_raw_obs_processing_ms: 3.0268179506510164\n",
      "  time_since_restore: 44779.1066672802\n",
      "  time_this_iter_s: 488.2831437587738\n",
      "  time_total_s: 44779.1066672802\n",
      "  timers:\n",
      "    learn_throughput: 111.292\n",
      "    learn_time_ms: 269560.544\n",
      "    sample_throughput: 140.664\n",
      "    sample_time_ms: 213274.845\n",
      "    update_time_ms: 2.97\n",
      "  timestamp: 1662992200\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 93\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     93 |          44779.1 | 2790000 |  285.971 |              302.498 |              269.985 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2820000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_09-24-56\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 301.7944019846013\n",
      "  episode_reward_mean: 284.13252567419147\n",
      "  episode_reward_min: 269.98511577763963\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1880\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.722437861219365\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028248928053344342\n",
      "          policy_loss: 0.013008101598676691\n",
      "          total_loss: 189.79105794054396\n",
      "          vf_explained_var: -3.424096561843726e-09\n",
      "          vf_loss: 189.76732422199655\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2820000\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2820000\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.66916548797737\n",
      "    ram_util_percent: 47.866619519094776\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0879731345486476\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33000589882665\n",
      "    mean_inference_ms: 1.8244857560985241\n",
      "    mean_raw_obs_processing_ms: 3.0067079335285394\n",
      "  time_since_restore: 45274.4671087265\n",
      "  time_this_iter_s: 495.3604414463043\n",
      "  time_total_s: 45274.4671087265\n",
      "  timers:\n",
      "    learn_throughput: 110.687\n",
      "    learn_time_ms: 271034.037\n",
      "    sample_throughput: 140.672\n",
      "    sample_time_ms: 213262.271\n",
      "    update_time_ms: 2.977\n",
      "  timestamp: 1662992696\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 94\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     94 |          45274.5 | 2820000 |  284.133 |              301.794 |              269.985 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2850000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_09-33-21\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 301.7944019846013\n",
      "  episode_reward_mean: 284.56572875105354\n",
      "  episode_reward_min: 269.98511577763963\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1900\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.618744421613977\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025283115584096252\n",
      "          policy_loss: 0.011755280053599718\n",
      "          total_loss: 190.43477263754986\n",
      "          vf_explained_var: -2.6885498272122277e-09\n",
      "          vf_loss: 190.41341738437083\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2850000\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2850000\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.434903047091414\n",
      "    ram_util_percent: 48.013711911357355\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797241422275437\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3300013079564\n",
      "    mean_inference_ms: 1.82446431941291\n",
      "    mean_raw_obs_processing_ms: 2.9870547127144893\n",
      "  time_since_restore: 45780.13568329811\n",
      "  time_this_iter_s: 505.6685745716095\n",
      "  time_total_s: 45780.13568329811\n",
      "  timers:\n",
      "    learn_throughput: 109.664\n",
      "    learn_time_ms: 273562.758\n",
      "    sample_throughput: 140.677\n",
      "    sample_time_ms: 213255.031\n",
      "    update_time_ms: 2.975\n",
      "  timestamp: 1662993201\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 95\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     95 |          45780.1 | 2850000 |  284.566 |              301.794 |              269.985 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2880000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_09-42-03\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 292.2422399905683\n",
      "  episode_reward_mean: 281.46679323715085\n",
      "  episode_reward_min: 269.98511577763963\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1920\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.592733347466652\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023829407365002175\n",
      "          policy_loss: 0.009211918726424746\n",
      "          total_loss: 193.8219982471872\n",
      "          vf_explained_var: -2.967550427612764e-09\n",
      "          vf_loss: 193.8037382507324\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2880000\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2880000\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.269354838709678\n",
      "    ram_util_percent: 47.7994623655914\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.087970813972721\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32999628622031\n",
      "    mean_inference_ms: 1.824478214052747\n",
      "    mean_raw_obs_processing_ms: 2.967857893708331\n",
      "  time_since_restore: 46301.97132396698\n",
      "  time_this_iter_s: 521.835640668869\n",
      "  time_total_s: 46301.97132396698\n",
      "  timers:\n",
      "    learn_throughput: 108.067\n",
      "    learn_time_ms: 277605.279\n",
      "    sample_throughput: 140.666\n",
      "    sample_time_ms: 213270.526\n",
      "    update_time_ms: 2.995\n",
      "  timestamp: 1662993723\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 96\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     96 |            46302 | 2880000 |  281.467 |              292.242 |              269.985 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2910000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_09-51-01\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 292.2422399905683\n",
      "  episode_reward_mean: 280.39153815440756\n",
      "  episode_reward_min: 262.2406190060378\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1940\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.648418664932251\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02433025572602555\n",
      "          policy_loss: 0.013036266602773933\n",
      "          total_loss: 196.67241032864186\n",
      "          vf_explained_var: -1.2174565799938364e-09\n",
      "          vf_loss: 196.65013609378894\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2910000\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2910000\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.037809647979138\n",
      "    ram_util_percent: 47.94341590612777\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797044999275308\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329966838849504\n",
      "    mean_inference_ms: 1.8245162388195078\n",
      "    mean_raw_obs_processing_ms: 2.9490907281156784\n",
      "  time_since_restore: 46839.70763874054\n",
      "  time_this_iter_s: 537.7363147735596\n",
      "  time_total_s: 46839.70763874054\n",
      "  timers:\n",
      "    learn_throughput: 105.926\n",
      "    learn_time_ms: 283216.103\n",
      "    sample_throughput: 140.648\n",
      "    sample_time_ms: 213298.182\n",
      "    update_time_ms: 2.997\n",
      "  timestamp: 1662994261\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 97\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     97 |          46839.7 | 2910000 |  280.392 |              292.242 |              262.241 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2940000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_10-00-04\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 292.2422399905683\n",
      "  episode_reward_mean: 279.2552327565166\n",
      "  episode_reward_min: 262.2406190060378\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1960\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.624580549483603\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024118546762830755\n",
      "          policy_loss: 0.013244553473654223\n",
      "          total_loss: 200.23768041732464\n",
      "          vf_explained_var: -1.1667292687533859e-09\n",
      "          vf_loss: 200.21527859626931\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2940000\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2940000\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.872903225806452\n",
      "    ram_util_percent: 48.02322580645161\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797140094893768\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329896850843205\n",
      "    mean_inference_ms: 1.8245163734519112\n",
      "    mean_raw_obs_processing_ms: 2.9306995317895046\n",
      "  time_since_restore: 47382.40748786926\n",
      "  time_this_iter_s: 542.6998491287231\n",
      "  time_total_s: 47382.40748786926\n",
      "  timers:\n",
      "    learn_throughput: 103.674\n",
      "    learn_time_ms: 289368.534\n",
      "    sample_throughput: 140.64\n",
      "    sample_time_ms: 213310.643\n",
      "    update_time_ms: 2.997\n",
      "  timestamp: 1662994804\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 98\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     98 |          47382.4 | 2940000 |  279.255 |              292.242 |              262.241 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 2970000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_10-09-09\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 292.2422399905683\n",
      "  episode_reward_mean: 277.89412350245067\n",
      "  episode_reward_min: 262.2406190060378\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1980\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.484812051488998\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023353659645580182\n",
      "          policy_loss: 0.014443044944448357\n",
      "          total_loss: 199.75387815759538\n",
      "          vf_explained_var: -4.058188451949718e-09\n",
      "          vf_loss: 199.73056755228245\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 2970000\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2970000\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.877091377091377\n",
      "    ram_util_percent: 48.131274131274125\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797315120692394\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329860776031836\n",
      "    mean_inference_ms: 1.82453192515155\n",
      "    mean_raw_obs_processing_ms: 2.9126588282638566\n",
      "  time_since_restore: 47927.49985432625\n",
      "  time_this_iter_s: 545.0923664569855\n",
      "  time_total_s: 47927.49985432625\n",
      "  timers:\n",
      "    learn_throughput: 101.503\n",
      "    learn_time_ms: 295557.792\n",
      "    sample_throughput: 140.635\n",
      "    sample_time_ms: 213318.196\n",
      "    update_time_ms: 3.031\n",
      "  timestamp: 1662995349\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 99\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |     99 |          47927.5 | 2970000 |  277.894 |              292.242 |              262.241 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3000000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_10-17-51\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 325.9319962858993\n",
      "  episode_reward_mean: 283.94270668799\n",
      "  episode_reward_min: 262.2406190060378\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2000\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.341563113801023\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0210949510600954\n",
      "          policy_loss: 0.015915159985343826\n",
      "          total_loss: 192.28909480642764\n",
      "          vf_explained_var: -1.8261848699907546e-09\n",
      "          vf_loss: 192.26517053157724\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3000000\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 3000000\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.246308724832215\n",
      "    ram_util_percent: 48.035033557046965\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797502774615013\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329898606086267\n",
      "    mean_inference_ms: 1.824529989387812\n",
      "    mean_raw_obs_processing_ms: 2.8949890523794157\n",
      "  time_since_restore: 48449.55561184883\n",
      "  time_this_iter_s: 522.055757522583\n",
      "  time_total_s: 48449.55561184883\n",
      "  timers:\n",
      "    learn_throughput: 100.204\n",
      "    learn_time_ms: 299388.961\n",
      "    sample_throughput: 140.628\n",
      "    sample_time_ms: 213328.443\n",
      "    update_time_ms: 3.021\n",
      "  timestamp: 1662995871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 100\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    100 |          48449.6 | 3000000 |  283.943 |              325.932 |              262.241 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3030000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_10-25-56\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 375.20814000867335\n",
      "  episode_reward_mean: 301.13312422539013\n",
      "  episode_reward_min: 262.2406190060378\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2020\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.094366987613921\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016456921509878444\n",
      "          policy_loss: 0.012081563712711981\n",
      "          total_loss: 187.88662819882657\n",
      "          vf_explained_var: -1.1667292687533859e-09\n",
      "          vf_loss: 187.8682980379145\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3030000\n",
      "    num_steps_sampled: 3030000\n",
      "    num_steps_trained: 3030000\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.87684515195369\n",
      "    ram_util_percent: 47.85397973950795\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08797795358450525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330011119118343\n",
      "    mean_inference_ms: 1.8244762661985607\n",
      "    mean_raw_obs_processing_ms: 2.8776666943515865\n",
      "  time_since_restore: 48933.93314695358\n",
      "  time_this_iter_s: 484.3775351047516\n",
      "  time_total_s: 48933.93314695358\n",
      "  timers:\n",
      "    learn_throughput: 100.192\n",
      "    learn_time_ms: 299424.385\n",
      "    sample_throughput: 140.613\n",
      "    sample_time_ms: 213350.995\n",
      "    update_time_ms: 3.007\n",
      "  timestamp: 1662996356\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3030000\n",
      "  training_iteration: 101\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    101 |          48933.9 | 3030000 |  301.133 |              375.208 |              262.241 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3060000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_10-34-00\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 375.20814000867335\n",
      "  episode_reward_mean: 317.3392259002203\n",
      "  episode_reward_min: 267.2956578304676\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2040\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.121302079951509\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020168927008152586\n",
      "          policy_loss: 0.01421510815977099\n",
      "          total_loss: 193.16813406437\n",
      "          vf_explained_var: 0.0\n",
      "          vf_loss: 193.14626091652727\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3060000\n",
      "    num_steps_sampled: 3060000\n",
      "    num_steps_trained: 3060000\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.93024602026049\n",
      "    ram_util_percent: 47.96078147612157\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08798022978155831\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3301228024885\n",
      "    mean_inference_ms: 1.8244412799271081\n",
      "    mean_raw_obs_processing_ms: 2.860676278133991\n",
      "  time_since_restore: 49418.46345281601\n",
      "  time_this_iter_s: 484.53030586242676\n",
      "  time_total_s: 49418.46345281601\n",
      "  timers:\n",
      "    learn_throughput: 100.204\n",
      "    learn_time_ms: 299390.166\n",
      "    sample_throughput: 140.609\n",
      "    sample_time_ms: 213357.629\n",
      "    update_time_ms: 3.055\n",
      "  timestamp: 1662996840\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3060000\n",
      "  training_iteration: 102\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    102 |          49418.5 | 3060000 |  317.339 |              375.208 |              267.296 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3090000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_10-42-05\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 375.20814000867335\n",
      "  episode_reward_mean: 330.92076878876765\n",
      "  episode_reward_min: 274.16414562019673\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2060\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.070984096932919\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018479015006203428\n",
      "          policy_loss: 0.014618943430225741\n",
      "          total_loss: 200.11109115275931\n",
      "          vf_explained_var: -2.866095583087258e-09\n",
      "          vf_loss: 200.08945580340446\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3090000\n",
      "    num_steps_sampled: 3090000\n",
      "    num_steps_trained: 3090000\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.864161849710985\n",
      "    ram_util_percent: 48.026300578034686\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08798262495172068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33021510752816\n",
      "    mean_inference_ms: 1.8244359658159561\n",
      "    mean_raw_obs_processing_ms: 2.843994007161174\n",
      "  time_since_restore: 49903.00657296181\n",
      "  time_this_iter_s: 484.54312014579773\n",
      "  time_total_s: 49903.00657296181\n",
      "  timers:\n",
      "    learn_throughput: 100.319\n",
      "    learn_time_ms: 299044.95\n",
      "    sample_throughput: 140.628\n",
      "    sample_time_ms: 213328.877\n",
      "    update_time_ms: 3.04\n",
      "  timestamp: 1662997325\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3090000\n",
      "  training_iteration: 103\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    103 |            49903 | 3090000 |  330.921 |              375.208 |              274.164 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3120000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_10-50-08\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 375.20814000867335\n",
      "  episode_reward_mean: 343.9585845087164\n",
      "  episode_reward_min: 283.3269544064753\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2080\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.020159309366916\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019044766121177486\n",
      "          policy_loss: 0.015209169710213516\n",
      "          total_loss: 203.6782284708226\n",
      "          vf_explained_var: -9.130924349953773e-10\n",
      "          vf_loss: 203.6557876067466\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3120000\n",
      "    num_steps_sampled: 3120000\n",
      "    num_steps_trained: 3120000\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.984202898550723\n",
      "    ram_util_percent: 48.028550724637675\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08798564405803816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330233886998784\n",
      "    mean_inference_ms: 1.8244483126579336\n",
      "    mean_raw_obs_processing_ms: 2.8276561229322756\n",
      "  time_since_restore: 50386.40586447716\n",
      "  time_this_iter_s: 483.39929151535034\n",
      "  time_total_s: 50386.40586447716\n",
      "  timers:\n",
      "    learn_throughput: 100.719\n",
      "    learn_time_ms: 297859.447\n",
      "    sample_throughput: 140.635\n",
      "    sample_time_ms: 213318.289\n",
      "    update_time_ms: 3.028\n",
      "  timestamp: 1662997808\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3120000\n",
      "  training_iteration: 104\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    104 |          50386.4 | 3120000 |  343.959 |              375.208 |              283.327 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3150000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_10-58-12\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 375.20814000867335\n",
      "  episode_reward_mean: 351.5891344441103\n",
      "  episode_reward_min: 308.95413289197495\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2100\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.904048620995055\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016270523800767506\n",
      "          policy_loss: 0.01287714520905246\n",
      "          total_loss: 203.2339161941853\n",
      "          vf_explained_var: -2.713913538343604e-09\n",
      "          vf_loss: 203.21486122293675\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3150000\n",
      "    num_steps_sampled: 3150000\n",
      "    num_steps_trained: 3150000\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.867246376811597\n",
      "    ram_util_percent: 48.10536231884058\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08798905460019167\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330209624202322\n",
      "    mean_inference_ms: 1.8245194550665096\n",
      "    mean_raw_obs_processing_ms: 2.8116147424123428\n",
      "  time_since_restore: 50870.497594833374\n",
      "  time_this_iter_s: 484.09173035621643\n",
      "  time_total_s: 50870.497594833374\n",
      "  timers:\n",
      "    learn_throughput: 101.458\n",
      "    learn_time_ms: 295689.13\n",
      "    sample_throughput: 140.627\n",
      "    sample_time_ms: 213330.882\n",
      "    update_time_ms: 3.023\n",
      "  timestamp: 1662998292\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3150000\n",
      "  training_iteration: 105\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    105 |          50870.5 | 3150000 |  351.589 |              375.208 |              308.954 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3180000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_11-06-17\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 402.9445428176635\n",
      "  episode_reward_mean: 355.41411062343207\n",
      "  episode_reward_min: 328.1845733591463\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2120\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.840304903679706\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01618137423063036\n",
      "          policy_loss: 0.011384369486625842\n",
      "          total_loss: 202.0592420082904\n",
      "          vf_explained_var: -1.4203660470002433e-09\n",
      "          vf_loss: 202.041713787647\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3180000\n",
      "    num_steps_sampled: 3180000\n",
      "    num_steps_trained: 3180000\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.83371924746744\n",
      "    ram_util_percent: 48.18740955137482\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08799277197523982\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33015808880876\n",
      "    mean_inference_ms: 1.8246111527829312\n",
      "    mean_raw_obs_processing_ms: 2.795864640555024\n",
      "  time_since_restore: 51354.99520254135\n",
      "  time_this_iter_s: 484.4976077079773\n",
      "  time_total_s: 51354.99520254135\n",
      "  timers:\n",
      "    learn_throughput: 102.754\n",
      "    learn_time_ms: 291960.083\n",
      "    sample_throughput: 140.63\n",
      "    sample_time_ms: 213326.13\n",
      "    update_time_ms: 3.009\n",
      "  timestamp: 1662998777\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3180000\n",
      "  training_iteration: 106\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    106 |            51355 | 3180000 |  355.414 |              402.945 |              328.185 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3210000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_11-14-18\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 441.6188864520022\n",
      "  episode_reward_mean: 370.88483416668925\n",
      "  episode_reward_min: 328.1845733591463\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2140\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.845024308143778\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018886622700820522\n",
      "          policy_loss: 0.009921910071032162\n",
      "          total_loss: 200.05178129317912\n",
      "          vf_explained_var: -4.058188451949718e-09\n",
      "          vf_loss: 200.03468829540495\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3210000\n",
      "    num_steps_sampled: 3210000\n",
      "    num_steps_trained: 3210000\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.935225618631733\n",
      "    ram_util_percent: 48.15866084425036\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0879972398284201\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.330043475033893\n",
      "    mean_inference_ms: 1.8247457728807541\n",
      "    mean_raw_obs_processing_ms: 2.780394780472587\n",
      "  time_since_restore: 51836.057232141495\n",
      "  time_this_iter_s: 481.06202960014343\n",
      "  time_total_s: 51836.057232141495\n",
      "  timers:\n",
      "    learn_throughput: 104.778\n",
      "    learn_time_ms: 286320.531\n",
      "    sample_throughput: 140.648\n",
      "    sample_time_ms: 213298.26\n",
      "    update_time_ms: 3.004\n",
      "  timestamp: 1662999258\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3210000\n",
      "  training_iteration: 107\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    107 |          51836.1 | 3210000 |  370.885 |              441.619 |              328.185 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3240000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_11-22-22\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 441.6188864520022\n",
      "  episode_reward_mean: 386.94784596949955\n",
      "  episode_reward_min: 330.1525525914227\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2160\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.835491282787729\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016238394401908184\n",
      "          policy_loss: 0.012488882088280738\n",
      "          total_loss: 206.9695465656037\n",
      "          vf_explained_var: -2.2066399818498894e-09\n",
      "          vf_loss: 206.95089161974317\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3240000\n",
      "    num_steps_sampled: 3240000\n",
      "    num_steps_trained: 3240000\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.85855072463768\n",
      "    ram_util_percent: 48.266376811594206\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08800062998094844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32995886261856\n",
      "    mean_inference_ms: 1.8248663106112217\n",
      "    mean_raw_obs_processing_ms: 2.7652429146110076\n",
      "  time_since_restore: 52319.806718826294\n",
      "  time_this_iter_s: 483.7494866847992\n",
      "  time_total_s: 52319.806718826294\n",
      "  timers:\n",
      "    learn_throughput: 106.982\n",
      "    learn_time_ms: 280419.855\n",
      "    sample_throughput: 140.644\n",
      "    sample_time_ms: 213303.898\n",
      "    update_time_ms: 3.013\n",
      "  timestamp: 1662999742\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3240000\n",
      "  training_iteration: 108\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    108 |          52319.8 | 3240000 |  386.948 |              441.619 |              330.153 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3270000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_11-30-26\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 441.6188864520022\n",
      "  episode_reward_mean: 402.5592462761748\n",
      "  episode_reward_min: 341.2757528729327\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2180\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8880518151344137\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016441125305910975\n",
      "          policy_loss: 0.013264124744393407\n",
      "          total_loss: 214.2054284586805\n",
      "          vf_explained_var: -1.0906381353592565e-09\n",
      "          vf_loss: 214.18592161624989\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3270000\n",
      "    num_steps_sampled: 3270000\n",
      "    num_steps_trained: 3270000\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.916521739130435\n",
      "    ram_util_percent: 48.28057971014493\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880036423565147\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329875410440927\n",
      "    mean_inference_ms: 1.824975065195917\n",
      "    mean_raw_obs_processing_ms: 2.7503835656540194\n",
      "  time_since_restore: 52803.39180016518\n",
      "  time_this_iter_s: 483.58508133888245\n",
      "  time_total_s: 52803.39180016518\n",
      "  timers:\n",
      "    learn_throughput: 109.38\n",
      "    learn_time_ms: 274272.137\n",
      "    sample_throughput: 140.646\n",
      "    sample_time_ms: 213301.017\n",
      "    update_time_ms: 2.958\n",
      "  timestamp: 1663000226\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3270000\n",
      "  training_iteration: 109\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    109 |          52803.4 | 3270000 |  402.559 |              441.619 |              341.276 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3300000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_11-38-29\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 455.21296576762836\n",
      "  episode_reward_mean: 419.79855235809833\n",
      "  episode_reward_min: 356.314251112648\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2200\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9007308925466333\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01672004189461159\n",
      "          policy_loss: 0.013943048154915426\n",
      "          total_loss: 215.4850948349973\n",
      "          vf_explained_var: -2.4349131599876728e-09\n",
      "          vf_loss: 215.46480294734874\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3300000\n",
      "    num_steps_sampled: 3300000\n",
      "    num_steps_trained: 3300000\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.887953555878084\n",
      "    ram_util_percent: 48.31393323657474\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08800581004218634\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329838783395857\n",
      "    mean_inference_ms: 1.8250067661750433\n",
      "    mean_raw_obs_processing_ms: 2.7357990469906825\n",
      "  time_since_restore: 53286.710572719574\n",
      "  time_this_iter_s: 483.3187725543976\n",
      "  time_total_s: 53286.710572719574\n",
      "  timers:\n",
      "    learn_throughput: 110.942\n",
      "    learn_time_ms: 270411.578\n",
      "    sample_throughput: 140.655\n",
      "    sample_time_ms: 213287.852\n",
      "    update_time_ms: 2.958\n",
      "  timestamp: 1663000709\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3300000\n",
      "  training_iteration: 110\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    110 |          53286.7 | 3300000 |  419.799 |              455.213 |              356.314 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3330000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_11-46-32\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 455.21296576762836\n",
      "  episode_reward_mean: 427.3769194491986\n",
      "  episode_reward_min: 399.53699548369855\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2220\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8856776473877277\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0167398926809783\n",
      "          policy_loss: 0.013598462554893675\n",
      "          total_loss: 226.55980562899975\n",
      "          vf_explained_var: -1.4203660470002433e-09\n",
      "          vf_loss: 226.5398522202512\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3330000\n",
      "    num_steps_sampled: 3330000\n",
      "    num_steps_trained: 3330000\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.901594202898547\n",
      "    ram_util_percent: 48.347101449275364\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08800773822521311\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329750163911832\n",
      "    mean_inference_ms: 1.8250629807427083\n",
      "    mean_raw_obs_processing_ms: 2.721496091109275\n",
      "  time_since_restore: 53769.79488325119\n",
      "  time_this_iter_s: 483.0843105316162\n",
      "  time_total_s: 53769.79488325119\n",
      "  timers:\n",
      "    learn_throughput: 110.991\n",
      "    learn_time_ms: 270291.643\n",
      "    sample_throughput: 140.661\n",
      "    sample_time_ms: 213278.56\n",
      "    update_time_ms: 2.975\n",
      "  timestamp: 1663001192\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3330000\n",
      "  training_iteration: 111\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    111 |          53769.8 | 3330000 |  427.377 |              455.213 |              399.537 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3360000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_11-54-36\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 455.21296576762836\n",
      "  episode_reward_mean: 423.4372417279476\n",
      "  episode_reward_min: 392.14764044175786\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2240\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8086559872931622\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021763320850862453\n",
      "          policy_loss: 0.008013958649987236\n",
      "          total_loss: 234.38707625531137\n",
      "          vf_explained_var: -3.069005050093665e-09\n",
      "          vf_loss: 234.370798659629\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3360000\n",
      "    num_steps_sampled: 3360000\n",
      "    num_steps_trained: 3360000\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.891014492753623\n",
      "    ram_util_percent: 48.45246376811595\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08800970623064684\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329718652576183\n",
      "    mean_inference_ms: 1.8250806209895465\n",
      "    mean_raw_obs_processing_ms: 2.7074779745530773\n",
      "  time_since_restore: 54253.67862153053\n",
      "  time_this_iter_s: 483.88373827934265\n",
      "  time_total_s: 54253.67862153053\n",
      "  timers:\n",
      "    learn_throughput: 111.019\n",
      "    learn_time_ms: 270225.01\n",
      "    sample_throughput: 140.66\n",
      "    sample_time_ms: 213280.533\n",
      "    update_time_ms: 2.926\n",
      "  timestamp: 1663001676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3360000\n",
      "  training_iteration: 112\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 14.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    112 |          54253.7 | 3360000 |  423.437 |              455.213 |              392.148 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3390000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_12-02-40\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 455.21296576762836\n",
      "  episode_reward_mean: 423.76307726490865\n",
      "  episode_reward_min: 392.14764044175786\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2260\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8044212953080523\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01756666723153306\n",
      "          policy_loss: 0.01194635302125615\n",
      "          total_loss: 237.5565095422623\n",
      "          vf_explained_var: -2.5870952047313267e-09\n",
      "          vf_loss: 237.53789346248544\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3390000\n",
      "    num_steps_sampled: 3390000\n",
      "    num_steps_trained: 3390000\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.830535455861074\n",
      "    ram_util_percent: 48.48350217076701\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08801189889076838\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329693304451848\n",
      "    mean_inference_ms: 1.82509493407637\n",
      "    mean_raw_obs_processing_ms: 2.69371342358522\n",
      "  time_since_restore: 54737.7349820137\n",
      "  time_this_iter_s: 484.05636048316956\n",
      "  time_total_s: 54737.7349820137\n",
      "  timers:\n",
      "    learn_throughput: 111.048\n",
      "    learn_time_ms: 270153.733\n",
      "    sample_throughput: 140.645\n",
      "    sample_time_ms: 213303.227\n",
      "    update_time_ms: 2.927\n",
      "  timestamp: 1663002160\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3390000\n",
      "  training_iteration: 113\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    113 |          54737.7 | 3390000 |  423.763 |              455.213 |              392.148 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3420000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_12-10-44\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 455.21296576762836\n",
      "  episode_reward_mean: 426.8124799310449\n",
      "  episode_reward_min: 392.14764044175786\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2280\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8210173156413627\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019185541898781373\n",
      "          policy_loss: 0.011031439617236561\n",
      "          total_loss: 240.05025447277313\n",
      "          vf_explained_var: -1.3189113134970398e-09\n",
      "          vf_loss: 240.03193847169268\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3420000\n",
      "    num_steps_sampled: 3420000\n",
      "    num_steps_trained: 3420000\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.872898550724635\n",
      "    ram_util_percent: 48.54304347826088\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08801306370311814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3296881850956\n",
      "    mean_inference_ms: 1.8251220279536693\n",
      "    mean_raw_obs_processing_ms: 2.6801898081519284\n",
      "  time_since_restore: 55221.57110929489\n",
      "  time_this_iter_s: 483.83612728118896\n",
      "  time_total_s: 55221.57110929489\n",
      "  timers:\n",
      "    learn_throughput: 111.038\n",
      "    learn_time_ms: 270178.944\n",
      "    sample_throughput: 140.633\n",
      "    sample_time_ms: 213321.573\n",
      "    update_time_ms: 2.972\n",
      "  timestamp: 1663002644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3420000\n",
      "  training_iteration: 114\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    114 |          55221.6 | 3420000 |  426.812 |              455.213 |              392.148 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3450000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_12-18-49\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 446.7319969224851\n",
      "  episode_reward_mean: 421.93405570196416\n",
      "  episode_reward_min: 392.14764044175786\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2300\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8871609875496396\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01916724295860684\n",
      "          policy_loss: 0.013659712259974727\n",
      "          total_loss: 249.15015961180342\n",
      "          vf_explained_var: -2.4349131599876728e-09\n",
      "          vf_loss: 249.12922165241648\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3450000\n",
      "    num_steps_sampled: 3450000\n",
      "    num_steps_trained: 3450000\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.859623733719246\n",
      "    ram_util_percent: 48.55340086830682\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08801455026039007\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329644006459716\n",
      "    mean_inference_ms: 1.8251944013652375\n",
      "    mean_raw_obs_processing_ms: 2.666910509934823\n",
      "  time_since_restore: 55705.9333987236\n",
      "  time_this_iter_s: 484.36228942871094\n",
      "  time_total_s: 55705.9333987236\n",
      "  timers:\n",
      "    learn_throughput: 111.026\n",
      "    learn_time_ms: 270206.3\n",
      "    sample_throughput: 140.633\n",
      "    sample_time_ms: 213321.15\n",
      "    update_time_ms: 2.963\n",
      "  timestamp: 1663003129\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3450000\n",
      "  training_iteration: 115\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    115 |          55705.9 | 3450000 |  421.934 |              446.732 |              392.148 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3480000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_12-26-53\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 446.7319969224851\n",
      "  episode_reward_mean: 417.29009548616176\n",
      "  episode_reward_min: 386.12312415755895\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2320\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8928192596232636\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021275852089103892\n",
      "          policy_loss: 0.014692394729267727\n",
      "          total_loss: 255.0111891141851\n",
      "          vf_explained_var: -2.6885498272122277e-09\n",
      "          vf_loss: 254.98841814893356\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3480000\n",
      "    num_steps_sampled: 3480000\n",
      "    num_steps_trained: 3480000\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.880897250361794\n",
      "    ram_util_percent: 48.62503617945006\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08801546332873914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329645597716617\n",
      "    mean_inference_ms: 1.8252437949587192\n",
      "    mean_raw_obs_processing_ms: 2.6538494619538415\n",
      "  time_since_restore: 56190.30755662918\n",
      "  time_this_iter_s: 484.3741579055786\n",
      "  time_total_s: 56190.30755662918\n",
      "  timers:\n",
      "    learn_throughput: 111.031\n",
      "    learn_time_ms: 270194.136\n",
      "    sample_throughput: 140.633\n",
      "    sample_time_ms: 213320.964\n",
      "    update_time_ms: 2.969\n",
      "  timestamp: 1663003613\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3480000\n",
      "  training_iteration: 116\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 14.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    116 |          56190.3 | 3480000 |   417.29 |              446.732 |              386.123 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3510000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_12-34-58\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 446.7319969224851\n",
      "  episode_reward_mean: 418.30852305325857\n",
      "  episode_reward_min: 386.12312415755895\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2340\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.821316075730831\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019189574930078904\n",
      "          policy_loss: 0.015611289866625312\n",
      "          total_loss: 258.03150912183395\n",
      "          vf_explained_var: -3.221187094837319e-09\n",
      "          vf_loss: 258.0086117342685\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3510000\n",
      "    num_steps_sampled: 3510000\n",
      "    num_steps_trained: 3510000\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.949132947976878\n",
      "    ram_util_percent: 49.02471098265896\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.088016844572355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329622542405943\n",
      "    mean_inference_ms: 1.8253204659879991\n",
      "    mean_raw_obs_processing_ms: 2.6410450141727106\n",
      "  time_since_restore: 56675.37699699402\n",
      "  time_this_iter_s: 485.06944036483765\n",
      "  time_total_s: 56675.37699699402\n",
      "  timers:\n",
      "    learn_throughput: 110.884\n",
      "    learn_time_ms: 270553.495\n",
      "    sample_throughput: 140.606\n",
      "    sample_time_ms: 213362.329\n",
      "    update_time_ms: 2.986\n",
      "  timestamp: 1663004098\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3510000\n",
      "  training_iteration: 117\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    117 |          56675.4 | 3510000 |  418.309 |              446.732 |              386.123 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3540000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_12-43-04\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 446.7319969224851\n",
      "  episode_reward_mean: 415.77340841955726\n",
      "  episode_reward_min: 386.12312415755895\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2360\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8823129886261962\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02002945277042343\n",
      "          policy_loss: 0.016792645733010897\n",
      "          total_loss: 262.81453919431\n",
      "          vf_explained_var: -3.8806429181192925e-09\n",
      "          vf_loss: 262.79014268266394\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3540000\n",
      "    num_steps_sampled: 3540000\n",
      "    num_steps_trained: 3540000\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.82900432900433\n",
      "    ram_util_percent: 49.06464646464647\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08801914961199703\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32960816419601\n",
      "    mean_inference_ms: 1.8253547733383828\n",
      "    mean_raw_obs_processing_ms: 2.628440832448858\n",
      "  time_since_restore: 57160.68887209892\n",
      "  time_this_iter_s: 485.3118751049042\n",
      "  time_total_s: 57160.68887209892\n",
      "  timers:\n",
      "    learn_throughput: 110.81\n",
      "    learn_time_ms: 270734.818\n",
      "    sample_throughput: 140.622\n",
      "    sample_time_ms: 213337.233\n",
      "    update_time_ms: 2.995\n",
      "  timestamp: 1663004584\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3540000\n",
      "  training_iteration: 118\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    118 |          57160.7 | 3540000 |  415.773 |              446.732 |              386.123 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3570000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_12-51-10\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 434.98052779777635\n",
      "  episode_reward_mean: 405.15981604102126\n",
      "  episode_reward_min: 370.4054138065082\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2380\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.924828207543556\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021729031363378403\n",
      "          policy_loss: 0.016374363304175278\n",
      "          total_loss: 272.6939657154489\n",
      "          vf_explained_var: -1.6740028252471006e-09\n",
      "          vf_loss: 272.6693415459166\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3570000\n",
      "    num_steps_sampled: 3570000\n",
      "    num_steps_trained: 3570000\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.902881844380403\n",
      "    ram_util_percent: 49.14913544668587\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08802212631798564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329548072874587\n",
      "    mean_inference_ms: 1.825406059762963\n",
      "    mean_raw_obs_processing_ms: 2.6160667218738105\n",
      "  time_since_restore: 57646.96328473091\n",
      "  time_this_iter_s: 486.2744126319885\n",
      "  time_total_s: 57646.96328473091\n",
      "  timers:\n",
      "    learn_throughput: 110.696\n",
      "    learn_time_ms: 271012.663\n",
      "    sample_throughput: 140.628\n",
      "    sample_time_ms: 213328.196\n",
      "    update_time_ms: 3.021\n",
      "  timestamp: 1663005070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3570000\n",
      "  training_iteration: 119\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    119 |            57647 | 3570000 |   405.16 |              434.981 |              370.405 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3600000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_12-59-17\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 429.36374458416003\n",
      "  episode_reward_mean: 398.69322953797797\n",
      "  episode_reward_min: 363.9510582004264\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2400\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.889036651367837\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02256982976825864\n",
      "          policy_loss: 0.01507653177777761\n",
      "          total_loss: 275.54465892710584\n",
      "          vf_explained_var: -2.5617314935999502e-09\n",
      "          vf_loss: 275.52101245636635\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3600000\n",
      "    num_steps_sampled: 3600000\n",
      "    num_steps_trained: 3600000\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.805323741007193\n",
      "    ram_util_percent: 49.20690647482014\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08802558946042162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329461243478363\n",
      "    mean_inference_ms: 1.8254658679747735\n",
      "    mean_raw_obs_processing_ms: 2.603929893693942\n",
      "  time_since_restore: 58133.94601535797\n",
      "  time_this_iter_s: 486.98273062705994\n",
      "  time_total_s: 58133.94601535797\n",
      "  timers:\n",
      "    learn_throughput: 110.544\n",
      "    learn_time_ms: 271384.943\n",
      "    sample_throughput: 140.632\n",
      "    sample_time_ms: 213322.202\n",
      "    update_time_ms: 3.033\n",
      "  timestamp: 1663005557\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3600000\n",
      "  training_iteration: 120\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    120 |          58133.9 | 3600000 |  398.693 |              429.364 |              363.951 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3630000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_13-07-26\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 429.36374458416003\n",
      "  episode_reward_mean: 398.7782645869287\n",
      "  episode_reward_min: 363.9510582004264\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2420\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.913370873471524\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0197462072104534\n",
      "          policy_loss: 0.015257603798675886\n",
      "          total_loss: 274.5314365565523\n",
      "          vf_explained_var: -2.8407320940004865e-09\n",
      "          vf_loss: 274.50868140687334\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3630000\n",
      "    num_steps_sampled: 3630000\n",
      "    num_steps_trained: 3630000\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.753295128939826\n",
      "    ram_util_percent: 49.23495702005731\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880294589738058\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329356943294496\n",
      "    mean_inference_ms: 1.825525277491118\n",
      "    mean_raw_obs_processing_ms: 2.5920353857900746\n",
      "  time_since_restore: 58623.14954042435\n",
      "  time_this_iter_s: 489.20352506637573\n",
      "  time_total_s: 58623.14954042435\n",
      "  timers:\n",
      "    learn_throughput: 110.296\n",
      "    learn_time_ms: 271995.843\n",
      "    sample_throughput: 140.632\n",
      "    sample_time_ms: 213323.183\n",
      "    update_time_ms: 3.06\n",
      "  timestamp: 1663006046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3630000\n",
      "  training_iteration: 121\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    121 |          58623.1 | 3630000 |  398.778 |              429.364 |              363.951 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3660000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_13-15-36\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 432.10808835494316\n",
      "  episode_reward_mean: 398.7591130835013\n",
      "  episode_reward_min: 363.9510582004264\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2440\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8763089311883805\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021346884169145312\n",
      "          policy_loss: 0.017557677763831266\n",
      "          total_loss: 277.9505719659684\n",
      "          vf_explained_var: -3.069005050093665e-09\n",
      "          vf_loss: 277.92490916799994\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3660000\n",
      "    num_steps_sampled: 3660000\n",
      "    num_steps_trained: 3660000\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.767335243553006\n",
      "    ram_util_percent: 49.019340974212035\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08803217857720007\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32932270214815\n",
      "    mean_inference_ms: 1.8255595069522206\n",
      "    mean_raw_obs_processing_ms: 2.5803022427560607\n",
      "  time_since_restore: 59112.99907255173\n",
      "  time_this_iter_s: 489.84953212738037\n",
      "  time_total_s: 59112.99907255173\n",
      "  timers:\n",
      "    learn_throughput: 110.057\n",
      "    learn_time_ms: 272586.764\n",
      "    sample_throughput: 140.628\n",
      "    sample_time_ms: 213328.86\n",
      "    update_time_ms: 3.077\n",
      "  timestamp: 1663006536\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3660000\n",
      "  training_iteration: 122\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    122 |            59113 | 3660000 |  398.759 |              432.108 |              363.951 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3690000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_13-23-47\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 432.10808835494316\n",
      "  episode_reward_mean: 399.3261472962705\n",
      "  episode_reward_min: 363.9510582004264\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2460\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.904076475995652\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020191141819368524\n",
      "          policy_loss: 0.015487368226923207\n",
      "          total_loss: 277.3796273673849\n",
      "          vf_explained_var: -2.866095583087258e-09\n",
      "          vf_loss: 277.35647383344934\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3690000\n",
      "    num_steps_sampled: 3690000\n",
      "    num_steps_trained: 3690000\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.742225392296717\n",
      "    ram_util_percent: 49.03880171184022\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880340153730081\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32925534246374\n",
      "    mean_inference_ms: 1.8256268468459078\n",
      "    mean_raw_obs_processing_ms: 2.568760554761234\n",
      "  time_since_restore: 59604.13633227348\n",
      "  time_this_iter_s: 491.137259721756\n",
      "  time_total_s: 59604.13633227348\n",
      "  timers:\n",
      "    learn_throughput: 109.762\n",
      "    learn_time_ms: 273319.722\n",
      "    sample_throughput: 140.644\n",
      "    sample_time_ms: 213303.895\n",
      "    update_time_ms: 3.089\n",
      "  timestamp: 1663007027\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3690000\n",
      "  training_iteration: 123\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    123 |          59604.1 | 3690000 |  399.326 |              432.108 |              363.951 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3720000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_13-31-58\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 432.10808835494316\n",
      "  episode_reward_mean: 403.9145277985382\n",
      "  episode_reward_min: 363.9510582004264\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2480\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.808623794291882\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01774663666927048\n",
      "          policy_loss: 0.013156357058323919\n",
      "          total_loss: 285.587956562448\n",
      "          vf_explained_var: -3.550915117500608e-09\n",
      "          vf_loss: 285.5680622052132\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3720000\n",
      "    num_steps_sampled: 3720000\n",
      "    num_steps_trained: 3720000\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.70784593437946\n",
      "    ram_util_percent: 49.12496433666192\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880345710721366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329259127430316\n",
      "    mean_inference_ms: 1.82564799111032\n",
      "    mean_raw_obs_processing_ms: 2.557400668308767\n",
      "  time_since_restore: 60095.074964523315\n",
      "  time_this_iter_s: 490.93863224983215\n",
      "  time_total_s: 60095.074964523315\n",
      "  timers:\n",
      "    learn_throughput: 109.477\n",
      "    learn_time_ms: 274030.45\n",
      "    sample_throughput: 140.645\n",
      "    sample_time_ms: 213303.545\n",
      "    update_time_ms: 3.038\n",
      "  timestamp: 1663007518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3720000\n",
      "  training_iteration: 124\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    124 |          60095.1 | 3720000 |  403.915 |              432.108 |              363.951 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3750000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_13-40-10\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 432.10808835494316\n",
      "  episode_reward_mean: 406.78616559751697\n",
      "  episode_reward_min: 380.87559032676273\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2500\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.917688309892695\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022465463604560216\n",
      "          policy_loss: 0.017617025595019632\n",
      "          total_loss: 289.2658810262477\n",
      "          vf_explained_var: -3.1958236057505474e-09\n",
      "          vf_loss: 289.239733805555\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3750000\n",
      "    num_steps_sampled: 3750000\n",
      "    num_steps_trained: 3750000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.744428571428568\n",
      "    ram_util_percent: 49.13442857142858\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08803409598729665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329273180205075\n",
      "    mean_inference_ms: 1.825668579928456\n",
      "    mean_raw_obs_processing_ms: 2.5462147287342103\n",
      "  time_since_restore: 60586.24120426178\n",
      "  time_this_iter_s: 491.16623973846436\n",
      "  time_total_s: 60586.24120426178\n",
      "  timers:\n",
      "    learn_throughput: 109.208\n",
      "    learn_time_ms: 274705.62\n",
      "    sample_throughput: 140.641\n",
      "    sample_time_ms: 213308.951\n",
      "    update_time_ms: 3.044\n",
      "  timestamp: 1663008010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3750000\n",
      "  training_iteration: 125\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    125 |          60586.2 | 3750000 |  406.786 |              432.108 |              380.876 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3780000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_13-48-22\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 432.10808835494316\n",
      "  episode_reward_mean: 405.28635628258667\n",
      "  episode_reward_min: 377.3769494328396\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2520\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8992895714780116\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025250521877141722\n",
      "          policy_loss: 0.0201699353216533\n",
      "          total_loss: 295.02122195629363\n",
      "          vf_explained_var: -2.967550427612764e-09\n",
      "          vf_loss: 294.99146549306016\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3780000\n",
      "    num_steps_sampled: 3780000\n",
      "    num_steps_trained: 3780000\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.743243243243242\n",
      "    ram_util_percent: 49.228449502133714\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08803388727588364\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329311506191498\n",
      "    mean_inference_ms: 1.825693253059813\n",
      "    mean_raw_obs_processing_ms: 2.5351980319074228\n",
      "  time_since_restore: 61078.614827394485\n",
      "  time_this_iter_s: 492.3736231327057\n",
      "  time_total_s: 61078.614827394485\n",
      "  timers:\n",
      "    learn_throughput: 108.893\n",
      "    learn_time_ms: 275500.824\n",
      "    sample_throughput: 140.638\n",
      "    sample_time_ms: 213313.667\n",
      "    update_time_ms: 3.064\n",
      "  timestamp: 1663008502\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3780000\n",
      "  training_iteration: 126\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    126 |          61078.6 | 3780000 |  405.286 |              432.108 |              377.377 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3810000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_13-56-34\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 431.3945423505843\n",
      "  episode_reward_mean: 403.2639218921288\n",
      "  episode_reward_min: 377.3769494328396\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2540\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9345331492322555\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020755476889515227\n",
      "          policy_loss: 0.016106765460460745\n",
      "          total_loss: 296.48778240609676\n",
      "          vf_explained_var: -2.0544579371062355e-09\n",
      "          vf_loss: 296.4637943332753\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3810000\n",
      "    num_steps_sampled: 3810000\n",
      "    num_steps_trained: 3810000\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.756837606837607\n",
      "    ram_util_percent: 49.57393162393163\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08803501424194185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329209242807746\n",
      "    mean_inference_ms: 1.8257812001568987\n",
      "    mean_raw_obs_processing_ms: 2.5243554534885253\n",
      "  time_since_restore: 61570.83282494545\n",
      "  time_this_iter_s: 492.21799755096436\n",
      "  time_total_s: 61570.83282494545\n",
      "  timers:\n",
      "    learn_throughput: 108.597\n",
      "    learn_time_ms: 276250.939\n",
      "    sample_throughput: 140.661\n",
      "    sample_time_ms: 213278.307\n",
      "    update_time_ms: 3.051\n",
      "  timestamp: 1663008994\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3810000\n",
      "  training_iteration: 127\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    127 |          61570.8 | 3810000 |  403.264 |              431.395 |              377.377 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3840000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_14-04-48\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 421.93253029464165\n",
      "  episode_reward_mean: 399.7925445257721\n",
      "  episode_reward_min: 377.3769494328396\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2560\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.069149076684992\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02650621718431077\n",
      "          policy_loss: 0.02095318585465801\n",
      "          total_loss: 297.7777352093636\n",
      "          vf_explained_var: -1.2174565799938364e-09\n",
      "          vf_loss: 297.74671795459506\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3840000\n",
      "    num_steps_sampled: 3840000\n",
      "    num_steps_trained: 3840000\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.648863636363636\n",
      "    ram_util_percent: 49.61803977272726\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08803621289486248\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329075701185864\n",
      "    mean_inference_ms: 1.82589193270971\n",
      "    mean_raw_obs_processing_ms: 2.5136963416717166\n",
      "  time_since_restore: 62063.89901280403\n",
      "  time_this_iter_s: 493.06618785858154\n",
      "  time_total_s: 62063.89901280403\n",
      "  timers:\n",
      "    learn_throughput: 108.291\n",
      "    learn_time_ms: 277030.53\n",
      "    sample_throughput: 140.664\n",
      "    sample_time_ms: 213273.959\n",
      "    update_time_ms: 3.035\n",
      "  timestamp: 1663009488\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3840000\n",
      "  training_iteration: 128\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    128 |          62063.9 | 3840000 |  399.793 |              421.933 |              377.377 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3870000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_14-13-01\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 419.4386315623287\n",
      "  episode_reward_mean: 399.52502258967\n",
      "  episode_reward_min: 377.3769494328396\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2580\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.101665683401392\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026893199146647978\n",
      "          policy_loss: 0.02134001876658542\n",
      "          total_loss: 298.48421408145987\n",
      "          vf_explained_var: -2.8914592942186346e-09\n",
      "          vf_loss: 298.45266271712933\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3870000\n",
      "    num_steps_sampled: 3870000\n",
      "    num_steps_trained: 3870000\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.693323863636362\n",
      "    ram_util_percent: 49.65681818181818\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08803838057064352\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328912807459215\n",
      "    mean_inference_ms: 1.8260111378889388\n",
      "    mean_raw_obs_processing_ms: 2.5031828851750064\n",
      "  time_since_restore: 62557.46911239624\n",
      "  time_this_iter_s: 493.57009959220886\n",
      "  time_total_s: 62557.46911239624\n",
      "  timers:\n",
      "    learn_throughput: 108.0\n",
      "    learn_time_ms: 277777.781\n",
      "    sample_throughput: 140.676\n",
      "    sample_time_ms: 213256.263\n",
      "    update_time_ms: 3.039\n",
      "  timestamp: 1663009981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3870000\n",
      "  training_iteration: 129\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    129 |          62557.5 | 3870000 |  399.525 |              419.439 |              377.377 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3900000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_14-21-15\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 419.4386315623287\n",
      "  episode_reward_mean: 398.84171867295265\n",
      "  episode_reward_min: 377.3769494328396\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2600\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.212544916335572\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03289003526993814\n",
      "          policy_loss: 0.024501489454563312\n",
      "          total_loss: 302.6484826790018\n",
      "          vf_explained_var: -3.3480056504942013e-09\n",
      "          vf_loss: 302.61149350592433\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3900000\n",
      "    num_steps_sampled: 3900000\n",
      "    num_steps_trained: 3900000\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.70581560283688\n",
      "    ram_util_percent: 49.44652482269503\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880415110667117\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328769110069153\n",
      "    mean_inference_ms: 1.8261038572745907\n",
      "    mean_raw_obs_processing_ms: 2.492828886366524\n",
      "  time_since_restore: 63051.51505565643\n",
      "  time_this_iter_s: 494.04594326019287\n",
      "  time_total_s: 63051.51505565643\n",
      "  timers:\n",
      "    learn_throughput: 107.729\n",
      "    learn_time_ms: 278476.281\n",
      "    sample_throughput: 140.671\n",
      "    sample_time_ms: 213264.201\n",
      "    update_time_ms: 3.03\n",
      "  timestamp: 1663010475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3900000\n",
      "  training_iteration: 130\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    130 |          63051.5 | 3900000 |  398.842 |              419.439 |              377.377 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3930000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_14-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 419.4386315623287\n",
      "  episode_reward_mean: 395.0491664080591\n",
      "  episode_reward_min: 363.89298011902713\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2620\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.233122423760435\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029097142678244783\n",
      "          policy_loss: 0.02285673218488692\n",
      "          total_loss: 310.21289296576316\n",
      "          vf_explained_var: -2.612458915862703e-09\n",
      "          vf_loss: 310.178987280663\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3930000\n",
      "    num_steps_sampled: 3930000\n",
      "    num_steps_trained: 3930000\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.706960227272727\n",
      "    ram_util_percent: 49.54659090909092\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880446082533878\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3285499959901\n",
      "    mean_inference_ms: 1.8262164260160583\n",
      "    mean_raw_obs_processing_ms: 2.482632648759007\n",
      "  time_since_restore: 63544.91734290123\n",
      "  time_this_iter_s: 493.40228724479675\n",
      "  time_total_s: 63544.91734290123\n",
      "  timers:\n",
      "    learn_throughput: 107.563\n",
      "    learn_time_ms: 278906.158\n",
      "    sample_throughput: 140.677\n",
      "    sample_time_ms: 213254.219\n",
      "    update_time_ms: 3.002\n",
      "  timestamp: 1663010969\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3930000\n",
      "  training_iteration: 131\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    131 |          63544.9 | 3930000 |  395.049 |              419.439 |              363.893 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3960000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_14-37-41\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 419.4386315623287\n",
      "  episode_reward_mean: 383.3508718698346\n",
      "  episode_reward_min: 329.2566527906445\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2640\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.1713210037921336\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.031165216270576716\n",
      "          policy_loss: 0.019970541287020364\n",
      "          total_loss: 315.5353884725368\n",
      "          vf_explained_var: -2.4095494488562963e-09\n",
      "          vf_loss: 315.5035842927973\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3960000\n",
      "    num_steps_sampled: 3960000\n",
      "    num_steps_trained: 3960000\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.78262108262108\n",
      "    ram_util_percent: 49.63960113960114\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804665889451314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328418993481435\n",
      "    mean_inference_ms: 1.826285249675879\n",
      "    mean_raw_obs_processing_ms: 2.472604328593659\n",
      "  time_since_restore: 64037.08976316452\n",
      "  time_this_iter_s: 492.1724202632904\n",
      "  time_total_s: 64037.08976316452\n",
      "  timers:\n",
      "    learn_throughput: 107.473\n",
      "    learn_time_ms: 279138.684\n",
      "    sample_throughput: 140.677\n",
      "    sample_time_ms: 213254.044\n",
      "    update_time_ms: 2.984\n",
      "  timestamp: 1663011461\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3960000\n",
      "  training_iteration: 132\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    132 |          64037.1 | 3960000 |  383.351 |              419.439 |              329.257 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 3990000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_14-45-53\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 419.4386315623287\n",
      "  episode_reward_mean: 377.70503976491796\n",
      "  episode_reward_min: 329.2566527906445\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2660\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.06739170723773\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023927807473513293\n",
      "          policy_loss: 0.015322357548816883\n",
      "          total_loss: 310.7731853241616\n",
      "          vf_explained_var: -4.108915874212471e-09\n",
      "          vf_loss: 310.748777063248\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 3990000\n",
      "    num_steps_sampled: 3990000\n",
      "    num_steps_trained: 3990000\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.7988603988604\n",
      "    ram_util_percent: 49.64188034188035\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804929678989211\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328343583342136\n",
      "    mean_inference_ms: 1.8263495181868918\n",
      "    mean_raw_obs_processing_ms: 2.4627279569577216\n",
      "  time_since_restore: 64528.72175741196\n",
      "  time_this_iter_s: 491.6319942474365\n",
      "  time_total_s: 64528.72175741196\n",
      "  timers:\n",
      "    learn_throughput: 107.463\n",
      "    learn_time_ms: 279165.325\n",
      "    sample_throughput: 140.662\n",
      "    sample_time_ms: 213276.925\n",
      "    update_time_ms: 2.985\n",
      "  timestamp: 1663011953\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3990000\n",
      "  training_iteration: 133\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    133 |          64528.7 | 3990000 |  377.705 |              419.439 |              329.257 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4020000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_14-54-07\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 410.7739192232412\n",
      "  episode_reward_mean: 373.16485742341104\n",
      "  episode_reward_min: 329.2566527906445\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2680\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.030142146171407\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025898615838291335\n",
      "          policy_loss: 0.015355706899922262\n",
      "          total_loss: 306.03020652608666\n",
      "          vf_explained_var: -1.9530033146253345e-09\n",
      "          vf_loss: 306.0050185540382\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4020000\n",
      "    num_steps_sampled: 4020000\n",
      "    num_steps_trained: 4020000\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.70340909090909\n",
      "    ram_util_percent: 49.659232954545466\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805191715394411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328254905522627\n",
      "    mean_inference_ms: 1.8264441176013235\n",
      "    mean_raw_obs_processing_ms: 2.4530189407791307\n",
      "  time_since_restore: 65022.28848481178\n",
      "  time_this_iter_s: 493.56672739982605\n",
      "  time_total_s: 65022.28848481178\n",
      "  timers:\n",
      "    learn_throughput: 107.359\n",
      "    learn_time_ms: 279436.723\n",
      "    sample_throughput: 140.668\n",
      "    sample_time_ms: 213268.331\n",
      "    update_time_ms: 2.979\n",
      "  timestamp: 1663012447\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4020000\n",
      "  training_iteration: 134\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    134 |          65022.3 | 4020000 |  373.165 |              410.774 |              329.257 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4050000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_15-02-22\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 400.4932876792188\n",
      "  episode_reward_mean: 370.16663479588743\n",
      "  episode_reward_min: 329.2566527906445\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2700\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.99981172206554\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025204487119979864\n",
      "          policy_loss: 0.01849465745798451\n",
      "          total_loss: 310.048676436404\n",
      "          vf_explained_var: -6.06191941088241e-09\n",
      "          vf_loss: 310.0206117443328\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4050000\n",
      "    num_steps_sampled: 4050000\n",
      "    num_steps_trained: 4050000\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.689250353606788\n",
      "    ram_util_percent: 49.7046676096181\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805459438002146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32817427522962\n",
      "    mean_inference_ms: 1.826549700978747\n",
      "    mean_raw_obs_processing_ms: 2.4434441091132806\n",
      "  time_since_restore: 65517.84641766548\n",
      "  time_this_iter_s: 495.55793285369873\n",
      "  time_total_s: 65517.84641766548\n",
      "  timers:\n",
      "    learn_throughput: 107.189\n",
      "    learn_time_ms: 279879.211\n",
      "    sample_throughput: 140.67\n",
      "    sample_time_ms: 213265.013\n",
      "    update_time_ms: 2.982\n",
      "  timestamp: 1663012942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4050000\n",
      "  training_iteration: 135\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    135 |          65517.8 | 4050000 |  370.167 |              400.493 |              329.257 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4080000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_15-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 400.4932876792188\n",
      "  episode_reward_mean: 371.21182631792965\n",
      "  episode_reward_min: 329.2566527906445\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2720\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.050895491660909\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028771986141949642\n",
      "          policy_loss: 0.02176442245318693\n",
      "          total_loss: 311.7462825823845\n",
      "          vf_explained_var: -3.221187094837319e-09\n",
      "          vf_loss: 311.7135939253138\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4080000\n",
      "    num_steps_sampled: 4080000\n",
      "    num_steps_trained: 4080000\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.6748595505618\n",
      "    ram_util_percent: 50.134691011235944\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805671860020803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328109392486343\n",
      "    mean_inference_ms: 1.826616978388338\n",
      "    mean_raw_obs_processing_ms: 2.434018030314559\n",
      "  time_since_restore: 66017.3361325264\n",
      "  time_this_iter_s: 499.48971486091614\n",
      "  time_total_s: 66017.3361325264\n",
      "  timers:\n",
      "    learn_throughput: 106.909\n",
      "    learn_time_ms: 280612.116\n",
      "    sample_throughput: 140.684\n",
      "    sample_time_ms: 213243.736\n",
      "    update_time_ms: 2.962\n",
      "  timestamp: 1663013442\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4080000\n",
      "  training_iteration: 136\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    136 |          66017.3 | 4080000 |  371.212 |              400.493 |              329.257 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4110000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_15-19-02\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 400.4932876792188\n",
      "  episode_reward_mean: 378.0373842634641\n",
      "  episode_reward_min: 348.72422924733513\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2740\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.024825407799254\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02180490322505203\n",
      "          policy_loss: 0.016888203411338298\n",
      "          total_loss: 315.5960704072993\n",
      "          vf_explained_var: 1.268183891234287e-10\n",
      "          vf_loss: 315.5709024794558\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4110000\n",
      "    num_steps_sampled: 4110000\n",
      "    num_steps_trained: 4110000\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.591176470588234\n",
      "    ram_util_percent: 50.175070028011206\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.088058851921798\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32802661997326\n",
      "    mean_inference_ms: 1.8266442224667205\n",
      "    mean_raw_obs_processing_ms: 2.424718421357072\n",
      "  time_since_restore: 66517.6522591114\n",
      "  time_this_iter_s: 500.3161265850067\n",
      "  time_total_s: 66517.6522591114\n",
      "  timers:\n",
      "    learn_throughput: 106.595\n",
      "    learn_time_ms: 281437.881\n",
      "    sample_throughput: 140.695\n",
      "    sample_time_ms: 213227.892\n",
      "    update_time_ms: 2.964\n",
      "  timestamp: 1663013942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4110000\n",
      "  training_iteration: 137\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    137 |          66517.7 | 4110000 |  378.037 |              400.493 |              348.724 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4140000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_15-27-23\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 400.4932876792188\n",
      "  episode_reward_mean: 379.83423396862815\n",
      "  episode_reward_min: 361.12784260551956\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2760\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.952165085609923\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02296717510135135\n",
      "          policy_loss: 0.016556482282467186\n",
      "          total_loss: 315.6034285200403\n",
      "          vf_explained_var: -4.6669170750135436e-09\n",
      "          vf_loss: 315.57815297877534\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4140000\n",
      "    num_steps_sampled: 4140000\n",
      "    num_steps_trained: 4140000\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.6515406162465\n",
      "    ram_util_percent: 50.25896358543417\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806077286685333\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32792614712551\n",
      "    mean_inference_ms: 1.82667440467735\n",
      "    mean_raw_obs_processing_ms: 2.415582044415126\n",
      "  time_since_restore: 67017.97901749611\n",
      "  time_this_iter_s: 500.3267583847046\n",
      "  time_total_s: 67017.97901749611\n",
      "  timers:\n",
      "    learn_throughput: 106.327\n",
      "    learn_time_ms: 282148.69\n",
      "    sample_throughput: 140.684\n",
      "    sample_time_ms: 213243.267\n",
      "    update_time_ms: 2.999\n",
      "  timestamp: 1663014443\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4140000\n",
      "  training_iteration: 138\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    138 |            67018 | 4140000 |  379.834 |              400.493 |              361.128 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4170000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_15-35-45\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 399.87291986216707\n",
      "  episode_reward_mean: 377.0112267326506\n",
      "  episode_reward_min: 342.6766287977947\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2780\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9128086607506933\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02650748451260198\n",
      "          policy_loss: 0.01979254383871213\n",
      "          total_loss: 319.12705402130774\n",
      "          vf_explained_var: -2.282731115244019e-09\n",
      "          vf_loss: 319.09719675916307\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4170000\n",
      "    num_steps_sampled: 4170000\n",
      "    num_steps_trained: 4170000\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.582960893854747\n",
      "    ram_util_percent: 50.24343575418994\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806256546883287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327879589432033\n",
      "    mean_inference_ms: 1.8266865692567646\n",
      "    mean_raw_obs_processing_ms: 2.406593108714949\n",
      "  time_since_restore: 67519.9219315052\n",
      "  time_this_iter_s: 501.94291400909424\n",
      "  time_total_s: 67519.9219315052\n",
      "  timers:\n",
      "    learn_throughput: 106.027\n",
      "    learn_time_ms: 282947.755\n",
      "    sample_throughput: 140.659\n",
      "    sample_time_ms: 213281.603\n",
      "    update_time_ms: 2.986\n",
      "  timestamp: 1663014945\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4170000\n",
      "  training_iteration: 139\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    139 |          67519.9 | 4170000 |  377.011 |              399.873 |              342.677 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4200000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_15-44-07\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 399.87291986216707\n",
      "  episode_reward_mean: 371.6681689821517\n",
      "  episode_reward_min: 332.4576866270363\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2800\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.909368185388281\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026674183509907214\n",
      "          policy_loss: 0.01630238988298051\n",
      "          total_loss: 319.6534660112097\n",
      "          vf_explained_var: -1.775457558750304e-09\n",
      "          vf_loss: 319.62703496730074\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4200000\n",
      "    num_steps_sampled: 4200000\n",
      "    num_steps_trained: 4200000\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.631938633193865\n",
      "    ram_util_percent: 50.33960948396095\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806348344434207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327789942669323\n",
      "    mean_inference_ms: 1.826716501383159\n",
      "    mean_raw_obs_processing_ms: 2.3977486467253732\n",
      "  time_since_restore: 68022.21354222298\n",
      "  time_this_iter_s: 502.29161071777344\n",
      "  time_total_s: 68022.21354222298\n",
      "  timers:\n",
      "    learn_throughput: 105.714\n",
      "    learn_time_ms: 283783.773\n",
      "    sample_throughput: 140.667\n",
      "    sample_time_ms: 213270.14\n",
      "    update_time_ms: 2.976\n",
      "  timestamp: 1663015447\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4200000\n",
      "  training_iteration: 140\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    140 |          68022.2 | 4200000 |  371.668 |              399.873 |              332.458 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4230000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_15-52-29\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 394.76426756690086\n",
      "  episode_reward_mean: 362.1508308872519\n",
      "  episode_reward_min: 307.03803333356456\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2820\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9907686426284465\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026315982337803433\n",
      "          policy_loss: 0.02098351519634115\n",
      "          total_loss: 319.075736093724\n",
      "          vf_explained_var: 1.2935476023656634e-09\n",
      "          vf_loss: 319.04476007339804\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4230000\n",
      "    num_steps_sampled: 4230000\n",
      "    num_steps_trained: 4230000\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.565411436541144\n",
      "    ram_util_percent: 50.08521617852163\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806423019928947\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327711659148534\n",
      "    mean_inference_ms: 1.8267570994486544\n",
      "    mean_raw_obs_processing_ms: 2.389017789662056\n",
      "  time_since_restore: 68524.46130514145\n",
      "  time_this_iter_s: 502.2477629184723\n",
      "  time_total_s: 68524.46130514145\n",
      "  timers:\n",
      "    learn_throughput: 105.388\n",
      "    learn_time_ms: 284662.529\n",
      "    sample_throughput: 140.663\n",
      "    sample_time_ms: 213275.818\n",
      "    update_time_ms: 3.039\n",
      "  timestamp: 1663015949\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4230000\n",
      "  training_iteration: 141\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    141 |          68524.5 | 4230000 |  362.151 |              394.764 |              307.038 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4260000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_16-00-52\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 394.76426756690086\n",
      "  episode_reward_mean: 351.41238910075367\n",
      "  episode_reward_min: 305.7561428078368\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2840\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.039420318197696\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025272722097591946\n",
      "          policy_loss: 0.01993963774580984\n",
      "          total_loss: 319.73316747462496\n",
      "          vf_explained_var: -5.326372676250912e-10\n",
      "          vf_loss: 319.7036315560848\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4260000\n",
      "    num_steps_sampled: 4260000\n",
      "    num_steps_trained: 4260000\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.528212290502793\n",
      "    ram_util_percent: 50.155586592178786\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806481989448538\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327662711796492\n",
      "    mean_inference_ms: 1.8267937811092276\n",
      "    mean_raw_obs_processing_ms: 2.380414397504632\n",
      "  time_since_restore: 69026.65089893341\n",
      "  time_this_iter_s: 502.18959379196167\n",
      "  time_total_s: 69026.65089893341\n",
      "  timers:\n",
      "    learn_throughput: 105.011\n",
      "    learn_time_ms: 285683.747\n",
      "    sample_throughput: 140.676\n",
      "    sample_time_ms: 213256.345\n",
      "    update_time_ms: 3.03\n",
      "  timestamp: 1663016452\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4260000\n",
      "  training_iteration: 142\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    142 |          69026.7 | 4260000 |  351.412 |              394.764 |              305.756 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4290000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_16-09-12\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 394.76426756690086\n",
      "  episode_reward_mean: 338.446727596858\n",
      "  episode_reward_min: 287.48226281986945\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2860\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.040617305471542\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02874147776581189\n",
      "          policy_loss: 0.021820356122198258\n",
      "          total_loss: 317.30719405803274\n",
      "          vf_explained_var: -4.76837147544984e-09\n",
      "          vf_loss: 317.2744607836135\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4290000\n",
      "    num_steps_sampled: 4290000\n",
      "    num_steps_trained: 4290000\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.541958041958043\n",
      "    ram_util_percent: 50.19216783216783\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806438730588134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327625953827795\n",
      "    mean_inference_ms: 1.826812122977397\n",
      "    mean_raw_obs_processing_ms: 2.37192872401174\n",
      "  time_since_restore: 69527.36012673378\n",
      "  time_this_iter_s: 500.70922780036926\n",
      "  time_total_s: 69527.36012673378\n",
      "  timers:\n",
      "    learn_throughput: 104.678\n",
      "    learn_time_ms: 286593.202\n",
      "    sample_throughput: 140.677\n",
      "    sample_time_ms: 213254.658\n",
      "    update_time_ms: 3.013\n",
      "  timestamp: 1663016952\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4290000\n",
      "  training_iteration: 143\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    143 |          69527.4 | 4290000 |  338.447 |              394.764 |              287.482 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4320000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_16-17-35\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 373.800036387883\n",
      "  episode_reward_mean: 329.74779147718147\n",
      "  episode_reward_min: 287.48226281986945\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2880\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.046420579058059\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027749263053906206\n",
      "          policy_loss: 0.021770713788387863\n",
      "          total_loss: 315.0701842904598\n",
      "          vf_explained_var: -1.116001846490633e-09\n",
      "          vf_loss: 315.03787732063455\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4320000\n",
      "    num_steps_sampled: 4320000\n",
      "    num_steps_trained: 4320000\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.615062761506277\n",
      "    ram_util_percent: 50.226080892608095\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880640362063727\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327584659236905\n",
      "    mean_inference_ms: 1.8268423002150707\n",
      "    mean_raw_obs_processing_ms: 2.3635480893380696\n",
      "  time_since_restore: 70029.9094285965\n",
      "  time_this_iter_s: 502.5493018627167\n",
      "  time_total_s: 70029.9094285965\n",
      "  timers:\n",
      "    learn_throughput: 104.358\n",
      "    learn_time_ms: 287470.869\n",
      "    sample_throughput: 140.663\n",
      "    sample_time_ms: 213275.236\n",
      "    update_time_ms: 3.019\n",
      "  timestamp: 1663017455\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4320000\n",
      "  training_iteration: 144\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    144 |          70029.9 | 4320000 |  329.748 |                373.8 |              287.482 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4350000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_16-25-59\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 354.6565294279693\n",
      "  episode_reward_mean: 323.6502509897124\n",
      "  episode_reward_min: 287.48226281986945\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2900\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.031377848970129\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022565221117228806\n",
      "          policy_loss: 0.01796487975716987\n",
      "          total_loss: 312.41904681915935\n",
      "          vf_explained_var: -2.6378226269940797e-09\n",
      "          vf_loss: 312.392513531624\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4350000\n",
      "    num_steps_sampled: 4350000\n",
      "    num_steps_trained: 4350000\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.582869080779943\n",
      "    ram_util_percent: 50.287883008356545\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806426080222954\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327607502885563\n",
      "    mean_inference_ms: 1.8268461919800643\n",
      "    mean_raw_obs_processing_ms: 2.3552756472704925\n",
      "  time_since_restore: 70533.33864474297\n",
      "  time_this_iter_s: 503.4292161464691\n",
      "  time_total_s: 70533.33864474297\n",
      "  timers:\n",
      "    learn_throughput: 104.075\n",
      "    learn_time_ms: 288252.376\n",
      "    sample_throughput: 140.66\n",
      "    sample_time_ms: 213280.853\n",
      "    update_time_ms: 3.01\n",
      "  timestamp: 1663017959\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4350000\n",
      "  training_iteration: 145\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    145 |          70533.3 | 4350000 |   323.65 |              354.657 |              287.482 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4380000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_16-34-22\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 362.26839980054353\n",
      "  episode_reward_mean: 326.80084953004297\n",
      "  episode_reward_min: 287.48226281986945\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2920\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.967699841641365\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02581581709011071\n",
      "          policy_loss: 0.018708426419278962\n",
      "          total_loss: 307.82746820328083\n",
      "          vf_explained_var: -5.072735564937148e-10\n",
      "          vf_loss: 307.7989582759776\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4380000\n",
      "    num_steps_sampled: 4380000\n",
      "    num_steps_trained: 4380000\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.7033426183844\n",
      "    ram_util_percent: 50.35779944289694\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880647580216542\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32764612837302\n",
      "    mean_inference_ms: 1.8268536132678397\n",
      "    mean_raw_obs_processing_ms: 2.3471321428735057\n",
      "  time_since_restore: 71036.39019560814\n",
      "  time_this_iter_s: 503.05155086517334\n",
      "  time_total_s: 71036.39019560814\n",
      "  timers:\n",
      "    learn_throughput: 103.955\n",
      "    learn_time_ms: 288586.575\n",
      "    sample_throughput: 140.645\n",
      "    sample_time_ms: 213302.689\n",
      "    update_time_ms: 3.04\n",
      "  timestamp: 1663018462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4380000\n",
      "  training_iteration: 146\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    146 |          71036.4 | 4380000 |  326.801 |              362.268 |              287.482 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4410000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_16-42-44\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 382.4089222103205\n",
      "  episode_reward_mean: 333.56089390196126\n",
      "  episode_reward_min: 287.48226281986945\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2940\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.7963593459636606\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0221952681317481\n",
      "          policy_loss: 0.015908324202780235\n",
      "          total_loss: 303.85248556745813\n",
      "          vf_explained_var: -5.224917831725406e-09\n",
      "          vf_loss: 303.8281504967872\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4410000\n",
      "    num_steps_sampled: 4410000\n",
      "    num_steps_trained: 4410000\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.576429567642954\n",
      "    ram_util_percent: 50.40097629009762\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806491162174368\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327675880602843\n",
      "    mean_inference_ms: 1.8268774411967064\n",
      "    mean_raw_obs_processing_ms: 2.339115489461292\n",
      "  time_since_restore: 71538.77178812027\n",
      "  time_this_iter_s: 502.38159251213074\n",
      "  time_total_s: 71538.77178812027\n",
      "  timers:\n",
      "    learn_throughput: 103.89\n",
      "    learn_time_ms: 288768.264\n",
      "    sample_throughput: 140.629\n",
      "    sample_time_ms: 213327.578\n",
      "    update_time_ms: 3.041\n",
      "  timestamp: 1663018964\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4410000\n",
      "  training_iteration: 147\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    147 |          71538.8 | 4410000 |  333.561 |              382.409 |              287.482 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4440000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_16-51-07\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 382.49561986871066\n",
      "  episode_reward_mean: 344.42123998272206\n",
      "  episode_reward_min: 299.6977685252388\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2960\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.770968504053481\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020825496972873125\n",
      "          policy_loss: 0.01734806558573024\n",
      "          total_loss: 306.0090126199925\n",
      "          vf_explained_var: 5.326372676250912e-10\n",
      "          vf_loss: 305.98375731772563\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4440000\n",
      "    num_steps_sampled: 4440000\n",
      "    num_steps_trained: 4440000\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.547140864714084\n",
      "    ram_util_percent: 50.48967921896792\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806525688482225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327718801723623\n",
      "    mean_inference_ms: 1.826886837867005\n",
      "    mean_raw_obs_processing_ms: 2.3311937118778445\n",
      "  time_since_restore: 72041.39456439018\n",
      "  time_this_iter_s: 502.6227762699127\n",
      "  time_total_s: 72041.39456439018\n",
      "  timers:\n",
      "    learn_throughput: 103.811\n",
      "    learn_time_ms: 288986.342\n",
      "    sample_throughput: 140.621\n",
      "    sample_time_ms: 213339.182\n",
      "    update_time_ms: 3.008\n",
      "  timestamp: 1663019467\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4440000\n",
      "  training_iteration: 148\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    148 |          72041.4 | 4440000 |  344.421 |              382.496 |              299.698 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4470000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_16-59-29\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 386.0961523177977\n",
      "  episode_reward_mean: 352.31767824712443\n",
      "  episode_reward_min: 304.089788558523\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2980\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8368274518276784\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023259311857970363\n",
      "          policy_loss: 0.01774532421779363\n",
      "          total_loss: 307.24819175882544\n",
      "          vf_explained_var: -2.6885498272122277e-09\n",
      "          vf_loss: 307.22161581161174\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4470000\n",
      "    num_steps_sampled: 4470000\n",
      "    num_steps_trained: 4470000\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.575592747559273\n",
      "    ram_util_percent: 50.172384937238505\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806533362539762\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327741797703847\n",
      "    mean_inference_ms: 1.8268814814232703\n",
      "    mean_raw_obs_processing_ms: 2.3233862332516457\n",
      "  time_since_restore: 72543.73335075378\n",
      "  time_this_iter_s: 502.3387863636017\n",
      "  time_total_s: 72543.73335075378\n",
      "  timers:\n",
      "    learn_throughput: 103.794\n",
      "    learn_time_ms: 289034.219\n",
      "    sample_throughput: 140.627\n",
      "    sample_time_ms: 213330.8\n",
      "    update_time_ms: 3.021\n",
      "  timestamp: 1663019969\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4470000\n",
      "  training_iteration: 149\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    149 |          72543.7 | 4470000 |  352.318 |              386.096 |               304.09 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4500000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_17-07-53\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 386.0961523177977\n",
      "  episode_reward_mean: 352.48848043915865\n",
      "  episode_reward_min: 304.86126389218197\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3000\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8719133245184065\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026576734621008596\n",
      "          policy_loss: 0.019931954078554633\n",
      "          total_loss: 312.8230724156156\n",
      "          vf_explained_var: -1.800821158859378e-09\n",
      "          vf_loss: 312.79305055334214\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4500000\n",
      "    num_steps_sampled: 4500000\n",
      "    num_steps_trained: 4500000\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.510027855153204\n",
      "    ram_util_percent: 50.10571030640668\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806496533281677\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327764514155696\n",
      "    mean_inference_ms: 1.8268778191331976\n",
      "    mean_raw_obs_processing_ms: 2.31569089907734\n",
      "  time_since_restore: 73047.34169244766\n",
      "  time_this_iter_s: 503.6083416938782\n",
      "  time_total_s: 73047.34169244766\n",
      "  timers:\n",
      "    learn_throughput: 103.752\n",
      "    learn_time_ms: 289150.666\n",
      "    sample_throughput: 140.617\n",
      "    sample_time_ms: 213346.028\n",
      "    update_time_ms: 3.02\n",
      "  timestamp: 1663020473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4500000\n",
      "  training_iteration: 150\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    150 |          73047.3 | 4500000 |  352.488 |              386.096 |              304.861 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4530000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_17-16-16\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 386.0961523177977\n",
      "  episode_reward_mean: 347.89983695669406\n",
      "  episode_reward_min: 303.403913751005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3020\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.905791956718932\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024228365941027806\n",
      "          policy_loss: 0.01929425892106163\n",
      "          total_loss: 309.13383570244974\n",
      "          vf_explained_var: -2.81536838286911e-09\n",
      "          vf_loss: 309.10534238125416\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4530000\n",
      "    num_steps_sampled: 4530000\n",
      "    num_steps_trained: 4530000\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.53245125348189\n",
      "    ram_util_percent: 50.215598885793874\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806455232864593\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327837072142557\n",
      "    mean_inference_ms: 1.8268472947859473\n",
      "    mean_raw_obs_processing_ms: 2.308081581481316\n",
      "  time_since_restore: 73550.74074196815\n",
      "  time_this_iter_s: 503.39904952049255\n",
      "  time_total_s: 73550.74074196815\n",
      "  timers:\n",
      "    learn_throughput: 103.713\n",
      "    learn_time_ms: 289258.644\n",
      "    sample_throughput: 140.612\n",
      "    sample_time_ms: 213353.294\n",
      "    update_time_ms: 2.958\n",
      "  timestamp: 1663020976\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4530000\n",
      "  training_iteration: 151\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    151 |          73550.7 | 4530000 |    347.9 |              386.096 |              303.404 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4560000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_17-24-40\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 386.0961523177977\n",
      "  episode_reward_mean: 337.10380102842316\n",
      "  episode_reward_min: 288.7310025435223\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3040\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8323727588450653\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023999374742344905\n",
      "          policy_loss: 0.018730011783401543\n",
      "          total_loss: 312.61647782346034\n",
      "          vf_explained_var: -3.2972782282314483e-09\n",
      "          vf_loss: 312.58863553635615\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4560000\n",
      "    num_steps_sampled: 4560000\n",
      "    num_steps_trained: 4560000\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.508356545961004\n",
      "    ram_util_percent: 50.183704735376054\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806384382307086\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.327919328270326\n",
      "    mean_inference_ms: 1.8267989265700515\n",
      "    mean_raw_obs_processing_ms: 2.3005531115676994\n",
      "  time_since_restore: 74053.89428424835\n",
      "  time_this_iter_s: 503.15354228019714\n",
      "  time_total_s: 74053.89428424835\n",
      "  timers:\n",
      "    learn_throughput: 103.678\n",
      "    learn_time_ms: 289358.747\n",
      "    sample_throughput: 140.614\n",
      "    sample_time_ms: 213349.439\n",
      "    update_time_ms: 2.966\n",
      "  timestamp: 1663021480\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4560000\n",
      "  training_iteration: 152\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    152 |          74053.9 | 4560000 |  337.104 |              386.096 |              288.731 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4590000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_17-33-04\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 386.0961523177977\n",
      "  episode_reward_mean: 331.21347421166604\n",
      "  episode_reward_min: 288.7310025435223\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3060\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8494347077227653\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026074858141488553\n",
      "          policy_loss: 0.01606228669312723\n",
      "          total_loss: 307.40716330670296\n",
      "          vf_explained_var: -4.540098519356661e-09\n",
      "          vf_loss: 307.3812014315991\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4590000\n",
      "    num_steps_sampled: 4590000\n",
      "    num_steps_trained: 4590000\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.52263888888889\n",
      "    ram_util_percent: 50.26\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806367434975063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32797112039818\n",
      "    mean_inference_ms: 1.8267959249918142\n",
      "    mean_raw_obs_processing_ms: 2.2931405998787944\n",
      "  time_since_restore: 74558.12956261635\n",
      "  time_this_iter_s: 504.2352783679962\n",
      "  time_total_s: 74558.12956261635\n",
      "  timers:\n",
      "    learn_throughput: 103.556\n",
      "    learn_time_ms: 289697.979\n",
      "    sample_throughput: 140.606\n",
      "    sample_time_ms: 213362.767\n",
      "    update_time_ms: 3.004\n",
      "  timestamp: 1663021984\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4590000\n",
      "  training_iteration: 153\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    153 |          74558.1 | 4590000 |  331.213 |              386.096 |              288.731 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4620000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_17-41-27\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 363.2482811058511\n",
      "  episode_reward_mean: 320.90451867517453\n",
      "  episode_reward_min: 283.3946377481833\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3080\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.873871552183273\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02206046076305105\n",
      "          policy_loss: 0.01743405002961926\n",
      "          total_loss: 308.9822590507345\n",
      "          vf_explained_var: -4.311825341218878e-10\n",
      "          vf_loss: 308.9564490200611\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4620000\n",
      "    num_steps_sampled: 4620000\n",
      "    num_steps_trained: 4620000\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.526880222841225\n",
      "    ram_util_percent: 50.333147632311984\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806289644001501\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328023637549624\n",
      "    mean_inference_ms: 1.8267800298579095\n",
      "    mean_raw_obs_processing_ms: 2.2858278456292003\n",
      "  time_since_restore: 75061.2201371193\n",
      "  time_this_iter_s: 503.09057450294495\n",
      "  time_total_s: 75061.2201371193\n",
      "  timers:\n",
      "    learn_throughput: 103.53\n",
      "    learn_time_ms: 289770.194\n",
      "    sample_throughput: 140.618\n",
      "    sample_time_ms: 213344.573\n",
      "    update_time_ms: 3.014\n",
      "  timestamp: 1663022487\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4620000\n",
      "  training_iteration: 154\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.4/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    154 |          75061.2 | 4620000 |  320.905 |              363.248 |              283.395 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4650000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_17-49-51\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 363.2482811058511\n",
      "  episode_reward_mean: 316.6223542336001\n",
      "  episode_reward_min: 283.3946377481833\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3100\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.865400803545688\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025302917744290766\n",
      "          policy_loss: 0.02042493740393919\n",
      "          total_loss: 306.8257023912795\n",
      "          vf_explained_var: -5.884373432962775e-09\n",
      "          vf_loss: 306.7956695069658\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4650000\n",
      "    num_steps_sampled: 4650000\n",
      "    num_steps_trained: 4650000\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.58509749303621\n",
      "    ram_util_percent: 50.45236768802227\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806245164947012\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328023267800887\n",
      "    mean_inference_ms: 1.826801282212183\n",
      "    mean_raw_obs_processing_ms: 2.278607449063697\n",
      "  time_since_restore: 75564.72989797592\n",
      "  time_this_iter_s: 503.5097608566284\n",
      "  time_total_s: 75564.72989797592\n",
      "  timers:\n",
      "    learn_throughput: 103.525\n",
      "    learn_time_ms: 289784.035\n",
      "    sample_throughput: 140.621\n",
      "    sample_time_ms: 213338.748\n",
      "    update_time_ms: 3.035\n",
      "  timestamp: 1663022991\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4650000\n",
      "  training_iteration: 155\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    155 |          75564.7 | 4650000 |  316.622 |              363.248 |              283.395 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4680000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_17-58-15\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 363.2482811058511\n",
      "  episode_reward_mean: 316.0675619208299\n",
      "  episode_reward_min: 283.3946377481833\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3120\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8036662673950197\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022393747146075643\n",
      "          policy_loss: 0.017813658915866323\n",
      "          total_loss: 304.45053137271964\n",
      "          vf_explained_var: -2.7392772494749806e-09\n",
      "          vf_loss: 304.42421448727873\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4680000\n",
      "    num_steps_sampled: 4680000\n",
      "    num_steps_trained: 4680000\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.516550764951322\n",
      "    ram_util_percent: 50.46898470097357\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806184003873475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3279797558472\n",
      "    mean_inference_ms: 1.8268593769839665\n",
      "    mean_raw_obs_processing_ms: 2.2714832552301503\n",
      "  time_since_restore: 76068.89268946648\n",
      "  time_this_iter_s: 504.1627914905548\n",
      "  time_total_s: 76068.89268946648\n",
      "  timers:\n",
      "    learn_throughput: 103.483\n",
      "    learn_time_ms: 289903.574\n",
      "    sample_throughput: 140.627\n",
      "    sample_time_ms: 213330.515\n",
      "    update_time_ms: 3.006\n",
      "  timestamp: 1663023495\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4680000\n",
      "  training_iteration: 156\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    156 |          76068.9 | 4680000 |  316.068 |              363.248 |              283.395 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4710000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_18-06-39\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 363.2482811058511\n",
      "  episode_reward_mean: 317.88204720861495\n",
      "  episode_reward_min: 275.2251496151734\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3140\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.734771018738442\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021146638559256935\n",
      "          policy_loss: 0.013855798431236218\n",
      "          total_loss: 304.3744202601656\n",
      "          vf_explained_var: -3.906006629250669e-09\n",
      "          vf_loss: 304.3525359165922\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4710000\n",
      "    num_steps_sampled: 4710000\n",
      "    num_steps_trained: 4710000\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.475382475660638\n",
      "    ram_util_percent: 50.563421418637006\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806129866422051\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32797766845187\n",
      "    mean_inference_ms: 1.8269027227350125\n",
      "    mean_raw_obs_processing_ms: 2.2644475377454585\n",
      "  time_since_restore: 76572.7661755085\n",
      "  time_this_iter_s: 503.8734860420227\n",
      "  time_total_s: 76572.7661755085\n",
      "  timers:\n",
      "    learn_throughput: 103.431\n",
      "    learn_time_ms: 290047.369\n",
      "    sample_throughput: 140.623\n",
      "    sample_time_ms: 213335.879\n",
      "    update_time_ms: 3.006\n",
      "  timestamp: 1663023999\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4710000\n",
      "  training_iteration: 157\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    157 |          76572.8 | 4710000 |  317.882 |              363.248 |              275.225 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4740000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_18-15-05\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 348.2523204033796\n",
      "  episode_reward_mean: 316.1251239807362\n",
      "  episode_reward_min: 275.2251496151734\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3160\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.784570347298967\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024374435186680993\n",
      "          policy_loss: 0.021087723914533854\n",
      "          total_loss: 302.1554586337475\n",
      "          vf_explained_var: -3.3733693616255778e-09\n",
      "          vf_loss: 302.1251162427537\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4740000\n",
      "    num_steps_sampled: 4740000\n",
      "    num_steps_trained: 4740000\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.433656509695293\n",
      "    ram_util_percent: 50.56440443213297\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805990538292413\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328023011123605\n",
      "    mean_inference_ms: 1.8268906067590764\n",
      "    mean_raw_obs_processing_ms: 2.2575045408058565\n",
      "  time_since_restore: 77078.9111764431\n",
      "  time_this_iter_s: 506.14500093460083\n",
      "  time_total_s: 77078.9111764431\n",
      "  timers:\n",
      "    learn_throughput: 103.309\n",
      "    learn_time_ms: 290392.089\n",
      "    sample_throughput: 140.618\n",
      "    sample_time_ms: 213343.363\n",
      "    update_time_ms: 3.011\n",
      "  timestamp: 1663024505\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4740000\n",
      "  training_iteration: 158\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    158 |          77078.9 | 4740000 |  316.125 |              348.252 |              275.225 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4770000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_18-23-33\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 348.2523204033796\n",
      "  episode_reward_mean: 318.7296406704884\n",
      "  episode_reward_min: 275.2251496151734\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3180\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8370188814528445\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024138396935862155\n",
      "          policy_loss: 0.018210915475885603\n",
      "          total_loss: 300.6271756825549\n",
      "          vf_explained_var: -3.3480056504942013e-09\n",
      "          vf_loss: 300.5997997137841\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4770000\n",
      "    num_steps_sampled: 4770000\n",
      "    num_steps_trained: 4770000\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.421931034482757\n",
      "    ram_util_percent: 50.678896551724144\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805860080544864\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328076470968636\n",
      "    mean_inference_ms: 1.8268786907974515\n",
      "    mean_raw_obs_processing_ms: 2.250645982756186\n",
      "  time_since_restore: 77586.63958954811\n",
      "  time_this_iter_s: 507.728413105011\n",
      "  time_total_s: 77586.63958954811\n",
      "  timers:\n",
      "    learn_throughput: 103.115\n",
      "    learn_time_ms: 290936.392\n",
      "    sample_throughput: 140.622\n",
      "    sample_time_ms: 213337.881\n",
      "    update_time_ms: 3.042\n",
      "  timestamp: 1663025013\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4770000\n",
      "  training_iteration: 159\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    159 |          77586.6 | 4770000 |   318.73 |              348.252 |              275.225 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4800000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_18-32-01\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 355.0073970277463\n",
      "  episode_reward_mean: 324.337661837517\n",
      "  episode_reward_min: 275.2251496151734\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3200\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8456395284165725\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024683459979170187\n",
      "          policy_loss: 0.019205615351254\n",
      "          total_loss: 294.7707601993642\n",
      "          vf_explained_var: -2.7392772494749806e-09\n",
      "          vf_loss: 294.7421824775858\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4800000\n",
      "    num_steps_sampled: 4800000\n",
      "    num_steps_trained: 4800000\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.498482758620693\n",
      "    ram_util_percent: 50.6944827586207\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805619085558886\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328154945687615\n",
      "    mean_inference_ms: 1.8268386639062486\n",
      "    mean_raw_obs_processing_ms: 2.2438739778594514\n",
      "  time_since_restore: 78094.82898616791\n",
      "  time_this_iter_s: 508.18939661979675\n",
      "  time_total_s: 78094.82898616791\n",
      "  timers:\n",
      "    learn_throughput: 102.949\n",
      "    learn_time_ms: 291406.895\n",
      "    sample_throughput: 140.63\n",
      "    sample_time_ms: 213325.372\n",
      "    update_time_ms: 3.047\n",
      "  timestamp: 1663025521\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4800000\n",
      "  training_iteration: 160\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    160 |          78094.8 | 4800000 |  324.338 |              355.007 |              275.225 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4830000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_18-40-34\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 355.0073970277463\n",
      "  episode_reward_mean: 326.830698794349\n",
      "  episode_reward_min: 275.2251496151734\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3220\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8197668838500975\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026491907088859082\n",
      "          policy_loss: 0.022531468635623126\n",
      "          total_loss: 298.74974322217577\n",
      "          vf_explained_var: -2.8914592942186346e-09\n",
      "          vf_loss: 298.71715293559623\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4830000\n",
      "    num_steps_sampled: 4830000\n",
      "    num_steps_trained: 4830000\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.41190150478796\n",
      "    ram_util_percent: 50.770314637482905\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805324526188799\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328228572950557\n",
      "    mean_inference_ms: 1.826792007103788\n",
      "    mean_raw_obs_processing_ms: 2.2371967979930987\n",
      "  time_since_restore: 78606.88790941238\n",
      "  time_this_iter_s: 512.0589232444763\n",
      "  time_total_s: 78606.88790941238\n",
      "  timers:\n",
      "    learn_throughput: 102.642\n",
      "    learn_time_ms: 292278.675\n",
      "    sample_throughput: 140.634\n",
      "    sample_time_ms: 213319.587\n",
      "    update_time_ms: 3.053\n",
      "  timestamp: 1663026034\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4830000\n",
      "  training_iteration: 161\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    161 |          78606.9 | 4830000 |  326.831 |              355.007 |              275.225 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4860000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_18-49-09\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 355.0073970277463\n",
      "  episode_reward_mean: 326.6598731779093\n",
      "  episode_reward_min: 284.9179035655231\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3240\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.7863432632608616\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024263907516811293\n",
      "          policy_loss: 0.0188048957143613\n",
      "          total_loss: 300.55139103016955\n",
      "          vf_explained_var: -2.4856405822504257e-09\n",
      "          vf_loss: 300.5233734812635\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4860000\n",
      "    num_steps_sampled: 4860000\n",
      "    num_steps_trained: 4860000\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.296059782608694\n",
      "    ram_util_percent: 50.79769021739131\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805041294261652\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328244060741795\n",
      "    mean_inference_ms: 1.8267729575908118\n",
      "    mean_raw_obs_processing_ms: 2.2306313519395\n",
      "  time_since_restore: 79122.7050602436\n",
      "  time_this_iter_s: 515.8171508312225\n",
      "  time_total_s: 79122.7050602436\n",
      "  timers:\n",
      "    learn_throughput: 102.205\n",
      "    learn_time_ms: 293527.547\n",
      "    sample_throughput: 140.622\n",
      "    sample_time_ms: 213337.212\n",
      "    update_time_ms: 3.046\n",
      "  timestamp: 1663026549\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4860000\n",
      "  training_iteration: 162\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    162 |          79122.7 | 4860000 |   326.66 |              355.007 |              284.918 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4890000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_18-57-47\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 355.0073970277463\n",
      "  episode_reward_mean: 324.3714359141813\n",
      "  episode_reward_min: 284.8684961098765\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3260\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.862201400716254\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02630747222490239\n",
      "          policy_loss: 0.015889560439267217\n",
      "          total_loss: 297.01503739377284\n",
      "          vf_explained_var: -3.1958236057505474e-09\n",
      "          vf_loss: 296.98915882516417\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4890000\n",
      "    num_steps_sampled: 4890000\n",
      "    num_steps_trained: 4890000\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.277476255088196\n",
      "    ram_util_percent: 50.91370420624151\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804791150623702\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328302041765447\n",
      "    mean_inference_ms: 1.82674126646643\n",
      "    mean_raw_obs_processing_ms: 2.224114597932204\n",
      "  time_since_restore: 79639.76815748215\n",
      "  time_this_iter_s: 517.0630972385406\n",
      "  time_total_s: 79639.76815748215\n",
      "  timers:\n",
      "    learn_throughput: 101.755\n",
      "    learn_time_ms: 294825.096\n",
      "    sample_throughput: 140.632\n",
      "    sample_time_ms: 213322.45\n",
      "    update_time_ms: 3.052\n",
      "  timestamp: 1663027067\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4890000\n",
      "  training_iteration: 163\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    163 |          79639.8 | 4890000 |  324.371 |              355.007 |              284.868 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4920000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_19-06-26\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 355.0073970277463\n",
      "  episode_reward_mean: 322.5058808096274\n",
      "  episode_reward_min: 284.8684961098765\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3280\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.757930568126922\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024198211323980288\n",
      "          policy_loss: 0.018232345312358216\n",
      "          total_loss: 301.14378388749793\n",
      "          vf_explained_var: -2.81536838286911e-09\n",
      "          vf_loss: 301.11636322670796\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4920000\n",
      "    num_steps_sampled: 4920000\n",
      "    num_steps_trained: 4920000\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.24345479082321\n",
      "    ram_util_percent: 50.963697705802964\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804554017816962\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328426080336204\n",
      "    mean_inference_ms: 1.8266903575419764\n",
      "    mean_raw_obs_processing_ms: 2.217684641989228\n",
      "  time_since_restore: 80158.5471329689\n",
      "  time_this_iter_s: 518.7789754867554\n",
      "  time_total_s: 80158.5471329689\n",
      "  timers:\n",
      "    learn_throughput: 101.226\n",
      "    learn_time_ms: 296365.6\n",
      "    sample_throughput: 140.614\n",
      "    sample_time_ms: 213350.625\n",
      "    update_time_ms: 3.108\n",
      "  timestamp: 1663027586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4920000\n",
      "  training_iteration: 164\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    164 |          80158.5 | 4920000 |  322.506 |              355.007 |              284.868 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4950000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_19-15-05\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 348.50049572139477\n",
      "  episode_reward_mean: 318.27939474788604\n",
      "  episode_reward_min: 284.8684961098765\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3300\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.859523419725134\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025404963553759548\n",
      "          policy_loss: 0.019809200138626422\n",
      "          total_loss: 297.06551427638277\n",
      "          vf_explained_var: -2.1559127816317414e-09\n",
      "          vf_loss: 297.03605887230407\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4950000\n",
      "    num_steps_sampled: 4950000\n",
      "    num_steps_trained: 4950000\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.20013495276653\n",
      "    ram_util_percent: 51.039406207827255\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804367008539302\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328578716372622\n",
      "    mean_inference_ms: 1.8265947763595596\n",
      "    mean_raw_obs_processing_ms: 2.2113297817147064\n",
      "  time_since_restore: 80678.18235945702\n",
      "  time_this_iter_s: 519.6352264881134\n",
      "  time_total_s: 80678.18235945702\n",
      "  timers:\n",
      "    learn_throughput: 100.674\n",
      "    learn_time_ms: 297990.404\n",
      "    sample_throughput: 140.622\n",
      "    sample_time_ms: 213338.37\n",
      "    update_time_ms: 3.099\n",
      "  timestamp: 1663028105\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4950000\n",
      "  training_iteration: 165\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    165 |          80678.2 | 4950000 |  318.279 |                348.5 |              284.868 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 4980000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_19-23-44\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 336.88437261396587\n",
      "  episode_reward_mean: 315.8052236045319\n",
      "  episode_reward_min: 284.8684961098765\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3320\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.741559483548428\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021611949392753058\n",
      "          policy_loss: 0.015050556957028172\n",
      "          total_loss: 297.51449030774705\n",
      "          vf_explained_var: -3.424096561843726e-09\n",
      "          vf_loss: 297.49123419903697\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 4980000\n",
      "    num_steps_sampled: 4980000\n",
      "    num_steps_trained: 4980000\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.328146143437078\n",
      "    ram_util_percent: 51.32002706359945\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804234792021047\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32869731594423\n",
      "    mean_inference_ms: 1.8265133649731207\n",
      "    mean_raw_obs_processing_ms: 2.205058301622247\n",
      "  time_since_restore: 81196.43490386009\n",
      "  time_this_iter_s: 518.2525444030762\n",
      "  time_total_s: 81196.43490386009\n",
      "  timers:\n",
      "    learn_throughput: 100.196\n",
      "    learn_time_ms: 299412.795\n",
      "    sample_throughput: 140.631\n",
      "    sample_time_ms: 213324.808\n",
      "    update_time_ms: 3.102\n",
      "  timestamp: 1663028624\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4980000\n",
      "  training_iteration: 166\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    166 |          81196.4 | 4980000 |  315.805 |              336.884 |              284.868 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5010000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_19-32-25\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 336.88437261396587\n",
      "  episode_reward_mean: 316.8336525966122\n",
      "  episode_reward_min: 284.8684961098765\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3340\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8269615578144154\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025071393007145285\n",
      "          policy_loss: 0.020000129033751944\n",
      "          total_loss: 294.42060704982026\n",
      "          vf_explained_var: -3.018277849875517e-09\n",
      "          vf_loss: 294.391086760176\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5010000\n",
      "    num_steps_sampled: 5010000\n",
      "    num_steps_trained: 5010000\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.22671140939597\n",
      "    ram_util_percent: 51.13812080536913\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804152797939042\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32882509736784\n",
      "    mean_inference_ms: 1.8264435728148567\n",
      "    mean_raw_obs_processing_ms: 2.1988546714859494\n",
      "  time_since_restore: 81718.19381546974\n",
      "  time_this_iter_s: 521.7589116096497\n",
      "  time_total_s: 81718.19381546974\n",
      "  timers:\n",
      "    learn_throughput: 99.603\n",
      "    learn_time_ms: 301196.57\n",
      "    sample_throughput: 140.628\n",
      "    sample_time_ms: 213329.348\n",
      "    update_time_ms: 3.099\n",
      "  timestamp: 1663029145\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5010000\n",
      "  training_iteration: 167\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    167 |          81718.2 | 5010000 |  316.834 |              336.884 |              284.868 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5040000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_19-41-07\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 340.580036827518\n",
      "  episode_reward_mean: 318.46756352150516\n",
      "  episode_reward_min: 292.20167894625894\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3360\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8419469556402652\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022353186280555947\n",
      "          policy_loss: 0.017992893012656653\n",
      "          total_loss: 295.32461081565697\n",
      "          vf_explained_var: -1.2681838912342869e-09\n",
      "          vf_loss: 295.29813024074474\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5040000\n",
      "    num_steps_sampled: 5040000\n",
      "    num_steps_trained: 5040000\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.243951612903224\n",
      "    ram_util_percent: 51.2255376344086\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804097149435011\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328905200727522\n",
      "    mean_inference_ms: 1.8264048410673406\n",
      "    mean_raw_obs_processing_ms: 2.1927338206457936\n",
      "  time_since_restore: 82239.51039648056\n",
      "  time_this_iter_s: 521.3165810108185\n",
      "  time_total_s: 82239.51039648056\n",
      "  timers:\n",
      "    learn_throughput: 99.098\n",
      "    learn_time_ms: 302729.246\n",
      "    sample_throughput: 140.638\n",
      "    sample_time_ms: 213313.717\n",
      "    update_time_ms: 3.146\n",
      "  timestamp: 1663029667\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5040000\n",
      "  training_iteration: 168\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    168 |          82239.5 | 5040000 |  318.468 |               340.58 |              292.202 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5070000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_19-49-50\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 340.8847574542818\n",
      "  episode_reward_mean: 320.75600635327964\n",
      "  episode_reward_min: 292.20167894625894\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3380\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.967735660025414\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026714810742996826\n",
      "          policy_loss: 0.02249076188660841\n",
      "          total_loss: 290.7074105412909\n",
      "          vf_explained_var: -3.0943687612250415e-09\n",
      "          vf_loss: 290.67477681910736\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5070000\n",
      "    num_steps_sampled: 5070000\n",
      "    num_steps_trained: 5070000\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.22788203753351\n",
      "    ram_util_percent: 51.33136729222521\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804149001392692\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328899275726467\n",
      "    mean_inference_ms: 1.826401950775426\n",
      "    mean_raw_obs_processing_ms: 2.1866859903092832\n",
      "  time_since_restore: 82762.6986527443\n",
      "  time_this_iter_s: 523.1882562637329\n",
      "  time_total_s: 82762.6986527443\n",
      "  timers:\n",
      "    learn_throughput: 98.596\n",
      "    learn_time_ms: 304272.679\n",
      "    sample_throughput: 140.636\n",
      "    sample_time_ms: 213316.486\n",
      "    update_time_ms: 3.11\n",
      "  timestamp: 1663030190\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5070000\n",
      "  training_iteration: 169\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    169 |          82762.7 | 5070000 |  320.756 |              340.885 |              292.202 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5100000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_19-58-34\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 344.2860064504996\n",
      "  episode_reward_mean: 324.03452344836495\n",
      "  episode_reward_min: 298.0804053932425\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3400\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.988925004512706\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025922668874499538\n",
      "          policy_loss: 0.02089916669823071\n",
      "          total_loss: 294.0430076274466\n",
      "          vf_explained_var: -2.612458915862703e-09\n",
      "          vf_loss: 294.0122657970672\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5100000\n",
      "    num_steps_sampled: 5100000\n",
      "    num_steps_trained: 5100000\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.209236947791165\n",
      "    ram_util_percent: 51.33855421686747\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804298687069334\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32886647430363\n",
      "    mean_inference_ms: 1.8264615235363737\n",
      "    mean_raw_obs_processing_ms: 2.180711256136538\n",
      "  time_since_restore: 83286.31138467789\n",
      "  time_this_iter_s: 523.6127319335938\n",
      "  time_total_s: 83286.31138467789\n",
      "  timers:\n",
      "    learn_throughput: 98.105\n",
      "    learn_time_ms: 305794.899\n",
      "    sample_throughput: 140.623\n",
      "    sample_time_ms: 213336.723\n",
      "    update_time_ms: 3.103\n",
      "  timestamp: 1663030714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5100000\n",
      "  training_iteration: 170\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    170 |          83286.3 | 5100000 |  324.035 |              344.286 |               298.08 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5130000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_20-07-18\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 344.2860064504996\n",
      "  episode_reward_mean: 317.6258969683899\n",
      "  episode_reward_min: 262.6130538578347\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3420\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9642416116024584\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026162218387768957\n",
      "          policy_loss: 0.017609028896871718\n",
      "          total_loss: 294.24244804219995\n",
      "          vf_explained_var: -2.8407320940004865e-09\n",
      "          vf_loss: 294.21490563250603\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5130000\n",
      "    num_steps_sampled: 5130000\n",
      "    num_steps_trained: 5130000\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.246122994652406\n",
      "    ram_util_percent: 51.388502673796786\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804542893006854\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328892508059155\n",
      "    mean_inference_ms: 1.826503963985258\n",
      "    mean_raw_obs_processing_ms: 2.174796037720359\n",
      "  time_since_restore: 83810.01946020126\n",
      "  time_this_iter_s: 523.7080755233765\n",
      "  time_total_s: 83810.01946020126\n",
      "  timers:\n",
      "    learn_throughput: 97.738\n",
      "    learn_time_ms: 306942.209\n",
      "    sample_throughput: 140.611\n",
      "    sample_time_ms: 213354.305\n",
      "    update_time_ms: 3.114\n",
      "  timestamp: 1663031238\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5130000\n",
      "  training_iteration: 171\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    171 |            83810 | 5130000 |  317.626 |              344.286 |              262.613 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5160000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_20-16-02\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 344.2860064504996\n",
      "  episode_reward_mean: 312.1397684956801\n",
      "  episode_reward_min: 262.6130538578347\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3440\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8842632410374094\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028755873297985398\n",
      "          policy_loss: 0.01747423538839088\n",
      "          total_loss: 295.7843473848383\n",
      "          vf_explained_var: -2.0037305148434825e-09\n",
      "          vf_loss: 295.75595514500395\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5160000\n",
      "    num_steps_sampled: 5160000\n",
      "    num_steps_trained: 5160000\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.183021390374332\n",
      "    ram_util_percent: 51.4427807486631\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804712270062712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3289570559633\n",
      "    mean_inference_ms: 1.8265184837840587\n",
      "    mean_raw_obs_processing_ms: 2.1689462687158216\n",
      "  time_since_restore: 84334.6185913086\n",
      "  time_this_iter_s: 524.5991311073303\n",
      "  time_total_s: 84334.6185913086\n",
      "  timers:\n",
      "    learn_throughput: 97.456\n",
      "    learn_time_ms: 307831.584\n",
      "    sample_throughput: 140.619\n",
      "    sample_time_ms: 213343.138\n",
      "    update_time_ms: 3.116\n",
      "  timestamp: 1663031762\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5160000\n",
      "  training_iteration: 172\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.7/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    172 |          84334.6 | 5160000 |   312.14 |              344.286 |              262.613 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5190000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_20-24-46\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 344.2860064504996\n",
      "  episode_reward_mean: 304.9057454459747\n",
      "  episode_reward_min: 262.6130538578347\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3460\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.84569247276225\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02703358535337821\n",
      "          policy_loss: 0.018566217439130266\n",
      "          total_loss: 293.13146313119444\n",
      "          vf_explained_var: -2.4095494488562963e-09\n",
      "          vf_loss: 293.1026325534252\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5190000\n",
      "    num_steps_sampled: 5190000\n",
      "    num_steps_trained: 5190000\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.207898259705487\n",
      "    ram_util_percent: 51.560374832663975\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804859914868399\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328990240725524\n",
      "    mean_inference_ms: 1.8265453328034067\n",
      "    mean_raw_obs_processing_ms: 2.1631801266790722\n",
      "  time_since_restore: 84857.83908581734\n",
      "  time_this_iter_s: 523.2204945087433\n",
      "  time_total_s: 84857.83908581734\n",
      "  timers:\n",
      "    learn_throughput: 97.26\n",
      "    learn_time_ms: 308453.059\n",
      "    sample_throughput: 140.622\n",
      "    sample_time_ms: 213337.424\n",
      "    update_time_ms: 3.089\n",
      "  timestamp: 1663032286\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5190000\n",
      "  training_iteration: 173\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    173 |          84857.8 | 5190000 |  304.906 |              344.286 |              262.613 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5220000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_20-33-31\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 344.2860064504996\n",
      "  episode_reward_mean: 293.9939937828248\n",
      "  episode_reward_min: 256.5276297070733\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3480\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.961651951708692\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.022138552745764886\n",
      "          policy_loss: 0.015908178275629403\n",
      "          total_loss: 294.11035279294276\n",
      "          vf_explained_var: -1.6993664253561747e-09\n",
      "          vf_loss: 294.08603879888005\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5220000\n",
      "    num_steps_sampled: 5220000\n",
      "    num_steps_trained: 5220000\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.160133333333334\n",
      "    ram_util_percent: 51.56546666666666\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804988873473686\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32905000009777\n",
      "    mean_inference_ms: 1.8265624649315786\n",
      "    mean_raw_obs_processing_ms: 2.1574872936890954\n",
      "  time_since_restore: 85383.3051404953\n",
      "  time_this_iter_s: 525.4660546779633\n",
      "  time_total_s: 85383.3051404953\n",
      "  timers:\n",
      "    learn_throughput: 97.042\n",
      "    learn_time_ms: 309144.827\n",
      "    sample_throughput: 140.637\n",
      "    sample_time_ms: 213314.529\n",
      "    update_time_ms: 3.021\n",
      "  timestamp: 1663032811\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5220000\n",
      "  training_iteration: 174\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    174 |          85383.3 | 5220000 |  293.994 |              344.286 |              256.528 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5250000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_20-42-17\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 320.98974687257333\n",
      "  episode_reward_mean: 282.35225776188867\n",
      "  episode_reward_min: 250.9062364887817\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3500\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.811882635887633\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023563724308190887\n",
      "          policy_loss: 0.01720847095739334\n",
      "          total_loss: 295.6747079110653\n",
      "          vf_explained_var: -2.916823005350011e-09\n",
      "          vf_loss: 295.6485528402126\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5250000\n",
      "    num_steps_sampled: 5250000\n",
      "    num_steps_trained: 5250000\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.14045393858478\n",
      "    ram_util_percent: 51.62283044058745\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805045433933398\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3291299117793\n",
      "    mean_inference_ms: 1.8265295507051291\n",
      "    mean_raw_obs_processing_ms: 2.15185528254737\n",
      "  time_since_restore: 85908.71173596382\n",
      "  time_this_iter_s: 525.4065954685211\n",
      "  time_total_s: 85908.71173596382\n",
      "  timers:\n",
      "    learn_throughput: 96.864\n",
      "    learn_time_ms: 309712.787\n",
      "    sample_throughput: 140.631\n",
      "    sample_time_ms: 213323.711\n",
      "    update_time_ms: 3.013\n",
      "  timestamp: 1663033337\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5250000\n",
      "  training_iteration: 175\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    175 |          85908.7 | 5250000 |  282.352 |               320.99 |              250.906 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5280000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_20-51-03\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 309.18392859832284\n",
      "  episode_reward_mean: 277.67737855779893\n",
      "  episode_reward_min: 244.90688369651238\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3520\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8962105758139427\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024872090840276435\n",
      "          policy_loss: 0.018741319711577702\n",
      "          total_loss: 291.3270359347729\n",
      "          vf_explained_var: -2.5617314935999502e-09\n",
      "          vf_loss: 291.29885108136114\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5280000\n",
      "    num_steps_sampled: 5280000\n",
      "    num_steps_trained: 5280000\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.22849533954727\n",
      "    ram_util_percent: 51.701597869507324\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805039734892403\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32918058672883\n",
      "    mean_inference_ms: 1.8265020846060174\n",
      "    mean_raw_obs_processing_ms: 2.146297958395289\n",
      "  time_since_restore: 86435.1044409275\n",
      "  time_this_iter_s: 526.3927049636841\n",
      "  time_total_s: 86435.1044409275\n",
      "  timers:\n",
      "    learn_throughput: 96.616\n",
      "    learn_time_ms: 310506.254\n",
      "    sample_throughput: 140.618\n",
      "    sample_time_ms: 213344.319\n",
      "    update_time_ms: 3.049\n",
      "  timestamp: 1663033863\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5280000\n",
      "  training_iteration: 176\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    176 |          86435.1 | 5280000 |  277.677 |              309.184 |              244.907 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5310000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_20-59-51\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 309.18392859832284\n",
      "  episode_reward_mean: 267.9553087489147\n",
      "  episode_reward_min: 211.771908593353\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3540\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9686092152494066\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027970863415443668\n",
      "          policy_loss: 0.022581601837833233\n",
      "          total_loss: 295.0600495553524\n",
      "          vf_explained_var: -2.3334585375067718e-09\n",
      "          vf_loss: 295.02684718679876\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5310000\n",
      "    num_steps_sampled: 5310000\n",
      "    num_steps_trained: 5310000\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.13585657370518\n",
      "    ram_util_percent: 51.78844621513945\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805073848116343\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32920320011044\n",
      "    mean_inference_ms: 1.8264797287571763\n",
      "    mean_raw_obs_processing_ms: 2.140812950734796\n",
      "  time_since_restore: 86962.85059905052\n",
      "  time_this_iter_s: 527.7461581230164\n",
      "  time_total_s: 86962.85059905052\n",
      "  timers:\n",
      "    learn_throughput: 96.432\n",
      "    learn_time_ms: 311100.171\n",
      "    sample_throughput: 140.615\n",
      "    sample_time_ms: 213349.195\n",
      "    update_time_ms: 3.14\n",
      "  timestamp: 1663034391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5310000\n",
      "  training_iteration: 177\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    177 |          86962.9 | 5310000 |  267.955 |              309.184 |              211.772 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5340000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_21-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 290.54746167978124\n",
      "  episode_reward_mean: 258.64430602590414\n",
      "  episode_reward_min: 211.771908593353\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3560\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.986612780144874\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02999778954327105\n",
      "          policy_loss: 0.021505059349707308\n",
      "          total_loss: 293.43816301061753\n",
      "          vf_explained_var: -2.9929141387441405e-09\n",
      "          vf_loss: 293.4052682819772\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5340000\n",
      "    num_steps_sampled: 5340000\n",
      "    num_steps_trained: 5340000\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.056481481481484\n",
      "    ram_util_percent: 51.88161375661376\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805080642136687\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32925968594083\n",
      "    mean_inference_ms: 1.8264467536781541\n",
      "    mean_raw_obs_processing_ms: 2.135377289479529\n",
      "  time_since_restore: 87492.32662534714\n",
      "  time_this_iter_s: 529.4760262966156\n",
      "  time_total_s: 87492.32662534714\n",
      "  timers:\n",
      "    learn_throughput: 96.184\n",
      "    learn_time_ms: 311900.77\n",
      "    sample_throughput: 140.604\n",
      "    sample_time_ms: 213364.674\n",
      "    update_time_ms: 3.088\n",
      "  timestamp: 1663034921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5340000\n",
      "  training_iteration: 178\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.8/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    178 |          87492.3 | 5340000 |  258.644 |              290.547 |              211.772 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5370000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_21-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 289.6326925286379\n",
      "  episode_reward_mean: 248.5730778735404\n",
      "  episode_reward_min: 199.80062819822393\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3580\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9488503854832753\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025806288272031196\n",
      "          policy_loss: 0.01917917486309926\n",
      "          total_loss: 295.1891283400515\n",
      "          vf_explained_var: -5.580009232453165e-10\n",
      "          vf_loss: 295.160151240572\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5370000\n",
      "    num_steps_sampled: 5370000\n",
      "    num_steps_trained: 5370000\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.09468791500664\n",
      "    ram_util_percent: 51.9\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08805019063740255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32932871610691\n",
      "    mean_inference_ms: 1.8264157164449164\n",
      "    mean_raw_obs_processing_ms: 2.1300106772174074\n",
      "  time_since_restore: 88020.470225811\n",
      "  time_this_iter_s: 528.1436004638672\n",
      "  time_total_s: 88020.470225811\n",
      "  timers:\n",
      "    learn_throughput: 96.041\n",
      "    learn_time_ms: 312367.938\n",
      "    sample_throughput: 140.586\n",
      "    sample_time_ms: 213392.905\n",
      "    update_time_ms: 3.086\n",
      "  timestamp: 1663035449\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5370000\n",
      "  training_iteration: 179\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    179 |          88020.5 | 5370000 |  248.573 |              289.633 |              199.801 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5400000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_21-26-19\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 289.6326925286379\n",
      "  episode_reward_mean: 239.13591931670416\n",
      "  episode_reward_min: 180.1952980643129\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3600\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.07456259189768\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02587385566117517\n",
      "          policy_loss: 0.02070845663042224\n",
      "          total_loss: 290.7913157199292\n",
      "          vf_explained_var: -2.7392772494749806e-09\n",
      "          vf_loss: 290.7607833602581\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5400000\n",
      "    num_steps_sampled: 5400000\n",
      "    num_steps_trained: 5400000\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.10357142857143\n",
      "    ram_util_percent: 52.00820105820105\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880492197727581\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329404689454222\n",
      "    mean_inference_ms: 1.8264098688339714\n",
      "    mean_raw_obs_processing_ms: 2.1247156545596924\n",
      "  time_since_restore: 88550.18303799629\n",
      "  time_this_iter_s: 529.7128121852875\n",
      "  time_total_s: 88550.18303799629\n",
      "  timers:\n",
      "    learn_throughput: 95.853\n",
      "    learn_time_ms: 312978.992\n",
      "    sample_throughput: 140.586\n",
      "    sample_time_ms: 213391.88\n",
      "    update_time_ms: 3.093\n",
      "  timestamp: 1663035979\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5400000\n",
      "  training_iteration: 180\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    180 |          88550.2 | 5400000 |  239.136 |              289.633 |              180.195 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5430000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_21-35-07\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 269.47252009643984\n",
      "  episode_reward_mean: 232.92042926235163\n",
      "  episode_reward_min: 180.1952980643129\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3620\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9642560177661004\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02768274534523426\n",
      "          policy_loss: 0.015683931615352233\n",
      "          total_loss: 282.39741266615846\n",
      "          vf_explained_var: -2.181276270718513e-09\n",
      "          vf_loss: 282.3712177390241\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5430000\n",
      "    num_steps_sampled: 5430000\n",
      "    num_steps_trained: 5430000\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.145019920318727\n",
      "    ram_util_percent: 52.07250996015935\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804811118221441\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329466335852757\n",
      "    mean_inference_ms: 1.826406702604134\n",
      "    mean_raw_obs_processing_ms: 2.1194743069478417\n",
      "  time_since_restore: 89078.054199934\n",
      "  time_this_iter_s: 527.8711619377136\n",
      "  time_total_s: 89078.054199934\n",
      "  timers:\n",
      "    learn_throughput: 95.719\n",
      "    learn_time_ms: 313418.002\n",
      "    sample_throughput: 140.601\n",
      "    sample_time_ms: 213369.079\n",
      "    update_time_ms: 3.075\n",
      "  timestamp: 1663036507\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5430000\n",
      "  training_iteration: 181\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 15.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    181 |          89078.1 | 5430000 |   232.92 |              269.473 |              180.195 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5460000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_21-43-57\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 257.07319586955975\n",
      "  episode_reward_mean: 226.47068335133127\n",
      "  episode_reward_min: 180.1952980643129\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3640\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.093747901815049\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025142988399008186\n",
      "          policy_loss: 0.017401436209440867\n",
      "          total_loss: 283.6247555866647\n",
      "          vf_explained_var: -2.7900046717377336e-09\n",
      "          vf_loss: 283.597807490572\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5460000\n",
      "    num_steps_sampled: 5460000\n",
      "    num_steps_trained: 5460000\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.211492734478202\n",
      "    ram_util_percent: 52.14676354029061\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804700386423789\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329505849462272\n",
      "    mean_inference_ms: 1.826423731283771\n",
      "    mean_raw_obs_processing_ms: 2.114291497514577\n",
      "  time_since_restore: 89608.49881458282\n",
      "  time_this_iter_s: 530.444614648819\n",
      "  time_total_s: 89608.49881458282\n",
      "  timers:\n",
      "    learn_throughput: 95.541\n",
      "    learn_time_ms: 314002.246\n",
      "    sample_throughput: 140.601\n",
      "    sample_time_ms: 213369.366\n",
      "    update_time_ms: 3.082\n",
      "  timestamp: 1663037037\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5460000\n",
      "  training_iteration: 182\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 15.9/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    182 |          89608.5 | 5460000 |  226.471 |              257.073 |              180.195 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5490000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_21-52-46\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 257.07319586955975\n",
      "  episode_reward_mean: 221.64796408912426\n",
      "  episode_reward_min: 180.1952980643129\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3660\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.970211040212753\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024448950978682365\n",
      "          policy_loss: 0.01726439879127243\n",
      "          total_loss: 281.19313205475504\n",
      "          vf_explained_var: -1.4203660470002433e-09\n",
      "          vf_loss: 281.1665850115837\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5490000\n",
      "    num_steps_sampled: 5490000\n",
      "    num_steps_trained: 5490000\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.15880794701987\n",
      "    ram_util_percent: 52.18158940397351\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804667470591082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329482074716225\n",
      "    mean_inference_ms: 1.8264622714926924\n",
      "    mean_raw_obs_processing_ms: 2.1091675354936803\n",
      "  time_since_restore: 90137.35153889656\n",
      "  time_this_iter_s: 528.852724313736\n",
      "  time_total_s: 90137.35153889656\n",
      "  timers:\n",
      "    learn_throughput: 95.368\n",
      "    learn_time_ms: 314572.362\n",
      "    sample_throughput: 140.606\n",
      "    sample_time_ms: 213362.474\n",
      "    update_time_ms: 3.08\n",
      "  timestamp: 1663037566\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5490000\n",
      "  training_iteration: 183\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    183 |          90137.4 | 5490000 |  221.648 |              257.073 |              180.195 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5520000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_22-01-36\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 248.08419951459504\n",
      "  episode_reward_mean: 220.02966533969814\n",
      "  episode_reward_min: 154.98957982586435\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3680\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.9955336567696103\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025526695466164637\n",
      "          policy_loss: 0.01841883601085778\n",
      "          total_loss: 273.05528722884804\n",
      "          vf_explained_var: -3.1958236057505474e-09\n",
      "          vf_loss: 273.02717658184946\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5520000\n",
      "    num_steps_sampled: 5520000\n",
      "    num_steps_trained: 5520000\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.116423841059603\n",
      "    ram_util_percent: 52.2282119205298\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804647114537621\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329430989639658\n",
      "    mean_inference_ms: 1.826490784259236\n",
      "    mean_raw_obs_processing_ms: 2.104082640251883\n",
      "  time_since_restore: 90666.49334549904\n",
      "  time_this_iter_s: 529.141806602478\n",
      "  time_total_s: 90666.49334549904\n",
      "  timers:\n",
      "    learn_throughput: 95.256\n",
      "    learn_time_ms: 314940.376\n",
      "    sample_throughput: 140.606\n",
      "    sample_time_ms: 213362.092\n",
      "    update_time_ms: 3.081\n",
      "  timestamp: 1663038096\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5520000\n",
      "  training_iteration: 184\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    184 |          90666.5 | 5520000 |   220.03 |              248.084 |               154.99 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5550000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_22-10-27\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 248.08419951459504\n",
      "  episode_reward_mean: 219.93510606905744\n",
      "  episode_reward_min: 154.98957982586435\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3700\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.128551256504465\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026727829090520353\n",
      "          policy_loss: 0.02069072802194414\n",
      "          total_loss: 270.3535008953987\n",
      "          vf_explained_var: -2.3588220265935433e-09\n",
      "          vf_loss: 270.32266126754433\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5550000\n",
      "    num_steps_sampled: 5550000\n",
      "    num_steps_trained: 5550000\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.049868073878628\n",
      "    ram_util_percent: 52.29300791556729\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804630798331607\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329358291197696\n",
      "    mean_inference_ms: 1.826516578133051\n",
      "    mean_raw_obs_processing_ms: 2.099049604383346\n",
      "  time_since_restore: 91197.87123584747\n",
      "  time_this_iter_s: 531.3778903484344\n",
      "  time_total_s: 91197.87123584747\n",
      "  timers:\n",
      "    learn_throughput: 95.074\n",
      "    learn_time_ms: 315544.709\n",
      "    sample_throughput: 140.611\n",
      "    sample_time_ms: 213354.797\n",
      "    update_time_ms: 3.088\n",
      "  timestamp: 1663038627\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5550000\n",
      "  training_iteration: 185\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    185 |          91197.9 | 5550000 |  219.935 |              248.084 |               154.99 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5580000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_22-19-20\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 236.43525907941594\n",
      "  episode_reward_mean: 216.20930075764775\n",
      "  episode_reward_min: 154.98957982586435\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3720\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.307504681932166\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.027653931585002036\n",
      "          policy_loss: 0.0181496064014178\n",
      "          total_loss: 270.7466274732225\n",
      "          vf_explained_var: -5.580009232453165e-10\n",
      "          vf_loss: 270.7179779929303\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5580000\n",
      "    num_steps_sampled: 5580000\n",
      "    num_steps_trained: 5580000\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.994473684210526\n",
      "    ram_util_percent: 52.36105263157896\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804601920712844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32931779892403\n",
      "    mean_inference_ms: 1.8265288226442111\n",
      "    mean_raw_obs_processing_ms: 2.0940749443075326\n",
      "  time_since_restore: 91730.47974777222\n",
      "  time_this_iter_s: 532.6085119247437\n",
      "  time_total_s: 91730.47974777222\n",
      "  timers:\n",
      "    learn_throughput: 94.888\n",
      "    learn_time_ms: 316162.258\n",
      "    sample_throughput: 140.608\n",
      "    sample_time_ms: 213358.795\n",
      "    update_time_ms: 3.056\n",
      "  timestamp: 1663039160\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5580000\n",
      "  training_iteration: 186\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    186 |          91730.5 | 5580000 |  216.209 |              236.435 |               154.99 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5610000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_22-28-13\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 239.19833617594767\n",
      "  episode_reward_mean: 218.33554814709797\n",
      "  episode_reward_min: 154.98957982586435\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3740\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.453474746663519\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.028085922100631117\n",
      "          policy_loss: 0.018600428318010367\n",
      "          total_loss: 267.5290485041192\n",
      "          vf_explained_var: -1.8261848699907546e-09\n",
      "          vf_loss: 267.4997836693297\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5610000\n",
      "    num_steps_sampled: 5610000\n",
      "    num_steps_trained: 5610000\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.073947368421052\n",
      "    ram_util_percent: 52.47250000000001\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804613797699887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32931682055997\n",
      "    mean_inference_ms: 1.8265276024489732\n",
      "    mean_raw_obs_processing_ms: 2.0891399410979807\n",
      "  time_since_restore: 92263.22939038277\n",
      "  time_this_iter_s: 532.7496426105499\n",
      "  time_total_s: 92263.22939038277\n",
      "  timers:\n",
      "    learn_throughput: 94.737\n",
      "    learn_time_ms: 316667.45\n",
      "    sample_throughput: 140.611\n",
      "    sample_time_ms: 213354.114\n",
      "    update_time_ms: 2.964\n",
      "  timestamp: 1663039693\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5610000\n",
      "  training_iteration: 187\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 16.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    187 |          92263.2 | 5610000 |  218.336 |              239.198 |               154.99 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5640000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_22-37-06\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 245.65708479711702\n",
      "  episode_reward_mean: 222.00270592795852\n",
      "  episode_reward_min: 154.98957982586435\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3760\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.268966768244479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02967689962478671\n",
      "          policy_loss: 0.021039785314549475\n",
      "          total_loss: 261.84495645401324\n",
      "          vf_explained_var: -6.594556567485199e-10\n",
      "          vf_loss: 261.8126491205743\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5640000\n",
      "    num_steps_sampled: 5640000\n",
      "    num_steps_trained: 5640000\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.02010512483574\n",
      "    ram_util_percent: 52.506570302233904\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804577406949178\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329370404523562\n",
      "    mean_inference_ms: 1.8265026938569928\n",
      "    mean_raw_obs_processing_ms: 2.08427763323056\n",
      "  time_since_restore: 92796.78672623634\n",
      "  time_this_iter_s: 533.5573358535767\n",
      "  time_total_s: 92796.78672623634\n",
      "  timers:\n",
      "    learn_throughput: 94.616\n",
      "    learn_time_ms: 317069.764\n",
      "    sample_throughput: 140.607\n",
      "    sample_time_ms: 213359.913\n",
      "    update_time_ms: 2.975\n",
      "  timestamp: 1663040226\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5640000\n",
      "  training_iteration: 188\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    188 |          92796.8 | 5640000 |  222.003 |              245.657 |               154.99 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5670000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_22-46-01\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 245.65708479711702\n",
      "  episode_reward_mean: 224.99965849441506\n",
      "  episode_reward_min: 200.17584128041628\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3780\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.2033835767177825\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02938026356369643\n",
      "          policy_loss: 0.02362795071973604\n",
      "          total_loss: 258.9143659421231\n",
      "          vf_explained_var: -2.7900046162265824e-10\n",
      "          vf_loss: 258.87958268510533\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5670000\n",
      "    num_steps_sampled: 5670000\n",
      "    num_steps_trained: 5670000\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 16.015334207077323\n",
      "    ram_util_percent: 52.595543905635644\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804503203406694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329458606666545\n",
      "    mean_inference_ms: 1.8264706795093628\n",
      "    mean_raw_obs_processing_ms: 2.079466113138419\n",
      "  time_since_restore: 93331.5139696598\n",
      "  time_this_iter_s: 534.7272434234619\n",
      "  time_total_s: 93331.5139696598\n",
      "  timers:\n",
      "    learn_throughput: 94.417\n",
      "    learn_time_ms: 317740.154\n",
      "    sample_throughput: 140.615\n",
      "    sample_time_ms: 213347.932\n",
      "    update_time_ms: 2.973\n",
      "  timestamp: 1663040761\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5670000\n",
      "  training_iteration: 189\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    189 |          93331.5 | 5670000 |      225 |              245.657 |              200.176 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5700000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_22-54-59\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 245.65708479711702\n",
      "  episode_reward_mean: 225.8137482600105\n",
      "  episode_reward_min: 197.07946693000636\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3800\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.227742805988231\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02898563096604602\n",
      "          policy_loss: 0.02413669462196846\n",
      "          total_loss: 257.26481522418084\n",
      "          vf_explained_var: -5.580009232453165e-10\n",
      "          vf_loss: 257.2296730220064\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5700000\n",
      "    num_steps_sampled: 5700000\n",
      "    num_steps_trained: 5700000\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.9619295958279\n",
      "    ram_util_percent: 52.98474576271187\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804418497541193\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329565258753302\n",
      "    mean_inference_ms: 1.82641501647533\n",
      "    mean_raw_obs_processing_ms: 2.0747100461394683\n",
      "  time_since_restore: 93868.83515644073\n",
      "  time_this_iter_s: 537.3211867809296\n",
      "  time_total_s: 93868.83515644073\n",
      "  timers:\n",
      "    learn_throughput: 94.185\n",
      "    learn_time_ms: 318523.584\n",
      "    sample_throughput: 140.63\n",
      "    sample_time_ms: 213325.319\n",
      "    update_time_ms: 2.966\n",
      "  timestamp: 1663041299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5700000\n",
      "  training_iteration: 190\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    190 |          93868.8 | 5700000 |  225.814 |              245.657 |              197.079 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5730000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_23-03-56\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 245.65708479711702\n",
      "  episode_reward_mean: 227.72876749246518\n",
      "  episode_reward_min: 197.07946693000636\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3820\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.293133376202685\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.032221925934644374\n",
      "          policy_loss: 0.024335964181400993\n",
      "          total_loss: 254.9841045817923\n",
      "          vf_explained_var: -2.3588220265935433e-09\n",
      "          vf_loss: 254.94753431604263\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5730000\n",
      "    num_steps_sampled: 5730000\n",
      "    num_steps_trained: 5730000\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.914993481095175\n",
      "    ram_util_percent: 53.03950456323338\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804345516953192\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329634917434397\n",
      "    mean_inference_ms: 1.8263646196443433\n",
      "    mean_raw_obs_processing_ms: 2.070000371381166\n",
      "  time_since_restore: 94406.26075696945\n",
      "  time_this_iter_s: 537.425600528717\n",
      "  time_total_s: 94406.26075696945\n",
      "  timers:\n",
      "    learn_throughput: 93.895\n",
      "    learn_time_ms: 319504.444\n",
      "    sample_throughput: 140.647\n",
      "    sample_time_ms: 213299.912\n",
      "    update_time_ms: 2.955\n",
      "  timestamp: 1663041836\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5730000\n",
      "  training_iteration: 191\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    191 |          94406.3 | 5730000 |  227.729 |              245.657 |              197.079 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5760000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_23-12-57\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 245.65708479711702\n",
      "  episode_reward_mean: 225.93805840164114\n",
      "  episode_reward_min: 197.07946693000636\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3840\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.34496216195695\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.030100834614193914\n",
      "          policy_loss: 0.021547343023715818\n",
      "          total_loss: 260.0705595592742\n",
      "          vf_explained_var: -8.116377014921738e-10\n",
      "          vf_loss: 260.03758311170213\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5760000\n",
      "    num_steps_sampled: 5760000\n",
      "    num_steps_trained: 5760000\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.963082901554404\n",
      "    ram_util_percent: 52.78756476683938\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804227532721796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329703980297936\n",
      "    mean_inference_ms: 1.8262916750220728\n",
      "    mean_raw_obs_processing_ms: 2.0653509978646385\n",
      "  time_since_restore: 94947.48959255219\n",
      "  time_this_iter_s: 541.2288355827332\n",
      "  time_total_s: 94947.48959255219\n",
      "  timers:\n",
      "    learn_throughput: 93.581\n",
      "    learn_time_ms: 320577.868\n",
      "    sample_throughput: 140.644\n",
      "    sample_time_ms: 213304.793\n",
      "    update_time_ms: 3.018\n",
      "  timestamp: 1663042377\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5760000\n",
      "  training_iteration: 192\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 16.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    192 |          94947.5 | 5760000 |  225.938 |              245.657 |              197.079 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5790000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_23-22-01\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 240.54251992836387\n",
      "  episode_reward_mean: 221.48313525637934\n",
      "  episode_reward_min: 197.07946693000636\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3860\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.259782592996638\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.03228251541580797\n",
      "          policy_loss: 0.022179855459785843\n",
      "          total_loss: 258.83828194800844\n",
      "          vf_explained_var: -2.4602768711190492e-09\n",
      "          vf_loss: 258.8038449161611\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5790000\n",
      "    num_steps_sampled: 5790000\n",
      "    num_steps_trained: 5790000\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.92860824742268\n",
      "    ram_util_percent: 52.85824742268042\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804152204016091\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32973092848082\n",
      "    mean_inference_ms: 1.8262428527815728\n",
      "    mean_raw_obs_processing_ms: 2.060748004806164\n",
      "  time_since_restore: 95491.41844248772\n",
      "  time_this_iter_s: 543.9288499355316\n",
      "  time_total_s: 95491.41844248772\n",
      "  timers:\n",
      "    learn_throughput: 93.148\n",
      "    learn_time_ms: 322067.948\n",
      "    sample_throughput: 140.632\n",
      "    sample_time_ms: 213322.273\n",
      "    update_time_ms: 3.006\n",
      "  timestamp: 1663042921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5790000\n",
      "  training_iteration: 193\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.1/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    193 |          95491.4 | 5790000 |  221.483 |              240.543 |              197.079 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5820000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_23-31-09\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 240.00398750811578\n",
      "  episode_reward_mean: 216.46255774500838\n",
      "  episode_reward_min: 191.22577586500697\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3880\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.280287111769331\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.029898705324356366\n",
      "          policy_loss: 0.022881363447720897\n",
      "          total_loss: 258.2944077804241\n",
      "          vf_explained_var: -2.713913538343604e-09\n",
      "          vf_loss: 258.2601745540538\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5820000\n",
      "    num_steps_sampled: 5820000\n",
      "    num_steps_trained: 5820000\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.894878361075547\n",
      "    ram_util_percent: 52.970166453265044\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804167844450575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329691739746366\n",
      "    mean_inference_ms: 1.8262402428166842\n",
      "    mean_raw_obs_processing_ms: 2.0562082674207516\n",
      "  time_since_restore: 96038.76196146011\n",
      "  time_this_iter_s: 547.3435189723969\n",
      "  time_total_s: 96038.76196146011\n",
      "  timers:\n",
      "    learn_throughput: 92.625\n",
      "    learn_time_ms: 323887.071\n",
      "    sample_throughput: 140.632\n",
      "    sample_time_ms: 213323.277\n",
      "    update_time_ms: 3.02\n",
      "  timestamp: 1663043469\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5820000\n",
      "  training_iteration: 194\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    194 |          96038.8 | 5820000 |  216.463 |              240.004 |              191.226 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5850000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_23-40-21\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 237.56350793727174\n",
      "  episode_reward_mean: 211.87594012429264\n",
      "  episode_reward_min: 183.88742194799522\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3900\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.244546425393287\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02827957565248521\n",
      "          policy_loss: 0.020920539295221578\n",
      "          total_loss: 258.91671294516703\n",
      "          vf_explained_var: -2.663186338125456e-09\n",
      "          vf_loss: 258.88505540563705\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5850000\n",
      "    num_steps_sampled: 5850000\n",
      "    num_steps_trained: 5850000\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.798350253807108\n",
      "    ram_util_percent: 53.01738578680202\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804261115442472\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32962272069183\n",
      "    mean_inference_ms: 1.8262745802457312\n",
      "    mean_raw_obs_processing_ms: 2.0517218594558546\n",
      "  time_since_restore: 96591.13040590286\n",
      "  time_this_iter_s: 552.368444442749\n",
      "  time_total_s: 96591.13040590286\n",
      "  timers:\n",
      "    learn_throughput: 92.033\n",
      "    learn_time_ms: 325968.867\n",
      "    sample_throughput: 140.62\n",
      "    sample_time_ms: 213340.648\n",
      "    update_time_ms: 3.012\n",
      "  timestamp: 1663044021\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5850000\n",
      "  training_iteration: 195\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    195 |          96591.1 | 5850000 |  211.876 |              237.564 |              183.887 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5880000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_23-49-40\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 233.58674611178256\n",
      "  episode_reward_mean: 205.25790537654402\n",
      "  episode_reward_min: 152.77965690431867\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3920\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.984553830674354\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0257291117667206\n",
      "          policy_loss: 0.020116821006336744\n",
      "          total_loss: 258.2525071294257\n",
      "          vf_explained_var: -1.0145471129874295e-09\n",
      "          vf_loss: 258.2226217651367\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5880000\n",
      "    num_steps_sampled: 5880000\n",
      "    num_steps_trained: 5880000\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.64667503136763\n",
      "    ram_util_percent: 53.10552070263488\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804363612840568\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329572318110504\n",
      "    mean_inference_ms: 1.8263028140664883\n",
      "    mean_raw_obs_processing_ms: 2.047276025410619\n",
      "  time_since_restore: 97149.42966508865\n",
      "  time_this_iter_s: 558.299259185791\n",
      "  time_total_s: 97149.42966508865\n",
      "  timers:\n",
      "    learn_throughput: 91.311\n",
      "    learn_time_ms: 328549.048\n",
      "    sample_throughput: 140.627\n",
      "    sample_time_ms: 213329.643\n",
      "    update_time_ms: 3.007\n",
      "  timestamp: 1663044580\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5880000\n",
      "  training_iteration: 196\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    196 |          97149.4 | 5880000 |  205.258 |              233.587 |               152.78 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5910000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-12_23-59-00\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 233.58674611178256\n",
      "  episode_reward_mean: 200.72637570835602\n",
      "  episode_reward_min: 152.77965690431867\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3940\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -4.024901150033829\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0270056452412912\n",
      "          policy_loss: 0.023172442558360228\n",
      "          total_loss: 253.05328548025577\n",
      "          vf_explained_var: -8.370014126235503e-10\n",
      "          vf_loss: 253.01985955745616\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5910000\n",
      "    num_steps_sampled: 5910000\n",
      "    num_steps_trained: 5910000\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.6991239048811\n",
      "    ram_util_percent: 53.19887359198997\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804485428220474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329504938340495\n",
      "    mean_inference_ms: 1.8263674384122683\n",
      "    mean_raw_obs_processing_ms: 2.0428904274892257\n",
      "  time_since_restore: 97709.82123827934\n",
      "  time_this_iter_s: 560.3915731906891\n",
      "  time_total_s: 97709.82123827934\n",
      "  timers:\n",
      "    learn_throughput: 90.554\n",
      "    learn_time_ms: 331295.843\n",
      "    sample_throughput: 140.616\n",
      "    sample_time_ms: 213347.057\n",
      "    update_time_ms: 3.013\n",
      "  timestamp: 1663045140\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5910000\n",
      "  training_iteration: 197\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 16.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    197 |          97709.8 | 5910000 |  200.726 |              233.587 |               152.78 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5940000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-13_00-08-25\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 227.97421070394014\n",
      "  episode_reward_mean: 189.0709257903024\n",
      "  episode_reward_min: 135.81708383308722\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3960\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.6866765765940888\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021672780388846426\n",
      "          policy_loss: 0.019303422139838655\n",
      "          total_loss: 261.1559328184737\n",
      "          vf_explained_var: -5.580009232453165e-10\n",
      "          vf_loss: 261.1284004536081\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5940000\n",
      "    num_steps_sampled: 5940000\n",
      "    num_steps_trained: 5940000\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.586972704714638\n",
      "    ram_util_percent: 53.29354838709677\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804582681726415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.3294550981826\n",
      "    mean_inference_ms: 1.8264211272038606\n",
      "    mean_raw_obs_processing_ms: 2.0385496342018907\n",
      "  time_since_restore: 98274.72311639786\n",
      "  time_this_iter_s: 564.901878118515\n",
      "  time_total_s: 98274.72311639786\n",
      "  timers:\n",
      "    learn_throughput: 89.707\n",
      "    learn_time_ms: 334423.036\n",
      "    sample_throughput: 140.611\n",
      "    sample_time_ms: 213354.21\n",
      "    update_time_ms: 3.013\n",
      "  timestamp: 1663045705\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5940000\n",
      "  training_iteration: 198\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.2/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    198 |          98274.7 | 5940000 |  189.071 |              227.974 |              135.817 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 5970000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-13_00-17-50\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 227.97421070394014\n",
      "  episode_reward_mean: 180.68238636657304\n",
      "  episode_reward_min: 135.81708383308722\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3980\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.7482957933304157\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.026571889137366373\n",
      "          policy_loss: 0.02445269749797088\n",
      "          total_loss: 254.8248849471072\n",
      "          vf_explained_var: -8.623650682437756e-10\n",
      "          vf_loss: 254.79034309062553\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5970000\n",
      "    num_steps_sampled: 5970000\n",
      "    num_steps_trained: 5970000\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.50620347394541\n",
      "    ram_util_percent: 53.6514888337469\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804600441959039\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.329460364948737\n",
      "    mean_inference_ms: 1.826441967579392\n",
      "    mean_raw_obs_processing_ms: 2.0342377683576234\n",
      "  time_since_restore: 98839.61542057991\n",
      "  time_this_iter_s: 564.8923041820526\n",
      "  time_total_s: 98839.61542057991\n",
      "  timers:\n",
      "    learn_throughput: 88.9\n",
      "    learn_time_ms: 337459.464\n",
      "    sample_throughput: 140.624\n",
      "    sample_time_ms: 213334.385\n",
      "    update_time_ms: 3.017\n",
      "  timestamp: 1663046270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5970000\n",
      "  training_iteration: 199\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    199 |          98839.6 | 5970000 |  180.682 |              227.974 |              135.817 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0950227-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0637333-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2394)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.0694892-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2397)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.063827-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220911-2050151662947415.1154096-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_3cbeb_00000:\n",
      "  agent_timesteps_total: 6000000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-13_00-27-16\n",
      "  done: true\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 213.75196893741642\n",
      "  episode_reward_mean: 175.7159948765555\n",
      "  episode_reward_min: 135.81708383308722\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4000\n",
      "  experiment_id: dbc9aa853ada45498a51b62906adf9c7\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.3796875000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -3.8834643844847982\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02844380441270382\n",
      "          policy_loss: 0.02480582501085356\n",
      "          total_loss: 247.53755872685858\n",
      "          vf_explained_var: -1.268183891234287e-10\n",
      "          vf_loss: 247.5019525308812\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 6000000\n",
      "    num_steps_sampled: 6000000\n",
      "    num_steps_trained: 6000000\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 15.587376237623763\n",
      "    ram_util_percent: 53.74121287128714\n",
      "  pid: 2392\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08804582265786273\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32947827261855\n",
      "    mean_inference_ms: 1.8264597596357217\n",
      "    mean_raw_obs_processing_ms: 2.0299759412747993\n",
      "  time_since_restore: 99405.43984699249\n",
      "  time_this_iter_s: 565.8244264125824\n",
      "  time_total_s: 99405.43984699249\n",
      "  timers:\n",
      "    learn_throughput: 88.158\n",
      "    learn_time_ms: 340299.497\n",
      "    sample_throughput: 140.618\n",
      "    sample_time_ms: 213344.684\n",
      "    update_time_ms: 3.022\n",
      "  timestamp: 1663046836\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6000000\n",
      "  training_iteration: 200\n",
      "  trial_id: 3cbeb_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 16.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | RUNNING  | 192.168.1.76:2392 |    200 |          99405.4 | 6000000 |  175.716 |              213.752 |              135.817 |               1500 |\n",
      "+-----------------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 16.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/7.49 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_0_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_3_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/6.0 CPU_group_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_2_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 CPU_group_5_4d46f3dd1ee711d79c878dde0e8cacd9, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_4d46f3dd1ee711d79c878dde0e8cacd9)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+-----------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_3cbeb_00000 | TERMINATED |       |    200 |          99405.4 | 6000000 |  175.716 |              213.752 |              135.817 |               1500 |\n",
      "+-----------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m 2022-09-13 00:27:17,404\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1027, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1103, in exit_actor\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 167, in format_exc\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 121, in format_exception\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     type(value), value, tb, limit=limit).format(chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 508, in __init__\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     capture_locals=capture_locals)\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 363, in extract\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     f.line\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 285, in line\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/linecache.py\", line 16, in getline\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     lines = getlines(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/linecache.py\", line 47, in getlines\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     return updatecache(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/linecache.py\", line 137, in updatecache\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     lines = fp.readlines()\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/codecs.py\", line 319, in decode\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     def decode(self, input, final=False):\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=2395)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m 2022-09-13 00:27:17,402\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1027, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1103, in exit_actor\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 167, in format_exc\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 121, in format_exception\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m     type(value), value, tb, limit=limit).format(chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 508, in __init__\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m     capture_locals=capture_locals)\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 358, in extract\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m     for filename in fnames:\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=2393)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m 2022-09-13 00:27:17,402\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1027, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/actor.py\", line 1103, in exit_actor\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 167, in format_exc\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 121, in format_exception\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m     type(value), value, tb, limit=limit).format(chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 508, in __init__\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m     capture_locals=capture_locals)\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/traceback.py\", line 359, in extract\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m     linecache.checkcache(filename)\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/linecache.py\", line 67, in checkcache\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m     if len(entry) == 1:\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m   File \"/home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=2396)\u001b[0m SystemExit: 1\n",
      "2022-09-13 00:27:17,509\tINFO tune.py:550 -- Total run time: 99426.35 seconds (99425.72 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python examples/train.py singleagent_figure_eight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
