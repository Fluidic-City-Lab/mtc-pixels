{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efa5b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "{'num_workers': 5, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'gamma': 0.999, 'lr': 5e-05, 'train_batch_size': 30000, 'model': {'_use_default_native_models': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': [[16, [8, 8], 4], [32, [4, 4], 2], [256, [11, 11], 1]], 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'horizon': 1500, 'soft_horizon': False, 'no_done_at_end': False, 'env': None, 'observation_space': None, 'action_space': None, 'env_config': {}, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'simple_optimizer': -1, 'monitor': -1, 'use_critic': True, 'use_gae': True, 'lambda': 0.97, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.02, 'vf_share_layers': -1}\n",
      "2022-09-30 11:11:26,822\tINFO services.py:1247 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "== Status ==\n",
      "Memory usage on this node: 7.3/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "+-----------------------------+----------+-------+\n",
      "| Trial name                  | status   | loc   |\n",
      "|-----------------------------+----------+-------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | PENDING  |       |\n",
      "+-----------------------------+----------+-------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m or from the matplotlib source distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:11:29,394\tINFO trainer.py:720 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m Bad key text.latex.preview in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 123 ('text.latex.preview : False')\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m Bad key mathtext.fallback_to_cm in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 155 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m Bad key savefig.jpeg_quality in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 418 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m Bad key keymap.all_axes in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 466 ('keymap.all_axes : a                 # enable all axes')\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m Bad key animation.avconv_path in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 477 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m or from the matplotlib source distribution\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m Bad key animation.avconv_args in file /home/michael/anaconda3/envs/flow/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 479 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m You probably need to get an updated matplotlibrc file from\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m https://github.com/matplotlib/matplotlib/blob/v3.5.1/matplotlibrc.template\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m or from the matplotlib source distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:11:32,778\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_11-16-40\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -6955.535827928273\n",
      "  episode_reward_mean: -7781.114802528032\n",
      "  episode_reward_min: -8220.84716882073\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 20\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3547519043151368\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005533137521520752\n",
      "          policy_loss: -0.0036410652380436657\n",
      "          total_loss: 19095.33430310838\n",
      "          vf_explained_var: -1.038115078699775e-05\n",
      "          vf_loss: 19095.336842586436\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.31409090909091\n",
      "    ram_util_percent: 32.85704545454546\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08785555788207663\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.51384646684761\n",
      "    mean_inference_ms: 1.8301998927302812\n",
      "    mean_raw_obs_processing_ms: 1.1635861542200647\n",
      "  time_since_restore: 307.949506521225\n",
      "  time_this_iter_s: 307.949506521225\n",
      "  time_total_s: 307.949506521225\n",
      "  timers:\n",
      "    learn_throughput: 302.472\n",
      "    learn_time_ms: 99182.866\n",
      "    sample_throughput: 143.715\n",
      "    sample_time_ms: 208746.624\n",
      "    update_time_ms: 3.026\n",
      "  timestamp: 1664554600\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 1\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 11.0/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |      1 |           307.95 | 30000 | -7781.11 |             -6955.54 |             -8220.85 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:16:40,756\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 778.0x the scale of `vf_clip_param`. This means that it will take more than 778.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_11-21-46\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -6647.992866471619\n",
      "  episode_reward_mean: -7458.076074542047\n",
      "  episode_reward_min: -8220.84716882073\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 40\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.229755480543096\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009357214708390694\n",
      "          policy_loss: -0.0049489945552727965\n",
      "          total_loss: 15660.722585605054\n",
      "          vf_explained_var: -1.3163749201794417e-08\n",
      "          vf_loss: 15660.726599900267\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.465903890160185\n",
      "    ram_util_percent: 39.37322654462243\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0879588986869748\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.454783392946922\n",
      "    mean_inference_ms: 1.8374177039505881\n",
      "    mean_raw_obs_processing_ms: 1.1645812605843924\n",
      "  time_since_restore: 613.9552953243256\n",
      "  time_this_iter_s: 306.0057888031006\n",
      "  time_total_s: 613.9552953243256\n",
      "  timers:\n",
      "    learn_throughput: 303.427\n",
      "    learn_time_ms: 98870.511\n",
      "    sample_throughput: 144.169\n",
      "    sample_time_ms: 208088.74\n",
      "    update_time_ms: 3.165\n",
      "  timestamp: 1664554906\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 2\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:21:46,825\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 746.0x the scale of `vf_clip_param`. This means that it will take more than 746.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |      2 |          613.955 | 60000 | -7458.08 |             -6647.99 |             -8220.85 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 90000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_11-26-55\n",
      "  done: false\n",
      "  episode_len_mean: 1482.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1951.921267889942\n",
      "  episode_reward_mean: -7195.570559947469\n",
      "  episode_reward_min: -8220.84716882073\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 60\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1230867988505262\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013265782981873482\n",
      "          policy_loss: -0.006633339469380518\n",
      "          total_loss: 14389.88693941157\n",
      "          vf_explained_var: -9.02946961645057e-09\n",
      "          vf_loss: 14389.892918051863\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.225\n",
      "    ram_util_percent: 39.49795454545454\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08799961912543305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.424941006989222\n",
      "    mean_inference_ms: 1.8396393196221097\n",
      "    mean_raw_obs_processing_ms: 1.1649672912675366\n",
      "  time_since_restore: 922.8502457141876\n",
      "  time_this_iter_s: 308.89495038986206\n",
      "  time_total_s: 922.8502457141876\n",
      "  timers:\n",
      "    learn_throughput: 303.622\n",
      "    learn_time_ms: 98806.993\n",
      "    sample_throughput: 143.684\n",
      "    sample_time_ms: 208791.663\n",
      "    update_time_ms: 3.21\n",
      "  timestamp: 1664555215\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 3\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:26:55,765\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 720.0x the scale of `vf_clip_param`. This means that it will take more than 720.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |      3 |           922.85 | 90000 | -7195.57 |             -1951.92 |             -8220.85 |             1482.3 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 120000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_11-32-08\n",
      "  done: false\n",
      "  episode_len_mean: 1486.725\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1951.921267889942\n",
      "  episode_reward_mean: -6944.0688856034885\n",
      "  episode_reward_min: -8220.84716882073\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 80\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0048644939635663\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01412147619148047\n",
      "          policy_loss: -0.0065383878082750325\n",
      "          total_loss: 11358.942086103723\n",
      "          vf_explained_var: -6.683544779662043e-05\n",
      "          vf_loss: 11358.947903091756\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.189910313901347\n",
      "    ram_util_percent: 39.5340807174888\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08806291164136301\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.40538184568235\n",
      "    mean_inference_ms: 1.8419319570622015\n",
      "    mean_raw_obs_processing_ms: 1.166999413304594\n",
      "  time_since_restore: 1235.1411726474762\n",
      "  time_this_iter_s: 312.2909269332886\n",
      "  time_total_s: 1235.1411726474762\n",
      "  timers:\n",
      "    learn_throughput: 303.59\n",
      "    learn_time_ms: 98817.458\n",
      "    sample_throughput: 142.891\n",
      "    sample_time_ms: 209949.912\n",
      "    update_time_ms: 3.202\n",
      "  timestamp: 1664555528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 4\n",
      "  trial_id: 89ae8_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |      4 |          1235.14 | 120000 | -6944.07 |             -1951.92 |             -8220.85 |            1486.72 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:32:08,103\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 694.0x the scale of `vf_clip_param`. This means that it will take more than 694.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 150000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_11-37-20\n",
      "  done: false\n",
      "  episode_len_mean: 1489.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1951.921267889942\n",
      "  episode_reward_mean: -6731.455773632899\n",
      "  episode_reward_min: -8220.84716882073\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 100\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.901924547819381\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014700914873403545\n",
      "          policy_loss: -0.007458480338348036\n",
      "          total_loss: 9979.987002992022\n",
      "          vf_explained_var: -3.359155380167067e-05\n",
      "          vf_loss: 9979.993726313165\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 150000\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.054831460674155\n",
      "    ram_util_percent: 39.56337078651686\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0880981448560798\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.392538942402602\n",
      "    mean_inference_ms: 1.8424623319033253\n",
      "    mean_raw_obs_processing_ms: 1.1683830987584416\n",
      "  time_since_restore: 1546.9932708740234\n",
      "  time_this_iter_s: 311.85209822654724\n",
      "  time_total_s: 1546.9932708740234\n",
      "  timers:\n",
      "    learn_throughput: 303.767\n",
      "    learn_time_ms: 98759.854\n",
      "    sample_throughput: 142.436\n",
      "    sample_time_ms: 210620.959\n",
      "    update_time_ms: 3.246\n",
      "  timestamp: 1664555840\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 5\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:37:20,002\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 673.0x the scale of `vf_clip_param`. This means that it will take more than 673.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |      5 |          1546.99 | 150000 | -6731.46 |             -1951.92 |             -8220.85 |            1489.38 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_11-42-31\n",
      "  done: false\n",
      "  episode_len_mean: 1489.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1951.921267889942\n",
      "  episode_reward_mean: -6207.688002767561\n",
      "  episode_reward_min: -7631.737226651055\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 120\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.7736724839819239\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014178987979631784\n",
      "          policy_loss: -0.0067825307826848424\n",
      "          total_loss: 7450.184375207779\n",
      "          vf_explained_var: -0.0001244963932549581\n",
      "          vf_loss: 7450.190441946476\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.126576576576575\n",
      "    ram_util_percent: 39.5472972972973\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08818678571236667\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.357049521682065\n",
      "    mean_inference_ms: 1.8450722716629642\n",
      "    mean_raw_obs_processing_ms: 1.17010945691511\n",
      "  time_since_restore: 1858.4467284679413\n",
      "  time_this_iter_s: 311.45345759391785\n",
      "  time_total_s: 1858.4467284679413\n",
      "  timers:\n",
      "    learn_throughput: 304.031\n",
      "    learn_time_ms: 98674.141\n",
      "    sample_throughput: 142.147\n",
      "    sample_time_ms: 211049.456\n",
      "    update_time_ms: 3.23\n",
      "  timestamp: 1664556151\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 6\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |      6 |          1858.45 | 180000 | -6207.69 |             -1951.92 |             -7631.74 |            1489.38 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:42:31,500\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 621.0x the scale of `vf_clip_param`. This means that it will take more than 621.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 210000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_11-47-43\n",
      "  done: false\n",
      "  episode_len_mean: 1489.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1951.921267889942\n",
      "  episode_reward_mean: -5672.934205035472\n",
      "  episode_reward_min: -7314.579001994731\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 140\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.6555151183808103\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01911974119329395\n",
      "          policy_loss: -0.009309717704086227\n",
      "          total_loss: 5425.114028839761\n",
      "          vf_explained_var: -2.7900046162265824e-10\n",
      "          vf_loss: 5425.122395279255\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 210000\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.145842696629217\n",
      "    ram_util_percent: 39.585617977528095\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08823998142040711\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.34383451620144\n",
      "    mean_inference_ms: 1.845172890542156\n",
      "    mean_raw_obs_processing_ms: 1.1720976439315764\n",
      "  time_since_restore: 2170.361969947815\n",
      "  time_this_iter_s: 311.91524147987366\n",
      "  time_total_s: 2170.361969947815\n",
      "  timers:\n",
      "    learn_throughput: 304.128\n",
      "    learn_time_ms: 98642.795\n",
      "    sample_throughput: 141.917\n",
      "    sample_time_ms: 211391.367\n",
      "    update_time_ms: 3.293\n",
      "  timestamp: 1664556463\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 7\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |      7 |          2170.36 | 210000 | -5672.93 |             -1951.92 |             -7314.58 |            1489.38 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:47:43,471\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 567.0x the scale of `vf_clip_param`. This means that it will take more than 567.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 240000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_11-52-55\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -3129.3261627612633\n",
      "  episode_reward_mean: -5106.76787336394\n",
      "  episode_reward_min: -6586.2630332517065\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 160\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.4749382290053875\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02376070858958593\n",
      "          policy_loss: -0.010182233221155215\n",
      "          total_loss: 3860.5647072390293\n",
      "          vf_explained_var: -1.2174565799938364e-09\n",
      "          vf_loss: 3860.573702834109\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 240000\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.113932584269662\n",
      "    ram_util_percent: 39.519775280898884\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08828935939398942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.336337739009632\n",
      "    mean_inference_ms: 1.845546763620992\n",
      "    mean_raw_obs_processing_ms: 1.1741025382110524\n",
      "  time_since_restore: 2482.1701924800873\n",
      "  time_this_iter_s: 311.80822253227234\n",
      "  time_total_s: 2482.1701924800873\n",
      "  timers:\n",
      "    learn_throughput: 304.203\n",
      "    learn_time_ms: 98618.253\n",
      "    sample_throughput: 141.753\n",
      "    sample_time_ms: 211635.511\n",
      "    update_time_ms: 3.293\n",
      "  timestamp: 1664556775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 8\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |      8 |          2482.17 | 240000 | -5106.77 |             -3129.33 |             -6586.26 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:52:55,325\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 511.0x the scale of `vf_clip_param`. This means that it will take more than 511.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 270000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_11-58-08\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2744.380475493265\n",
      "  episode_reward_mean: -4505.516305802332\n",
      "  episode_reward_min: -6195.162924513693\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 180\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.32287268508621986\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02283977114607548\n",
      "          policy_loss: -0.008030162251831844\n",
      "          total_loss: 2518.705419921875\n",
      "          vf_explained_var: -9.891835128783555e-10\n",
      "          vf_loss: 2518.7123090508644\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 270000\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.084304932735424\n",
      "    ram_util_percent: 39.556278026905844\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08831296610381834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.33212942442671\n",
      "    mean_inference_ms: 1.8450694173940565\n",
      "    mean_raw_obs_processing_ms: 1.174460768031671\n",
      "  time_since_restore: 2794.832511663437\n",
      "  time_this_iter_s: 312.6623191833496\n",
      "  time_total_s: 2794.832511663437\n",
      "  timers:\n",
      "    learn_throughput: 303.926\n",
      "    learn_time_ms: 98708.266\n",
      "    sample_throughput: 141.635\n",
      "    sample_time_ms: 211811.319\n",
      "    update_time_ms: 3.267\n",
      "  timestamp: 1664557088\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 9\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |      9 |          2794.83 | 270000 | -4505.52 |             -2744.38 |             -6195.16 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 11:58:08,034\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 451.0x the scale of `vf_clip_param`. This means that it will take more than 451.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-03-19\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2477.755934939958\n",
      "  episode_reward_mean: -3935.4969120459027\n",
      "  episode_reward_min: -5539.119713035528\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 200\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.19395326481537617\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016678727768200615\n",
      "          policy_loss: -0.005850356393790943\n",
      "          total_loss: 2356.9816527281414\n",
      "          vf_explained_var: -5.580009232453165e-10\n",
      "          vf_loss: 2356.9866722593915\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.10630630630631\n",
      "    ram_util_percent: 40.01216216216216\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08834513228835718\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.328372268671938\n",
      "    mean_inference_ms: 1.8456921764860197\n",
      "    mean_raw_obs_processing_ms: 1.174747336640364\n",
      "  time_since_restore: 3106.1396341323853\n",
      "  time_this_iter_s: 311.30712246894836\n",
      "  time_total_s: 3106.1396341323853\n",
      "  timers:\n",
      "    learn_throughput: 304.099\n",
      "    learn_time_ms: 98652.052\n",
      "    sample_throughput: 141.546\n",
      "    sample_time_ms: 211944.662\n",
      "    update_time_ms: 3.252\n",
      "  timestamp: 1664557399\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 10\n",
      "  trial_id: 89ae8_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     10 |          3106.14 | 300000 |  -3935.5 |             -2477.76 |             -5539.12 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 12:03:19,385\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 394.0x the scale of `vf_clip_param`. This means that it will take more than 394.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 330000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-08-30\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2296.8163349600554\n",
      "  episode_reward_mean: -3407.3259850279996\n",
      "  episode_reward_min: -4995.116224086208\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 220\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.028476404360634214\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016579355262588743\n",
      "          policy_loss: -0.004642639872122635\n",
      "          total_loss: 1528.536270674036\n",
      "          vf_explained_var: -2.5363678171630433e-11\n",
      "          vf_loss: 1528.5400805144614\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 330000\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.10810810810811\n",
      "    ram_util_percent: 40.07342342342343\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08836929315985277\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.325039235784388\n",
      "    mean_inference_ms: 1.8465462646956945\n",
      "    mean_raw_obs_processing_ms: 1.1755204202399712\n",
      "  time_since_restore: 3417.3744065761566\n",
      "  time_this_iter_s: 311.23477244377136\n",
      "  time_total_s: 3417.3744065761566\n",
      "  timers:\n",
      "    learn_throughput: 304.423\n",
      "    learn_time_ms: 98547.133\n",
      "    sample_throughput: 141.257\n",
      "    sample_time_ms: 212378.406\n",
      "    update_time_ms: 3.255\n",
      "  timestamp: 1664557710\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 11\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     11 |          3417.37 | 330000 | -3407.33 |             -2296.82 |             -4995.12 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 12:08:30,665\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 341.0x the scale of `vf_clip_param`. This means that it will take more than 341.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 360000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-13-42\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1852.3487756804705\n",
      "  episode_reward_mean: -2932.2110634682263\n",
      "  episode_reward_min: -4304.571930645629\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 240\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.19243692928330694\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019105855893627618\n",
      "          policy_loss: -0.004596467701856919\n",
      "          total_loss: 1088.8218866875832\n",
      "          vf_explained_var: -0.0001507287088315934\n",
      "          vf_loss: 1088.8255291877908\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 360000\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.09035874439462\n",
      "    ram_util_percent: 39.56008968609867\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08839714380747805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.323197387534666\n",
      "    mean_inference_ms: 1.8471575059976018\n",
      "    mean_raw_obs_processing_ms: 1.1759886807669753\n",
      "  time_since_restore: 3729.596413373947\n",
      "  time_this_iter_s: 312.2220067977905\n",
      "  time_total_s: 3729.596413373947\n",
      "  timers:\n",
      "    learn_throughput: 304.424\n",
      "    learn_time_ms: 98546.653\n",
      "    sample_throughput: 140.845\n",
      "    sample_time_ms: 213000.554\n",
      "    update_time_ms: 3.263\n",
      "  timestamp: 1664558022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 12\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 12:13:42,929\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 293.0x the scale of `vf_clip_param`. This means that it will take more than 293.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     12 |           3729.6 | 360000 | -2932.21 |             -1852.35 |             -4304.57 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 390000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-18-55\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1211.8341697308356\n",
      "  episode_reward_mean: -2541.337607724246\n",
      "  episode_reward_min: -4163.807624808251\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 260\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.1806744798542337\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015458724702522044\n",
      "          policy_loss: -0.003724471519384137\n",
      "          total_loss: 934.5416610652842\n",
      "          vf_explained_var: -8.116377014921738e-10\n",
      "          vf_loss: 934.5446131669714\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 390000\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.047191011235956\n",
      "    ram_util_percent: 39.59258426966292\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0884208101526964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32151782827541\n",
      "    mean_inference_ms: 1.8476146265602282\n",
      "    mean_raw_obs_processing_ms: 1.1766326932355076\n",
      "  time_since_restore: 4041.9003417491913\n",
      "  time_this_iter_s: 312.30392837524414\n",
      "  time_total_s: 4041.9003417491913\n",
      "  timers:\n",
      "    learn_throughput: 304.374\n",
      "    learn_time_ms: 98562.925\n",
      "    sample_throughput: 140.63\n",
      "    sample_time_ms: 213325.317\n",
      "    update_time_ms: 3.235\n",
      "  timestamp: 1664558335\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 13\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     13 |           4041.9 | 390000 | -2541.34 |             -1211.83 |             -4163.81 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 12:18:55,281\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 254.0x the scale of `vf_clip_param`. This means that it will take more than 254.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 420000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-24-08\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1127.0163568389307\n",
      "  episode_reward_mean: -2149.2820844378894\n",
      "  episode_reward_min: -3331.2285445400335\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 280\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.6587941740675175\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011167029577827265\n",
      "          policy_loss: -0.002021767250856662\n",
      "          total_loss: 420.9915316837392\n",
      "          vf_explained_var: -5.377099654424455e-09\n",
      "          vf_loss: 420.9929946379966\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 420000\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.035346756152123\n",
      "    ram_util_percent: 39.5917225950783\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08844076211086513\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.320181617414313\n",
      "    mean_inference_ms: 1.8481045930272797\n",
      "    mean_raw_obs_processing_ms: 1.1774467229594974\n",
      "  time_since_restore: 4354.571543455124\n",
      "  time_this_iter_s: 312.6712017059326\n",
      "  time_total_s: 4354.571543455124\n",
      "  timers:\n",
      "    learn_throughput: 304.27\n",
      "    learn_time_ms: 98596.496\n",
      "    sample_throughput: 140.627\n",
      "    sample_time_ms: 213329.777\n",
      "    update_time_ms: 3.286\n",
      "  timestamp: 1664558648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 14\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     14 |          4354.57 | 420000 | -2149.28 |             -1127.02 |             -3331.23 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18802)\u001b[0m 2022-09-30 12:24:08,002\tWARNING ppo.py:242 -- The magnitude of your environment rewards are more than 215.0x the scale of `vf_clip_param`. This means that it will take more than 215.0 iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 450000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-29-19\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1019.8931527064137\n",
      "  episode_reward_mean: -1755.3698139955864\n",
      "  episode_reward_min: -2965.353146388706\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 300\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.049999999999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.7237370681001785\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007807754238300702\n",
      "          policy_loss: -0.0005119814769305448\n",
      "          total_loss: 384.00073116221324\n",
      "          vf_explained_var: -3.018277849875517e-09\n",
      "          vf_loss: 384.0008530961706\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 450000\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.16711711711712\n",
      "    ram_util_percent: 39.60495495495495\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08846353946180457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.319209576591696\n",
      "    mean_inference_ms: 1.8485364419486556\n",
      "    mean_raw_obs_processing_ms: 1.178114575564232\n",
      "  time_since_restore: 4666.045343399048\n",
      "  time_this_iter_s: 311.47379994392395\n",
      "  time_total_s: 4666.045343399048\n",
      "  timers:\n",
      "    learn_throughput: 304.378\n",
      "    learn_time_ms: 98561.575\n",
      "    sample_throughput: 140.629\n",
      "    sample_time_ms: 213326.848\n",
      "    update_time_ms: 3.253\n",
      "  timestamp: 1664558959\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 15\n",
      "  trial_id: 89ae8_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     15 |          4666.05 | 450000 | -1755.37 |             -1019.89 |             -2965.35 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 480000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-34-31\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -1019.8931527064137\n",
      "  episode_reward_mean: -1490.9460545709237\n",
      "  episode_reward_min: -2367.0801382069926\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 320\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.608633591152252\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013395278390392954\n",
      "          policy_loss: -0.00201267066411674\n",
      "          total_loss: 513.7535467853952\n",
      "          vf_explained_var: -2.5363677824685738e-09\n",
      "          vf_loss: 513.7552233042616\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 480000\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.041479820627803\n",
      "    ram_util_percent: 39.857847533632274\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08848499728486221\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.31853045158692\n",
      "    mean_inference_ms: 1.8490393698337706\n",
      "    mean_raw_obs_processing_ms: 1.1786903560909772\n",
      "  time_since_restore: 4978.414261341095\n",
      "  time_this_iter_s: 312.3689179420471\n",
      "  time_total_s: 4978.414261341095\n",
      "  timers:\n",
      "    learn_throughput: 304.16\n",
      "    learn_time_ms: 98632.251\n",
      "    sample_throughput: 140.616\n",
      "    sample_time_ms: 213347.618\n",
      "    update_time_ms: 3.246\n",
      "  timestamp: 1664559271\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 16\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     16 |          4978.41 | 480000 | -1490.95 |             -1019.89 |             -2367.08 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 510000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-39-44\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -55.248089313385876\n",
      "  episode_reward_mean: -1201.927090438076\n",
      "  episode_reward_min: -2092.2548945201497\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 340\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.7411771930532253\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025361770101354795\n",
      "          policy_loss: -0.0026797692469776946\n",
      "          total_loss: 511.04454541145486\n",
      "          vf_explained_var: -0.0005536143435165286\n",
      "          vf_loss: 511.04659263448514\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 510000\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.05573033707865\n",
      "    ram_util_percent: 39.849213483146066\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08849465395674631\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.317661483458306\n",
      "    mean_inference_ms: 1.849318769689285\n",
      "    mean_raw_obs_processing_ms: 1.1788452045838391\n",
      "  time_since_restore: 5290.78067111969\n",
      "  time_this_iter_s: 312.36640977859497\n",
      "  time_total_s: 5290.78067111969\n",
      "  timers:\n",
      "    learn_throughput: 303.975\n",
      "    learn_time_ms: 98692.418\n",
      "    sample_throughput: 140.625\n",
      "    sample_time_ms: 213332.587\n",
      "    update_time_ms: 3.226\n",
      "  timestamp: 1664559584\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 17\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     17 |          5290.78 | 510000 | -1201.93 |             -55.2481 |             -2092.25 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 540000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-44-56\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 274.2362901765574\n",
      "  episode_reward_mean: -889.2041423460211\n",
      "  episode_reward_min: -2008.1914020948707\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 360\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -0.9321753305069944\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019901220336493924\n",
      "          policy_loss: -0.0002242063806253545\n",
      "          total_loss: 505.0464927640874\n",
      "          vf_explained_var: -3.728460651331034e-09\n",
      "          vf_loss: 505.0462188785634\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 540000\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.099327354260087\n",
      "    ram_util_percent: 39.7865470852018\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08850674088065352\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.317050389744708\n",
      "    mean_inference_ms: 1.8496213684595628\n",
      "    mean_raw_obs_processing_ms: 1.178732790330151\n",
      "  time_since_restore: 5603.316934347153\n",
      "  time_this_iter_s: 312.53626322746277\n",
      "  time_total_s: 5603.316934347153\n",
      "  timers:\n",
      "    learn_throughput: 303.766\n",
      "    learn_time_ms: 98760.146\n",
      "    sample_throughput: 140.622\n",
      "    sample_time_ms: 213337.792\n",
      "    update_time_ms: 3.207\n",
      "  timestamp: 1664559896\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 18\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     18 |          5603.32 | 540000 | -889.204 |              274.236 |             -2008.19 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 570000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-50-08\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 668.6884806706656\n",
      "  episode_reward_mean: -554.2446061344284\n",
      "  episode_reward_min: -1326.0824267152389\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 380\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.0538505363971629\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013989758181839005\n",
      "          policy_loss: 0.0004227795721368587\n",
      "          total_loss: 480.0261669142703\n",
      "          vf_explained_var: -4.337188830305649e-09\n",
      "          vf_loss: 480.0253939949198\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 570000\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.059775280898876\n",
      "    ram_util_percent: 39.5741573033708\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08850943935980378\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.31646327092637\n",
      "    mean_inference_ms: 1.8496618356511794\n",
      "    mean_raw_obs_processing_ms: 1.178530043235213\n",
      "  time_since_restore: 5914.901497125626\n",
      "  time_this_iter_s: 311.5845627784729\n",
      "  time_total_s: 5914.901497125626\n",
      "  timers:\n",
      "    learn_throughput: 304.071\n",
      "    learn_time_ms: 98661.099\n",
      "    sample_throughput: 140.628\n",
      "    sample_time_ms: 213329.047\n",
      "    update_time_ms: 3.208\n",
      "  timestamp: 1664560208\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 19\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.5/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     19 |           5914.9 | 570000 | -554.245 |              668.688 |             -1326.08 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 600000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_12-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 668.6884806706656\n",
      "  episode_reward_mean: -257.9409628641218\n",
      "  episode_reward_min: -1326.0824267152389\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 400\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.0919284566412581\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018228092993766917\n",
      "          policy_loss: -0.0007260007038712501\n",
      "          total_loss: 503.71525889944525\n",
      "          vf_explained_var: -2.1559127816317414e-09\n",
      "          vf_loss: 503.7155296358149\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 600000\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.11193693693694\n",
      "    ram_util_percent: 39.64752252252252\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08850511862249533\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.31620886373391\n",
      "    mean_inference_ms: 1.8495720295861744\n",
      "    mean_raw_obs_processing_ms: 1.1783443821397988\n",
      "  time_since_restore: 6226.572824239731\n",
      "  time_this_iter_s: 311.6713271141052\n",
      "  time_total_s: 6226.572824239731\n",
      "  timers:\n",
      "    learn_throughput: 304.025\n",
      "    learn_time_ms: 98676.04\n",
      "    sample_throughput: 140.614\n",
      "    sample_time_ms: 213350.506\n",
      "    update_time_ms: 3.209\n",
      "  timestamp: 1664560520\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 20\n",
      "  trial_id: 89ae8_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     20 |          6226.57 | 600000 | -257.941 |              668.688 |             -1326.08 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 630000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_13-00-32\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 691.0008144827162\n",
      "  episode_reward_mean: 78.79076475135524\n",
      "  episode_reward_min: -1170.7844057930868\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 420\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.2317339836790206\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.025585823252427486\n",
      "          policy_loss: -0.0011451540766482023\n",
      "          total_loss: 394.91404383882565\n",
      "          vf_explained_var: -3.0943687612250415e-09\n",
      "          vf_loss: 394.9145506254156\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 630000\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.03116591928251\n",
      "    ram_util_percent: 39.62242152466368\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08849309169610016\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.31602074231063\n",
      "    mean_inference_ms: 1.849435582373724\n",
      "    mean_raw_obs_processing_ms: 1.1781580962839977\n",
      "  time_since_restore: 6538.7078769207\n",
      "  time_this_iter_s: 312.13505268096924\n",
      "  time_total_s: 6538.7078769207\n",
      "  timers:\n",
      "    learn_throughput: 303.821\n",
      "    learn_time_ms: 98742.245\n",
      "    sample_throughput: 140.598\n",
      "    sample_time_ms: 213374.344\n",
      "    update_time_ms: 3.205\n",
      "  timestamp: 1664560832\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 21\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     21 |          6538.71 | 630000 |  78.7908 |              691.001 |             -1170.78 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 660000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_13-05-44\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 722.2607169006629\n",
      "  episode_reward_mean: 290.3506664150944\n",
      "  episode_reward_min: -783.846641679688\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 440\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.3242448854446411\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013676193919993572\n",
      "          policy_loss: 0.0010088607853159625\n",
      "          total_loss: 416.0263480328499\n",
      "          vf_explained_var: -0.0003546973457559943\n",
      "          vf_loss: 416.02499683136637\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 660000\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.28561797752809\n",
      "    ram_util_percent: 39.64741573033708\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08848721244281223\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.316028801677973\n",
      "    mean_inference_ms: 1.8495109382988795\n",
      "    mean_raw_obs_processing_ms: 1.1780208649053123\n",
      "  time_since_restore: 6850.972492218018\n",
      "  time_this_iter_s: 312.2646152973175\n",
      "  time_total_s: 6850.972492218018\n",
      "  timers:\n",
      "    learn_throughput: 303.748\n",
      "    learn_time_ms: 98765.954\n",
      "    sample_throughput: 140.611\n",
      "    sample_time_ms: 213354.846\n",
      "    update_time_ms: 3.177\n",
      "  timestamp: 1664561144\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 22\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     22 |          6850.97 | 660000 |  290.351 |              722.261 |             -783.847 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 690000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_13-10-56\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 722.2607169006629\n",
      "  episode_reward_mean: 418.3947124739008\n",
      "  episode_reward_min: -170.40283768772434\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 460\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.4494998487005843\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015795388817477593\n",
      "          policy_loss: 0.00149149922961171\n",
      "          total_loss: 335.88984047098364\n",
      "          vf_explained_var: -0.00031387541093863547\n",
      "          vf_loss: 335.88795434830035\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 690000\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.089213483146064\n",
      "    ram_util_percent: 39.66134831460675\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08848385815421675\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.31576811150602\n",
      "    mean_inference_ms: 1.8496989877337966\n",
      "    mean_raw_obs_processing_ms: 1.1780048034933421\n",
      "  time_since_restore: 7162.928069591522\n",
      "  time_this_iter_s: 311.95557737350464\n",
      "  time_total_s: 7162.928069591522\n",
      "  timers:\n",
      "    learn_throughput: 303.851\n",
      "    learn_time_ms: 98732.616\n",
      "    sample_throughput: 140.612\n",
      "    sample_time_ms: 213353.251\n",
      "    update_time_ms: 3.176\n",
      "  timestamp: 1664561456\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 23\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     23 |          7162.93 | 690000 |  418.395 |              722.261 |             -170.403 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 720000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_13-16-09\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 722.2607169006629\n",
      "  episode_reward_mean: 303.3868587850301\n",
      "  episode_reward_min: -357.62319441642444\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 480\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.8045093476011398\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010025178012066602\n",
      "          policy_loss: 0.002026373764222607\n",
      "          total_loss: 250.25648752740088\n",
      "          vf_explained_var: -4.537785207503475e-05\n",
      "          vf_loss: 250.25421012391436\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 720000\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.050672645739912\n",
      "    ram_util_percent: 39.69663677130045\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08848933509367207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.315479243729698\n",
      "    mean_inference_ms: 1.850166503308254\n",
      "    mean_raw_obs_processing_ms: 1.1781905467369125\n",
      "  time_since_restore: 7475.186723709106\n",
      "  time_this_iter_s: 312.25865411758423\n",
      "  time_total_s: 7475.186723709106\n",
      "  timers:\n",
      "    learn_throughput: 303.976\n",
      "    learn_time_ms: 98692.077\n",
      "    sample_throughput: 140.612\n",
      "    sample_time_ms: 213352.563\n",
      "    update_time_ms: 3.115\n",
      "  timestamp: 1664561769\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 24\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     24 |          7475.19 | 720000 |  303.387 |              722.261 |             -357.623 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 750000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_13-21-21\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 722.2607169006629\n",
      "  episode_reward_mean: 195.37873506278174\n",
      "  episode_reward_min: -357.62319441642444\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 500\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.4796148011532235\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013212658277083645\n",
      "          policy_loss: 0.000662580644018314\n",
      "          total_loss: 293.45391825249857\n",
      "          vf_explained_var: -1.3950023358688668e-09\n",
      "          vf_loss: 293.45292448977204\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 750000\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.043820224719102\n",
      "    ram_util_percent: 39.70224719101124\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08849824654561629\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.31500036895417\n",
      "    mean_inference_ms: 1.850561402474056\n",
      "    mean_raw_obs_processing_ms: 1.1784111287759986\n",
      "  time_since_restore: 7787.276702165604\n",
      "  time_this_iter_s: 312.0899784564972\n",
      "  time_total_s: 7787.276702165604\n",
      "  timers:\n",
      "    learn_throughput: 303.804\n",
      "    learn_time_ms: 98747.976\n",
      "    sample_throughput: 140.608\n",
      "    sample_time_ms: 213358.421\n",
      "    update_time_ms: 3.107\n",
      "  timestamp: 1664562081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 25\n",
      "  trial_id: 89ae8_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     25 |          7787.28 | 750000 |  195.379 |              722.261 |             -357.623 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 780000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_13-26-35\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 722.2607169006629\n",
      "  episode_reward_mean: 175.96113770946354\n",
      "  episode_reward_min: -357.62319441642444\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 520\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.6915237107682735\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01808669456481401\n",
      "          policy_loss: 0.0014753720569523408\n",
      "          total_loss: 279.9461507594332\n",
      "          vf_explained_var: -8.87728779375152e-10\n",
      "          vf_loss: 279.94422316530915\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 780000\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.943875278396433\n",
      "    ram_util_percent: 39.73028953229399\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.08851203950591895\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.314923317149695\n",
      "    mean_inference_ms: 1.8508122475992013\n",
      "    mean_raw_obs_processing_ms: 1.1784313789202983\n",
      "  time_since_restore: 8101.670458316803\n",
      "  time_this_iter_s: 314.39375615119934\n",
      "  time_total_s: 8101.670458316803\n",
      "  timers:\n",
      "    learn_throughput: 303.138\n",
      "    learn_time_ms: 98964.676\n",
      "    sample_throughput: 140.618\n",
      "    sample_time_ms: 213344.186\n",
      "    update_time_ms: 3.113\n",
      "  timestamp: 1664562395\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 26\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     26 |          8101.67 | 780000 |  175.961 |              722.261 |             -357.623 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "Result for PPO_AccelEnv-v0_89ae8_00000:\n",
      "  agent_timesteps_total: 810000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-09-30_13-31-50\n",
      "  done: false\n",
      "  episode_len_mean: 1500.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 563.8818877600565\n",
      "  episode_reward_mean: 50.272446945681274\n",
      "  episode_reward_min: -357.62319441642444\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 540\n",
      "  experiment_id: 96d4e2aa868f48cbb852dcd9a82cd15d\n",
      "  hostname: michael-home\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_kl_coeff: 0.024999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: -1.4776933062837478\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015926380874329057\n",
      "          policy_loss: 0.0007435327191698425\n",
      "          total_loss: 270.7291792914208\n",
      "          vf_explained_var: -8.87728779375152e-10\n",
      "          vf_loss: 270.7280378301093\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 810000\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.1.76\n",
      "  num_healthy_workers: 5\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 22.136830357142856\n",
      "    ram_util_percent: 39.761160714285715\n",
      "  pid: 18802\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0885242408090231\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.314652553881988\n",
      "    mean_inference_ms: 1.8509922138581738\n",
      "    mean_raw_obs_processing_ms: 1.1783727368950636\n",
      "  time_since_restore: 8416.183834791183\n",
      "  time_this_iter_s: 314.5133764743805\n",
      "  time_total_s: 8416.183834791183\n",
      "  timers:\n",
      "    learn_throughput: 302.457\n",
      "    learn_time_ms: 99187.63\n",
      "    sample_throughput: 140.623\n",
      "    sample_time_ms: 213335.972\n",
      "    update_time_ms: 3.078\n",
      "  timestamp: 1664562710\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 27\n",
      "  trial_id: 89ae8_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 12.6/31.3 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 6.0/6 CPUs, 0/6 GPUs, 0.0/8.06 GiB heap, 0.0/14.65 GiB objects (0.0/1.0 CPU_group_1_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_4_22556c35e92c241b7076d67bb9171997, 0.0/1.0 accelerator_type:G, 0.0/1.0 CPU_group_5_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_0_22556c35e92c241b7076d67bb9171997, 0.0/6.0 CPU_group_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_2_22556c35e92c241b7076d67bb9171997, 0.0/1.0 CPU_group_3_22556c35e92c241b7076d67bb9171997)\n",
      "Result logdir: /home/michael/ray_results/singleagent_figure_eight\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "| Trial name                  | status   | loc                |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "|-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
      "| PPO_AccelEnv-v0_89ae8_00000 | RUNNING  | 192.168.1.76:18802 |     27 |          8416.18 | 810000 |  50.2724 |              563.882 |             -357.623 |               1500 |\n",
      "+-----------------------------+----------+--------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18801)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4385743-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18800)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4640067-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18799)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4009597-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18804)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.4456818-0_emission.csv ./michael_files/emission_collection/\n",
      "\u001b[2m\u001b[36m(pid=18803)\u001b[0m ./michael_files/emission_collection/singleagent_figure_eight_20220930-1111311664554291.388778-0_emission.csv ./michael_files/emission_collection/\n"
     ]
    }
   ],
   "source": [
    "!python examples/train.py singleagent_figure_eight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
